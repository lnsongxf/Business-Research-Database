[{"ex:issue": "1", "ex:abstract": "No abstract available.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Management Insights", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1300", "ex:pages": "iv-vii", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": [], "ex:creator": [{"ex:name": "Michael F. Gorman", "ex:email": "michael.gorman@udayton.edu"}]}, {"ex:issue": "1", "ex:abstract": "A U.S. law mandating nonintrusive imaging and radiation detection for 100% of U.S.-bound containers at international ports has provoked widespread concern that the resulting congestion would hinder trade significantly. Using detailed data on container movements, gathered from two large international terminals, we simulate the impact of the two most important inspection policies that are being considered. We find that the current inspection regime being advanced by the U.S. Department of Homeland Security can only handle a small percentage of the total load. An alternate inspection protocol that emphasizes screening--a rapid primary scan of all containers, followed by a more careful secondary scan of only a few containers that fail the primary test--holds promise as a feasible solution for meeting the 100% scanning requirement. This paper was accepted by Yossi Aviv, operations management.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Estimating the Operational Impact of Container Inspections at International Ports", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1252", "ex:pages": "1-20", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["homeland security", "container inspections", "queueing simulation"], "ex:creator": [{"ex:name": "Nitin Bakshi", "ex:email": "nbakshi@london.edu"}, {"ex:name": "Stephen E. Flynn", "ex:email": "sflynn@centerfornationalpolicy.org"}, {"ex:name": "Noah Gans", "ex:email": "gans@wharton.upenn.edu"}]}, {"ex:issue": "1", "ex:abstract": "For fossil fuel power plants to be built in the future, carbon capture and storage (CCS) technologies offer the potential for significant reductions in carbon dioxide (CO<sub>2</sub>) emissions. We examine the break-even value for CCS adoptions, that is, the critical value in the charge for CO<sub>2</sub> emissions that would justify investment in CCS capabilities. Our analysis takes explicitly into account that the supply of electricity at the wholesale level (generation) is organized competitively in some U.S. jurisdictions, whereas in others a regulated utility provides integrated generation and distribution services. For either market structure, we find that emissions charges near $30 per tonne of CO<sub>2</sub> would be the break-even value for adopting CCS capabilities at new coal-fired power plants. The corresponding break-even values for natural gas plants are substantially higher, near $60 per tonne. Our break-even estimates serve as a basis for projecting the change in electricity prices once carbon emissions become costly. CCS capabilities effectively put an upper bound on the increase in electricity prices resulting from carbon regulations, and we estimate this bound to be near 30% at the retail level for both coal and natural gas plants. In contrast to the competitive power supply scenario, however, these price increases materialize only gradually for a regulated utility. The delay in price adjustments reflects that for regulated firms the basis for setting product prices is historical cost, rather than current cost. This paper was accepted by Grard P. Cachon, accounting.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Carbon Capture by Fossil Fuel Power Plants: An Economic Analysis", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1268", "ex:pages": "21-39", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["cost-benefit analysis", "environment", "pollution", "government", "energy policies", "accounting", "natural resources", "energy"], "ex:creator": [{"ex:name": "zge \\.I\\c{s}legen", "ex:email": "oislegen@stanford.edu"}, {"ex:name": "Stefan Reichelstein", "ex:email": "reichelstein@stanford.edu"}]}, {"ex:issue": "1", "ex:abstract": "In many services, the quality or value provided by the service increases with the time the service provider spends with the customer. However, longer service times also result in longer waits for customers. We term such services, in which the interaction between quality and speed is critical, as customer-intensive services. In a queueing framework, we parameterize the degree of customer intensity of the service. The service speed chosen by the service provider affects the quality of the service through its customer intensity. Customers queue for the service based on service quality, delay costs, and price. We study how a service provider facing such customers makes the optimal \"quality-speed trade-off.\" Our results demonstrate that the customer intensity of the service is a critical driver of equilibrium price, service speed, demand, congestion in queues, and service provider revenues. Customer intensity leads to outcomes very different from those of traditional models of service rate competition. For instance, as the number of competing servers increases, the price increases, and the servers become slower. This paper was accepted by Sampath Rajagopalan, operations and supply chain management.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Quality-Speed Conundrum: Trade-offs in Customer-Intensive Services", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1250", "ex:pages": "40-56", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["strategic customers", "queueing games", "service operations", "cost disease"], "ex:creator": [{"ex:name": "Krishnan S. Anand", "ex:email": "k.anand@utah.edu"}, {"ex:name": "M. Faz{\\i}l Pa", "ex:email": "mpac@wharton.upenn.edu"}, {"ex:name": "Senthil Veeraraghavan", "ex:email": "senthilv@wharton.upenn.edu"}]}, {"ex:issue": "1", "ex:abstract": "Advertisers use online customer data to target their marketing appeals. This has heightened consumers' privacy concerns, leading governments to pass laws designed to protect consumer privacy by restricting the use of data and by restricting online tracking techniques used by websites. We use the responses of 3.3 million survey takers who had been randomly exposed to 9,596 online display (banner) advertising campaigns to explore how privacy regulation in the European Union (EU) has influenced advertising effectiveness. This privacy regulation restricted advertisers' ability to collect data on Web users in order to target ad campaigns. We find that, on average, display advertising became far less effective at changing stated purchase intent after the EU laws were enacted, relative to display advertising in other countries. The loss in effectiveness was more pronounced for websites that had general content (such as news sites), where non-data-driven targeting is particularly hard to do. The loss of effectiveness was also more pronounced for ads with a smaller presence on the webpage and for ads that did not have additional interactive, video, or audio features. This paper was accepted by Pradeep Chintagunta, marketing.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Privacy Regulation and Online Advertising", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1246", "ex:pages": "57-71", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["privacy", "online advertising", "targeting"], "ex:creator": [{"ex:name": "Avi Goldfarb", "ex:email": "agoldfarb@rotman.utoronto.ca"}, {"ex:name": "Catherine E. Tucker", "ex:email": "cetucker@mit.edu"}]}, {"ex:issue": "1", "ex:abstract": "Prior research hypothesizes managers use \"real actions,\" including the reduction of discretionary expenditures, to manage earnings to meet or beat key benchmarks. This paper examines this hypothesis by testing how different types of marketing expenditures are used to boost earnings for a durable commodity consumer product that can be easily stockpiled by end consumers. Combining supermarket scanner data with firm-level financial data, we find evidence that differs from prior literature. Instead of reducing expenditures to boost earnings, soup manufacturers roughly double the frequency and change the mix of marketing promotions (price discounts, feature advertisements, and aisle displays) at the fiscal quarter-end when they have greater incentive to boost earnings. Our results confirm managers' stated willingness to sacrifice long-term value in order to smooth earnings and their stated preference to use real actions to boost earnings to meet different types of earnings benchmarks. We estimate that marketing actions can be used to boost quarterly net income by up to 5% depending on the depth and duration of promotion. However, there is a price to pay, with the cost in the following period being approximately 7.5% of quarterly net income. Finally, a unique aspect of the research setting allows tests of who is responsible for the earnings management. Although firms appear unable to increase the frequency of aisle display promotions in the short run, they can reallocate these promotions within their portfolio of brands. Results show firms shifting display promotions away from smaller revenue brands toward larger ones following periods of poor financial performance. This indicates the behavior is determined by parties above brand managers in the firm. These findings are consistent with firms engaging in real earnings management and suggest that effects on subsequent reporting periods and competitor behavior are greater than previously documented. This paper was accepted by Stefan Reichelstein, accounting.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "An Investigation of Earnings Management Through Marketing Actions", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1254", "ex:pages": "72-92", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["accounting", "marketing", "pricing", "promotion", "real earnings management"], "ex:creator": [{"ex:name": "Craig J. Chapman", "ex:email": "c-chapman@kellogg.northwestern.edu"}, {"ex:name": "Thomas J. Steenburgh", "ex:email": "tsteenburgh@hbs.edu"}]}, {"ex:issue": "1", "ex:abstract": "In this paper, we investigate how market competition contributes to the expression of overconfidence among those competing for influence. We find evidence that market competition exacerbates the tendency to express excessive confidence. This evidence comes from experiments in which advisors attempt to sell their advice. In the first, advisors must compete with other advice sellers. In the second, advisors and their customers are paired. Advisors are overconfident in both studies and it helps advisors sell their advice. However, competition between advisors in the market further exacerbates overconfidence. In a third study, we demonstrate that the market competition drives overconfidence even when advisors vary in quality. We also investigate the strategic expressions and interpretations of confidence by both sides in the exchange. This paper was accepted by Peter Wakker, decision analysis.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Competing to Be Certain (But Wrong): Market Dynamics and Excessive Confidence in Judgment", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1255", "ex:pages": "93-106", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["overconfidence", "advice", "competition", "markets", "judgment"], "ex:creator": [{"ex:name": "Joseph R. Radzevick", "ex:email": "jrr2@cmu.edu"}, {"ex:name": "Don A. Moore", "ex:email": "dmoore@haas.berkeley.edu"}]}, {"ex:issue": "1", "ex:abstract": "A common approach to innovation, parallel search, is to identify a large number of opportunities and then to select a subset for further development, with just a few coming to fruition. One potential weakness with parallel search is that it permits repetition. The same, or a similar, idea might be generated multiple times, because parallel exploration processes typically operate without information about the ideas that have already been identified. In this paper we analyze repetition in five data sets comprising 1,368 opportunities and use that analysis to address three questions: (1) When a large number of efforts to generate ideas are conducted in parallel, how likely are the resulting ideas to be redundant? (2) How large are the opportunity spaces? (3) Are the unique ideas more valuable than those similar to many others? The answer to the first question is that although there is clearly some redundancy in the ideas generated by aggregating parallel efforts, this redundancy is quite small in absolute terms in our data, even for a narrowly defined domain. For the second question, we propose a method to extrapolate how many unique ideas would result from an unbounded effort by an unlimited number of comparable idea generators. Applying that method, and for the settings we study, the estimated total number of unique ideas is about one thousand for the most narrowly defined domain and greater than two thousand for the more broadly defined domains. On the third question, we find a positive relationship between the number of similar ideas and idea value: the ideas that are least similar to others are not generally the most valuable ones. This paper was accepted by Lee Fleming, entrepreneurship and innovation.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Opportunity Spaces in Innovation: Empirical Analysis of Large Samples of Ideas", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1247", "ex:pages": "107-128", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["search", "opportunity", "opportunities", "idea", "ideation", "idea generation", "innovation", "creativity", "innovation process", "opportunity identification", "concept development", "product development", "product design", "entrepreneurship"], "ex:creator": [{"ex:name": "Laura J. Kornish", "ex:email": "kornish@colorado.edu"}, {"ex:name": "Karl T. Ulrich", "ex:email": "ulrich@wharton.upenn.edu"}]}, {"ex:issue": "1", "ex:abstract": "When firms recruit inventors, they acquire not only the use of their skills but also enhanced access to their stock of ideas. But do hiring firms actually increase their use of new recruits' prior inventions? Our estimates suggest they do, quite significantly in fact, by approximately 219% on average. However, this does not necessarily reflect widespread \"learning by hiring.\" In fact, we estimate that a recruit's exploitation of her own prior ideas accounts for almost half of the above effect, with much of the diffusion to others being limited to the recruit's immediate collaborative network. Furthermore, although one might expect the recruit's role to diminish rapidly as her tacit knowledge diffuses across her new firm, our estimates indicate that her importance is surprisingly persistent over time. We base these findings on an empirical strategy that exploits the variation over time in hiring firms' citations to the recruits' premove patents. Specifically, we employ a difference-in-differences approach to compare premove versus postmove citation rates for the recruits' prior patents and corresponding matched-pair control patents. Our methodology has three benefits compared to previous studies that also examine the link between labor mobility and knowledge flow: (1) it does not suffer from the upward bias inherent in the conventional cross-sectional comparison, (2) it generates results that are robust to a more stringently matched control sample, and (3) it enables a temporal examination of knowledge flow patterns. This paper was accepted by Kamalini Ramdas, entrepreneurship and innovation.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Recruiting for Ideas: How Firms Exploit the Prior Inventions of New Hires", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1253", "ex:pages": "129-150", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["inventor mobility", "access to ideas", "knowledge spillovers", "learning by hiring", "difference in differences", "coarsened exact matching", "collaborative networks", "patent citations"], "ex:creator": [{"ex:name": "Jasjit Singh", "ex:email": "jasjit.singh@insead.edu"}, {"ex:name": "Ajay Agrawal", "ex:email": "ajay.agrawal@rotman.utoronto.ca"}]}, {"ex:issue": "1", "ex:abstract": "This paper presents a new implicit formulation for shift scheduling problems, using context-free grammars to model the rules for the composition of shifts. From the grammar, we generate an integer programming (IP) model having a linear programming relaxation equivalent to that of the classical set covering model. When solved by a state-of-the-art IP solver on problem instances with a small number of shifts, our model, the set covering formulation, and a typical implicit model from the literature yield comparable solution times. On instances with a large number of shifts, our formulation shows superior performance and can model a wider variety of constraints. In particular, multiactivity cases, which cannot be modeled by existing implicit formulations, can easily be handled with grammars. We present comparative experimental results on a large set of instances involving one work activity, as well as on problems dealing with up to 10 work activities. This paper was accepted by Dimitris Bertsimas, optimization.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Grammar-Based Integer Programming Models for Multiactivity Shift Scheduling", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1264", "ex:pages": "151-163", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["shift scheduling", "implicit models", "mixed integer programming", "context-free grammars"], "ex:creator": [{"ex:name": "Marie-Claude Ct", "ex:email": "marie-claude.cote@polymtl.ca"}, {"ex:name": "Bernard Gendron", "ex:email": "gendron@iro.umontreal.ca"}, {"ex:name": "Louis-Martin Rousseau", "ex:email": "louis-martin.rousseau@polymtl.ca"}]}, {"ex:issue": "1", "ex:abstract": "We study markets for information goods and find that they differ significantly from markets for traditional industrial goods. Markets for information goods in which products are vertically differentiated lack the segmentation inherent in markets for industrial goods. As a result, a monopoly will offer only a single product. Competition leads to highly concentrated information-good markets, with the leading firm behaving almost like a monopoly even with free entry and without network effects. We study how the structure of the firms' cost functions drives our results. This paper was accepted by Barrie R. Nault, information systems.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Information Goods vs. Industrial Goods: Cost Structure and Competition", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1262", "ex:pages": "164-176", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["information goods", "convex development cost", "product and price competition"], "ex:creator": [{"ex:name": "Roy Jones", "ex:email": "rjones@simon.rochester.edu"}, {"ex:name": "Haim Mendelson", "ex:email": "mendelson_haim@gsb.stanford.edu"}]}, {"ex:issue": "1", "ex:abstract": "We investigate how auctioneers set reserve prices in auctions. A well-established theoretical result, assuming risk neutrality of the seller, is that the optimal reserve price should not depend on the number of participating bidders. In a set of controlled laboratory experiments, we find that seller behavior often deviates from the theoretical benchmarks. We extend the existing theory to explore three alternative explanations for our results: risk aversion, anticipated regret, and probability weighting. After fitting our data to each of these models through parameter estimation techniques on both an aggregate and individual level, we find that all three models are consistent with some of the characteristics of our data, but that the regret model provides a slightly more favorable fit overall. This paper was accepted by Teck-Hua Ho, decision analysis.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Do Auctioneers Pick Optimal Reserve Prices?", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1258", "ex:pages": "177-192", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["reserve prices", "procurement auctions", "behavioral operations"], "ex:creator": [{"ex:name": "Andrew M. Davis", "ex:email": "adavis@psu.edu"}, {"ex:name": "Elena Katok", "ex:email": "ekatok@psu.edu"}, {"ex:name": "Anthony M. Kwasnica", "ex:email": "kwasnica@psu.edu"}]}, {"ex:issue": "1", "ex:abstract": "Cumulative prospect theory introduced the weighting of probabilities as an additional component to capture risk attitudes. However, this addition would be a less significant challenge to expected utility theory (EU) if utility curvature and probability weighting showed strong positive correlation. In that case the utility curvature in EU alone, although not properly describing risky behavior in general, would still capture most of the variance of individual risk aversion. This study provides experimental evidence that such a strong and positive correlation does not exist. Although most individuals exhibit concave utility and convex probability weighting, the two components show no strong positive correlation. This paper was accepted by Peter Wakker, decision analysis.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Understanding the Two Components of Risk Attitudes: An Experimental Analysis", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1260", "ex:pages": "193-199", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["risk attitude", "cumulative prospect theory", "experimental study"], "ex:creator": [{"ex:name": "Jianying Qiu", "ex:email": "jianying.qiu@univie.ac.at"}, {"ex:name": "Eva-Maria Steiger", "ex:email": "steiger@econ.mpg.de"}]}, {"ex:issue": "1", "ex:abstract": "We develop comparative results for ratio-based efficiency analysis (REA) based on the decision-making units' (DMUs') relative efficiencies over sets of feasible weights that characterize preferences for input and output variables. Specifically, we determine (i) ranking intervals, which indicate the best and worst efficiency rankings that a DMU can attain relative to other DMUs; (ii) dominance relations, which show what other DMUs a given DMU dominates in pairwise efficiency comparisons; and (iii) efficiency bounds, which show how much more efficient a given DMU can be relative to some other DMU or a subset of other DMUs. Unlike conventional efficiency scores, these results are insensitive to outlier DMUs. They also show how the DMUs' efficiency ratios relate to each other for all feasible weights, rather than for those weights only for which the data envelopment analysis (DEA) efficiency score of some DMU is maximized. We illustrate the usefulness of these results by revisiting reported DEA studies and by describing a recent case study on the efficiency comparison of university departments. This paper was accepted by Teck-Hua Ho, decision analysis.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Ranking Intervals and Dominance Relations for Ratio-Based Efficiency Analysis", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1265", "ex:pages": "200-214", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["efficiency analysis", "data envelopment analysis", "preference modeling"], "ex:creator": [{"ex:name": "Ahti Salo", "ex:email": "ahti.salo@tkk.fi"}, {"ex:name": "Antti Punkka", "ex:email": "antti.punkka@tkk.fi"}]}, {"ex:issue": "2", "ex:abstract": "No abstract available.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Management Insights", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1316", "ex:pages": "iv-vi", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": [], "ex:creator": [{"ex:name": "Michael F. Gorman", "ex:email": "michael.gorman@udayton.edu"}]}, {"ex:issue": "2", "ex:abstract": "Websites typically provide several links on each page visited by a user. Whereas some of these links help users easily navigate the site, others are typically used to provide targeted recommendations based on the available user profile. When the user profile is not available (or is inadequate), the site cannot effectively target products, promotions, and advertisements. In those situations, the site can learn the profile of a user as the user traverses the site. Naturally, the faster the site can learn a user's profile, the sooner the site can benefit from personalization. We develop a technique that sites can use to learn the profile as quickly as possible. The technique identifies links for sites to make available that will lead to a more informative profile when the user chooses one of the offered links. Experiments conducted using our approach demonstrate that it enables learning the profiles markedly better after very few user interactions as compared to benchmark approaches. The approach effectively learns multiple attributes simultaneously, can learn well classes that have highly skewed priors, and remains quite effective even when the distribution of link profiles at a site is relatively homogeneous. The approach works particularly well when a user's traversal is influenced by the most recently visited pages on a site. Finally, we show that the approach is robust to noise in the estimates for the probability parameters needed for its implementation. This paper was accepted by Sandra Slaughter, information systems.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Accelerated Learning of User Profiles", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1266", "ex:pages": "215-239", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["personalization", "Bayesian learning", "information theory", "recommendation systems"], "ex:creator": [{"ex:name": "Pelin Atahan", "ex:email": "pelin.atahan@ozyegin.edu.tr"}, {"ex:name": "Sumit Sarkar", "ex:email": "sumit@utdallas.edu"}]}, {"ex:issue": "2", "ex:abstract": "This article analyzes the relationship between organizational change and employee health. It illuminates the potentially negative outcomes of change at the level of the employee. In addition, it relates to the ongoing debate over how employees react to and respond to organizational change. I hypothesize that change increases the risk of negative stress, and I test this hypothesis using a comprehensive panel data set of all stress-related medicine prescriptions for 92,860 employees working in 1,517 of the largest Danish organizations. The findings suggest that the risk of receiving stress-related medication increases significantly for employees at organizations that change, especially those that undergo broad simultaneous changes along several dimensions. Thus, organizational changes are associated with significant risks of employee health problems. These effects are further explored with respect to employees at different hierarchical levels as well as at firms of different sizes and from different sectors. This paper was accepted by Jesper Srensen, organizations.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Organizational Change and Employee Stress", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1273", "ex:pages": "240-256", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["organizational studies", "personnel", "behavior", "strategy"], "ex:creator": [{"ex:name": "Michael S. Dahl", "ex:email": "md@business.aau.dk"}]}, {"ex:issue": "2", "ex:abstract": "This paper investigates the effect of founders' professional-education background on the adoption of an open-science technology strategy, using a sample of 512 young biotechnology firms. After controlling for founders' prior work experience and other organizational and environmental factors, I find that firms with proportionally more Ph.D.-holding entrepreneurs on the founding team have a higher probability of adopting open science. In addition, founders' educational background can mitigate the constraint of organizational environments on strategy. A crowded technological niche provides a more challenging environment for firms to implement open science, due to higher scooping risks. The deterrent effect, however, of such a high-risk environment is smaller among firms founded by proportionally more Ph.D.-holding entrepreneurs. There is also some evidence of a stronger effect of founders' educational background on open science in an institutional environment in which open science has yet to become the industry norm. This finding is consistent with and complements the growing body of research that emphasizes the importance of entrepreneurial background in developing knowledge about new-venture strategy and structure. This paper was accepted by Olav Sorenson, organizations.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "The Impact of Founders' Professional-Education Background on the Adoption of Open Science by For-Profit Biotechnology Firms", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1278", "ex:pages": "257-273", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["entrepreneurship", "founder background", "professional education", "open science", "diffusion of innovation", "TMT"], "ex:creator": [{"ex:name": "Waverly W. Ding", "ex:email": "wding@haas.berkeley.edu"}]}, {"ex:issue": "2", "ex:abstract": "How much are we influenced by an author's identity when evaluating his or her work? This paper exploits a natural experiment to measure the impact of status signals in the context of open standards development. For a period of time, e-mails announcing new submissions to the Internet Engineering Task Force would replace individual author names with \"et al.\" if submission volumes were unusually high. We measure the impact of status signals by comparing the effect of obscuring high- versus low-status author names. Our results show that name-based signals can explain up to three-quarters of the difference in publication rates between high- and low-status authors. The signaling effect disappears for a set of prescreened proposals that receive more scrutiny than a typical submission, suggesting that status signals are more important when attention is scarce (or search costs high). We also show that submissions from high-status authors receive more attention on electronic discussion boards, which may help high-status authors to develop their ideas and bring them forward to publication. This paper was accepted by Jesper Srensen, organizations.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Status, Quality, and Attention: What's in a (Missing) Name?", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1270", "ex:pages": "274-290", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["status", "technology", "sociology of science"], "ex:creator": [{"ex:name": "Timothy S. Simcoe", "ex:email": "tsimcoe@bu.edu"}, {"ex:name": "Dave M. Waguespack", "ex:email": "dwaguesp@rhsmith.umd.edu"}]}, {"ex:issue": "2", "ex:abstract": "This paper examines the drivers of adoption of Internet banking and the linkages among adoption drivers and outcomes (product acquisition, service activity, profitability, loyalty). We relate Internet banking adoption to customer demand for banking services, the availability of alternative channels, customers' efficiency in service coproduction (\"customer efficiency\"), and local Internet banking penetration. We find that customers who have greater transaction demand and higher efficiency, and reside in areas with a greater density of online banking adopters, are faster to adopt online banking after controlling for time, regional, and individual characteristics. Consistent with prior work, we find that customers significantly increase their banking activity, acquire more products, and perform more transactions. These changes in behavior are not associated with short-run increases in customer profitability, but customers who adopt online banking have a lower propensity to leave the bank. Building on these observations we also find that the adoption drivers are linked to the postadoption changes in behavior or profitability. Customers who live in areas with a high branch density or high Internet banking penetration increase their product acquisition and transaction activity more than Internet banking adopters in other regions. Efficient customers and those with high service demand show greater postadoption profitability. This paper was accepted by Sandra Slaughter, information systems.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Determinants and Outcomes of Internet Banking Adoption", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1187", "ex:pages": "291-307", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["Internet banking adoption", "customer efficiency", "network effects"], "ex:creator": [{"ex:name": "Mei Xue", "ex:email": "xueme@bc.edu"}, {"ex:name": "Lorin M. Hitt", "ex:email": "lhitt@wharton.upenn.edu"}, {"ex:name": "Pei-yu Chen", "ex:email": "pychen@temple.edu"}]}, {"ex:issue": "2", "ex:abstract": "The conventional method of estimating a probability prediction model by maximum likelihood (MLE) is a form of maximum score estimation with economic meaning. Of all the probabilities that a given model might have produced, those obtained by MLE yield maximum in-sample betting return to a log utility investor. Recognition of this affinity between MLE and log utility begs the wider methodological question of whether different decision makers benefit in different degrees from different probabilities. Probabilities produced by MLE can be either too conservative or too bold relative to those found by maximizing utility under more risk-tolerant or risk-averse score functions. A very (not very) risk-averse user, who bets characteristically small (large) fractions of wealth based on a conservative forecast, is bound to make a rapidly (slowly) increasing bet as the forecast probability becomes progressively bolder or more distant from the market probability. The effect of this interaction between risk aversion and forecast is that a highly risk-averse user may need a much bolder forecast to obtain the same certainty equivalent as a more risk-tolerant investor. It follows more broadly that professional forecasters should anticipate how a client with given risk aversion expects to gain from any given forecast, or forecast revision, before committing resources toward making a better informed (but still honest) forecast. This paper was accepted by Peter Wakker, decision analysis.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Economic Interpretation of Probabilities Estimated by Maximum Likelihood or Score", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1272", "ex:pages": "308-314", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["probability forecast", "scoring rule", "maximum likelihood", "maximum score estimation"], "ex:creator": [{"ex:name": "D. J. Johnstone", "ex:email": "d.johnstone@econ.usyd.edu.au"}]}, {"ex:issue": "2", "ex:abstract": "We formulate and carry out an analytical treatment of a single-period portfolio choice model featuring a reference point in wealth, S-shaped utility (value) functions with loss aversion, and probability weighting under Kahneman and Tversky's cumulative prospect theory (CPT). We introduce a new measure of loss aversion for large payoffs, called the large-loss aversion degree (LLAD), and show that it is a critical determinant of the well-posedness of the model. The sensitivity of the CPT value function with respect to the stock allocation is then investigated, which, as a by-product, demonstrates that this function is neither concave nor convex. We finally derive optimal solutions explicitly for the cases in which the reference point is the risk-free return and those in which it is not (while the utility function is piecewise linear), and we employ these results to investigate comparative statics of optimal risky exposures with respect to the reference point, the LLAD, and the curvature of the probability weighting. This paper was accepted by Wei Xiong, finance.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Portfolio Choice Under Cumulative Prospect Theory: An Analytical Treatment", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1269", "ex:pages": "315-331", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["portfolio choice", "single period", "cumulative prospect theory", "reference point", "loss aversion", "S-shaped utility function", "probability weighting", "well-posedness"], "ex:creator": [{"ex:name": "Xue Dong He", "ex:email": "xh2140@columbia.edu"}, {"ex:name": "Xun Yu Zhou", "ex:email": "zhouxy@maths.ox.ac.uk"}]}, {"ex:issue": "2", "ex:abstract": "We study how a manager's short-term interest in the firm's market value may motivate channel stuffing: shipping excess inventory to the downstream channel. Channel stuffing allows a manager to report sales in excess of demand in order to influence investors' valuation of the firm. We apply an inventory model that highlights the potential role of inventory in the manager's channel stuffing and the investors' valuation strategies. Sales in our model are constrained by available inventory. Our model yields a semiseparating and semipooling equilibrium contingent on the initial inventory level: When the demand is lower than a threshold that depends on and is below the initial inventory level, the manager pads sales by a part of the excess inventory and releases the inflated sales report. The investors \"correct\" the reported sales and are able to infer perfectly the firm's value. When the demand reaches or exceeds this threshold, the manager pads any excess inventory to the sales and reports the initial inventory is sold out, which censors large demand realizations. Then the investors only infer the real demand is no less than the threshold and value the firm accordingly by expectation. Channel stuffing can influence the inventory decision, too. We find both over- and underinvestment in the initial inventory can arise in our model. We discuss empirical and managerial implications of our findings. This paper was accepted by Paul H. Zipkin, operations and supply chain management.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Channel Stuffing with Short-Term Interest in Market Value", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1275", "ex:pages": "332-346", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["channel stuffing", "inventory management", "market value"], "ex:creator": [{"ex:name": "Guoming Lai", "ex:email": "guoming.lai@mccombs.utexas.edu"}, {"ex:name": "Laurens Debo", "ex:email": "laurens.debo@chicagobooth.edu"}, {"ex:name": "Lin Nan", "ex:email": "linnan@andrew.cmu.edu"}]}, {"ex:issue": "2", "ex:abstract": "This paper investigates the pricing and restocking fee decisions of two competing firms selling horizontally differentiated products. We model a duopoly facing consumers who have heterogeneous tastes for the products and who must experience a product before knowing how well it matches with their preferences. The analysis yields several key insights. Restocking fees not only can be sustained in a competitive environment, but also are more severe when consumers are less informed about product fit and when consumers place a greater importance on how well products' attributes fit with their preferences. We compare the competitive equilibrium prices to a scenario in which consumers are certain about their preferences and find conditions defining when consumer uncertainty results in higher equilibrium prices. Comparison to a monopoly setting yields a surprising result: Equilibrium restocking fees in a competitive environment can be higher than those charged by a monopolist. This paper was accepted by Jagmohan S. Raju, marketing.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Managing Consumer Returns in a Competitive Environment", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1274", "ex:pages": "347-362", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["marketing", "channels of distribution", "competitive strategy", "pricing"], "ex:creator": [{"ex:name": "Jeffrey D. Shulman", "ex:email": "jshulman@u.washington.edu"}, {"ex:name": "Anne T. Coughlan", "ex:email": "a-coughlan@kellogg.northwestern.edu"}, {"ex:name": "R. Canan Savaskan", "ex:email": "csavaskan@cox.smu.edu"}]}, {"ex:issue": "2", "ex:abstract": "Companies and managers are apt to forget information, yet classic game theory analysis assumes that all players have perfect recall. This paper expands the literature by examining how introducing forgetfulness into a multiplayer game-theoretic framework can help or hinder cooperative behavior. We find that forgetfulness impacts the ability of firms to cooperate in countervailing directions. On one hand, forgetfulness can diminish the ability to punish deviators, making cooperation more difficult. On the other hand, under some conditions forgetfulness can make meting out severe punishments--even below-(stage) minimax punishments--credible and decrease the ability for players to effectively deviate, facilitating cooperation even in circumstances where cooperation cannot be sustained under perfect recall. We apply our model to a number of strategic games that commonly appear in the literature. This paper was accepted by Preyas Desai, marketing.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Cooperation in Games with Forgetfulness", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1271", "ex:pages": "363-375", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["marketing", "competitive strategy", "games-group decisions", "information systems", "IT policy and management"], "ex:creator": [{"ex:name": "Raphael Thomadsen", "ex:email": "raphael.thomadsen@anderson.ucla.edu"}, {"ex:name": "Pradeep Bhardwaj", "ex:email": "pradeep.bhardwaj@sauder.ubc.ca"}]}, {"ex:issue": "2", "ex:abstract": "Medical devices play an increasingly significant role in the delivery of health care today. However, persistent quality problems with medical devices and the associated recalls present potential health risks to patients and personnel using these devices. This study addresses three key issues in this regard. First, it empirically assesses the financial implications of medical device recalls to understand if these consequences are severe enough to deter firms from introducing potentially hazardous medical devices into the market, as can be inferred from the literature. Second, the study considers a cross section of medical device manufacturers to examine the effect of firm characteristics on the costs of poor quality. Third, in an attempt to explore the sources of recalls, this study investigates firm characteristics that are likely to be associated with device recalls. The econometric analyses in the study are based on data from manufacturers in the medical device industry over a four-year period (2002-2005). Contrary to our expectations, the findings of the study indicate that at an aggregate level, the market penalties for medical device recalls are not significant, i.e., at the aggregate level, the costs of poor quality are not severe. Furthermore, we find that the magnitude of financial consequences of device recalls is affected by the product scope, sales, growth prospects, and the capital structure of a firm. In our analyses exploring the sources of device recalls, we find that firms with a research and development focus, developing broader product portfolios, have a higher likelihood of device recalls. Also, we find that the likelihood of recalls decreases with prior recall experience, indicating the presence of learning. Implications of the study findings, limitations, and directions for future research are identified. This paper was accepted by Sampath Rajagopalan, operations and supply chain management.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Product Recalls in the Medical Device Industry: An Empirical Exploration of the Sources and Financial Consequences", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1267", "ex:pages": "376-392", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["medical device", "recalls", "quality", "econometric analyses", "performance", "learning"], "ex:creator": [{"ex:name": "Sriram Thirumalai", "ex:email": "sriram.thirumalai@business.utah.edu"}, {"ex:name": "Kingshuk K. Sinha", "ex:email": "ksinha@umn.edu"}]}, {"ex:issue": "2", "ex:abstract": "We investigate the epistemology of trust in social networks. We posit trust as a special epistemic state that depends on actors' beliefs about each others' beliefs as well as about states of the world. It offers new ideas and tools for representing the core elements of trust both within dyads and larger groups and presents an approach that makes trust measurable in a noncircular and predictive, rather than merely postdictive, fashion. After advancing arguments for the importance of interactive belief systems to the successful coordination of behavior, we tune our investigation of trust by focusing on beliefs that are important to mobilization and coordination and show how trust functions to influence social capital arising from network structure. We present empirical evidence corroborating the importance of higher-order beliefs to understanding trust and the interactive analysis of trust to the likelihood of successful coordination. This paper was accepted by Jesper Srensen, organizations and social networks.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "\"I Think You Think I Think You're Lying\": The Interactive Epistemology of Trust in Social Networks", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1279", "ex:pages": "393-412", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["organizational studies", "strategy", "networks graphs", "theory", "design", "information", "philosophy of modeling"], "ex:creator": [{"ex:name": "Mihnea C. Moldoveanu", "ex:email": "micamo@rotman.utoronto.ca"}, {"ex:name": "Joel A. C. Baum", "ex:email": "jbaum@rotman.utoronto.ca"}]}, {"ex:issue": "2", "ex:abstract": "No abstract available.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Referees", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1310", "ex:pages": "413-423", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": [], "ex:creator": [{"ex:name": "anonymous"}]}, {"ex:issue": "3", "ex:abstract": "No abstract available.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Management Insights", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1332", "ex:pages": "iv-vi", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": [], "ex:creator": [{"ex:name": "Michael F. Gorman", "ex:email": "michael.gorman@udayton.edu"}]}, {"ex:issue": "3", "ex:abstract": "We find that the enforcement of noncompete clauses significantly impedes entrepreneurship and employment growth. Based on a panel of metropolitan areas in the United States from 1993 to 2002, our results indicate that, relative to states that enforce noncompete covenants, an increase in the local supply of venture capital in states that restrict the scope of these agreements has significantly stronger positive effects on (i) the number of patents, (ii) the number of firm starts, and (iii) employment. We address potential endogeneity in the supply of venture capital by using endowment returns as an instrumental variable. Our results point to a strong interaction between financial intermediation and the legal regime in promoting entrepreneurship and economic growth. This paper was accepted by Grard P. Cachon, entrepreneurship and innovation.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Noncompete Covenants: Incentives to Innovate or Impediments to Growth", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1280", "ex:pages": "425-438", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["venture capital", "financial intermediaries", "legal institutions", "entrepreneurship", "employment", "innovation", "wages"], "ex:creator": [{"ex:name": "Sampsa Samila", "ex:email": "sampsa.samila@brocku.ca"}, {"ex:name": "Olav Sorenson", "ex:email": "olav.sorenson@yale.edu"}]}, {"ex:issue": "3", "ex:abstract": "What is the best way to design tournaments for status, in which individuals labor primarily for the esteem of their peers? What process, in other words, should organizers of status-based contests impose upon those who covet peer recognition? We propose a formal model of status-based competition that contrasts two competing alternatives. The first, following Merton, is the \"Matthew Effect,\" according to which a tournament's architect directs slack resources to elite actors and thus widens the distribution of rewards by favoring cumulative advantage. The second is the \"Mark Effect,\" under which a tournament's designer instead pushes slack resources to marginal actors and thus tightens the distribution of rewards. Our results suggest that although the Mark Effect is better for the social welfare of most tournaments, the Matthew Effect is preferable in two distinct contexts: in small tournaments where variation in underlying ability translates into acute advantages for the most capable contestants; and in large tournaments whose contestants face constant, rather than rising, marginal costs--a condition we relate to contestants' perception of their work as intrinsically valuable. Our contributions are twofold: We find, counter to the thrust of Merton's work, that cumulative advantage is not invariably optimal for the functioning of status contests; and we identify circumstances in which the production of superstars is likely to make contests for status better off in aggregate. Implications for future research on status and management are discussed. This paper was accepted by Olav Sorenson, organizations and social networks.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Organizing Contests for Status: The Matthew Effect vs. the Mark Effect", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1281", "ex:pages": "439-457", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["networks", "graphs", "theory", "organizational studies", "design", "effectiveness", "performance", "status", "leadership"], "ex:creator": [{"ex:name": "Matthew S. Bothner", "ex:email": "mbothner@cornell.edu"}, {"ex:name": "Joel M. Podolny", "ex:email": "podolny@apple.com"}, {"ex:name": "Edward Bishop Smith", "ex:email": "nedsmith@umich.edu"}]}, {"ex:issue": "3", "ex:abstract": "We explore substitution patterns across advertising platforms. Using data on the advertising prices paid by lawyers for 139 Google search terms in 195 locations, we exploit a natural experiment in \"ambulance-chaser\" regulations across states. When lawyers cannot contact clients by mail, advertising prices per click for search engine advertisements are 5%-7% higher. Therefore, online advertising substitutes for offline advertising. This substitution toward online advertising is strongest in markets with fewer customers, suggesting that the relationship between the online and offline media is mediated by the marketers' need to target their communications. This paper was accepted by Pradeep Chintagunta, marketing.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Search Engine Advertising: Channel Substitution When Pricing Ads to Context", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1287", "ex:pages": "458-470", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["advertising and media", "information systems", "IT policy and management", "electronic commerce", "search engine advertising"], "ex:creator": [{"ex:name": "Avi Goldfarb", "ex:email": "agoldfarb@rotman.utoronto.ca"}, {"ex:name": "Catherine Tucker", "ex:email": "cetucker@mit.edu"}]}, {"ex:issue": "3", "ex:abstract": "Multiservice providers, such as telecommunication and financial service companies, can benefit from understanding how customers' service portfolios evolve over the course of their relationships. This can provide guidance for managerial issues such as customer valuation and predicting customers' future behavior, whether it is acquiring additional services, selectively dropping current services, or ending the relationship entirely. In this research, we develop a dynamic hidden Markov model to identify latent states that govern customers' affinity for the available services through which customers evolve. In addition, we incorporate and demonstrate the importance of separating two other sources of dynamics: portfolio inertia and service stickiness. We then examine the relationship between state membership and managerially relevant metrics, including customers' propensities for acquiring additional services or terminating the relationship, and customer lifetime value. Through a series of illustrative vignettes, we show that customers who have discarded a particular service may have an increased risk of canceling all services in the near future (as intuition would suggest) but also may be more prone to acquire more services, a provocative finding of interest to service providers. Our findings also emphasize the need to look beyond the previous period, as in much current research, and consider how customers have evolved over their entire relationship in order to predict their future actions. This paper was accepted by Pradeep Chintagunta, marketing.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Portfolio Dynamics for Customers of a Multiservice Provider", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1284", "ex:pages": "471-486", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["customer relationship management", "dynamic hidden Markov model", "customer value"], "ex:creator": [{"ex:name": "David A. Schweidel", "ex:email": "dschweidel@bus.wisc.edu"}, {"ex:name": "Eric T. Bradlow", "ex:email": "ebradlow@wharton.upenn.edu"}, {"ex:name": "Peter S. Fader", "ex:email": "faderp@wharton.upenn.edu"}]}, {"ex:issue": "3", "ex:abstract": "We develop a new goodness-of-fit test for validating the performance of probability forecasts. Our test statistic is particularly powerful under sparseness and dependence in the observed data. To build our test statistic, we start from a formal definition of calibrated forecasts, which we operationalize by introducing two components. The first component tests the level of the estimated probabilities; the second validates the shape, measuring the differentiation between high and low probability events. After constructing test statistics for both level and shape, we provide a global goodness-of-fit statistic, which is asymptotically \\chi <sup>2</sup> distributed. In a simulation exercise, we find that our approach is correctly sized and more powerful than alternative statistics. In particular, our shape statistic is significantly more powerful than the Kolmogorov-Smirnov test. Under independence, our global test has significantly greater power than the popular Hosmer-Lemeshow's \\chi <sup>2</sup> test. Moreover, even under dependence, our global test remains correctly sized and consistent. As a timely and important empirical application of our method, we study the validation of a forecasting model for credit default events. This paper was accepted by Wei Xiong, finance.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "A New Goodness-of-Fit Test for Event Forecasting and Its Application to Credit Defaults", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1283", "ex:pages": "487-505", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["out-of-sample validation", "probability calibration", "Hosmer-Lemeshow statistic", "Bernoulli mixture models", "credit risk"], "ex:creator": [{"ex:name": "Andreas Blchlinger", "ex:email": "andreas.bloechlinger@zkb.ch"}, {"ex:name": "Markus Leippold", "ex:email": "leippold@isb.uzh.ch"}]}, {"ex:issue": "3", "ex:abstract": "Reference-dependent preferences have been well accepted in decision sciences, experimental economics, behavioral finance, and marketing. However, we still know very little about how decision makers form and update their reference points given a sequence of information. Our paper provides some novel experiments in a financial context to advance the understanding of reference-point formation over time. Our subjects' reference price is best described as a combination of the first and the last price of the time series, with intermediate prices receiving smaller and nondecaying weights. Hence, reference prices are not recursive. We provide a parsimonious formula to predict the reference points, which we test out-of-sample. The fit of the model is reasonably good. This paper was accepted by George Wu, decision analysis.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Reference-Point Formation and Updating", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1286", "ex:pages": "506-519", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["reference-point formation", "reference-dependent preferences", "disposition effect", "probability weighting"], "ex:creator": [{"ex:name": "Manel Baucells", "ex:email": "manel.baucells@upf.edu"}, {"ex:name": "Martin Weber", "ex:email": "weber@bank.bwl.uni-mannheim.de"}, {"ex:name": "Frank Welfens", "ex:email": "frank@welfens.de"}]}, {"ex:issue": "3", "ex:abstract": "The academic and practitioner literature justifies firms' use of product costs in product pricing and capacity planning decisions as heuristics to address an otherwise intractable problem. However, product costs are the output of a cost reporting system, which itself is the outcome of heuristic design choices. In particular, because of informational limitations, when designing cost systems firms use simple rules of thumb to group resources into cost pools and to select drivers used to allocate the pooled costs to products. Using simulations, we examine how popular choices in costing system design influence the error in reported costs. Taking information needs into account, we offer alternative ways to translate the vague guidance in the literature to implementable methods. Specifically, we compare size-based rules for forming cost pools with more informationally demanding correlation-based rules and develop a blended method that performs well in terms of accuracy. In addition, our analysis suggests that significant gains can be made from using a composite driver rather than selecting a driver based on the consumption pattern for the largest resource only, especially when combined with correlation-based rules to group resources. We vary properties of the underlying cost structure (such as the skewness in resource costs, the traceability of resources to products, the sharing of resources across products, and the variance in resource consumption patterns) to address the generalizability of our findings and to show when different heuristics might be preferred. This paper was accepted by Stefan Reichelstein, accounting.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Evaluating Heuristics Used When Designing Product Costing Systems", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1293", "ex:pages": "520-541", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["costing", "estimation", "activity-based costing", "cost drivers", "cost pools"], "ex:creator": [{"ex:name": "Ramji Balakrishnan", "ex:email": "ramji-balakrishnan@uiowa.edu"}, {"ex:name": "Stephen Hansen", "ex:email": "shansen@gwu.edu"}, {"ex:name": "Eva Labro", "ex:email": "eva_labro@unc.edu"}]}, {"ex:issue": "3", "ex:abstract": "This paper presents a new model of probabilistic binary choice under risk. In this model, a decision maker always satisfies first-order stochastic dominance. If neither lottery stochastically dominates the other alternative, a decision maker chooses in a probabilistic manner. The proposed model is derived from four standard axioms (completeness, weak stochastic transitivity, continuity, and common consequence independence) and two relatively new axioms. The proposed model provides a better fit to experimental data than do existing models. The baseline model can be extended to other domains such as modeling variable consumer demand. This paper was accepted by Peter Wakker, decision analysis.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "A Model of Probabilistic Choice Satisfying First-Order Stochastic Dominance", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1285", "ex:pages": "542-548", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["probabilistic choice", "first-order stochastic dominance", "random utility", "strong utility"], "ex:creator": [{"ex:name": "Pavlo R. Blavatskyy", "ex:email": "pavlo.blavatskyy@uibk.ac.at"}]}, {"ex:issue": "3", "ex:abstract": "Prior firm experience, firm capabilities, and the industry environment are known to be important determinants of new-venture performance. We hypothesize that firm experience prior to setting up a new venture influences the ability to learn from experience after start-up (which is a key capability), and that this relationship is moderated by the importance of learning by doing within the new venture's industry (which is a critical aspect of the industry environment). We argue that together, these relationships influence performance differences among new plant ventures of incumbents, diversifying entrants, and entrepreneurial (de novo) entrants. Using data on 47,915 new plant ventures in U.S. manufacturing, we find that incumbents and diversifying entrants establish significantly more productive new plants than de novo entrants, and that this advantage significantly increases with the importance of learning by doing in an industry (industry learning intensity). These productivity differences appear to be driven more by learning subsequent to plant start-up than by initial disparities in productivity. Together, these findings strongly suggest that pre-start-up experience adds to the process of post-start-up learning, and that the industry learning environment plays an important role in whether entrepreneurial firms can achieve a competitive advantage over existing firms. This paper was accepted by Lee Fleming, entrepreneurship.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "New Plant Venture Performance Differences Among Incumbent, Diversifying, and Entrepreneurial Firms: The Impact of Industry Learning Intensity", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1294", "ex:pages": "549-565", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["entrepreneurs", "learning environment", "pre-start-up experience", "dynamic capabilities"], "ex:creator": [{"ex:name": "Natarajan Balasubramanian", "ex:email": "nabalasu@syr.edu"}]}, {"ex:issue": "3", "ex:abstract": "This paper studies the incentive for vertical information sharing in competing supply chains with production technologies that exhibit diseconomies of scale. We consider a model of two supply chains each consisting of one manufacturer selling to one retailer, with the retailers engaging in Cournot or Bertrand competition. For Cournot retail competition, we show that information sharing benefits a supply chain when (1) the production diseconomy is large and (2) either competition is less intense or at least one retailer's information is less accurate. A supply chain may become worse off when making its information more accurate or production diseconomy smaller, if such an improvement induces the firms in the rival supply chain to cease sharing information. For Bertrand retail competition, we show that information sharing benefits a supply chain when (1) the production diseconomy is large and (2) either competition is less intense or information is more accurate. Under Bertrand competition a manufacturer may be worse off by receiving information, which is never the case under Cournot competition. Information sharing in one supply chain triggers a competitive reaction from the other supply chain and this reaction is damaging to the first supply chain under Cournot competition but may be beneficial under Bertrand competition. This paper was accepted by Martin Lariviere, operations management.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Sharing Demand Information in Competing Supply Chains with Production Diseconomies", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1295", "ex:pages": "566-581", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["supply chain management", "supply chain competition", "information sharing"], "ex:creator": [{"ex:name": "Albert Y. Ha", "ex:email": "imayha@ust.hk"}, {"ex:name": "Shilu Tong", "ex:email": "sl.tong@unsw.edu.au"}, {"ex:name": "Hongtao Zhang", "ex:email": "imhzhang@ust.hk"}]}, {"ex:issue": "3", "ex:abstract": "This paper introduces a parameter-free method for measuring the weighting functions of prospect theory and rank-dependent utility. These weighting functions capture risk attitudes, subjective beliefs, and ambiguity attitudes. Our method, called the midweight method, is based on a convenient way to obtain midpoints in the weighting function scale. It can be used both for risk (known probabilities) and for uncertainty (unknown probabilities). The resulting integrated treatment of risk and uncertainty is particularly useful for measuring ambiguity, i.e., the difference between uncertainty and risk. Compared to existing methods to measure weighting functions and attitudes toward uncertainty and ambiguity, our method is more efficient and can accommodate violations of expected utility under risk. An experiment demonstrates the tractability of our method, yielding plausible results such as ambiguity aversion for moderate and high likelihoods but ambiguity seeking for low likelihoods, as predicted by Ellsberg. This paper was accepted by George Wu, decision analysis.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "The Midweight Method to Measure Attitudes Toward Risk and Ambiguity", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1282", "ex:pages": "582-598", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["prospect theory", "ambiguity", "probability weighting", "pessimism"], "ex:creator": [{"ex:name": "Gijs van de Kuilen", "ex:email": "g.v.d.kuilen@uvt.nl"}, {"ex:name": "Peter P. Wakker", "ex:email": "wakker@ese.eur.nl"}]}, {"ex:issue": "3", "ex:abstract": "We investigate firms' competitive behaviors in industries where customers are sensitive to both promised delivery time (PDT) and quality of service (QoS) measured by the on-time delivery rate. To study the competition in PDT at the marketing level, we construct an oligopoly game with an external QoS requirement. We show that there exists a unique Nash equilibrium, and the equilibrium QoS exhibits a switching surface structure with respect to capacities. To study the competition in capacity at the strategic level, we construct a two-stage game in which the firms compete in terms of their capacities in stage 1 and in terms of PDT in stage 2. We show the existence of two different types of pure strategy equilibria and characterize them. This study provides the following insights: an index of time-based competitive advantage (ITCA) and the first-mover advantage determine the positions of the firms in time-based competition; either the well-known prisoner's dilemma or off-equilibrium behaviors due to different preferences for equilibria (when multiple equilibria exist) may lead the firms to overinvest in capacity, but no one may gain a competitive advantage; a uniform improvement in internal efficiency (i.e., a uniform capacity cost reduction) may harm everyone; quality differentiation (i.e., going beyond the QoS benchmark) plays a dual role in time-based competition, either helping a firm with a larger ITCA to compete more effectively, or helping a firm possibly with a smaller ITCA to preempt competitors and protect its market advantage. This paper was accepted by Paul H. Zipkin, operations and supply chain management.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Promised Delivery Time and Capacity Games in Time-Based Competition", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1292", "ex:pages": "599-610", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["time-based competition", "consumer choice model", "Nash equilibrium", "switching surface", "quality differentiation", "capacity competition", "marketing-operations interface"], "ex:creator": [{"ex:name": "Weixin Shang", "ex:email": "shangwx@fudan.edu.cn"}, {"ex:name": "Liming Liu", "ex:email": "lgtliulm@polyu.edu.hk"}]}, {"ex:issue": "4", "ex:abstract": "No abstract available.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Management Insights", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1347", "ex:pages": "iv-vi", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": [], "ex:creator": [{"ex:name": "Michael F. Gorman", "ex:email": "michael.gorman@udayton.edu"}]}, {"ex:issue": "4", "ex:abstract": "Although relative performance schemes are pervasive in organizations, reliable empirical data on induced sabotage behavior are almost nonexistent. We study sabotage in repeated tournaments in a controlled laboratory experiment and observe that effort and sabotage are higher for higher wage spreads. Additionally, we find that also in the presence of tournament incentives, agents react reciprocally to higher wages by exerting higher effort. Destructive activities are reduced by explicitly calling them by their name \"sabotage.\" Communication among principal and agents can curb sabotage when they agree on flat prize structures and increased output. If sabotage is not possible, the principals choose tournament incentives more often. This paper was accepted by Peter Wakker, decision analysis.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Sabotage in Tournaments: Evidence from a Laboratory Experiment", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1296", "ex:pages": "611-627", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["decision analysis", "applications", "organizational studies", "decision making", "motivation", "incentives"], "ex:creator": [{"ex:name": "Christine Harbring", "ex:email": "christine.harbring@rwth-aachen.de"}, {"ex:name": "Bernd Irlenbusch", "ex:email": "bernd.irlenbusch@uni-koeln.de"}]}, {"ex:issue": "4", "ex:abstract": "We develop a unified model of the interactions among investors, fund companies, and fund managers. We show that the interplay between a manager's incentives from her compensation structure and career concerns leads to a nonmonotonic (approximately U-shaped) relation between her risk choices and prior performance relative to her peers. Significantly outperforming (underperforming) managers are less (more) likely to be fired in the future and are also more likely to increase relative risk. Ceteris paribus, relative risk declines with the level of employment risk faced by a manager. Using a large sample of mutual fund managers, we find strong support for the hypothesized U-shaped relation between relative risk and prior performance. Our findings also highlight the importance of employment risk as the underlying driver of risk shifting by fund managers. Our theoretical model also generates additional hypotheses that link determinants of the fund flow-performance relation and managers' employment risk to their risk-taking behavior. In support, our empirical analysis shows that funds with higher expense ratios have less convex fund flow-performance relations and less convex U-shaped relations between relative risk and prior performance; funds with younger managers, who face greater employment risk, have more convex U-shaped relative risk-prior performance relations; and managers in larger fund families have lower incentives to engage in risk shifting, thereby leading to a less convex U-shaped relation. This paper was accepted by Wei Xiong, finance.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Fund Flows, Performance, Managerial Career Concerns, and Risk Taking", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1305", "ex:pages": "628-646", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["mutual funds", "asset flows", "relative risk", "ability", "career concerns", "employment risk"], "ex:creator": [{"ex:name": "Ping Hu", "ex:email": "ping.hu@wachovia.com"}, {"ex:name": "Jayant R. Kale", "ex:email": "jkale@gsu.edu"}, {"ex:name": "Marco Pagani", "ex:email": "marco.pagani@sjsu.edu"}, {"ex:name": "Ajay Subramanian", "ex:email": "insasu@langate.gsu.edu"}]}, {"ex:issue": "4", "ex:abstract": "We consider a complex planning problem in integrated steel production. A sequence of coils of sheet metal needs to be color coated in consecutive stages. Different coil geometries and changes of colors necessitate time-consuming setup work. In most coating stages one can choose between two parallel color tanks. This can either reduce the number of setups needed or enable setups concurrent with production. A production plan comprises the sequencing of coils and the scheduling of color tanks and setup work. The aim is to minimize the makespan for a given set of coils. We present an optimization model for this integrated sequencing and scheduling problem. A core component is a graph theoretical model for concurrent setup scheduling. It is instrumental for building a fast heuristic that is embedded into a genetic algorithm to solve the sequencing problem. The quality of our solutions is evaluated via an integer program based on a combinatorial relaxation, showing that our solutions are within 10% of the optimum. Our algorithm is implemented at Salzgitter Flachstahl GmbH, a major German steel producer. This has led to an average reduction in makespan by over 13% and has greatly exceeded expectations. This paper was accepted by Dimitris Bertsimas, optimization.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Integrated Sequencing and Scheduling in Coil Coating", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1302", "ex:pages": "647-666", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["sequencing", "scheduling", "integrated steel production", "coil coating", "2-union graphs", "independent set", "branch-and-price"], "ex:creator": [{"ex:name": "Wiebke Hhn", "ex:email": "hoehn@math.tu-berlin.de"}, {"ex:name": "Felix G. Knig", "ex:email": "fkoenig@math.tu-berlin.de"}, {"ex:name": "Rolf H. Mhring", "ex:email": "rolf.moehring@tu-berlin.de"}, {"ex:name": "Marco E. Lbbecke", "ex:email": "marco.luebbecke@rwth-aachen.de"}]}, {"ex:issue": "4", "ex:abstract": "Theoretical models of information asymmetry have identified a trade-off between the desire to learn and the desire to prevent an opponent from learning private information. This paper reports a laboratory experiment that investigates if actual bidders account for this trade-off, using a sequential procurement auction with private cost information and varying information revelation policies. Specifically, the Complete Information Revelation Policy, where all submitted bids are revealed between auctions, is compared to the Incomplete Information Revelation Policy, where only the winning bid is revealed. The experimental results are largely consistent with the theoretical predictions. For example, bidders pool with other types to prevent an opponent from learning significantly more often under a Complete Information Revelation Policy. Also as predicted, the procurer pays less when employing an Incomplete Information Revelation Policy only when the market is highly competitive. Bids are usually more aggressive than the risk-neutral quantitative prediction, which is broadly consistent with risk aversion. This paper was accepted by Teck Ho, decision analysis.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "An Experimental Study of Information Revelation Policies in Sequential Auctions", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1301", "ex:pages": "667-688", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["complete and incomplete information revelation policies", "laboratory study", "procurement auction", "multistage game"], "ex:creator": [{"ex:name": "Timothy N. Cason", "ex:email": "cason@purdue.edu"}, {"ex:name": "Karthik N. Kannan", "ex:email": "kkarthik@purdue.edu"}, {"ex:name": "Ralph Siebert", "ex:email": "rsiebert@purdue.edu"}]}, {"ex:issue": "4", "ex:abstract": "Exploring the tension between theory and practice regarding complexity and performance in contract design is especially relevant. The goal of this paper is to understand why simpler contracts may commonly be preferred in practice despite being theoretically suboptimal. We study a two-tier supply chain with a single supplier and a single buyer to characterize the impact of contract complexity and asymmetric information on performance and to compare theoretical predictions to actual behavior in human subject experiments. In the experiments, the computerized buyer faces a newsvendor setting and has better information on end-consumer demand than the human supplier. The supplier offers either a quantity discount contract (with two or three price blocks) or a price-only contract, contracts that are commonplace in practice, yet different in complexity. Results show that, contrary to theoretical predictions, quantity discounts do not necessarily increase the supplier's profits. We also observe a more equitable distribution of profits between the supplier and the buyer than what theory predicts. These observations can be described with three decision biases (the probabilistic choice bias, the reinforcement bias, and the memory bias) and can be modeled using the experience-weighted attraction learning model. Our results demonstrate that simpler contracts, such as a price-only contract or a quantity discount contract with a low number of price blocks, are sufficient for a supplier designing contracts under asymmetric demand information. This paper was accepted by Christian Terwiesch, operations and supply chain management.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Contract Complexity and Performance Under Asymmetric Demand Information: An Experimental Evaluation", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1318", "ex:pages": "689-704", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["behavioral operations management", "all-unit quantity discount contracts", "price-only contracts", "complex contracts", "contract performance", "supply chain efficiency", "asymmetric demand information", "experience-weighted attraction learning model"], "ex:creator": [{"ex:name": "Basak Kalkanci", "ex:email": "kalkanci@stanford.edu"}, {"ex:name": "Kay-Yut Chen", "ex:email": "kychen@hpl.hp.com"}, {"ex:name": "Feryal Erhun", "ex:email": "ferhun@stanford.edu"}]}, {"ex:issue": "4", "ex:abstract": "This article develops a method for drawing samples from a distribution with no finite quantiles or moments. The method provides researchers with a way to give subjects the experience of ambiguity. In any experiment, learning the distribution from experience is impossible for the subjects, essentially because it is impossible for the experimenter. We characterize our method, illustrate it in simulations, and then test it in a laboratory experiment. Our method does not withhold sampling information, does not assume that the subject is incapable of making statistical inferences, is replicable across experiments, and requires no special apparatus. We compare our method to the techniques used in related experiments that attempt to produce an ambiguous experience for the subjects. This paper was accepted by Peter Wakker, decision analysis.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Generating Ambiguity in the Laboratory", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1307", "ex:pages": "705-712", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["ambiguity", "Ellsberg", "Knightian uncertainty", "laboratory experiments", "decision analysis", "theory"], "ex:creator": [{"ex:name": "Jack Stecher", "ex:email": "jstecher@cmu.edu"}, {"ex:name": "Timothy Shields", "ex:email": "shields@chapman.edu"}, {"ex:name": "John Dickhaut (deceased)"}]}, {"ex:issue": "4", "ex:abstract": "Provision of real-time information by a firm to its customers has become prevalent in recent years in both the service and retail sectors. In this paper, we study a retail operations model where customers are strategic in both their actions and in the way they interpret information, whereas the retailer is strategic in the way it provides information. This paper focuses on the ability (or the lack thereof) to communicate unverifiable information and influence customers' actions. We develop a game-theoretic framework to study this type of communication and discuss the equilibrium language emerging between the retailer and its customers. We show that for a single retailer and homogeneous customer population setting, the equilibrium language that emerges carries no information. In this sense, a single retailer providing information on its own cannot create any credibility with the customers. We study how the results are impacted due to the heterogeneity of the customers. We provide conditions under which the firm may be able to influence the customer behavior. In particular, we show that the customers' willingness to pay and willingness to wait cannot be ranked in an opposite manner. However, even when the firm can influence each customer class separately, the effective demand is not impacted. This paper was accepted by Yossi Aviv, operations management.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Buying from the Babbling Retailer? The Impact of Availability Information on Customer Behavior", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1306", "ex:pages": "713-726", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["inventory", "cheap talk", "revenue management"], "ex:creator": [{"ex:name": "Gad Allon", "ex:email": "g-allon@kellogg.northwestern.edu"}, {"ex:name": "Achal Bassamboo", "ex:email": "a-bassamboo@kellogg.northwestern.edu"}]}, {"ex:issue": "4", "ex:abstract": "A service plan is a type of optional warranty beyond manufacturers' base warranties that retailers offer to consumers. In this paper, we examine how a service plan affects the role played by a manufacturer's base warranty. Analysis shows that when consumers can assess product quality (i.e., the probability of product failure), the manufacturer's warranty is negatively affected by the presence of a service plan. In the presence of such a plan, a base warranty is offered only when the manufacturer is very cost-efficient in providing a warranty relative to the retailer. In this case, although the double-marginalization problem is aggravated, offering a (limited) base warranty reduces the total warranty cost in the channel and provokes the retailer into enlarging the service plan coverage. When consumers cannot assess product quality, a high-quality manufacturer is motivated to offer a base warranty to signal its quality. In the presence of a service plan, however, a very cost-efficient manufacturer is discouraged from doing so. This paper was accepted by Preyas Desai, marketing.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "How Does a Retailer's Service Plan Affect a Manufacturer's Warranty?", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1308", "ex:pages": "727-740", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["service plans", "warranty", "signaling", "distribution channels", "game theory"], "ex:creator": [{"ex:name": "Bo Jiang", "ex:email": "jiangbo@baf.msmail.cuhk.edu.hk"}, {"ex:name": "Xubing Zhang", "ex:email": "msxubing@polyu.edu.hk"}]}, {"ex:issue": "4", "ex:abstract": "Upward channel decentralization occurs when firms choose to not manufacture products by themselves and procure products from upstream suppliers. Current voices from marketing scholars and practitioners have predominantly focused on the cost benefits when production is outsourced to lower-cost upstream suppliers. In this paper, we study the effects of upward channel decentralization where competing firms can outsource their production to upstream suppliers who do not have any advantages on production costs. We show how downstream firms can still benefit from upward channel decentralization provided their product positioning is endogenous. Thus, we provide a new theory on the strategic benefits of upward channel decentralization. We also use this framework to show a new benefit to manufacturers selling through downstream retailers rather than directly. We examine the implications of our theory for consumer and social welfare, and also draw managerial implications. This paper was accepted by Pradeep Chintagunta, marketing.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "The Benefits of Competitive Upward Channel Decentralization", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1311", "ex:pages": "741-751", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["upward channel decentralization", "production outsourcing", "product positioning", "distribution channel", "game theory"], "ex:creator": [{"ex:name": "Yunchuan Liu", "ex:email": "liuf@uiuc.edu"}, {"ex:name": "Rajeev K. Tyagi", "ex:email": "rktyagi@uci.edu"}]}, {"ex:issue": "4", "ex:abstract": "Comarketing alliances often involve multiple partners, and a given partner's marketing efforts on behalf of the alliance can indirectly affect the demand of the other partners. Individual partners, however, can ignore the effects of such an externality and invest suboptimally to the detriment of the alliance. This paper examines the relative effectiveness of outcome- and action-based contracts in providing the alliance partners with the incentives to invest appropriately. We develop a mathematical model in which a focal firm (e.g., Sony) contracts with two partners (e.g., McDonald's and Old Navy) when each of these partners is privately informed about the impact of the alliance on its demand. Our analysis evaluates the strengths and weaknesses of outcome- (or output-) and action-based (or input-based) contracts in settings with varying levels of the demand externality. We find that when there is either no externality or a relatively weak positive externality, there is a strict preference for output-based contracts; that preference, however, is reversed with a sufficiently strong positive externality. This paper explains the underlying rationale for these findings. This paper was accepted by Preyas Desai, marketing.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Comarketing Alliances: Should You Contract on Actions or Outcomes?", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1297", "ex:pages": "752-762", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["comarketing alliances", "marketing externality", "information asymmetry", "input versus output monitoring"], "ex:creator": [{"ex:name": "Pavan Rao Chennamaneni", "ex:email": "chennamp@uww.edu"}, {"ex:name": "Ramarao Desiraju", "ex:email": "rdesiraju@bus.ucf.edu"}]}, {"ex:issue": "4", "ex:abstract": "We analyze the competitive capacity investment timing decisions of both established firms and start-ups entering new markets, which have a high degree of demand uncertainty. Firms may invest in capacity early (when uncertainty is high) or late (when uncertainty has been resolved), possibly at different costs. Established firms choose an investment timing and capacity level to maximize expected profits, whereas start-ups make those choices to maximize the probability of survival. When a start-up competes against an established firm, we find that when demand uncertainty is high and costs do not decline too severely over time, the start-up takes a leadership role and invests first in capacity, whereas the established firm follows; by contrast, when two established firms compete in an otherwise identical game, both firms invest late. We conclude that the threat of firm failure significantly impacts the dynamics of competition involving start-ups. This paper was accepted by Yossi Aviv, operations management.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Capacity Investment Timing by Start-ups and Established Firms in New Markets", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1309", "ex:pages": "763-777", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["capacity", "competition", "uncertainty", "investment timing", "game theory"], "ex:creator": [{"ex:name": "Robert Swinney", "ex:email": "swinney@stanford.edu"}, {"ex:name": "Grard P. Cachon", "ex:email": "cachon@wharton.upenn.edu"}, {"ex:name": "Serguei Netessine", "ex:email": "serguei.netessine@insead.edu"}]}, {"ex:issue": "4", "ex:abstract": "A fast fashion system combines quick response production capabilities with enhanced product design capabilities to both design \"hot\" products that capture the latest consumer trends and exploit minimal production lead times to match supply with uncertain demand. We develop a model of such a system and compare its performance to three alternative systems: quick-response-only systems, enhanced-design-only systems, and traditional systems (which lack both enhanced design and quick response capabilities). In particular, we focus on the impact of each of the four systems on \"strategic\" or forward-looking consumer purchasing behavior, i.e., the intentional delay in purchasing an item at the full price to obtain it during an end-of-season clearance. We find that enhanced design helps to mitigate strategic behavior by offering consumers a product they value more, making them less willing to risk waiting for a clearance sale and possibly experiencing a stockout. Quick response mitigates strategic behavior through a different mechanism: by better matching supply to demand, it reduces the chance of a clearance sale. Most importantly, we find that although it is possible for quick response and enhanced design to be either complements or substitutes, the complementarity effect tends to dominate. Hence, when both quick response and enhanced design are combined in a fast fashion system, the firm typically enjoys a greater incremental increase in profit than the sum of the increases resulting from employing either system in isolation. Furthermore, complementarity is strongest when customers are very strategic. We conclude that fast fashion systems can be of significant value, particularly when consumers exhibit strategic behavior. This paper was accepted by Yossi Aviv, operations management.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "The Value of Fast Fashion: Quick Response, Enhanced Design, and Strategic Consumer Behavior", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1303", "ex:pages": "778-795", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["strategic consumer behavior", "quick response", "fast fashion", "game theory"], "ex:creator": [{"ex:name": "Grard P. Cachon", "ex:email": "cachon@wharton.upenn.edu"}, {"ex:name": "Robert Swinney", "ex:email": "swinney@stanford.edu"}]}, {"ex:issue": "5", "ex:abstract": "No abstract available.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Management Insights", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1372", "ex:pages": "iv-vi", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": [], "ex:creator": [{"ex:name": "Michael F. Gorman", "ex:email": "michael.gorman@udayton.edu"}]}, {"ex:issue": "5", "ex:abstract": "Consistent with public statements made by sophisticated practitioners, we document that the hedge returns to Sloan's (Sloan, R. G. 1996. Do stock prices fully reflect information in accruals and cash flows about future earnings? Accounting Rev. 71(3) 289-315) accruals anomaly appear to have decayed in U.S. stock markets to the point that they are, on average, no longer reliably positive. We explore some potential reasons why this has happened. Our empirical analyses suggest that the anomaly's demise stems in part from an increase in the amount of capital invested by hedge funds into exploiting it, as measured by hedge fund assets under management and trading volume in extreme accrual firms. A decline in the size of the accrual mispricing signal, as measured by the magnitude of extreme decile accruals and the relative persistence of cash flows and accruals, may also play a (weaker) role. This paper was accepted by Stefan Reichelstein, accounting.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Going, Going, Gone? The Apparent Demise of the Accruals Anomaly", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1320", "ex:pages": "797-816", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["accruals anomaly", "market efficiency", "hedge funds"], "ex:creator": [{"ex:name": "Jeremiah Green", "ex:email": "jrg28@psu.edu"}, {"ex:name": "John R. M. Hand", "ex:email": "hand@unc.edu"}, {"ex:name": "Mark T. Soliman", "ex:email": "msoliman@u.washington.edu"}]}, {"ex:issue": "5", "ex:abstract": "Individuals, groups, and teams who are behind their opponents in competition tend to be more likely to lose. In contrast, we show that through increasing motivation, being slightly behind can actually increase success. Analysis of more than 18,000 professional basketball games illustrates that being slightly behind at halftime leads to a discontinuous increase in winning percentage. Teams behind by a point at halftime, for example, actually win more often than teams ahead by one, or approximately six percentage points more often than expected. This psychological effect is roughly half the size of the proverbial home-team advantage. Analysis of more than 45,000 collegiate basketball games finds consistent, though smaller, results. Experiments corroborate the field data and generalize their findings, providing direct causal evidence that being slightly behind increases effort and casting doubt on alternative explanations for the results. Taken together, these findings illustrate that losing can sometimes lead to winning. This paper was accepted by Peter Wakker, decision analysis.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Can Losing Lead to Winning?", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1328", "ex:pages": "817-827", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["competition", "motivation", "performance", "prospect theory"], "ex:creator": [{"ex:name": "Jonah Berger", "ex:email": "jberger@wharton.upenn.edu"}, {"ex:name": "Devin Pope", "ex:email": "devin.pope@chicagobooth.edu"}]}, {"ex:issue": "5", "ex:abstract": "Popularity information is usually thought to reinforce existing sales trends by encouraging customers to flock to mainstream products with broad appeal. We suggest a countervailing market force: popularity information may benefit niche products with narrow appeal disproportionately, because the same level of popularity implies higher quality for narrow-appeal products than for broad-appeal products. We examine this hypothesis empirically using field experiment data from a website that lists wedding service vendors. Our findings are consistent with this hypothesis: narrow-appeal vendors receive more visits than equally popular broad-appeal vendors after the introduction of popularity information. This paper was accepted by Pradeep Chintagunta, marketing.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "How Does Popularity Information Affect Choices? A Field Experiment", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1312", "ex:pages": "828-842", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["popularity information", "observational learning", "field experiment", "Internet marketing"], "ex:creator": [{"ex:name": "Catherine Tucker", "ex:email": "cetucker@mit.edu"}, {"ex:name": "Juanjuan Zhang", "ex:email": "jjzhang@mit.edu"}]}, {"ex:issue": "5", "ex:abstract": "Contests are a historically important and increasingly popular mechanism for encouraging innovation. A central concern in designing innovation contests is how many competitors to admit. Using a unique data set of 9,661 software contests, we provide evidence of two coexisting and opposing forces that operate when the number of competitors increases. Greater rivalry reduces the incentives of all competitors in a contest to exert effort and make investments. At the same time, adding competitors increases the likelihood that at least one competitor will find an extreme-value solution. We show that the effort-reducing effect of greater rivalry dominates for less uncertain problems, whereas the effect on the extreme value prevails for more uncertain problems. Adding competitors thus systematically increases overall contest performance for high-uncertainty problems. We also find that higher uncertainty reduces the negative effect of added competitors on incentives. Thus, uncertainty and the nature of the problem should be explicitly considered in the design of innovation tournaments. We explore the implications of our findings for the theory and practice of innovation contests. This paper was accepted by Christian Terwiesch, operations management.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Incentives and Problem Uncertainty in Innovation Contests: An Empirical Analysis", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1322", "ex:pages": "843-863", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["innovation contests", "uncertainty", "innovation", "problem solving", "tournaments"], "ex:creator": [{"ex:name": "Kevin J. Boudreau", "ex:email": "kboudreau@london.edu"}, {"ex:name": "Nicola Lacetera", "ex:email": "nicola.lacetera@utoronto.ca"}, {"ex:name": "Karim R. Lakhani", "ex:email": "k@hbs.edu"}]}, {"ex:issue": "5", "ex:abstract": "Is the right amount of effort exerted in multiperson tournaments where contestants have two different levels of initial endowments (termed \"favorites\" and \"underdogs\")? We develop theoretical predictions for the level of effort and the effect of varying the prize structure. We test these predictions for three-person tournaments using an economic experiment in a social environment where contest outcomes are publicly announced. We find that both favorites and underdogs overexert effort relative to the theoretical point predictions. Moreover, in the treatment with two favorites and one underdog, favorites increase their effort when the number of prizes is increased from one to two, contrary to the theory prediction. We show that a generalized model that allows for psychological losses from losing for favorites and psychological gains from winning for underdogs because of social comparisons tracks the experimental results better than the standard theoretical model. This paper was accepted by Peter Wakker, decision analysis.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Designing Multiperson Tournaments with Asymmetric Contestants: An Experimental Study", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1325", "ex:pages": "864-883", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["tournaments", "compensation", "sales management", "experimental economics", "behavioral economics"], "ex:creator": [{"ex:name": "Hua Chen", "ex:email": "hchen26@uh.edu"}, {"ex:name": "Sung H. Ham", "ex:email": "sham@kent.edu"}, {"ex:name": "Noah Lim", "ex:email": "nlim@bus.wisc.edu"}]}, {"ex:issue": "5", "ex:abstract": "This paper derives two mechanisms through which Bayesian-rational individuals with differing priors will tend to be relatively overconfident about their estimates and predictions, in the sense of overestimating the precision of these estimates. The intuition behind one mechanism is slightly ironic: In trying to update optimally, Bayesian agents overweight information of which they overestimate the precision and underweight in the opposite case. This causes overall an overestimation of the precision of the final estimate, which tends to increase as agents get more data. This paper was accepted by Teck Ho, decision analysis.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Overconfidence by Bayesian-Rational Agents", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1323", "ex:pages": "884-896", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["overconfidence", "decision analysis", "risk", "Bayesian updating", "differing priors", "heterogeneous priors"], "ex:creator": [{"ex:name": "Eric Van den Steen", "ex:email": "evandensteen@hbs.edu"}]}, {"ex:issue": "5", "ex:abstract": "We examine, in a strategic setting, the broad issue of how retail channel structures--retail monopoly versus retail duopoly--impact a manufacturer's optimal new product design, both in terms of engineering design specifications as well as manufacturer and retailer profits. Our strategic framework enables manufacturers in specific contexts to anticipate the reactions of the retailers and competitive manufacturers to new designs in terms of the retail and wholesale pricing and to understand how different channel structures and channel strategies (such as an exclusive channel strategy) impact the engineering design of the new product, conditional on consumer preference distributions and competitor product attributes. Based on a simple numerical and a power tool design example, we illustrate how the insight from the framework translates to design guidelines; specifically, understanding which designs are optimal under differing channel structure conditions, and which design variables need precise targeting given their profit sensitivity. This paper was accepted by Christoph Loch, R&D and product development.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Retail Channel Structure Impact on Strategic Engineering Product Design", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1326", "ex:pages": "897-914", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["new product design", "engineering design", "research and development", "retail channels", "marketing", "game theory", "genetic algorithms", "latent class models", "structural models"], "ex:creator": [{"ex:name": "Nathan Williams", "ex:email": "nathan.n.williams@shell.com"}, {"ex:name": "P. K. Kannan", "ex:email": "pkannan@rhsmith.umd.edu"}, {"ex:name": "Shapour Azarm", "ex:email": "azarm@umd.edu"}]}, {"ex:issue": "5", "ex:abstract": "To what extent are firms kept out of a market by patents covering related technologies? Do patents held by potential entrants make it easier to enter markets? We estimate the empirical relationship between market entry and patents for 27 narrowly defined categories of software products during the period 1990-2004. Controlling for demand, market structure, average patent quality, and other factors, we find that a 10% increase in the number of patents relevant to market reduces the rate of entry by 3%-8%, and this relationship intensified following expansions in the patentability of software in the mid-1990s. However, potential entrants with patent applications relevant to a market are more likely to enter it. Finally, patents appear to substitute for complementary assets in the entry process, because patents have both greater entry-deterring and entry-promoting effects for firms without prior experience in other markets. This paper was accepted by Bruno Cassiman, business strategy.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Entry and Patenting in the Software Industry", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1321", "ex:pages": "915-933", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["innovation", "intellectual property rights", "software patents", "entry"], "ex:creator": [{"ex:name": "Iain M. Cockburn", "ex:email": "cockburn@bu.edu"}, {"ex:name": "Megan J. MacGarvie", "ex:email": "mmacgarv@bu.edu"}]}, {"ex:issue": "5", "ex:abstract": "In recent years, vendor liability for software security vulnerabilities has been the center of an important debate in the software community and a topic gaining government attention in legislative committees and hearings. The importance of this question surrounding vendor security liability is amplified when one considers the increasing emergence of zero-day attacks where hackers take advantage of vulnerabilities before the software vendor has a chance to release protective patches. In this paper, we compare the effectiveness of three software liability policies: vendor liability for damages, vendor liability for patching costs, and government imposed security standards. We find that vendor liability for losses is not effective in improving social welfare in the short run, while liability for patching costs can be effective if either patching costs are large and the likelihood of a zero-day attack is low, or patching costs are small and zero-day likelihood is high. In the long run, when the vendor can invest in reducing the likelihood of security vulnerabilities, loss liability is still ineffective when the zero-day attack probability is high but can increase both vendor investment in security and social welfare when zero-day attack likelihood is sufficiently low. When the zero-day attack probability is high, patch liability is ineffective if user patching costs are large, but partial patch liability can boost vendor investment and improve welfare when patching costs are small. In contrast, in an environment with low zero-day attack probability, full vendor patch liability can be optimal. Finally, comparing the effectiveness of the three liability policies under study, we find that government imposed standards on software security investment can be preferable to both patching and loss liability on the vendor, if zero-day attack likelihood is sufficiently low. However, if zero-day attacks are a common occurrence and patching costs are not too high, partial patch liability is the most effective policy. This paper was accepted by Sandra Slaughter, information systems.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Who Should Be Responsible for Software Security? A Comparative Analysis of Liability Policies in Network Environments", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1304", "ex:pages": "934-959", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["IT policy and management", "economics of IS", "network economics", "enabling technologies", "software", "liability", "zero-day"], "ex:creator": [{"ex:name": "Terrence August", "ex:email": "taugust@ucsd.edu"}, {"ex:name": "Tunay I. Tunca", "ex:email": "tunca_tunay@gsb.stanford.edu"}]}, {"ex:issue": "5", "ex:abstract": "We introduce two new methods to calculate bounds for zero-sum game options using Monte Carlo simulation. These extend and generalize upper-bound duality results to the case where both parties of a contract have Bermudan optionality. It is shown that the primal-dual simulation method can still be used as a generic way to obtain bounds in the extended framework, and we apply the new results to the pricing of convertible bonds by simulation. This paper was accepted by Wei Xiong, finance.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Monte Carlo Bounds for Game Options Including Convertible Bonds", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1319", "ex:pages": "960-974", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["finance", "asset pricing", "games-group decisions", "stochastic", "probability", "stochastic model applications", "Monte Carlo simulation", "Bermudan optionality"], "ex:creator": [{"ex:name": "Christopher Beveridge", "ex:email": "chrisjbeveridge@gmail.com"}, {"ex:name": "Mark Joshi", "ex:email": "mark.joshi@unimelb.edu.au"}]}, {"ex:issue": "5", "ex:abstract": "Intertemporal decision making under risk involves two dimensions: time preferences and risk preferences. This paper focuses on the impact of time on risk preferences, independent of the intertemporal trade-off of outcomes, i.e., time preferences. It reports the results of an experimental study that examines how delayed resolution and payment of risky options influence individual choice. We used a simple experimental design based on the comparison of two-outcome monetary lotteries with the same delay. Raw data clearly reveal that subjects become more risk tolerant for delayed lotteries. Assuming a prospect theory-like model under risk, we analyze the impact of time on utility and decision weights, independent of time preferences. We show that the subjective treatment of outcomes (i.e., utility) is not significantly affected by time. In fact, the impact of time is completely absorbed by the probability weighting function. The effect of time on risk preferences was found to generate probabilistic optimism resulting in a higher risk tolerance for delayed lotteries. This paper was accepted by Teck Ho, decision analysis.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Risk Preferences at Different Time Periods: An Experimental Investigation", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1324", "ex:pages": "975-987", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["time preferences", "risk preferences", "delayed lotteries", "attitude toward risk", "utility", "decision weights", "optimism", "sensitivity to probabilities"], "ex:creator": [{"ex:name": "Mohammed Abdellaoui", "ex:email": "abdellaoui@hec.fr"}, {"ex:name": "Enrico Diecidue", "ex:email": "enrico.diecidue@insead.edu"}, {"ex:name": "Ayse ncler", "ex:email": "onculer@essec.fr"}]}, {"ex:issue": "6", "ex:abstract": "No abstract available.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Management Insights", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1387", "ex:pages": "iv-vi", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": [], "ex:creator": [{"ex:name": "Michael F. Gorman", "ex:email": "michael.gorman@udayton.edu"}]}, {"ex:issue": "6", "ex:abstract": "We examine the roots of gender segregation in the screening process by using a longitudinal data set of candidates considered for temporary projects at a staffing firm and following their progress through the hiring pipeline. Theories invoked to explain gender segregation across jobs traditionally rely on firm-specific human capital and expectations of future commitment to explain this phenomenon. These do not apply in this setting. Yet we find that the staffing firm is more likely to shortlist women for low-paid projects and less likely to do so for high-paid ones. These effects are due to women being considered for different projects than men, and associated at least partially to the level of competition within vacancies. Although client companies also exhibit some gender-sorting behavior in the later steps of the hiring process, they are more likely to prefer women and less likely to sort them into lower-paid projects. Our findings are consistent with \"anticipatory gender-sorting\" mechanisms, by which first screeners generate segregation when narrowing down the pool of candidates for later decision makers. We discuss the implications of this case for theories of gender stratification and workplace inequality, especially in mediated labor markets. This paper was accepted by Jesper Srensen, organizations.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Anticipatory Sorting and Gender Segregation in Temporary Employment", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1333", "ex:pages": "989-1008", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["organizational studies", "personnel", "hiring", "gender stratification"], "ex:creator": [{"ex:name": "Isabel Fernandez-Mateo", "ex:email": "ifernandezmateo@london.edu"}, {"ex:name": "Zella King", "ex:email": "z.king@henley.reading.ac.uk"}]}, {"ex:issue": "6", "ex:abstract": "Product variety is an important strategic tool that firms can use to attract customers and respond to competition. This study focuses on the retail industry and investigates how stores manage their product variety, contingent on the presence of competition and their actual distance from rivals. Using a unique data set that contains all Best Buy and Circuit City stores in the United States, the authors find that a store's product variety (i.e., number of stock-keeping units) increases if a rival store exists in its market but, in the presence of such competition, decreases when the rival store is collocated (within one mile of the focal store). Moreover, collocated rival stores tend to differentiate themselves by overlapping less in product range than do noncollocated rivals. This smaller and more differentiated product variety may be because of coordinated interactions between collocated stores. In summary, this paper presents evidence of both coordination and competition in retailers' use of product variety. This paper was accepted by Bruno Cassiman, business strategy.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Managing Product Variety and Collocation in a Competitive Environment: An Empirical Investigation of Consumer Electronics Retailing", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1327", "ex:pages": "1009-1024", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["product variety", "competition", "collocation", "differentiation"], "ex:creator": [{"ex:name": "Charlotte R. Ren", "ex:email": "rren@purdue.edu"}, {"ex:name": "Ye Hu", "ex:email": "yehu@uh.edu"}, {"ex:name": "Yu (Jeffrey) Hu", "ex:email": "yuhu@purdue.edu"}, {"ex:name": "Jerry Hausman", "ex:email": "jhausman@mit.edu"}]}, {"ex:issue": "6", "ex:abstract": "We derive explicit solutions to life-cycle utility maximization problems involving stock and bond investment, perishable consumption, and the rental and ownership of residential real estate. Prices of houses, stocks and bonds, and labor income are correlated. Because of a positive correlation between house prices and labor income, young individuals want little exposure to house price risk and tend to rent their home. Later in life the desired housing investment increases and will eventually reach and exceed the desired consumption, suggesting that the individual should buy his home--and either additional housing units (for renting out) or house price-linked financial assets. In the final years, preferences shift back to home rental. The derived strategies are still useful if housing positions are only reset infrequently. Our results suggest that markets for real estate investment trusts or other house price-linked contracts lead to nonnegligible welfare gains. This paper was accepted by Wei Xiong, finance.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Optimal Housing, Consumption, and Investment Decisions over the Life Cycle", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1336", "ex:pages": "1025-1041", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["housing", "labor income", "portfolio choice", "life-cycle decisions", "REITs"], "ex:creator": [{"ex:name": "Holger Kraft", "ex:email": "holgerkraft@finance.uni-frankfurt.de"}, {"ex:name": "Claus Munk", "ex:email": "cmunk@econ.au.dk"}]}, {"ex:issue": "6", "ex:abstract": "We use a behavioral laboratory experiment to study how agents with reputation concerns select the difficulty of their tasks. Drawing upon existing theory, we subjected participants in our study to a context in which they had to convince a principal of their capability to reap financial benefits. Our results show that participants tended to increase the difficulty of their task to enhance their reputation. In addition, we provide evidence that performance rewards reduce a less capable agent's tendency to choose a more difficult task, whereas a highly capable agent's pattern of choices is unaffected by performance rewards. Although the productivity of agents in our experiment therefore decreased if they had to convince a principal of their capability, we show that these detrimental performance implications can to some degree be overcome for less capable agents through performance rewards or by ensuring that the principal can interpret the agent's choice. This paper was accepted by Christoph Loch, R&D and product development.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Why Genius Leads to Adversity: Experimental Evidence on the Reputational Effects of Task Difficulty Choices", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1331", "ex:pages": "1042-1054", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["incentives in R&D", "behavioral operations", "career concerns", "decentralization"], "ex:creator": [{"ex:name": "Elena Katok", "ex:email": "ekatok@psu.edu"}, {"ex:name": "Enno Siemsen", "ex:email": "siems017@umn.edu"}]}, {"ex:issue": "6", "ex:abstract": "In this paper, we investigate the integrated information and pricing strategy for a seller who can take customer preorders before the release of a product. The preorder option enables the seller to sell a product at an early stage when consumers are less certain about their valuations. We find that the optimal pricing strategy may be highly dependent on the amount of information available at preorder and that a small change in the latter may cause a dramatic change in the proportion of consumers who preorder under optimal pricing. Furthermore, the seller's optimal information strategy depends on a key measure, the normalized margin, which is the ratio between the expected profit margin and the standard deviation of consumer valuation. Although the seller may want to release some information or none, she should never release all information. Finally, under the optimal information and pricing strategy, the benefit of preorder is most pronounced when the normalized margin is in a medium range. This paper was accepted by Martin Lariviere, operations management.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Optimal Preorder Strategy with Endogenous Information Control", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1335", "ex:pages": "1055-1077", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["preorder", "advance selling", "information release", "consumer valuation control"], "ex:creator": [{"ex:name": "Leon Yang Chu", "ex:email": "leonyzhu@usc.edu"}, {"ex:name": "Hao Zhang", "ex:email": "zhanghao@marshall.usc.edu"}]}, {"ex:issue": "6", "ex:abstract": "In this paper, we study price competition for an oligopoly in a dynamic setting, where each of the sellers has a fixed number of units available for sale over a fixed number of periods. Demand is stochastic, and depending on how it evolves, sellers may change their prices at any time. This reflects the fact that firms constantly, and almost costlessly, change their prices, reacting to updates in their estimates of market demand, competitor prices, or inventory levels. In a setting with demand uncertainty, we show that there is a unique subgame-perfect equilibrium for a duopoly, in which all states sellers engage in Bertrand competition and the seller with the lower equilibrium reservation value sells a unit at a price equal to the competitor's equilibrium reservation value. This structure therefore extends the marginal-value concept of bid-price control, used in many revenue management implementations, to a competitive model. We give a closed-form solution to the equilibrium price paths for a duopoly and extend all the results to an n-firm oligopoly. We then study extensions to multiple customer types, uncertain valuations, and differentiated products. This paper was accepted by Martin Lariviere, operations management.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Dynamic Price Competition with Fixed Capacities", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1337", "ex:pages": "1078-1093", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["revenue management", "bid prices", "subgame-perfect equilibrium"], "ex:creator": [{"ex:name": "Victor Martnez-de-Albniz", "ex:email": "valbeniz@iese.edu"}, {"ex:name": "Kalyan Talluri", "ex:email": "kalyan.talluri@upf.edu"}]}, {"ex:issue": "6", "ex:abstract": "This study investigates reference-dependent choice with a stochastic, state-dependent reference point. The optimal reference-dependent solution equals the optimal consumption solution (no loss aversion) if the reference point is selected fully endogenously. Given that loss aversion is widespread, we conclude that the reference point generally includes an important exogenously fixed component. We develop a choice model in which adjustment costs can cause stickiness relative to an initial, exogenous reference point. Using historical U.S. investment benchmark data, we show that this model is consistent with diversification across bonds and stocks for a wide range of evaluation horizons, despite the historically high-risk premium of stocks compared to bonds. This paper was accepted by Peter Wakker, decision analysis.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Loss Aversion with a State-Dependent Reference Point", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1338", "ex:pages": "1094-1110", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["behavioral finance", "asset pricing", "equity premium puzzle", "reference-dependent preferences", "loss aversion", "stochastic reference point"], "ex:creator": [{"ex:name": "Enrico G. De Giorgi", "ex:email": "enrico.degiorgi@unisg.ch"}, {"ex:name": "Thierry Post", "ex:email": "thierrypost@hotmail.com"}]}, {"ex:issue": "6", "ex:abstract": "This paper investigates the capacity investment decision of a supplier who solicits private forecast information from a manufacturer. To ensure abundant supply, the manufacturer has an incentive to inflate her forecast in a costless, nonbinding, and nonverifiable type of communication known as \"cheap talk.\" According to standard game theory, parties do not cooperate and the only equilibrium is uninformative--the manufacturer's report is independent of her forecast and the supplier does not use the report to determine capacity. However, we observe in controlled laboratory experiments that parties cooperate even in the absence of reputation-building mechanisms and complex contracts. We argue that the underlying reason for cooperation is trust and trustworthiness. The extant literature on forecast sharing and supply chain coordination implicitly assumes that supply chain members either absolutely trust each other and cooperate when sharing forecast information, or do not trust each other at all. Contrary to this all-or-nothing view, we determine that a continuum exists between these two extremes. In addition, we determine (i) when trust is important in forecast information sharing, (ii) how trust is affected by changes in the supply chain environment, and (iii) how trust affects related operational decisions. To explain and better understand the observed behavioral regularities, we also develop an analytical model of trust to incorporate both pecuniary and nonpecuniary incentives in the game-theoretic analysis of cheap-talk forecast communication. The model identifies and quantifies how trust and trustworthiness induce effective cheap-talk forecast sharing under the wholesale price contract. We also determine the impact of repeated interactions and information feedback on trust and cooperation in forecast sharing. We conclude with a discussion on the implications of our results for developing effective forecast management policies. This paper was accepted by Ananth Iyer, operations and supply chain management.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Trust in Forecast Information Sharing", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1334", "ex:pages": "1111-1137", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["trust", "trustworthiness", "cheap talk", "asymmetric forecast information", "wholesale price contract", "behavioral economics", "experimental economics"], "ex:creator": [{"ex:name": "zalp zer", "ex:email": "oozer@utdallas.edu"}, {"ex:name": "Yanchong Zheng", "ex:email": "yczheng@stanford.edu"}, {"ex:name": "Kay-Yut Chen", "ex:email": "kay-yut.chen@hp.com"}]}, {"ex:issue": "6", "ex:abstract": "We examine the effects of mandating the provision of fair value information for long-lived tangible assets on firms' information asymmetry. Specifically, we investigate whether European real estate firms' compulsory adoption of International Accounting Standard 40 (IAS 40; Investment Property), which mandated the provision of investment property fair values in 2005, resulted in reduced information asymmetry across market participants. Using as a control group firms that voluntarily provided these fair values prior to the mandatory adoption of IAS 40, we find that mandatory adoption firms exhibit a larger decline in information asymmetry, as reflected in lower bid-ask spreads. However, we also find that mandatory adoption firms continue to have higher information asymmetry than voluntary adoption firms, which appears partially attributable to the lower reliability of fair values reported by the mandatory adoption firms. Together, this evidence adds to the debate on fair value accounting by demonstrating that common adoption of fair value, even for long-lived tangible assets, under a mandatory reporting regime can reduce, but not necessarily eliminate, information asymmetry differences across firms. This paper was accepted by Stefan Reichelstein, accounting.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Mandatory Fair Value Accounting and Information Asymmetry: Evidence from the European Real Estate Industry", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1339", "ex:pages": "1138-1153", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["fair value", "disclosure", "IFRS", "information asymmetry", "investment property"], "ex:creator": [{"ex:name": "III Karl A. Muller", "ex:email": "kam23@psu.edu"}, {"ex:name": "Edward J. Riedl", "ex:email": "eriedl@hbs.edu"}, {"ex:name": "Thorsten Sellhorn", "ex:email": "thorsten.sellhorn@whu.edu"}]}, {"ex:issue": "6", "ex:abstract": "We consider an assemble-to-order system in which multiple products are assembled from a common component and a set of product-dedicated components. Component capacities are chosen prior to a finite-horizon selling season, and the common component is allocated to the products based on observed demands. We propose a collection of allocation mechanisms involving varying degrees of demand aggregation, ranging from a scheme under which all demands are observed prior to making the allocation decision to allocations made for each arriving demand. In this context, we explore the impact of the allocation scheme on sales, profits, and capacity decisions, including the degree of capacity imbalance. We find that the benefit from increased demand aggregation is closely linked to the degree of capacity imbalance: profit gains from delayed allocation tend to be higher in systems in which the optimal capacity portfolio is highly unbalanced when the allocation decision is made after observing all demands. We develop insights into what detailed system parameters lead to the largest gains from demand aggregation and also explore the trade-offs associated with the choice of an allocation scheme when customers exhibit impatience if the allocation scheme forces them to wait to be served. This paper was accepted by Ananth Iyer, operations and supply chain management.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "The Impact of Demand Aggregation Through Delayed Component Allocation in an Assemble-to-Order System", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1340", "ex:pages": "1154-1171", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["assemble-to-order", "inventory production", "policies", "capacity", "stochastic", "multi-item"], "ex:creator": [{"ex:name": "Fernando Bernstein", "ex:email": "fernando@duke.edu"}, {"ex:name": "Gregory A. DeCroix", "ex:email": "gdecroix@bus.wisc.edu"}, {"ex:name": "Yulan Wang", "ex:email": "tcywang@polyu.edu.hk"}]}, {"ex:issue": "6", "ex:abstract": "We analyze the computational problem of estimating financial risk in a nested simulation. In this approach, an outer simulation is used to generate financial scenarios, and an inner simulation is used to estimate future portfolio values in each scenario. We focus on one risk measure, the probability of a large loss, and we propose a new algorithm to estimate this risk. Our algorithm sequentially allocates computational effort in the inner simulation based on marginal changes in the risk estimator in each scenario. Theoretical results are given to show that the risk estimator has a faster convergence order compared to the conventional uniform inner sampling approach. Numerical results consistent with the theory are presented. This paper was accepted by Grard Cachon, stochastic models and simulation.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Efficient Risk Estimation via Nested Sequential Simulation", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1330", "ex:pages": "1172-1194", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["simulation", "decision analysis", "risk", "risk management", "sequential analysis"], "ex:creator": [{"ex:name": "Mark Broadie", "ex:email": "mnb2@columbia.edu"}, {"ex:name": "Yiping Du", "ex:email": "yd2166@columbia.edu"}, {"ex:name": "Ciamac C. Moallemi", "ex:email": "ciamac@gsb.columbia.edu"}]}, {"ex:issue": "7", "ex:abstract": "No abstract available.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Editorial Statement: Behavioral Economics", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1405", "ex:pages": "iv-iv", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": [], "ex:creator": [{"ex:name": "Uri Gneezy", "ex:email": "ugneezy@ucsd.edu"}, {"ex:name": "Teck-Hua Ho", "ex:email": "hoteck@haas.berkeley.edu"}, {"ex:name": "John List", "ex:email": "jlist@uchicago.edu"}]}, {"ex:issue": "7", "ex:abstract": "No abstract available.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Management Insights", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1406", "ex:pages": "v-vi", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": [], "ex:creator": [{"ex:name": "Michael F. Gorman", "ex:email": "michael.gorman@udayton.edu"}]}, {"ex:issue": "7", "ex:abstract": "The Capital Assistance Program (CAP) was created by the U.S. government in February 2009 to provide backup capital to large financial institutions unable to raise sufficient capital from private investors. Under the terms of the CAP, a participating bank receives contingent capital by issuing preferred shares to the Treasury combined with embedded options for both parties: The bank gets the option to redeem the shares or convert them to common equity, with conversion mandatory after seven years; the Treasury earns dividends on the preferred shares and gets warrants on the bank's common equity. We develop a contingent claims framework in which to estimate market values of these CAP securities. The interaction between the competing options held by the buyer and issuer of these securities creates a game between the two parties, and our approach captures this strategic element of the joint valuation problem and clarifies the incentives it creates. We apply our method to the 18 publicly held bank holding companies that participated in the Supervisory Capital Assessment Program (the stress test) launched together with the CAP. On average, we estimate that compared to a market transaction, the CAP securities carry a net value of approximately 30% of the capital invested for a bank participating to the maximum extent allowed under the terms of the program. We also find that the net value varies widely across banks. We compare our estimates with abnormal stock price returns for the stress test banks at the time the terms of the CAP were announced; we find correlations between 0.78 and 0.85, depending on the precise choice of period and set of banks included. These results suggest that our valuation aligns with shareholder perception of the value of the program, prompting questions about industry reactions and the overall impact of the program. This paper was accepted by Wei Xiong, finance.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Valuing the Treasury's Capital Assistance Program", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1351", "ex:pages": "1195-1211", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["finance", "securities", "financial institutions", "banks", "dynamic programming", "applications"], "ex:creator": [{"ex:name": "Paul Glasserman", "ex:email": "pg20@columbia.edu"}, {"ex:name": "Zhenyu Wang", "ex:email": "zhenyu.wang@ny.frb.org"}]}, {"ex:issue": "7", "ex:abstract": "We study competitive interaction between a profit-maximizing firm that sells software and complementary services, and a free open-source competitor. We examine the firm's choice of business model between the proprietary model (where all software modules are proprietary), the open-source model (where all modules are open source), and the mixed-source model (where some--but not all--modules are open). When a module is opened, users can access and improve the code, which increases quality and value creation. Opened modules, however, are available for others to use free of charge. We derive the set of possibly optimal business models when the modules of the firm and the open-source competitor are compatible (and thus can be combined) and incompatible, and show that (i) when the firm's modules are of high (low) quality, the firm is more open under incompatibility (compatibility) than under compatibility (incompatibility); (ii) firms are more likely to open substitute, rather than complementary, modules to existing open-source projects; and (iii) there may be no trade-off between value creation and value capture when comparing business models with different degrees of openness. This paper was accepted by Bruno Cassiman, business strategy.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Mixed Source", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1353", "ex:pages": "1212-1230", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["open source", "user innovation", "business models", "complementarity", "compatibility", "value creation", "value capture"], "ex:creator": [{"ex:name": "Ramon Casadesus-Masanell", "ex:email": "casadesus@gmail.com"}, {"ex:name": "Gastn Llanes", "ex:email": "gaston@llanes.com.ar"}]}, {"ex:issue": "7", "ex:abstract": "We address the empirical implementation of the static asset allocation problem by developing a forward-looking approach that uses information from market option prices. To this end, we extract constant maturity S&P 500 implied distributions and transform them to the corresponding risk-adjusted ones. Then we form optimal portfolios consisting of a risky and a risk-free asset and evaluate their out-of-sample performance. We find that the use of risk-adjusted implied distributions times the market and makes the investor better off than if she uses historical returns' distributions to calculate her optimal strategy. The results hold under a number of evaluation metrics and utility functions and carry through even when transaction costs are taken into account. Not surprisingly, the reported market timing ability deteriorated during the recent subprime crisis. An extension of the approach to a dynamic asset allocation setting is also presented. This paper was accepted by Wei Xiong, finance.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Market Timing with Option-Implied Distributions: A Forward-Looking Approach", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1346", "ex:pages": "1231-1249", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["asset allocation", "option-implied distributions", "market timing", "performance evaluation", "portfolio choice", "risk aversion"], "ex:creator": [{"ex:name": "Alexandros Kostakis", "ex:email": "a.kostakis@liverpool.ac.uk"}, {"ex:name": "Nikolaos Panigirtzoglou", "ex:email": "n.panigirtzoglou@qmul.ac.uk"}, {"ex:name": "George Skiadopoulos", "ex:email": "gskiado@unipi.gr"}]}, {"ex:issue": "7", "ex:abstract": "This paper highlights the rationale for exclusive territories in a model of repeated interaction between competing supply chains. We show that with observable contracts exclusive territories have two countervailing effects on manufacturers' incentives to sustain tacit collusion. First, granting local monopolies to retailers softens competition in a one-shot game. Hence, punishment profits are larger, thereby rendering deviation more profitable. Second, exclusive territories stifle deviation profits because retailers of competing brands adjust their prices to the wholesale contract offered by a deviant manufacturer, whereas intrabrand competition prevents such \"instantaneous reaction.\" We show that the latter effect tends to dominate, thereby making exclusive territories a more suitable organizational mode to cooperate. These insights are robust to endogenous communication between manufacturers. We also consider retailers' service investments. Here, a novel effect emerges that softens the procollusive value of exclusive territories: Retailers of a deviant manufacturer increase investments, which renders deviation more profitable. This paper was accepted by Preyas Desai, marketing.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Exclusive Territories and Manufacturers' Collusion", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1352", "ex:pages": "1250-1266", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["exclusive territories", "supply chains", "tacit collusion", "information sharing", "vertical restraints"], "ex:creator": [{"ex:name": "Salvatore Piccolo", "ex:email": "salvatore.piccolo@unina.it"}, {"ex:name": "Markus Reisinger", "ex:email": "markus.reisinger@lrz.uni-muenchen.de"}]}, {"ex:issue": "7", "ex:abstract": "In this paper, we focus on modeling and predicting the loss distribution for credit risky assets such as bonds and loans. We model the probability of default and the recovery rate given default based on shared covariates. We develop a new class of default models that explicitly accounts for sector specific and regime dependent unobservable heterogeneity in firm characteristics. Based on the analysis of a large default and recovery data set over the horizon 1980-2008, we document that the specification of the default model has a major impact on the predicted loss distribution, whereas the specification of the recovery model is less important. In particular, we find evidence that industry factors and regime dynamics affect the performance of default models, implying that the appropriate choice of default models for loss prediction will depend on the credit cycle and on portfolio characteristics. Finally, we show that default probabilities and recovery rates predicted out of sample are negatively correlated and that the magnitude of the correlation varies with seniority class, industry, and credit cycle. This paper was accepted by Wei Xiong, finance.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Modeling the Loss Distribution", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1345", "ex:pages": "1267-1287", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["loss distribution", "default prediction", "recovery rates", "Basel II"], "ex:creator": [{"ex:name": "Sudheer Chava", "ex:email": "sudheer.chava@mgt.gatech.edu"}, {"ex:name": "Catalina Stefanescu", "ex:email": "catalina.stefanescu-cuntze@esmt.org"}, {"ex:name": "Stuart Turnbull", "ex:email": "sturnbull@uh.edu"}]}, {"ex:issue": "7", "ex:abstract": "The widespread implementation of customer relationship management technologies in business has allowed companies to increasingly focus on both acquiring and retaining customers. The challenge of designing incentive mechanisms that simultaneously focus on customer acquisition and customer retention comes from the fact that customer acquisition and customer retention are usually separate but intertwined tasks that make providing proper incentives more difficult. The present study develops incentive mechanisms that simultaneously address acquisition and retention of customers with an emphasis on the interactions between them. The main focus of this study is to examine the impact of the negative effect of acquisition on retention, i.e., the spoiling effect, on firm performance under direct selling and delegation of customer acquisition. Our main finding is that the negative effect of acquisition on retention has a significant impact on acquisition and retention efforts and firm profit. In particular, when the customer acquisition and retention are independent, the firm's profit is higher under direct selling than under delegation; however, when acquisition spoils retention, interestingly, the firm's profit may be higher under delegation. Our analysis also finds that the spoiling effect not only reduces the optimal acquisition effort but may also reduce retention effort under both direct selling and delegation. Comparing the optimal efforts under direct selling and delegation, the acquisition effort is always lower under delegation regardless of the spoiling effect, but the retention effort may be higher under delegation with the spoiling effect. Furthermore, when the customer antagonism effect from price promotions is considered, our main results hold regarding the firm's preferences between direct selling and delegation, which demonstrates the robustness of our model. This paper was accepted by Pradeep Chintagunta, marketing.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "When Acquisition Spoils Retention: Direct Selling vs. Delegation Under CRM", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1344", "ex:pages": "1288-1299", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["customer acquisition", "customer retention", "customer value", "customer relationship management", "incentive mechanism"], "ex:creator": [{"ex:name": "Yan Dong", "ex:email": "yandong@rhsmith.umd.edu"}, {"ex:name": "Yuliang Yao", "ex:email": "yuy3@lehigh.edu"}, {"ex:name": "Tony Haitao Cui", "ex:email": "tcui@umn.edu"}]}, {"ex:issue": "7", "ex:abstract": "One of the most important operational challenges faced by emergency departments (EDs) in the United States is patient overcrowding. In periods of overcrowding, an ED can request the emergency medical services (EMS) agency to divert incoming ambulances to neighboring hospitals, a phenomenon known as \"ambulance diversion.\" The EMS agency may accept this request provided that at least one of the neighboring EDs is not on diversion. From an operations perspective, properly executed ambulance diversion should result in resource pooling and reduce the overcrowding and delays in a network of EDs. Recent evidence indicates, however, that this potential benefit is not always realized. In this paper, we provide one potential explanation for this discrepancy and suggest potential remedies. Using a queueing game between two EDs that aim to minimize their own waiting time, we find that decentralized decisions regarding diversion explain the lack of pooling benefits. Specifically, we find the existence of a defensive equilibrium, wherein each ED does not accept diverted ambulances from the other ED. This defensiveness results in a depooling of the network and, subsequently, in delays that are significantly higher than when a social planner coordinates diversion. The social optimum is itself difficult to characterize analytically and has limited practical appeal because it depends on problem parameters such as arrival rates and length of stay. Instead, we identify an alternative solution that does not require the exact knowledge of the parameters and may be used by the EMS agencies to coordinate diversion decisions when defensive diversion is present. We show that this solution is approximately optimal for the social planner's problem. Moreover, it is Pareto improving over the defensive equilibrium whereas the social optimum, in general, might not be. This paper was accepted by Yossi Aviv, operations management.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Centralized vs. Decentralized Ambulance Diversion: A Network Perspective", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1342", "ex:pages": "1300-1319", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["emergency department", "ambulance diversion", "game theory", "queueing networks"], "ex:creator": [{"ex:name": "Sarang Deo", "ex:email": "s-deo@kellogg.northwestern.edu"}, {"ex:name": "Itai Gurvich", "ex:email": "i-gurvich@kellogg.northwestern.edu"}]}, {"ex:issue": "7", "ex:abstract": "This paper finds preference reversals in measurements of ambiguity aversion, even if psychological and informational circumstances are kept constant. The reversals are of a fundamentally different nature than the reversals found before because they cannot be explained by context-dependent weightings of attributes. We offer an explanation based on Sugden's random-reference theory, with different elicitation methods generating different random reference points. Then measurements of ambiguity aversion that use willingness to pay are confounded by loss aversion and hence overestimate ambiguity aversion. This paper was accepted by Teck Ho, decision analysis.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Preference Reversals for Ambiguity Aversion", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1343", "ex:pages": "1320-1333", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["ambiguity aversion", "preference reversal", "loss aversion", "choice versus valuation"], "ex:creator": [{"ex:name": "Stefan T. Trautmann", "ex:email": "s.t.trautmann@uvt.nl"}, {"ex:name": "Ferdinand M. Vieider", "ex:email": "fvieider@gmail.com"}, {"ex:name": "Peter P. Wakker", "ex:email": "wakker@ese.eur.nl"}]}, {"ex:issue": "7", "ex:abstract": "Numerous theoretical predictions such as precautionary saving or preventive behavior have been derived for prudent decision makers. Further, prudence can be characterized as downside risk aversion and plays a key role in preference for skewness. We use a simple experimental method to test for prudence and skewness preference in the laboratory and compare the two. To this end, we introduce a novel graphical representation of compound lotteries that is easily accessible to subjects and test it for robustness, using a factorial design. Prudence is observed on the aggregate and individual level. We find that prudence does not boil down to skewness seeking. We further provide some theoretical explanations for this result. This paper was accepted by Peter Wakker, decision analysis.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Testing for Prudence and Skewness Seeking", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1354", "ex:pages": "1334-1349", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["decision making under risk", "precautionary savings", "prudence", "downside risk", "skewness seeking", "laboratory experiment"], "ex:creator": [{"ex:name": "Sebastian Ebert", "ex:email": "sebastianebert@uni-bonn.de"}, {"ex:name": "Daniel Wiesen", "ex:email": "daniel.wiesen@uni-bonn.de"}]}, {"ex:issue": "8", "ex:abstract": "No abstract available.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Management Insights", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1423", "ex:pages": "iv-vi", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": [], "ex:creator": [{"ex:name": "Michael F. Gorman", "ex:email": "michael.gorman@udayton.edu"}]}, {"ex:issue": "8", "ex:abstract": "No abstract available.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "2011 Management Science Service Awards", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1422", "ex:pages": "1351-1353", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": [], "ex:creator": []}, {"ex:issue": "8", "ex:abstract": "This paper examines a unique selling strategy, Group Buying, under which consumers enjoy a discounted group price if they are willing and able to achieve a required group size and coordinate their transaction time. We argue that Group Buying allows a seller to gain from facilitating consumer social interaction, i.e., using a group discount to motivate informed customers to work as \"sales agents\" to acquire less-informed customers through interpersonal information/knowledge sharing. We formally model such an information-sharing effect and examine if and when Group Buying is more profitable than (1) traditional individual-selling strategies, and (2) another popular social interaction scheme, Referral Rewards programs. We show that Group Buying dominates traditional individual-selling strategies when the information/knowledge gap between expert and novice consumers is neither too high nor too low (e.g., for products in the midstage of their life cycle) and when interpersonal information sharing is very efficient (e.g., in cultures that emphasize trust and group conformity, or when implemented through existing online social networks). We also show that, unlike Referral Rewards programs, Group Buying requires information sharing before any transaction takes place, thereby increasing the scale of social interaction but also incurring a higher cost. As a result, Group Buying is optimal when interpersonal communication is very efficient or when the product valuation of the less-informed consumer segment is high. This paper was accepted by Preyas Desai, marketing.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Group Buying: A New Mechanism for Selling Through Social Interactions", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1366", "ex:pages": "1354-1372", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["Group Buying", "word of mouth", "interpersonal information sharing", "Referral Rewards programs", "pricing", "social interaction", "marketing", "Internet"], "ex:creator": [{"ex:name": "Xiaoqing Jing", "ex:email": "xiaoqing.jing@mgt.gatech.edu"}, {"ex:name": "Jinhong Xie", "ex:email": "jinhong.xie@warrington.ufl.edu"}]}, {"ex:issue": "8", "ex:abstract": "Many markets have historically been dominated by a small number of best-selling products. The Pareto principle, also known as the 80/20 rule, describes this common pattern of sales concentration. However, information technology in general and Internet markets in particular have the potential to substantially increase the collective share of niche products, thereby creating a longer tail in the distribution of sales. This paper investigates the Internet's \"long tail\" phenomenon. By analyzing data collected from a multichannel retailer, it provides empirical evidence that the Internet channel exhibits a significantly less concentrated sales distribution when compared with traditional channels. Previous explanations for this result have focused on differences in product availability between channels. However, we demonstrate that the result survives even when the Internet and traditional channels share exactly the same product availability and prices. Instead, we find that consumers' usage of Internet search and discovery tools, such as recommendation engines, are associated with an increase the share of niche products. We conclude that the Internet's long tail is not solely due to the increase in product selection but may also partly reflect lower search costs on the Internet. If the relationships we uncover persist, the underlying trends in technology portend an ongoing shift in the distribution of product sales. This paper was accepted by Ramayya Krishnan, information systems.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Goodbye Pareto Principle, Hello Long Tail: The Effect of Search Costs on the Concentration of Product Sales", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1371", "ex:pages": "1373-1386", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["long tail", "search cost", "product variety", "concentration", "product sales", "Internet", "electronic commerce"], "ex:creator": [{"ex:name": "Erik Brynjolfsson", "ex:email": "erikb@mit.edu"}, {"ex:name": "Yu (Jeffrey) Hu", "ex:email": "yuhu@purdue.edu"}, {"ex:name": "Duncan Simester", "ex:email": "simester@mit.edu"}]}, {"ex:issue": "8", "ex:abstract": "This paper develops dynamic measures of the systemic risk of the financial sector as a whole. It defines systemic risk as the conditional probability of failure of a sufficiently large fraction of the total population of financial institutions. This definition recognizes that the cause of systemic distress is the correlated failure of institutions to meet obligations to creditors, customers, and trading partners. The likelihood estimators of the failure probability are based on a dynamic hazard model of correlated failure timing that captures the influence on failure timing of time-varying macroeconomic and sector-specific risk factors, and of spillover effects. Tests indicate that our measures provide accurate out-of-sample forecasts of the term structure of systemic risk in the United States for the period from 1998 to 2009. This paper was accepted by Wei Xiong, finance.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Systemic Risk: What Defaults Are Telling Us", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1375", "ex:pages": "1387-1405", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["banks", "financial system", "correlated failure", "systemic risk"], "ex:creator": [{"ex:name": "Kay Giesecke", "ex:email": "giesecke@stanford.edu"}, {"ex:name": "Baeho Kim", "ex:email": "baehokim@korea.ac.kr"}]}, {"ex:issue": "8", "ex:abstract": "This paper proposes a generalized measure of riskiness that nests the original measures pioneered by Aumann and Serrano (Aumann, R. J., R. Serrano. 2008. An economic index of riskiness. J. Political Econom. 116(5) 810-836) and Foster and Hart (Foster, D. P., S. Hart. 2009. An operational measure of riskiness. J. Political Econom. 117(5) 785-814). The paper introduces the generalized options' implied measure of riskiness based on the risk-neutral return distribution of financial securities. It also provides asset allocation implications and shows that the forward-looking measures of riskiness successfully predict the cross section of 1-, 3-, 6-, and 12-month-ahead risk-adjusted returns of individual stocks. The empirical results indicate that the generalized measure of riskiness is able to rank equity portfolios based on their expected returns per unit of risk and hence yields a more efficient strategy for maximizing expected return of the portfolio while minimizing its risk. This paper was accepted by Wei Xiong, finance.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "A Generalized Measure of Riskiness", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1373", "ex:pages": "1406-1423", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["riskiness", "economic index of riskiness", "operational measure of riskiness", "risk-neutral measures", "stock returns"], "ex:creator": [{"ex:name": "Turan G. Bali", "ex:email": "bali@georgetown.edu"}, {"ex:name": "Nusret Cakici", "ex:email": "cakici@fordham.edu"}, {"ex:name": "Fousseni Chabi-Yo", "ex:email": "chabi-yo_1@fisher.osu.edu"}]}, {"ex:issue": "8", "ex:abstract": "This paper considers the desirability of aggregate performance measures in light of the fact that many individuals' performance incentives are driven by a desire to shape external perceptions (and thus future pay). In contrast to the case of explicit incentive contracts, we find that when individuals' actions are driven by career incentives, an aggregate measure (e.g., group or team output) can sometimes alleviate moral hazard concerns and improve efficiency. Aggregation intermingles performance measures that may be differentially affected by skill and effort of many agents. When such entanglement increases the prospect that the external market will attribute an employee's effort-driven contribution to transferable skills, the employee exerts higher effort as a means of posturing to the market. The incentive benefit of aggregation is weighed against the incentive cost because of information loss. Information loss from aggregation can reduce the market's reliance on the measure and thus diminish agents' desire to undertake effort to influence the measure. This paper was accepted by Stefan Reichelstein, accounting.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "The Benefits of Aggregate Performance Metrics in the Presence of Career Concerns", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1363", "ex:pages": "1424-1437", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["aggregation", "career concerns", "group performance measures"], "ex:creator": [{"ex:name": "Anil Arya", "ex:email": "arya_4@fisher.osu.edu"}, {"ex:name": "Brian Mittendorf", "ex:email": "mittendorf_3@fisher.osu.edu"}]}, {"ex:issue": "8", "ex:abstract": "This paper analyzes the interactions between competitive (wholesale) spot, retail, and forward markets and vertical integration in electricity markets. We develop an equilibrium model with producers, retailers, and traders to study and quantify the impact of forward markets and vertical integration on prices, risk premia, and retail market shares. We point out that forward hedging and vertical integration are two separate mechanisms for demand and spot price risk diversification that both reduce the retail price and increase retail market shares. We show that they differ in their impact on prices and firms' utility because of the asymmetry between production and retail segments. Vertical integration restores the symmetry between producers' and retailers' exposure to demand risk, whereas linear forward contracts do not. Vertical integration is superior to forward hedging when retailers are highly risk averse. We illustrate our analysis with data from the French electricity market. This paper was accepted by Wei Xiong, finance.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Hedging and Vertical Integration in Electricity Markets", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1357", "ex:pages": "1438-1452", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["corporate finance", "industries", "electric-electronic", "financial institutions", "markets", "asset pricing"], "ex:creator": [{"ex:name": "Ren Ad", "ex:email": "rene.aid@edf.fr"}, {"ex:name": "Gilles Chemla", "ex:email": "g.chemla@imperial.ac.uk"}, {"ex:name": "Arnaud Porchet", "ex:email": "porchet.arnaud@gmail.com"}, {"ex:name": "Nizar Touzi", "ex:email": "touzi@cmap.polytechnique.fr"}]}, {"ex:issue": "8", "ex:abstract": "The existence of mandatory emission trading schemes in Europe and the United States, and the increased liquidity of trading on futures contracts on CO<sub>2</sub> emissions allowances, led naturally to the next step in the development of these markets: These futures contracts are now used as underliers for a vibrant derivative market. In this paper, we give a rigorous analysis of a simple risk-neutral reduced-form model for allowance futures prices, demonstrate its calibration to historical data, and show how to price European call options written on these contracts. This paper was accepted by Haitao Li, guest editor, finance.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Risk-Neutral Models for Emission Allowance Prices and Option Valuation", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1358", "ex:pages": "1453-1468", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["emission derivatives", "emissions markets", "cap-and-trade schemes", "environmental finance"], "ex:creator": [{"ex:name": "Ren Carmona", "ex:email": "rcarmona@princeton.edu"}, {"ex:name": "Juri Hinz", "ex:email": "mathj@nus.edu.sg"}]}, {"ex:issue": "8", "ex:abstract": "Are the attitudes and beliefs of chief executive officers (CEOs) linked to their firms' innovative performance? This paper uses a measure of overconfidence, based on CEO stock-option exercise, to study the relationship between a CEO's \"revealed beliefs\" about future performance and standard measures of corporate innovation. We begin by developing a career concern model where CEOs innovate to provide evidence of their ability. The model predicts that overconfident CEOs, who underestimate the probability of failure, are more likely to pursue innovation, and that this effect is larger in more competitive industries. We test these predictions on a panel of large publicly traded firms for the years from 1980 to 1994. We find a robust positive association between overconfidence and citation-weighted patent counts in both cross-sectional and fixed-effect models. This effect is larger in more competitive industries. Our results suggest that overconfident CEOs are more likely to take their firms in a new technological direction. This paper was accepted by Kamalini Ramdas, entrepreneurship and innovation.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "CEO Overconfidence and Innovation", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1374", "ex:pages": "1469-1484", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["innovation", "R&D", "CEO overconfidence", "managerial biases"], "ex:creator": [{"ex:name": "Alberto Galasso", "ex:email": "alberto.galasso@rotman.utoronto.ca"}, {"ex:name": "Timothy S. Simcoe", "ex:email": "tsimcoe@bu.edu"}]}, {"ex:issue": "8", "ex:abstract": "Increasingly, user-generated product reviews serve as a valuable source of information for customers making product choices online. The existing literature typically incorporates the impact of product reviews on sales based on numeric variables representing the valence and volume of reviews. In this paper, we posit that the information embedded in product reviews cannot be captured by a single scalar value. Rather, we argue that product reviews are multifaceted, and hence the textual content of product reviews is an important determinant of consumers' choices, over and above the valence and volume of reviews. To demonstrate this, we use text mining to incorporate review text in a consumer choice model by decomposing textual reviews into segments describing different product features. We estimate our model based on a unique data set from Amazon containing sales data and consumer review data for two different groups of products (digital cameras and camcorders) over a 15-month period. We alleviate the problems of data sparsity and of omitted variables by providing two experimental techniques: clustering rare textual opinions based on pointwise mutual information and using externally imposed review semantics. This paper demonstrates how textual data can be used to learn consumers' relative preferences for different product features and also how text can be used for predictive modeling of future changes in sales. This paper was accepted by Ramayya Krishnan, information systems.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Deriving the Pricing Power of Product Features by Mining Consumer Reviews", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1370", "ex:pages": "1485-1509", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["Bayesian learning", "consumer reviews", "discrete choice", "electronic commerce", "electronic markets", "opinion mining", "sentiment analysis", "user-generated content", "text mining", "econometrics"], "ex:creator": [{"ex:name": "Nikolay Archak", "ex:email": "narchak@stern.nyu.edu"}, {"ex:name": "Anindya Ghose", "ex:email": "aghose@stern.nyu.edu"}, {"ex:name": "Panagiotis G. Ipeirotis", "ex:email": "panos@stern.nyu.edu"}]}, {"ex:issue": "9", "ex:abstract": "No abstract available.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Management Insights", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1436", "ex:pages": "iv-vii", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": [], "ex:creator": [{"ex:name": "Michael F. Gorman", "ex:email": "michael.gorman@udayton.edu"}]}, {"ex:issue": "9", "ex:abstract": "No abstract available.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Introduction to the Special Issue on Marketing Within the Enterprise and Beyond", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1432", "ex:pages": "1511-1511", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": [], "ex:creator": [{"ex:name": "Pradeep K. Chintagunta", "ex:email": "pradeep.chintagunta@chicagobooth.edu"}, {"ex:name": "Preyas S. Desai", "ex:email": "desai@duke.edu"}]}, {"ex:issue": "9", "ex:abstract": "Labels certify that a product meets some standard for quality, but often consumers are unsure of the exact standard that the label represents. Focusing on the case of ecolabels for environmental quality, we show how even small amounts of uncertainty can create consumer confusion that reduces or eliminates the value to firms of adopting voluntary labels. First, consumers are most suspicious of a label when a product with a bad reputation has it, so labels are often unpersuasive at showing that a seemingly bad product is actually good. Second, label proliferation aggravates the effect of uncertainty, causing the informativeness of labels to decrease rather than increase. Third, uncertainty makes labeling and nonlabeling equilibria more likely to coexist as the number of labels increases, so consumers face greater strategic uncertainty over how to interpret the presence or absence of a label. Finally, a label can be legitimitized or spoiled for other products when a product with a good or bad reputation displays it, so firms may adopt labels strategically to manipulate such information spillovers, which further exacerbates label confusion. Managers can reduce label confusion by supporting mandatory labeling or by undertaking investments to make certain labels \"focal.\" This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Label Confusion: The Groucho Effect of Uncertain Standards", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1412", "ex:pages": "1512-1527", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["marketing", "communications", "information theory", "environment"], "ex:creator": [{"ex:name": "Rick Harbaugh", "ex:email": "riharbau@indiana.edu"}, {"ex:name": "John W. Maxwell", "ex:email": "jwmax@indiana.edu"}, {"ex:name": "Beatrice Roussillon", "ex:email": "beatrice.roussillon@upmf-grenoble.fr"}]}, {"ex:issue": "9", "ex:abstract": "This research builds on the complementary corporate social responsibility (CSR) literatures in strategy and marketing to provide insight into the efficacy of CSR as a challenger's competitive weapon against a market leader. Through an investigation of a real-world CSR initiative, we show that the challenger can reap superior business returns (i.e., more positive attitudinal and behavioral outcomes) among consumers who had participated in its CSR initiative, relative to those who were merely aware of the initiative. Specifically, participant consumers demonstrate the desired attitudinal and behavioral changes in favor of the challenger, regardless of their affective trust in the leader, whereas aware consumers' reactions become less favorable as their affective trust in the leader increases. Furthermore, participant consumers, but not aware ones, form a communal, trust-based bond with the challenger. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Corporate Social Responsibility and Competitive Advantage: Overcoming the Trust Barrier", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1403", "ex:pages": "1528-1545", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["corporate social responsibility", "competitive strategy", "challenger brand", "affective trust"], "ex:creator": [{"ex:name": "Shuili Du", "ex:email": "shuili.du@simmons.edu"}, {"ex:name": "C. B. Bhattacharya", "ex:email": "cb@esmt.org"}, {"ex:name": "Sankar Sen", "ex:email": "sankar.sen@baruch.cuny.edu"}]}, {"ex:issue": "9", "ex:abstract": "This paper studies assortment planning and pricing for a product category with heterogeneous product types from two brands. We model consumer choice using the nested multinomial logit framework with two different hierarchical structures: a brand-primary model in which consumers choose a brand first, then a product type in the chosen brand, and a type-primary model in which consumers choose a product type first, then a brand within that product type. We consider a centralized regime that finds the optimal solution for the whole category and a decentralized regime that finds a competitive equilibrium between two brands. We find that optimal and competitive assortments and prices have quite distinctive properties across different models. Specifically, with the brand-primary model, both the optimal and the competitive assortments for each brand consist of the most popular product types from the brand. With the type-primary choice model, the optimal and the competitive assortments for each brand may not always consist of the most popular product types of the brand. Instead, the overall assortment in the category consists of a set of most popular product types. The price of a product under the centralized regime can be characterized by a sum of a markup that is constant across all products and brands, its procurement cost, and its marginal operational cost, implying a lower price for more popular products. The markup may be different for each brand and product type under the decentralized regime, implying a higher price for brands with a larger market share. These properties of the assortments and prices can be used as effective guidelines for managers to identify and price the best assortments and to rule out nonoptimal assortments. Our results suggest that to offer the right set of products and prices, category and/or brand managers should create an assortment planning process that is aligned with the hierarchical choice process consumers commonly follow to make purchasing decisions. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Optimal and Competitive Assortments with Endogenous Pricing Under Hierarchical Consumer Choice Models", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1402", "ex:pages": "1546-1563", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["assortment planning", "product variety", "category management", "pricing", "inventory costs", "nested multinomial logit model"], "ex:creator": [{"ex:name": "A. Grhan Kk", "ex:email": "gurhan.kok@duke.edu"}, {"ex:name": "Yi Xu", "ex:email": "yxu@rhsmith.umd.edu"}]}, {"ex:issue": "9", "ex:abstract": "Aubiquitous feature of even the fastest self-service technology transactions is the wait. Conventional wisdom and operations theory suggest that the longer people wait, the less satisfied they become; we demonstrate that because of what we term the labor illusion, when websites engage in operational transparency by signaling that they are exerting effort, people can actually prefer websites with longer waits to those that return instantaneous results--even when those results are identical. In five experiments that simulate service experiences in the domains of online travel and online dating, we demonstrate the impact of the labor illusion on service value perceptions, demonstrate that perceptions of service provider effort induce feelings of reciprocity that together mediate the link between operational transparency and increased valuation, and explore boundary conditions and alternative explanations. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "The Labor Illusion: How Operational Transparency Increases Perceived Value", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1376", "ex:pages": "1564-1579", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["marketing", "channels of distribution", "queues", "industries", "business services", "inventory-production", "operating characteristics", "service operations", "service design"], "ex:creator": [{"ex:name": "Ryan W. Buell", "ex:email": "rbuell@hbs.edu"}, {"ex:name": "Michael I. Norton", "ex:email": "mnorton@hbs.edu"}]}, {"ex:issue": "9", "ex:abstract": "It is well known that transaction-specific investments (TSIs) made in customers by account managers makes them vulnerable to opportunism by customers (i.e., the targets of the investments). The present research shows that TSIs made in customers by account managers can also lead them to be concerned about internal opportunism by nontargets of the investments (e.g., information technology or finance specialists in their own teams). Furthermore, it shows that concern about internal opportunism leads account managers to engage in internal blocking of their own team members (i.e., restricting their access to customers and to customer information), which results in lower performance with customers. This phenomenon is a conundrum in that account managers interested in stronger performance with customers appear to block the very functional specialists who can help them attain better performance. This research also identifies two types of continuities (account manager-customer continuity and specialist-customer continuity) that moderate the relationship between TSIs and concern about internal opportunism. Building on the literature in economics and organization theory, our research suggests that cross-functional teams that are designed to bring different functional areas together are more complex to manage than previously believed. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "The Threat from Within: Account Managers' Concern About Opportunism by Their Own Team Members", "ex:url": "http://dx.doi.org/10.1287/mnsc.1100.1298", "ex:pages": "1580-1593", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["transaction-specific investments", "internal opportunism", "continuity", "internal blocking", "sales teams"], "ex:creator": [{"ex:name": "Brian R. Murtha", "ex:email": "brian.murtha@uky.edu"}, {"ex:name": "Goutam Challagalla", "ex:email": "goutam.challagalla@mgt.gatech.edu"}, {"ex:name": "Ajay K. Kohli", "ex:email": "ajay.kohli@mgt.gatech.edu"}]}, {"ex:issue": "9", "ex:abstract": "The budgets for research and development (R&D) and marketing should be determined by managers to attain product market advantages. However, in response to investor expectations for short-term stock returns, managers may modify these budgets myopically to avoid unexpected short-term earnings shortfalls, at the cost of long-term profitability. We propose that the past behavior of firm stock returns and volatility may create investor expectations of short-term financial performance, which drives managers to modify either R&D or marketing budgets or both. In the context of high-technology firms, a Bayesian vector autoregression model, supported by content analysis, shows that few firms exhibit high levels of managerial myopia by simultaneously cutting both R&D and marketing budgets; instead, firms display moderate myopic reactions, in the form of unanticipated decreases in R&D budgets but increased budgets for marketing functions. The tendency to manage myopically in response to past stock returns and volatility increases as firm size or industry concentration decrease. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "The Stock Market in the Driver's Seat! Implications for R&D and Marketing", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1317", "ex:pages": "1594-1609", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["finance", "marketing", "research and development"], "ex:creator": [{"ex:name": "Anindita Chakravarty", "ex:email": "achakra@uga.edu"}, {"ex:name": "Rajdeep Grewal", "ex:email": "rgrewal@psu.edu"}]}, {"ex:issue": "9", "ex:abstract": "A considerable body of research has extolled the virtues of establishing rapport in negotiations. Negotiators who are high in rapport tend to be more likely to reach an agreement and more satisfied with the outcome. Although rapport generally has been found to have positive effects in standard negotiation settings, we investigate the effects of rapport in impasse settings, where conflict between negotiators' core needs means that a successful deal can only be reached when one or both parties acts unethically or \"misbehaves,\" for example, by lying to the negotiation partner. In a series of three experiments, we find that negotiators who have a high level of rapport are more likely to behave unethically than are negotiators who have a low level of rapport. We find this effect holds both when high rapport results from the way in which negotiations are conducted (face-to-face versus computer mediated) and also when rapport is established through a brief rapport-building exercise before negotiations begin. Finally, we find that the negative effects (unethical behavior)--but not the positive effects (satisfaction with the negotiation, trust, and willingness to work in the future with the negotiation partner)--of high rapport are reduced when negotiators are given a simple reminder before negotiations begin that one's actions can have long-term repercussions for one's reputation. Taken together, this research supports the idea that, despite its several advantages, in certain situations rapport has a dark side, of which negotiators must be wary. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "The Dark Side of Rapport: Agent Misbehavior Face-to-Face and Online", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1359", "ex:pages": "1610-1622", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["buyer-seller interactions", "misbehavior", "unethical behavior", "rapport", "emotion", "online media", "lying", "misleading", "overpromising"], "ex:creator": [{"ex:name": "Sandy Jap", "ex:email": "sjap@emory.edu"}, {"ex:name": "Diana C. Robertson", "ex:email": "robertsd@wharton.upenn.edu"}, {"ex:name": "Ryan Hamilton", "ex:email": "ryan_hamilton@bus.emory.edu"}]}, {"ex:issue": "9", "ex:abstract": "We examine how firms can create word-of-mouth peer influence and social contagion by designing viral features into their products and marketing campaigns. To econometrically identify the effectiveness of different viral features in creating social contagion, we designed and conducted a randomized field experiment involving the 1.4 million friends of 9,687 experimental users on Facebook.com. We find that viral features generate econometrically identifiable peer influence and social contagion effects. More surprisingly, we find that passive-broadcast viral features generate a 246% increase in peer influence and social contagion, whereas adding active-personalized viral features generate only an additional 98% increase. Although active-personalized viral messages are more effective in encouraging adoption per message and are correlated with more user engagement and sustained product use, passive-broadcast messaging is used more often, generating more total peer adoption in the network. Our work provides a model for how randomized trials can identify peer influence in social networks. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Creating Social Contagion Through Viral Product Design: A Randomized Trial of Peer Influence in Networks", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1421", "ex:pages": "1623-1639", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["peer influence", "social contagion", "social networks", "viral marketing", "viral product design", "information systems", "randomized experiment"], "ex:creator": [{"ex:name": "Sinan Aral", "ex:email": "sinan@stern.nyu.edu"}, {"ex:name": "Dylan Walker", "ex:email": "dwalker@stern.nyu.edu"}]}, {"ex:issue": "9", "ex:abstract": "Despite annual expenditures on public relations exceeding $19.42 billion, U.S. businesses lack practical guidance about the effectiveness of publicity in mass media. Here, we assemble a rich and novel data set to gauge the impact of news reports on consumer sign-ups with the U.S. Do Not Call (DNC) Registry. Using multiple identification strategies, we found robust evidence that news reports increased consumer registrations. Specifically, a 1% increase in the number of news reports increased DNC registrations by 0.018%. The impact increased with mention of the toll-free telephone number and URL, but decreased with the length of the headline and main text. Furthermore, we found evidence that reports affect behavior through persuasion as well as information--the impact on registration was higher for reports that mentioned the number of other people registering. Finally, the impact of news reports on consumer registration was stronger in national than local newspapers and in politically neutral and Democrat than Republican newspapers. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Newspaper Reports and Consumer Choice: Evidence from the Do Not Call Registry", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1392", "ex:pages": "1640-1654", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["advertising", "journalism", "information", "persuasion", "policy", "publicity"], "ex:creator": [{"ex:name": "Khim-Yong Goh", "ex:email": "gohky@comp.nus.edu.sg"}, {"ex:name": "Kai-Lung Hui", "ex:email": "klhui@ust.hk"}, {"ex:name": "Ivan P. L. Png", "ex:email": "ipng@nus.edu.sg"}]}, {"ex:issue": "9", "ex:abstract": "Many durable products cannot be used without a contingent consumable product, e.g., printers require ink, iPods require songs, razors require blades, etc. For such products, manufacturers may be able to lock in consumers by making their products incompatible with consumables that are produced by other firms. We examine the effectiveness of such a strategy in the presence of strategic consumers who anticipate the future prices of both the durable product and the contingent consumable. Under a lock-in strategy, the manufacturer has pricing power over the contingent consumable, which she can use to extract additional rents from higher valuation consumers, but such pricing power may also reduce consumers' willingness to pay for the durable because it subjects them to being held up with higher consumables prices in the future. Restricting our attention to linear pricing policies, we find that if the manufacturer can commit to shutting down production of her durable after an initial one-time sale, then competition from another consumable of an appropriately degraded level of quality can benefit the manufacturer by mitigating consumers' fears of being held up. On the other hand, when the manufacturer cannot commit to shutting down production of her durable, then her own output of additional durables gives her an incentive to keep consumables prices low, and competition in the consumables market is less beneficial. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Durable Products, Time Inconsistency, and Lock-in", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1397", "ex:pages": "1655-1670", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["marketing", "product policy", "new products", "decision analysis", "strategic consumers"], "ex:creator": [{"ex:name": "Stephen M. Gilbert", "ex:email": "steve.gilbert@mccombs.utexas.edu"}, {"ex:name": "Sreelata Jonnalagedda", "ex:email": "sreelata@iimb.ernet.in"}]}, {"ex:issue": "9", "ex:abstract": "We quantify how user mobile Internet usage relates to unique characteristics of the mobile Internet. In particular, we focus on examining how the mobile-phone-based content generation behavior of users relates to content usage behavior. The key objective is to analyze whether there is a positive or negative interdependence between the two activities. We use a unique panel data set that consists of individual-level mobile Internet usage data that encompass individual multimedia content generation and usage behavior. We combine this knowledge with data on user calling patterns, such as duration, frequency, and locations from where calls are placed, to construct their social network and to compute their geographical mobility. We build an individual-level simultaneous equation panel data model that controls for the different sources of endogeneity of the social network. We find that there is a negative and statistically significant temporal interdependence between content generation and usage. This finding implies that an increase in content usage in the previous period has a negative impact on content generation in the current period and vice versa. The marginal effect of this interdependence is stronger on content usage (up to 8.7%) than on content generation (up to 4.3%). The extent of geographical mobility of users has a positive effect on their mobile Internet activities. Users more frequently engage in content usage compared to content generation when they are traveling. In addition, the variance of user mobility has a stronger impact on their mobile Internet activities than does the mean. We also find that the social network has a strong positive effect on user behavior in the mobile Internet. These analyses unpack the mechanisms that stimulate user behavior on the mobile Internet. Implications for shaping user mobile Internet usage behavior are discussed. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "An Empirical Analysis of User Content Generation and Usage Behavior on the Mobile Internet", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1350", "ex:pages": "1671-1691", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["mobile Internet", "social networks", "content generation", "content usage", "interdependence", "geographical mobility", "identification"], "ex:creator": [{"ex:name": "Anindya Ghose", "ex:email": "aghose@stern.nyu.edu"}, {"ex:name": "Sang Pil Han", "ex:email": "shan2@stern.nyu.edu"}]}, {"ex:issue": "9", "ex:abstract": "Fruit and vegetable marketing organization the Greenery has experienced various governance structure changes, like horizontal merger, forward integration, and the emergence of grower associations. A multilateral incomplete contracting model is presented to account for these changes by analysing the interactions between pooling, access, and countervailing power. This model does not only explain the changes at the Greenery, but it contributes also to the design of efficient channel governance. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Pooling, Access, and Countervailing Power in Channel Governance", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1369", "ex:pages": "1692-1702", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["channel governance", "cooperatives", "pooling", "foreclosure", "market power", "incomplete contracts"], "ex:creator": [{"ex:name": "George Hendrikse", "ex:email": "ghendrikse@rsm.nl"}]}, {"ex:issue": "9", "ex:abstract": "Keyword advertising, or sponsored search, is one of the most successful advertising models on the Internet. One distinctive feature of keyword auctions is that they enable advertisers to adjust their bids and rankings dynamically, and the payoffs are realized in real time. We capture this unique feature with a dynamic model and identify an equilibrium bidding strategy. We find that under certain conditions, advertisers may engage in cyclical bid adjustments, and equilibrium bidding prices may follow a cyclical pattern: price-escalating phases interrupted by price-collapsing phases, similar to an \"Edgeworth cycle\" in the context of dynamic price competitions. Such cyclical bidding patterns can take place in both first- and second-price auctions. We obtain two data sets containing detailed bidding records of all advertisers for a sample of keywords in two leading search engines. Our empirical framework, based on a Markov switching regression model, suggests the existence of such cyclical bidding strategies. The cyclical bid-updating behavior we find cannot be easily explained with static models. This paper emphasizes the importance of adopting a dynamic perspective in studying equilibrium outcomes of keyword auctions. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors. This paper was accepted by Pradeep Chintagunta and Preyas Desai, special issue editors.", "ex:volume": "57", "ex:source": "Management Science", "ex:title": "Cyclical Bid Adjustments in Search-Engine Advertising", "ex:url": "http://dx.doi.org/10.1287/mnsc.1110.1408", "ex:pages": "1703-1719", "@context": {"dc": "http://schema.org/"}, "ex:template": "Template-Type: ReDIF-Article 1.0", "ex:date": "2011", "ex:keyword": ["bid adjustment", "Edgeworth cycle", "keyword auction"], "ex:creator": [{"ex:name": "Xiaoquan (Michael) Zhang", "ex:email": "zhang@ust.hk"}, {"ex:name": "Juan Feng", "ex:email": "juafeng@cityu.edu.hk"}]}]