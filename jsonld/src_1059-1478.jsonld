[{"e:year": 1992, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1992.tb00003.x", "e:abstract": "We present a new paradigm of hierarchical decision making in production planning and capacity expansion problems under uncertainty. We show that under reasonable assumptions, the strategic level management can base the capacity decision on aggregated information from the shopfloor, and the operational level management, given this decision, can derive a production plan for the system, without too large a loss in optimality when compared to simultaneous determination of optimal capacity and production decisions.", "e:keyword": ["HIERARCHICAL DECISION MAKING", "CAPACITY EXPANSION", "PRODUCTION PLANNING", "DYNAMIC PROGRAMMING", "MARKOV PROCESSES", "NEAR‐OPTIMAL DECISIONS"]}, {"e:year": 1992, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1992.tb00004.x", "e:abstract": "Station interdependence, blocking caused by finite buffer capacities, and periodic material handling make modeling and analysis of kanban-controlled lines challenging. Also, one must consider flows of material as well as flows of kanbans. The many models given in the literature contribute to the confusion and debate that often characterize kanban research. The only element common to all kanban systems appears to be finite buffer capacities. I describe blocking by total queue size, blocking by part type, and the single-card and twocard systems. I review the kanban literature and organize it by type of system and decision area. First, I discuss elements of system design, including setting kanban numbers, performance measures, material-handling frequencies, and container sizes. Then I cover the production control topics of sequencing and batch-sizing. I conclude with a comparison of kanban and conventional methods of production control and with suggestions for future research.", "e:keyword": ["KANBAN PRODUCTION CONTROL", "SINGLE‐CARD SYSTEM", "TWO‐CARD SYSTEM", "QUEUING"]}, {"e:year": 1992, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1992.tb00335.x", "e:abstract": "The challenges and opportunities in production and operations management (POM) are almost unlimited because in the world economy, manufacturing andservice operations account for more than 10 trillion dollars per year and in any single industry, the performance varies widely from country to country and from organization to organization. The goal of Production and Operations Management is to contribute to improving the management of manufacturing and service operations all over the world. The editors and reviewers judge the papers published in the journal for their contribution to improving of business practices and to further closeness between research and practice. The journal will publish high quality papers on a broad range of topics in POM, and it encourages all paradigms, old and new. We also invite managers from around the world to describe specific POM problems that provide challenging opportunities for academic research.", "e:keyword": ["PRODUCTION AND OPERATIONS MANAGEMENT", "MANUFACTURING", "SERVICES", "RESEARCH", "PRACTICE", "EDUCATION"]}, {"e:year": 1992, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1992.tb00336.x", "e:abstract": "Despite the attention given to restructuring and trimming down manufacturing firms during the 198Os, little attention has been paid to the mix of skills they needed under different circumstances. We examined the patterns of employment by occupation in manufacturing industries utilizing different production technologies and the effect of establishment size on nonproduction employment.", "e:keyword": ["OVERHEAD", "MANUFACTURING", "TECHNOLOGY", "STAFFING"]}, {"e:year": 1992, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1992.tb00337.x", "e:abstract": "To plan and schedule the repair shops for recoverable parts at Deutsche Lufthansa AC, we designed a hierarchical model consisting of two levels. The top level calculates the optimal number of parts in the system to guarantee a certain service level while minimizing the capital tied up in parts. Given this provision, the lower level schedules the repair of parts so that the service level is actually maintained. Using queuing theory, the solution gives special attention to the different hierarchical dependencies. Lufthansa has implemented the model for its repair shops of electronic parts. Their experience with the model is discussed briefly.", "e:keyword": ["PRODUCTION PLANNING", "LOGISTICS", "HIERARCHICAL PLANNING", "QUEUING THEORY"]}, {"e:year": 1992, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1992.tb00339.x", "e:abstract": "With the use of questionnaire data from owners, presidents, CEOs, and chairmen of boards and a logistic regression approach, we analyzed the manufacturing strategies of 64 new-venture firms in the computer and communications equipment manufacturing industries. We found statistically significant differences in manufacturing posture as a function of whether the new venture was corporate-sponsored or independent (i.e., new venture origin).", "e:keyword": ["MANUFACTURING STRATEGY", "NEW VENTURES", "NEW‐VENTURE ORIGIN"]}, {"e:year": 1992, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1992.tb00341.x", "e:abstract": "We formulate a general sequencing problem that includes two classes of jobs with setup times, setup costs, holding costs, and deadlines. The formulation is unique in its explicit recognition of the opportunities to exploit productive capacity increases due to batching. An algorithm based on tabu search is then used as a solution method. Computational results are presented that suggest that the algorithm is effective.", "e:keyword": ["SEQUENCING", "TABU SEARCH"]}, {"e:year": 1992, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1992.tb00342.x", "e:abstract": "As the world moves toward a global economy, it is increasingly important that operations management courses prepare students to address globalization issues. The purpose of this paper is to contribute to the dialog concerning how international topics are best incorporated into operations management curricula. On the basis of the results of a survey of operations management academicians worldwide, current course offerings are cataloged and topic areas critical to the globalization of operations are identified. Four major reasons for studying international operations management are proposed, which provide the basis for recommendations on how international topics can be introduced into established operations courses and for the design of an elective course in global operations. Finally, teaching materials relevant to international operations are surveyed.", "e:keyword": ["INTERNATIONAL OPERATIONS", "CURRICULUM DEVELOPMENT", "COURSE SURVEY"]}, {"e:year": 1992, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1992.tb00343.x", "e:abstract": "Our understanding of quality has undergone great changes over the last decade, propelled forward by the quality paradigm that has evolved in Japan. This paradigm has rendered obsolete the traditional quality-cost trade off model. I outline the key elements responsible for forcing a new understanding of quality-cost relationships.", "e:keyword": ["QUALITY", "TRADE OFFS", "CUSTOMER"]}, {"e:year": 1992, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00388.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1992, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1992.tb00348.x", "e:abstract": "R. J. Reynolds Tobacco USA (RJR) is currently implementing a microcomputer-based decision support system to computerize and optimize the selection of patterns for loading cases of finished product into truck trailers at RJR's Central Distribution Center. This system allows for the efficient loading of trucks with less supervision. Total annual savings from reduced personnel and shipping costs is approximately $850,000. In addition to these benefits, the system is a stepping stone for trailer loading automation and the integration of a comprehensive load planning system.", "e:keyword": ["LOAD CUBING", "CARGO LOADING", "TRAILER LOADING", "INTEGER PROGRAMMING APPLICATION"]}, {"e:year": 1992, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1992.tb00349.x", "e:abstract": "The persistent shortage of nurses adversely affects the productivity, quality of care, and operating costs in most acute care hospitals. Aggravating the shortage are high nurse turnover rates, approaching 200% in some institutions. Policies to ensure adequate staffing levels and provide more attractive work schedules are alleged to improve nurse retention. However, their cost is seldom discussed.", "e:keyword": ["HEALTH CARE", "WORKPORCE SCHEDULING", "SIMULATION APPLICATIONS"]}, {"e:year": 1992, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1992.tb00351.x", "e:abstract": "Most inventory and production planning models in the academic literature treat lead times either as constants or random variables with known distributions outside of management control. However, a number of recent articles in the popular press have argued that reducing lead times is a dominant issue in manufacturing strategy. The benefits of reducing customer lead times that are frequently cited include increased customer demand, improved quality, reduced unit cost, lower carrying cost, shorter forecast horizon, less safety stock inventory, and better market position.", "e:keyword": ["LEAD TIME REDUCTION", "TIME‐BASED COMPETITION", "OPTIMAL LEAD TIME"]}, {"e:year": 1992, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1992.tb00353.x", "e:abstract": "We are concerned with a discrete-time undiscounted dynamic lot size model in which demand and the production setup cost are constant for an initial few periods and the holding cost of inventory is an arbitrary nondecreasing function assumed to be stationary (i.e., explicitly independent of time) in the same initial few periods. We show that there exists a finite forecast horizon in our model and obtain an explicit formula for it. In addition, we obtain fairly general conditions under which the existence of a solution horizon in the model implies the existence of a forecast horizon. We also derive an explicit formula for the minimal solution horizon. These results extend the earlier ones obtained for the dynamic lot size model with linearly increasing holding costs.", "e:keyword": ["FORECAST HORIZONS", "SOLUTION HORIZONS", "DECISION HORIZONS", "DYNAMIC LOT SIZE MODEL", "GRAPH THEORY"]}, {"e:year": 1992, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1992.tb00355.x", "e:abstract": "During the 19805 much attention, both pro and con, was directed toward optimized production technology (OPT). Criticism was directed at the proprietary nature of the scheduling algorithms within the software. Despite these criticisms, many large companies installed OPT. Little has been written on how the software is constructed and operates. This article introduces the software, provides a discussion of how it interfaces with management, and how various algorithms are imbedded in the software function. Last, a survey of companies that had implemented the software revealed that the major users are in the automotive industry.", "e:keyword": ["OPT", "SCHEDULING", "OPTIMIZED PRODUCTION TECHNOLOGY"]}, {"e:year": 1992, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00388.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1992, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1992.tb00357.x", "e:abstract": "This essay is based on my plenary address at the second annual meeting of the Production and Operations Management Society on November 11, 1991. I propose that as the competitive environment in which production and operations management (POM) practitioners operate becomes ever more demanding and the problems about which POM academics study and teach become more complex and interrelated, we need new approaches both in our teaching and our research. I describe five ways of expanding our “requisite variety” of capabilities.", "e:keyword": ["PRODUCTION AND OPERATIONS MANAGEMENT", "PRACTICE", "TEACHING", "RESEARCH"]}, {"e:year": 1992, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1992.tb00358.x", "e:abstract": "This paper introduces a stochastic model of a distribution system where the stocking location is owned by a dealer (or retailer) and the product is supplied by a manufacturer. Inventory is managed by the dealer, and the manufacturer is responsible for delivery of the product through both regular replenishment and expedite shipment modes. The dealer and the manufacturer share the goal of providing a high level of customer service. Demand, moreover, is a function of the service level offered to the market by the dealer. We develop optimal stock control policies for the cases where each decision maker in turn is dominant and acts unilaterally while being constrained by the supply/demand linkages of the system. We also develop an optimum policy for the case where both levels are managed under centralized control (i.e., both levels cooperate). Results indicate that the expected profit for a dominant dealer (or dominant manufacturer) is higher under decentralized control than the optimal solution for either under centralized control. However, the centralized solution is a global-optimal solution and therefore will guarantee longterm stability. Differences between the various solutions are analyzed explicitly to estimate the cost of coordination.", "e:keyword": ["MULTI‐OWNER DISTRIBUTION SYSTEMS", "STOCHASTIC INVENTORY MODELS", "MANUFACTURER‐DEALER INTERACTIONS"]}, {"e:year": 1992, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1992.tb00360.x", "e:abstract": "Integration is a buzzword in manufacturing strategies for global competitiveness. However, some fundamental questions have yet to be answered scientifically; namely, what is integration, why integrate, and what should be integrated? How do existing integration models approach the problems of integration and to what extent are they successful?", "e:keyword": ["INTEGRATION THEORY", "MANUFACTURING INTEGRATION", "INTEGRATION MODEL", "INFORMATION MODELING"]}, {"e:year": 1992, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1992.tb00362.x", "e:abstract": "I consider a dynamic input scheduling problem of a stochastic parallel processing system consisting of n identical flexible machining cells. The processing times at each cell are independent random variables. Previous study has indicated the NP complexity of the problem. In this paper, I prove the separability under an ideal just-in-time input condition. Using the separability, I then construct an approximation procedure for most realistic applications where the separability condition is violated. The approximation procedure requires only linear time and performed quite well on an extensive test with numerical examples.", "e:keyword": ["DYNAMIC PROGRAMMING", "VARIABLE YIELD"]}, {"e:year": 1992, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00388.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1993, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00388.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1993, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1993.tb00035.x", "e:abstract": "Recent developments in the design of job shop scheduling systems have inspired a new approach to priority dispatching. The basis for the approach is in elementary decision theory: at each decision juncture define the alternative courses of action, evaluate the consequences of each alternative according to a given criterion, and choose the best alternative. The experimental results of a simulated single machine queueing system reinforce earlier findings that a decision theory approach represents a significant advance over conventional priority dispatching.", "e:keyword": ["JOB SHOP SCHEDULING", "PRIORITY DISPATCHING", "DECISION THEORY", "SIMULATION", "QUEUEING"]}, {"e:year": 1993, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1993.tb00036.x", "e:abstract": "An innovation strategy for the manufacturing function covers four areas: a firm's desired innovation leadership orientation (i.e., being a leader versus being a follower), its level of emphasis on process and product innovation, its use of internal and external sources of innovations, and its intensity of investment in innovation. We examine two models of the association between manufacturing companies' innovation strategy and their financial performance. The first examines the variations in company financial performance as a function of the simultaneous effect of the dimensions of innovation strategy. The second is a sequential model that suggests a causal sequence among the dimensions of innovation strategy that may lead to higher performance. We used data from a sample of 149 manufacturing companies to test the models. The results (1) support the importance of innovation strategy as a determinant of company financial performance, (2) suggest that both models are appropriate for examining the associations between the dimensions of innovation strategy and company performance, and (3) show that the sequential model provides additional insights into the indirect contribution of the individual dimensions of innovation strategy to company performance. Finally, we discuss the implications of these results for managers.", "e:keyword": ["MANUFACTURING INNOVATION", "INNOVATION STRATEGY", "COMPANY PERFORMANCE"]}, {"e:year": 1993, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1993.tb00094.x", "e:abstract": "Queueing models can usefully represent production systems experiencing congestion due to irregular flows, but exact analyses of these queueing models can be difficult. Thus it is natural to seek relatively simple approximations that are suitably accurate for engineering purposes. Here approximations for a basic queueing model are developed and evaluated. The model is the GI/G/m queue, which has m identical servers in parallel, unlimited waiting room, and the first-come first-served queue discipline, with service and interarrival times coming from independent sequences of independent and identically distributed random variables with general distributions. The approximations depend on the general interarrival-time and service-time distributions only through their first two moments. The main focus is on the expected waiting time and the probability of having to wait before beginning service, but approximations are also developed for other congestion measures, including the entire distributions of waiting time, queue-length and number in system. These relatively simple approximations are useful supplements to algorithms for computing the exact values that have been developed in recent years. The simple approximations can serve as starting points for developing approximations for more complicated systems for which exact solutions are not yet available. These approximations are especially useful for incorporating GI/G/m models in larger models, such as queueing networks, wherein the approximations can be components of rapid modeling tools.", "e:keyword": ["PERFORMANCE EVALUATION", "ROUGH CUT ANALYSES", "RAPID MODELING TOOLS", "QUEUEING THEORY", "QUEUEING NETWORKS", "PRODUCTION NETWORKS", "CONGESTION MEASURES", "MULTISERVER QUEUES", "WAITING TIMES", "HEAVY‐TRAFFIC LIMIT THEOREMS", "APPROXIMATIONS"]}, {"e:year": 1993, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00388.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1993, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1993.tb00096.x", "e:abstract": "The allocation and weekly scheduling of mobile magnetic resonance imaging (MRI) units leased to a group of hospitals that share the equipment can be a complex problem. Similar problems occur in other domains where expensive equipment or facilities such as video conference facilities, aircraft, and supercomputers are leased. The crux of the problem was determining the number of days and which days of the week various types of equipment types should be leased to hospitals, so as to maximize the rental revenues and satisfy client preferences for days of the week and equipment types. We found rental revenues were a decreasing function of the number of days allocated to a hospital. We considered two sub-problems linked by a set of variables to model the problem. We show that one of these subproblems is a minimum cost network flow problem and the other is an integer multi-commodity transportation problem. We developed a procedure for solving the latter problem by exploiting earlier results for specialized networks. We conducted a computational study to evaluate the performance of this procedure and showed that it generally provides near-optimal integer solutions. We describe the development and implementation of a spreadsheet-based decision support system based on this model. This system was successfully implemented by a small firm with no expertise or prior experience using models.", "e:keyword": ["RESOURCE ALLOCATION", "SCHEDULING", "NETWORKS", "HEALTH SERVICES", "PRACTICE"]}, {"e:year": 1993, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1993.tb00098.x", "e:abstract": "We developed a framework for analyzing semiconductor fabrication facilities where each processing step of each product can use a collection of resources. The interaction of these resources is not prespecified by the analysis system but is described by the modeler. Our framework includes three types of modeling approaches: analytic approximation, simulation, and a hybrid analytic/simulation technique. All models are automatically generated from a data description of the facility and the products produced, along with the resource interaction models provided by the user. The novel feature of our approach is that the data description language includes a simple but quite flexible simulation-like modeling language for expressing resource interactions. Our analytic modeling approach is an extension of the standard decomposition method used for studying networks of queues. In our hybrid analytic/simulation technique we use simulation to estimate processing step flow times to improve the performance of the analytic model.", "e:keyword": ["SIMULATION", "QUEUEING NETWORKS", "MARKOV CHAINS", "MARKOV RENEWAL PROCESSES", "AUTOMATIC MODELING", "MANUFACTURING SYSTEM DESIGN AND EVALUATION"]}, {"e:year": 1993, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00388.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1993, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1993.tb00101.x", "e:abstract": "In this paper, I investigate the impact of the conformance quality of a durable product on manufacturer's and user's replacement costs while the product is under warranty. I first relate conformance quality to reliability and then examine its effects on warranty costs to manufacturer and customer under both pro-rata and free-replacement warranties. In particular, I show that the reduction in customer's cost is generally contingent on more stringent quality improvement than the reduction in manufacturer's costs. I also discuss the value of inspection, and I present an application based on real data.", "e:keyword": ["CONFORMANCE QUALITY", "WARRANTY ANALYSIS", "RELIABILITY", "STOCHASTIC ORDERING"]}, {"e:year": 1993, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1993.tb00103.x", "e:abstract": "In assembly plants, random line stoppages cause production variability. For analytic tractability and data availability, researchers commonly assume that the production process possesses the independent increments property (necessary for a process to be Poisson). If the production process has independent increments, then the production in any interval is independent of the production in any other nonoverlapping interval. This property means, for one thing, that the current period's production is never influenced by previous production periods. Intuition, however, suggests that current production could be correlated to past production-violating this assumption of independence. If production problems persist from one period to the next, then one would expect the production in adjacent time periods to be correlated. Although the independent increments property is oflen assumed, its validity has not been demonstrated in practice. We analyze data from an automotive assembly plant to assess the validity of the independent increments assumption for its production.", "e:keyword": ["AUTOMOTIVE", "PRODUCTION", "INDEPENDENCE", "AUTOCORRELATION", "POISSON"]}, {"e:year": 1993, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1993.tb00104.x", "e:abstract": "We address a medium- to short-term production planning problem in a flexible manufacturing environment. First we present a single-machine, mixed integer programming model for part type selection and lot-sizing problems over a T-period planning horizon. Demand for part types changes dynamically through the periods. The objective is to meet the demand for part types during the periods they are demanded. Available machine time and tool magazine capacities are the system constraints in our models. We next extend on the single- machine model to include multiple machines. In addition to part type selection and lotsizing decisions, the extended model also addresses the machine-loading decision. We present exact branch and bound procedures based on linear programming relaxations for the two models. We also report the results of our computational experiments.", "e:keyword": ["FLEXIBLE MANUFACTURING SYSTEMS", "PART TYPE SELECTION", "MACHINE‐LOADING", "MIXED INTEGER PROGRAMMING", "BRANCH AND BOUND"]}, {"e:year": 1994, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00388.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1994, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1994.tb00106.x", "e:abstract": "We present a pavement management expert system developed by the University of Wisconsin-Madison and implemented within a geographical information system for the Wisconsin Department of Transportation. The system uses pavement data regularly collected on the state's 12,000 miles of highway to assist engineers, planners, and budget analysts' management decisions about pavements to be included in 6-year improvement and 3-year maintenance programs. The system has a three-layer architecture. The lowest level suggests treatments for each of a large number of small segments of highway. The middle layer aggregates segments, suggests alternative treatments, and estimates the cost of each. The top layer prioritizes the projects and incorporates them into intermediate-range plans. The geographical information system environment enables integration of existing databases within the system using a topologically structured geographic database and specialized software.", "e:keyword": ["PRODUCTION AND OPERATIONS MANAGEMENT", "SERVICES", "EXPERT SYSTEMS", "HIERARCHICAL PLANNING"]}, {"e:year": 1994, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1994.tb00107.x", "e:abstract": "We examine the phenomenon of shifting production bottlenecks from an analytic perspective. We quantify the propensity of a work center to be a bottleneck, defined as maximal queue length, using a simple Jackson production network model. Comparison of the analytic model against an empirical simulation-based model shows that the two are in good agreement. A scalar measure of bottleneck shiftiness is proposed and used to investigate several policies for mitigating shiftiness. Simulation experiments show that several commonly observed managerial policies for coping with shifting bottlenecks actually increase shiftiness, but that shiftiness declines when the capacity of nonbottleneck resources is increased.", "e:keyword": ["CAPACITY", "BOTTLENECKS", "UTILIZATION", "QUEUEING NETWORKS"]}, {"e:year": 1994, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1994.tb00108.x", "e:abstract": "An important issue in planning capacity expansion under uncertain demand is the effect of lead time on the timing of plant construction. Our model helps decide whether (1) plant construction is initiated after a certain deficit is accumulated, or (2) plant construction is initiated ahead of demand when a certain capacity surplus is reached. In addition to our analytical results, we present computational results to show that it is economically attractive to delay plant construction beyond the time when existing excess capacity becomes fully absorbed, with relatively short construction lead time.", "e:keyword": ["CAPACITY EXPANSION", "INTERRUPTED DEMAND GROWTH", "LEAD TIME"]}, {"e:year": 1994, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1994.tb00110.x", "e:abstract": "Work flows in a job shop are influenced by the load per release and time interval between release factors. We focus on the latter factor, job release times. Building on Elvers' work, this study evaluates the impact of different job release time distributions on shop performance. Using a computer simulation of a random job shop and a full factorial experimental design, we demonstrate that the type of distribution does affect performance–a finding consistent with results from job shops characterized by good shop floor control practices. These findings are explained by examining the shape and variance traits of the underlying job release time distributions.", "e:keyword": ["PRODUCTION SCHEDULING", "JOB SHOP"]}, {"e:year": 1994, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00388.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1994, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1994.tb00112.x", "e:abstract": "As manufacturing firms push to achieve shorter lead times and higher levels of customer service, the basic capability of underlying manufacturing processes must be reexamined. The capacity and operational variability of a process dictate a certain set of realistic performance goals. In this paper, we examine this fundamental relationship from an economic perspective using two levels of analysis. At the aggregate level, we model the manufacturing process as a single server queue and compare the traditional roles of marketing and manufacturing in setting performance and process design parameters. Insights gained at this level are incorporated into the analysis of a realistic multiserver, multistation manufacturing line. We develop an interaction decision tool to guide the selection of process and performance parameters in this more complex environment.", "e:keyword": ["CAPACITY ANALYSIS", "LEADTIME", "CUSTOMER SERVICE", "MARKETING‐MANUFACTURING INTERFACE"]}, {"e:year": 1994, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1994.tb00113.x", "e:abstract": "This is a case study of workforce scheduling in the U.S. postal system. We use it to analyze the benefits of scheduling flexibility at postal distribution systems, which can come from several sources. We focus on the additional flexibility deriving from increasing the proportion of part-time employees, as well as from increasing the cross-training of part-time employees. These two dimensions of scheduling flexibility are decision points of particular interest to the postal management.", "e:keyword": ["DISTRIBUTION", "FLEXIBILITY", "SERVICE OPERATIONS", "POST OFFICE"]}, {"e:year": 1994, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1994.tb00114.x", "e:abstract": "The focus of this work is on the effects of learning on economic production quantity in batch production systems. We assumed that both unit variable manufacturing time and setup time follow a learning curve. We modified the classical Economic Production Quantity model to incorporate these two types of learning phenomena. We also incorporated the forgetting effect in our model so that a fraction of the learning is lost between consecutive lots. We developed a dynamic program to obtain the optimal solution to the problem. We investigated the nonincreasing lot size property and used it to improve the efficiency of our dynamic program. We consider a special case of the model in which all lot sizes are assumed equal. After theoretical treatment, we carried out a computational study of the effect of assuming equal lot sizes on the optimal solutions. The results of our examples strongly indicate that the assumption of equal lot sizes not only simplifies the determination of the optimal solutions, but also provides close approximations to the optimal solutions.", "e:keyword": ["ECONOMIC PRODUCTION QUANTITY", "LEARNING", "DYNAMIC PROGRAMMING"]}, {"e:year": 1994, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1994.tb00115.x", "e:abstract": "This is a study of a single-machine scheduling problem with the objective of minimizing the sum of a function of earliness and tardiness called the earliness and tardiness (ET) problem. I will show that if priority weights of jobs are proportional to their processing times, and if earliness and tardiness cost functions are linear, the problem will be equivalent to the total weighted tardiness problem. This proves that the et problem is np-hard. In addition, I present a heuristic algorithm with worst case bound for the et problem based on the equivalence relation between the two. When earliness and tardiness cost functions are quadratic, I consider the problem for a common due date for all jobs and for different job due dates. In general, the et problem with quadratic earliness and tardiness cost functions and all job weights equal to one is np-hard. I show that in many cases, when weights of jobs are proportional to their processing times, the problem can be solved efficiently. In the published results on the et problem with quadratic earliness and tardiness cost functions other researchers have assumed a zero starting time for the schedule. I discuss the advantages of a nonzero starting time for the schedule.", "e:keyword": ["PRODUCTION SCHEDULING", "SINGLE MACHINE", "EARLINESS AND TARDINESS", "PROPORTIONAL WEIGHTS"]}, {"e:year": 1994, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1994.tb00116.x", "e:abstract": "In the early 1980s, companies around the world, learning from the Japanese experience, saw that they could address their severe competitive problems related to productivity and quality only by looking at the entire set of processes and organizational relationships in the context of the customer's needs. This approach was termed total quality management (TQM). As companies pursue quality-related initiatives, they must deal with a number of issues; some of these issues are addressed here: measurement of benefits, feedback and recognition, work-teams, teaching continuous improvement, and enhancing the effectiveness of statistical process control charts.", "e:keyword": ["TOTAL QUALITY MANAGEMENT", "CONTINUOUS IMPROVEMENTS", "PRODUCTION AND OPERATIONS MANAGEMENT"]}, {"e:year": 1994, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1994.tb00117.x", "e:abstract": "Recent theoretical work suggests that quality-improvement activities can yield significant indirect effects through process improvements and reduced factory congestion and confusion, benefits that are overlooked or hidden in most management accounting or cost of quality systems. Using time series data from two consumer durables manufacturing plants, I estimate the indirect productivity gains from quality improvement. The evidence from the plants indicates that the indirect effects from improved quality are at least two to three times the direct benefits attributable to lower scrap, rework, and inventory holding costs. An important implication of these findings is that companies that justify investments and measure performance based only on the direct costs of poor quality will motivate managers to make suboptimal decisions regarding quality-improvement activities.", "e:keyword": ["PRODUCTIVITY", "QUALITY COSTS", "CONFORMANCE QUALITY", "MANAGEMENT ACCOUNTING", "PROCESS IMPROVEMENT"]}, {"e:year": 1994, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1994.tb00118.x", "e:abstract": "Market globalization, higher requirements for improved quality, and tough, faster-pace, price-sensitive competition have led to two parallel and visible quality thrust: the Baldrige Award in the U.S. and, internationally, the ISO 9000 standards. The relationship between the Baldrige Award and ISO 9000 registration is widely confused. Two common misper-ceptions stand out: (1) that they both cover the same requirements and (2) that they both address improvement, relying on high quality results, and thus, are both forms of recognition. Many have concluded that the Baldrige Award and ISO 9000 are equivalent and that companies should choose one or the other. These conclusions are incorrect. The Baldrige Award and ISO 9000 registration differ fundamentally in focus, purpose, and content.", "e:keyword": ["TOTAL QUALITY MANAGEMENT", "BALDRIDGE NATIONAL QUALITY AWARD", "ISO 9000"]}, {"e:year": 1994, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1994.tb00120.x", "e:abstract": "Originally conceived by Frank and Lillian Gilbreth, the “tabletop improvement experiments” have been used in Japan since 1925 to teach important principles of continuous improvement. The experiments, designed for classroom use, communicate their lessons in a striking and memorable way. The work-related experiments categorize the sources of resistance to change and show how to neutralize them. The process-related experiments sharpen understanding of where the biggest opportunities for process improvement usually lie. Surprisingly, the experiments are hardly known in the West. We describe all of them and document their history for the first time.", "e:keyword": ["KAIZEN", "CONTINUOUS IMPROVEMENT", "QUALITY CONTROL", "OPERATIONS MANAGEMENT"]}, {"e:year": 1994, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00388.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1994, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1994.tb00124.x", "e:abstract": "We address the issue of performance analysis of fabrication/assembly (F/A) systems, which are systems that first fabricate components and then join the components and subassemblies into a product. Here we consider an F/A system consisting of a single assembly station with input from K fabrication stations. We assume that the system uses a Kanban control mechanism with a fixed number of kanbans circulating between each input station and the assembly station. Even with Markovian assumptions, computing an exact solution for the performance evaluation of such systems becomes intractable due to an explosion in the state-space. We develop computationally efficient algorithms to approximate the throughput and mean queue lengths. The accuracy of the approximations is studied by comparison to exact results (K = 2) and to simulations (K > 2). Part II of this paper demonstrates how these models can be used as building blocks to evaluate more complex F/A systems with multiple levels of assembly stations.", "e:keyword": ["ASSEMBLY‐LIKE QUEUES", "CONWIP", "KANBAN", "QUEUEING NETWORK APPROXIMATIONS"]}, {"e:year": 1994, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1994.tb00127.x", "e:abstract": "A resource-based construct of manufacturing competence, termed strategic production competence, is examined with respect to its convergent, discriminant, and predictive validity. The construct evaluates manufacturing performance across a comprehensive domain of competitive priorities relative to item importance and performance. Data from an earlier study of furniture firms (n = 65) are used for statistical testing. The results establish the convergent and discriminant validity of strategic production competence and show that it is positively related to business performance.", "e:keyword": ["PRODUCTION AND OPERATIONS MANAGEMENT", "STRATEGIC MANAGEMENT AND POLICY", "STATISTICS"]}, {"e:year": 1995, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00388.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1995, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1995.tb00038.x", "e:abstract": "The mantra of health care reform in hospitals in the United States and elsewhere, the spiralling costs of health care, and the development of diagnostic-related groups (DRGS) that define health services as “products” are influencing the strategic role of operations planning and control in hospital delivery systems. We developed a new operations planning and control system that we call “Hospital Resource Planning” (HRP). This system is based on the concept of DRGS and the familiar concept of manufacturing resources planning (MRP-II). TO determine the potential feasibility of HRP, we gathered longitudinal data from two hospitals, one 300-bed community hospital and one 1,100-bed teaching hospital. Our exploratory study indicated that while the concept of MRP-II can be transferred to hospitals, the traditional MRP logic has shortcomings. HRP advances prior research in three ways: (1) consideration of DRGS as products with a bill of resources structure that simultaneously incorporates both capacity and materials resources, (2) implementation of a hospital-wide (versus a functional) planning and control'system, and (3) gross-to-net requirements logic based on notions of treatment staging. Other feasibility issues that we addressed pertain to a stochastic bill of resources, trends toward hospital product standardization, and the coordination of a central planning system with decentralized decision making. The paper concludes with a description of areas for future research.", "e:keyword": ["HOSPITAL RESOURCE PLANNING", "PLANNING AND CONTROL SYSTEMS", "BILL OF RESOURCES", "TREATMENT STAGING", "OPERATIONS STRATEGY", "REENGI‐NEERING HEALTHCARE"]}, {"e:year": 1995, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1995.tb00039.x", "e:abstract": "This paper describes a global job shop scheduling procedure that uses a genetic algorithm to find a good schedule. Unlike previously considered algorithms, this procedure has been implemented in the scheduling system for a manufacturing facility and has led to improved scheduling. This facility is a semiconductor test area. The test area is a job shop and has sequence-dependent setup times at some operations. The concern of management is to meet their customer due dates and to increase throughput. This requires the coordination of many resources, a task beyond the ability of simple dispatching rules. We discuss a centralized procedure that can find a good schedule through the use of a detailed scheduling model and a genetic algorithm that searches over combinations of dispatching rules. We discuss our effort in developing a system that models the shop, creates schedules for the test area personnel, and makes a number of contributions to test area management.", "e:keyword": ["JOB SHOP SCHEDULING", "GENETIC ALGORITHMS", "SEMICONDUCTOR MANUFACTURING"]}, {"e:year": 1995, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1995.tb00040.x", "e:abstract": "This is an investigation into how optimal production rates and optimal price levels react to the introduction of an environmental tax on emissions. While, in the case of perfect competition, a linear tax has no effect, I show that in the monopolistic case the optimal production and emissions rates decrease in all instances-without an additional smoothing effect. The desirable effect, emissions peaks being cut off, is only achieved when a progressive tax is imposed.", "e:keyword": ["PRODUCTION SMOOTHING", "MARKETING", "PRICING", "ENVIRONMENTAL CONSTRAINTS", "MATHEMATICAL PROGRAMMING", "OPTIMAL CONTROL"]}, {"e:year": 1995, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1995.tb00042.x", "e:abstract": "This paper is an extension of Billington, who used the framework of the economic production quantity (EPQ) to model setup cost reduction. In the present paper, we use the EPQ model as a starting point to investigate the nature of setup costs and the effect of setup time reduction on the increase in available capacity. Reducing setup is vital to a company's success because a lengthy changeover of machinery is expensive: it demands long production runs to justify its cost, and these, in turn, lead to excessive inventory and to a slow response to customer needs. As in Billington, setup reduction is modeled as a function of an annual amortized investment. The paper examines the behavior of the setup time, the inventory cost, the lot size, and the freeing up of machine time in the face of a capacity constraint. A solution algorithm is provided to find setup times that minimize the sum of setup and holding cost, subject to a constraint on machine availability. The analysis sheds light on the true nature of setup cost and on the opportunity cost of not reducing setups. In the constrained optimization, the Lagrangian multiplier gives an estimate of the marginal value of adding one time unit of machine capacity, or, alternatively, of reducing one unit of setup time.", "e:keyword": ["SETUP TIME/COST", "SETUP REDUCTION", "CAPACITY INCREASE", "JIT"]}, {"e:year": 1995, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00388.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1995, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1995.tb00044.x", "e:abstract": "We give a tutorial on bottleneck dynamics. Bottleneck dynamics is a scheduling framework that uses approximate dual resource prices to make decentralized decisions. The basic idea is to establish a price for a resource as a function of the set of jobs that need to be processed by the resource. Tasks are then sequenced according to a cost/benefit ratio. Starting with one resource sequencing problems, we describe how priorities for jobs can be developed and how they translate into resource prices. We then describe how resource prices can be approximated in a multiresource situation and how lead times which are critical for these approximations can be accurately computed. We also describe a number of studies that have shown bottleneck dynamics to be an effective approach in several different problem areas.", "e:keyword": ["BOTTLENECK DYNAMICS", "SCHEDULING MODELS", "BENEFIT/COST RATIO", "SEQUENCING", "RESOURCE PRICING METHODS"]}, {"e:year": 1995, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1995.tb00045.x", "e:abstract": "Computer-integrated manufacturing implementation is often hindered by human resource issues like stress. By focusing on one type of potential human obstacle to the integration of islands of automation in our exploratory case study, we examine the sources of stress and the lack of job control experienced in three functional departments: computer-aided design and manufacturing, manufacturing planning and control, and computer numerical control/robot manufacturing; we also suggest management interventions to alleviate stress in each group of workers.", "e:keyword": ["AUTOMATION", "TECHNOLOGY MANAGEMENT", "STRESS"]}, {"e:year": 1995, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1995.tb00046.x", "e:abstract": "Determining safety stocks in multistage manufacturing systems with serial or divergent structures, where end-item demands are allowed to be correlated both between products as well as in time, is my focus. I show that these types of correlation have contrary effects on the distribution of safety stocks over the manufacturing stages and that neglecting the correlation of demand can lead to significant deviation from the optimal buffer policy. Using base-stock control and assuming total reliability for internal supplies, I present a procedure for integrated multilevel safety stock optimization that can be applied to arbitrary serial and divergent systems even when demand is jointly cross-product and cross-time correlated. As I demonstrate in an example for autocorrelated demands of a moving average type, there are specific solution properties that drastically reduce the computational effort for safety stock planning. Safety stocks determined in that way can be used as an appropriate protection against demand uncertainties in material requirements planning systems.", "e:keyword": ["BASE‐STOCK CONTROL", "CORRELATION OF DEMANDS", "MULTISTAGE MANUFACTURING SYSTEMS", "SAFETY STOCK OPTIMIZATION"]}, {"e:year": 1995, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1995.tb00047.x", "e:abstract": "Cyclic scheduling has been primarily studied under deterministic assumptions. In practice, stochastic variability exists and must be taken into account. In this paper, the descriptive Markov chain model of Bowman and Muckstadt is extended to cover demand variability. A production control algorithm is developed using cyclic time and task criticality estimates from the model. Application of the algorithm to a case study shows that material release and anticipatory inventory buildup decisions can be effective in reducing inventory holding and overtime costs when significant demand variability is present.", "e:keyword": ["CYCLIC SCHEDULING", "PRODUCTION CONTROL", "MARKOV CHAIN"]}, {"e:year": 1995, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1995.tb00050.x", "e:abstract": "A nationwide research program on the performance of American industry, sponsored by the Alfred P. Sloan Foundation, now involves scores of faculty researchers and more than 100 graduate students at several American universities. Ten research centers have been established, and each one is dedicated to the study of a particular industry. An eleventh center is carrying out research on problems that cut across these industries. It is expected that the Sloan Industry Studies program will make useful contributions to the performance of the industries themselves, to policymaking at all levels of government, and to the development of interdisciplinary research communities within the universities.", "e:keyword": ["INDUSTRIAL PERFORMANCE", "MANUFACTURING", "UNIVERSITY‐INDUSTRY RELATIONS"]}, {"e:year": 1995, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1995.tb00051.x", "e:abstract": "A serious gap is emerging between what is espoused as total quality management and what is actually being implemented. Examples of actual implementation failures are given. In addition to affecting the offending firms, these gaps threaten the viability of the quality management movement in the United States. Their causes and appropriate counter measures are worthy topics for research.", "e:keyword": ["TOTAL QUALITY MANAGEMENT", "IMPLEMENTATION GAPS", "TQM RESEARCH"]}, {"e:year": 1995, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1995.tb00052.x", "e:abstract": "A methodology for benchmarking manufacturing practices in the worldwide semiconductor industry is presented. Several metrics for measuring semiconductor manufacturing performance are defined and discussed. Interviews conducted during site visits are used to identify the managerial, technical, and organizational practices underlying superior metric performance. Multivariate statistical analyses of the performance metric data indicate that these performance metrics measure independent aspects of performance and expose significant performance differences among fabs.", "e:keyword": ["BENCHMARKING", "SEMICONDUCTOR MANUFACTURING"]}, {"e:year": 1995, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1995.tb00053.x", "e:abstract": "Redesigning and improving business processes to better serve customer needs has become a priority in service industries as they scramble to become more competitive. We describe an approach to process improvement that is being developed collaboratively by applied researchers at US WEST, a major telecommunications company, and the University of Colorado. Motivated by the need to streamline and to add more quantitative power to traditional quality improvement processes, the new approach uses an artificial intelligence (AI) statistical tree growing method using customer survey data to identify operations areas where improvements are expected to affect customers most. This AI/statistical method also identifies realistic quantitative targets for improvement and suggests specific strategies predicted to have high impart. This research, funded in part by the Colorado Advanced Software Institute (CASI) to stimulate profitable innovations, has resulted in a practical methodology used successfully at US WEST to help set process improvement priorities and guide resource allocation decisions throughout the company.", "e:keyword": ["QUALITY IMPROVEMENT", "HEURISTIC OPTIMIZATION", "MACHINE LEARNING", "SERVICE INDUSTRY", "CUSTOMER SERVICE MEASURES"]}, {"e:year": 1995, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1995.tb00057.x", "e:abstract": "Total quality management (TQM) is a revolutionary approach to effective management. The research in TQM has emerged from practical needs of organizations embracing this philosophy, and the literature is mostly conceptual and practitioner-oriented. There is a lack of sound theoretical framework classifying past efforts and guiding future research. To fill the void, a study of the published TQM literature is undertaken. A review, classification, and analysis of the research in TQM spanning the last two decades is presented. A total of 226 TQM-related articles are identified from 44 refereed management journals published from 1970 to 1993. These articles are then classified and analyzed using the following two-dimensional scheme: (1) article orientation (conceptual, case study, empirical, analytical, simulation, and overview) and (2) article focus using the Malcolm Baldrige National Quality Award criteria. The analysis of the literature presents pertinent developments in each of the seven criteria. In addition, it provides future research directions as well as a ready reference of the TQM literature. The suggestions for research should guide future developments in the TQM field and help transform it into a formal discipline.", "e:keyword": ["QUALITY MANAGEMENT", "THE MALCOLM BALDRIGE NATIONAL QUALITY AWARD", "CONTINUOUS IMPROVEMENT"]}, {"e:year": 1995, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00388.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1995, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1995.tb00301.x", "e:abstract": "We describe a set of models that are used to manage the product and process design in a mass placement printed circuit board (PCB) assembly cell. Our models can be divided into two categories. First, we characterize the cell design problem and develop models to design an efficient assembly cell. Second, we present models for optimizing the different operational aspects of the assembly cell. These models were developed to assist the managers of a large electronic manufacturing firm in establishing mass placement PCB assembly cells.", "e:keyword": ["PCB ASSEMBLY", "INTEGER PROGRAMMING", "DYNAMIC PROGRAMMING"]}, {"e:year": 1995, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1995.tb00302.x", "e:abstract": "We propose an agglomerative heuristic cluster analysis framework for application to the part-family and machine-cell formation problems associated with group technology. This framework addresses the notion of concurrently forming clusters of parts (families) and machines (cells) based on natural between-part and between-machine relationships and the strength of association relating pairs of parts with pairs of machines. An illustrative model is presented and operational aspects demonstrated using a small problem.", "e:keyword": ["FACILITIES PLANNING", "CELLULAR MANUFACTURING SYSTEM DESIGN", "CLUSTER ANALYSIS"]}, {"e:year": 1996, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00380.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1996, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00381.x", "e:abstract": "The concept and techniques of “manufacturing strategy” offer managers the opportunity to use their production function as a strategic weapon in competition, an apparently attractive objective. Yet after about 25 years, the use of manufacturing in corporate strategy (MCS) as a management practice is not widespread. In contrast, however, in academic literature it appears to be flourishing and rapidly growing in popularity. This paper seeks to answer this apparent paradox, beginning with the history of MCS as it was developed as a theory of design to enable a manufacturing system to be focused on a key competitive task. Common criticisms of MCS, such as “tradeoffs,” “focus” and “undynamic,” are examined and refuted as valid reasons for its only modest usage. Instead, three “new” problems in the MCS concept and its techniques are suggested as genuine needs for the completion of the theory and for its becoming more universally understood and used by industrial managers.", "e:keyword": ["MANUFACTURING STRATEGY", "FOCUSED FACTORIES", "TRADEOFFS IN MANUFACTURING", "OPERATIONS STRATEGY"]}, {"e:year": 1996, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00382.x", "e:abstract": "After a decade of updating and modernizing U.S. manufacturing with advanced management techniques (AMTS), competitive results have been generally disappointing. Industrial managers under pressure have relied on AMTS to solve their problems, but in this era of ever more intense and fast-moving competition, this has generally proven inadequate. Competitors abroad have moved ahead just as vigorously and usually earlier in applying AMTS such as JIT, TQM, and MRP, so the result has been “competitíve gridlock.” Simultaneously, industry is full of misfits between manufacturing policies and strategy, as AMT-driven managers make and change policies piecemeal. The mediocre results of this conventional, operational mindset demonstrate that sheer productivity improvement or other conventional performance objectives seldom build unique competitive advantage. Winning in competition today requires a different management approach, one which is focused on establishing competitive superiority. Basic structural redesign is the key to clear competitive advantage, but its rare practice signals the presence of problems in the skills, attitudes, and premises of many industrial managers. Rather than continuing the common practice of relying on available AMTS, a new breed of industrial managers is needed, equipped with a breadth of skills which encompass all the functional areas of production and who are business- and strategy-rather than narrowly operation- and functionally-oriented.", "e:keyword": ["MANUFACTURING STRATEGY", "PLANNING AND CONTROL TECHNIQUES", "COMPETITIVE STRATEGY", "MANAGEMENT DEVELOPMENT"]}, {"e:year": 1996, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00383.x", "e:abstract": "The concept of “manufacturing strategy” is still, in human terms, barely past adolescence. In years, it is younger than most of the MBAs who study it today. So it is not surprising that–like them–it has been undergoing almost continual growth and elaboration throughout its short life, as it tested itself against the real world and as that world evolved. Today it is facing perhaps the greatest challenge in its short history, as it finds itself in the crossfire of debates about core aspects of its two parent disciplines: manufacturing management and competitive strategy. This paper begins by briefly reviewing some of the key steps in the conceptual development of the manufacturing strategy paradigm, then describes the attacks now being directed at both the manufacturing management and the competitive strategy paradigms, and finally discusses the new perspectives that these two paradigm shifts are shedding on some familiar problems.", "e:keyword": ["MANUFACTURING STRATEGY", "COMPETITIVE STRATEGY", "CAPABILITIES"]}, {"e:year": 1996, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00384.x", "e:abstract": "In light of the widespread adoption of advanced production concepts over the last decade, the traditional concern of manufacturing strategy–linking manufacturing structure and infrastructure to business strategy–has seemed less powerful in explaining competitive success or improving competitive performance. Companies that have introduced just-in-time, total quality management, continuous improvement, design for manufacturability, or concurrent engineering appear to have reaped the benefits of quality, dependability, flexibility, high variety, and low cost. This raises an important question: is manufacturing strategy in its traditional vintage passe? In this paper, I first explore the logic behind the traditional prescriptions in manufacturing strategy using a classic case on Searle's Medical Instruments Group. Then, using the term advanced manufacturing system (AMS) as shorthand for best practice in production, design and engineering, and logistics, I revisit the Searle case as taught in 1995 to illustrate the logic of the AMS. Finally, I offer a framework for synthesis, arguing that manufacturing's true competitive power lies in integrating the capabilities of an AMS with strategic management of manufacturing.", "e:keyword": ["MANUFACTURING STRATEGY", "ADVANCED MANUFACTURING CONCEPTS", "COMPETITIVE ADVANTAGE"]}, {"e:year": 1996, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00385.x", "e:abstract": "In spite of the significant progress made by a wide range of manufacturing companies over the past decade, few senior executives in U.S. firms would point to manufacturing as a significant source of competitive advantage. This paper seeks to explore some of the basic reasons for this. It begins by providing a framework for manufacturing competitiveness. It then outlines a handful of characteristics that seem to have been pervasive in a wide range of manufacturing competitiveness programs over the past decade. In contrast to those characteristics, it uses three quite different organizations to illustrate a very different mode for pursuing manufacturing competitiveness. Finally, the paper concludes by outlining three elements that appear to be essential in the successful pursuit of manufacturing advantage.", "e:keyword": ["MANUFACTURING STRATEGY", "COMPETITIVE ADVANTAGE"]}, {"e:year": 1996, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00386.x", "e:abstract": "Today's markets are characterized by time and product quality-based competition. Companies must compete through their ability to manage the whole cycle of product realization and delivery, from the initial concept through to delivery and support at the customer. They must do this through managing an integrated company, not a set of separate functions. This paper addresses the issue of how companies should develop operations strategies for engineering and manufacturing combined. It uses field research into 15 engineering companies to develop the concept of the manufacturing system mission, and proposes strategic choices for manufacturing, engineering and linked functions.", "e:keyword": ["MANUFACTURING STRATEGY", "ENGINEERING", "ALIGNMENT"]}, {"e:year": 1996, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00387.x", "e:abstract": "This paper demonstrates an approach to successfully managing change of manufacturing strategy. It first introduces the issues and management guidelines, and then describes how one company used this approach to achieve dramatic benefits from changing its manufacturing strategy. A third part of the paper elaborates on how the company made the approach work.", "e:keyword": ["MANUFACTURING", "STRATEGY", "CHANGE"]}, {"e:year": 1996, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00388.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1996, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00390.x", "e:abstract": "We consider an important topic from the traditional quality literature-the impact of conformance quality of a manufactured product on the preventive maintenance costs to downstream users of this product. Folk wisdom supports the notion that higher conformance quality translates into lower maintenance costs (as well as other components of life-cycle costs) for these users. We examine this proposition in some detail on the basis of a failure-time model that relates conformance quality to reliability. We consider both repairable and nonrepairable items that are maintained by a block-replacement or a minimal-repair strategy. In addition to maintenance cycles and costs, we discuss the value of information to the user as to the actual production quality, and the value of inspection.", "e:keyword": ["CONFORMANCE QUALITY", "PREVENTIVE MAINTENANCE", "TQM", "TPM", "BLOCK‐REPLACEMENT STRATEGY", "MINIMAL‐REPAIR STRATEGY"]}, {"e:year": 1996, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00393.x", "e:abstract": "Kramer and Lee recently addressed a common due window scheduling problem with earliness and tardiness penalties, where earliness and tardiness penalty factors are constant and the common window size is given. They showed that the problem is polynomial when the location of the due window is a decision variable. For the case where the location of the due window is given, the problem is also polynomial when the latest due date is greater than or equal to the makespan, and they proposed a pseudopolynomial dynamic programming algorithm to find an optimal schedule when the latest due date is less than the makespan. In this note we address the problem for the case where the location of the due window is given. Specifically, we show that the problem is polynomial if the window location is unrestricted, and present a more efficient dynamic program algorithm to optimally solve the problem if the window location is restricted. The concepts of unrestricted and restricted window locations are defined in this note.", "e:keyword": ["PRODUCTION SCHEDULING", "DUE WINDOW", "DYNAMIC PROGRAMMING"]}, {"e:year": 1996, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00388.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1996, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00395.x", "e:abstract": "It has been argued in the literature that business strategy and manufacturing flexibility independently affect the performance of an organization. However, no empirical examination of the interrelationship among these three constructs has been performed. In this paper, based on a field study of 269 firms in the manufacturing industry, the identified constructs have been used to test a theoretical model using path analysis techniques. Our results indicate that business strategy contributes both directly and indirectly to organizational performance. The findings provide evidence of direct effects of (i) business strategy on manufacturing flexibility and (ii) manufacturing flexibility on organizational performance.", "e:keyword": ["MANUFACTURING FLEXIBILITY", "BUSINESS STRATEGY", "ORGANIZATIONAL PERFORMANCE", "PATH MODEL"]}, {"e:year": 1996, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00396.x", "e:abstract": "Focus in the manufacturing plant is generally deemed to be an important element of success in manufacturing strategy. Yet, little work has been completed in the measurement of plant focus and a dearth of empirical evidence exists to support the broad popularity of this concept. This paper presents a plant focus measurement approach and reports the results of a field study that uses a site visit research design to apply the focus measure to a multi-industry sample of manufacturing plants. Regression analysis is used to study the relationships between the plant focus variable and the environmental variables of plant size, number of product lines, plant age, number of processes, and type of processes. Although highly intuitive, these relationships have undergone very little empirical study in the literature. Our study provides evidence of a strong logarithmic relationship between our plant focus measure and the number of product lines. Support is also demonstrated in that our measure of plant focus is linked to the number and type of manufacturing processes. However, the variables of plant age and plant size do not appear related to the plant focus measure. The literature-based multicriteria focus measure can be used by managers and researchers as an objective, formal, and generalizable approach for assessing plant focus, for identifying areas in the plant that detract from focus, and for tracking focus improvement efforts over time.", "e:keyword": ["FOCUSED FACTORY", "MANUFACTURING FOCUS", "MANUFACTURING STRATEGY"]}, {"e:year": 1996, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00397.x", "e:abstract": "This study addresses the problem of replanning frequency for a rolling horizon master production schedule (MPS) in a process industry environment under demand certainty. The major contribution of this paper is the demonstration of how the appropriate replanning frequency for a MPS can be determined under the conditions of minimum batch-size production restrictions in a rolling planning horizon setting. In addition, the problem environment for this study is an actual MPS operation that includes features such as multiple production lines, multiple products, capacity constraints, minimum inventory requirements, and multiple goals. Actual data from a paint company are used to determine the appropriate replanning frequency for a rolling horizon MPS. Results indicate that a 2-month replanning frequency was the best at this firm because of the significant cost savings it provided when compared to actual company performance and the other replanning intervals.", "e:keyword": ["MASTER PRODUCTION SCHEDULING", "GOAL PROGRAMMING"]}, {"e:year": 1996, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00398.x", "e:abstract": "The main advantage of deep lane storage systems compared with conventional high bay warehouses is seen in a better space utilization, because products are stored in channels one pallet behind the other. However, for deep lane storage systems the last-in-first-out principle holds and direct access to pallets is lost apart from the last pallet entering a channel. To operate deep lane storage systems effectively, namely, providing high throughput rates even at times of high storage rack utilization requires a sophisticated operational planning system. We will describe a totally new concept consisting of five modules for storage and retrieval assignments, as well as for a reorganization of storage location occupations.", "e:keyword": ["DEEP LANE STORAGE SYSTEMS", "WAREHOUSE ADMINISTRATION SYSTEM"]}, {"e:year": 1996, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00388.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1996, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00402.x", "e:abstract": "This paper presents a personal perspective on the history, current research, and emerging topics in the field of Service Operations Management. I see research in the field evolving from a focus on classifications and operations research models in the 1970s and 1980s, to a current focus on laboratory studies, and survey- and case-based research. Selected current research is presented under the following headings: Service encounter design, service quality, drivers of service competitiveness, yield management, and the information revolution and the globalization of services. Examples of creativity in service delivery and some whimsical characteristics of service junkies are also presented.", "e:keyword": ["SERVICE OPERATIONS MANAGEMENT", "SERVICE ENCOUNTER", "CUSTOMER CONTACT", "POKA YOKE"]}, {"e:year": 1996, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00404.x", "e:abstract": "Engineering changes in the design of a product, while attractive from a marketing viewpoint (in terms of increased sales opportunities, matching competitors innovations, etc.) cause disruptions in the manufacturing function of a firm. These disruptions include delays or backorders in the delivery of both committed-orders and forecast-demands of existing products, increased capacity requirements that could result in greater use of subcontracts, higher component inventories, and obsolescence of certain components. In this paper, we establish how the marketing opportunities and manufacturing costs associated with engineering changes can be managed so as to enhance the firm's profits over a planning horizon. Using an optimization model, we show that an enhanced product with increased marketing opportunities may not immediately replace the existing product; it may be phased in over a period of time. We further illustrate how the firm's overall profit, and the mechanics of phasing out the old product and phasing in the new product, are affected by factors such as the manufacturing lead time of the new product, its market attractiveness as compared to the old product, capacity availability, subcontracting premiums, and backorder costs. We develop several insights that allow managers to quickly establish whether an engineering change would be desirable and discuss a multitude of options that may be used to further enhance their desirability. Finally, we show that if the phase out period of the old product is set arbitrarily, rather than optimally, the result may be a substantial reduction in overall profits.", "e:keyword": ["ENGINEERING CHANGE", "MANUFACTURING‐MARKETING INTERFACE", "BILL OF MATERIALS"]}, {"e:year": 1996, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00405.x", "e:abstract": "Since the development of early versions of material requirements planning (mrp) systems, it has been known that a weak link in this technique is the failure to consider the available capacity at the time the lot sizes for individual items are calculated. Ignoring the available capacity may result in infeasible production plans, i.e., those that can only be accomplished with the use of overtime. We present a technique to search for feasible production plans by means of minimizing the total overtime. The technique is based on modifying periodic-order-quantity (poq) lot sizes within a tabu search framework. Computational experiments with the largest problem structure reported in the literature show that the procedure is effective in determining lot sizes for individual items that either minimize or eliminate overtime. Additional experiments reveal that, with appropriate calibration of search parameters, the procedure is also able to deal with more general cost functions (e.g., those that include holding and setup costs).", "e:keyword": ["LOT‐SIZING", "CAPACITY REQUIREMENTS PLANNING", "MATERIALS REQUIREMENT PLANNING"]}, {"e:year": 1996, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1996.tb00407.x", "e:abstract": "This is a study of single and parallel machine scheduling problems with controllable processing time for each job. The processing time for job j depends on the position of the job in the schedule and is a function of the number of resource units allocated to its processing. Processing time functions and processing cost functions are allowed to be nonlinear. The scheduling problems considered here have important applications in industry and include many of the existing scheduling models as special cases. For the single machine problem, the objective is minimization of total compression costs plus a scheduling measure. The scheduling measures include makespan, total flow time, total differences in completion times, total differences in waiting times, and total earliness and tardiness with a common due date for all jobs. Except when the total earliness and tardiness measure is involved, each case the problem is solved efficiently. Under an assumption typically satisfied in just-in-time systems, the problem with total earliness and tardiness measure is also solved efficiently. Finally, for a large class of processing time functions; parallel machine problems with total flow time and total earliness and tardiness measures are solved efficiently. In each case we reduce the problem to a transportation problem.", "e:keyword": ["SINGLE AND MULTIPLE MACHINE SCHEDULING", "CONTROLLABLE TIMES", "APPLICATIONS OF TRANSPORTATION PROBLEM"]}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00408.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00409.x", "e:abstract": "Since Eli Goldratt first appeared on the scene in the late 1970s, his ideas concerning production management have generated a huge amount of interest, controversy, and misunderstanding. These ideas have been proliferated under several names such as optimized production technology (OPT), drum-buffer-rope (DBR), synchronized manufacturing (SM), and theory of constraints (TOC). Although there seems to be general agreement on the importance of how capacity-constrained resources are scheduled, research aimed at advancing the state of the art for the specific problem addressed by DBR continues to be limited by prior misunderstandings and the lack of a rigorous examination by the academic community. This paper seeks “to advance the state of research on constraint scheduling in several ways. First, it presents a concise history of the evolution of DBR. It then explains the use of rods in constraint scheduling. Next, it presents in detail the solution algorithm incorporated by the Goldratt Institute in their production software and, finally, relates that algorithm to alternative methods. In the process of these activities, several lingering misconceptions are resolved.", "e:keyword": ["CONSTRAINT SCHEDULING", "DRUM‐BUFFER‐ROPE", "SEQUENCING"]}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00410.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00411.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00412.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00413.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00414.x", "e:abstract": "We study the dynamic routing problem for a flexible manufacturing system consisting of two unreliable machines and a finite buffer. One product-type is produced which requires two operations in sequence. The demand rate is assumed to be constant. Each machine is capable of performing both operations. The objective is to trace the demand while keeping the work-in-process low and the cycle-time short. An optimal control formulation is established for the dynamic routing problem. A production flow control algorithm is developed based on a combination of mathematical modeling and heuristics. The control policy is simulated and a comparison with the numerical optimal solution shows that it performs well for the instances under consideration.", "e:keyword": ["FLEXIBLE MANUFACTURING SYSTEMS", "PRODUCTION FLOW CONTROL", "DYNAMIC ROUTING"]}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00415.x", "e:abstract": "We study the problem of scheduling jobs on a single batch processing machine to minimize the total weighted completion time. A batch processing machine is one that can process a number of jobs simultaneously as a batch. The processing time of a batch is given by the processing time of the longest job in the batch. We present a branch and bound algorithm to obtain optimal solutions and develop lower bounds and dominance conditions. We also develop a number of heuristics and evaluate their performance through extensive computational experiments. Results show that two of the heuristics consistently generate high-quality solutions in modest CPU times.", "e:keyword": ["SCHEDULING", "BATCH PROCESSING MACHINES", "SEMICONDUCTOR MANUFACTURING", "HEURISTICS"]}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00417.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00418.x", "e:abstract": "We are moving rapidly into an age of transnational manufacturing, where things made in one country are shipped across national borders for further work, storage, sales, repair, remanufacture, recycle, or disposal; but our laws, policies, and management practices are slow in adjusting to this reality. They are often based on inaccurate premises. This article examines these premises and suggests what they imply for management of manufacturing.", "e:keyword": ["GLOBAL PRODUCTION", "TRANSNATIONAL MANUFACTURING", "GLOBAL FACTORY NETWORK", "MANUFACTURING FOREIGN DIRECT INVESTMENT"]}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00419.x", "e:abstract": "The competitiveness of Western European manufacturing is slowly being eroded away and European firms must act decisively to halt this decline. Costs in Europe are high and getting higher. Productivity is not keeping pace. European manufacturers have adopted some of the ideas that have proved useful to manufacturers elsewhere around the globe, but they need to do more. Many European countries remain net exporters of direct investment. If the erosion is to be halted, European manufacturers must address overcapacity, particularly among the many small factories there, inappropriate plant locations, and company organizations that foster too much country-specific independence.", "e:keyword": ["WESTERN EUROPE", "MANUFACTURING", "PRODUCTIVITY", "COMPETITIVENESS"]}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00420.x", "e:abstract": "There should be two distinctly different pom introductory courses (or even tracks) for MBAs. Course one (called pom) would consist of traditional pom materials emphasizing domestic POM course materials. Course two, called international production and operations management (ipom), would focus on international aspects of pom, emphasizing cross-boundary operations. Training of instructors differs significantly for the two courses. ipom accentuates operations crossing borders where different languages, cultures and currencies apply. The ipom syllabus employs cases and examples based on companies and/or divisions located in a great variety of countries. Three important drivers of the international pom curriculum should be recognized: (1) supply chain management with ipom responsible for coordinating sources-of materials as well as making and delivering goods and services across global boundaries, (2) portfolio management because ipom can reduce risks by geographically diversifying operations, and (3) capabilities management because ipom must spot, develop and implement special global opportunities. Teaching how these three international drivers interact challenges the pom field to provide proper curriculum development and instructor methodology.", "e:keyword": ["INTERNATIONAL POM", "SUPPLY CHAIN MANAGEMENT", "PORTPOLIO MANAGEMENT", "CAPABILITIES MANAGEMENT"]}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00421.x", "e:abstract": "This essay argues that it is difficult to justify intellectually a separate subject of international operations management. Nevertheless, courses with titles like that abound and other professional activities are centered on international operations, at least in the United States. Of course, there are real differences in management activities in different parts of the world that must be contended with. A comparison of European and U.S. managers' exposure to international business suggests that there is a higher startup cost for U.S. managers to do so. Drawing an analogy between the management of operations and the solving of a huge mathematical programming problem implies that there are few new variables introduced by going international, but that the weights on existing variables can change substantially. Therefore, even though difficult to justify intellectually, continuing to treat international operations management separately may provide us some short-term advantages. By helping us focus our attention on the important variables that change, it may provide us the insights to help reduce the startup cost for U.S. managers entering international operations.", "e:keyword": ["NTERNATIONAL OPERATIONS", "TEACHING OPERATIONS MANAGEMENT", "INTERNATIONAL DIFFERENCES"]}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00422.x", "e:abstract": "In this paper we present the results of an empirical study of the manufacturing sites of foreign electronics companies in Singapore and Taiwan. The manufacturing and R&D capabilities at the sites are assessed. The way in which host government policies interact with R&D development at the sites and the speed of the R&D development are also considered. The results suggest that Singapore and Taiwan are now host to some advanced manufacturing and R&D operations. We show, however, that the product design work at the sites visited is never leading edge for the companies concerned. The speed at which product design responsibilities were designated to the sites is shown to be rapid when compared to an earlier study of foreign sites in the United Kingdom. We indicate areas in which national strategies in Singapore and Taiwan may have contributed to this faster development. In Singapore, we identify tax holidays and R&D grants as contributing to the pace of development.", "e:keyword": ["OFF‐SHORE MANUFACTURING", "ELECTRONICS", "OVERSEAS RESEARCH", "DEVELOPMENT"]}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00423.x", "e:abstract": "It has been more than a decade since the quality movement was reborn in U.S. industry, and there is widespread dissatisfaction with the results of some of these programs. At the same time, product and service R&D is on the rise. These trends are incorporated here into an extension of the Utterback-Abernathy model to examine the quality, technology, and performance relationship. Six hundred durable goods firms in 20 countries were surveyed and it was found that technology significantly moderated the association of R&D intensity and total quality management (tqm) with market share, controlling for industry category. In high technology firms, R&D intensity was significantly associated with market share; in low technology firms, tqm was significantly associated with market share. R&D intensity and tqm were significantly and inversely related, while R&D intensity and computer-aided manufacturing (cam) were significantly and directly related.", "e:keyword": ["TITLE R&D", "MARKET SHARE", "INDUSTRY DIFFERENCES"]}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00424.x", "e:abstract": "Increasing globalization has affected the way that firms are managed today. While its impact on competitive strategy, marketing, and finance has been well accepted and well studied, its effect on the firm's technology and operations has not. This paper provides resources for research and teaching in international technology and operations management (itom). Included are an extensive bibliography of papers and an overview of large-scale survey research initiatives in the area. By bringing together and categorizing this body of work, we hope to facilitate further work in the area and to help define ITOM'S scope.", "e:keyword": ["INTERNATIONAL TECHNOLOGY AND OPERATIONS", "GLOBAL SUPPLY CHAINS", "INTERNATIONAL INFORMATION SYSTEMS", "TECHNOLOGY TRANSFER", "INTERNATIONAL SERVICE OPERATIONS"]}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00425.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00426.x", "e:abstract": "In this paper, we present a review of the models for the management of global supply chains and some evidence concerning current practice. Our review is restricted to the literature on intrafirm global supply chains and is motivated by empirical data concerning the extent of intrafirm globalization. The review of the literature suggests that research has not evolved in a coherent manner, while the data suggest that the extent of globalization is also hard to gauge. Indeed, the journey toward supply chain globalization is far from over. Significant gaps exist between theory and the practice. We conclude with a summary of directions for future research.", "e:keyword": []}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00427.x", "e:abstract": "Reducing lead time enables a company to react more quickly to demand information and, hence, to better match supply with uncertain demand. But it is only one lever for improving response capability. Managers are familiar with others (e.g., excess capacity, supplier choice, and so forth) but lack techniques to quantify the impact of adjusting these levers. Here, we enumerate a number of these levers and present a model whereby they might be combined into effective response capability. The impact of adjusting these levers is illustrated by data obtained from a skiwear manufacturer that did so. Some of the insights that resulted run counter to intuition.", "e:keyword": []}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00428.x", "e:abstract": "This research investigates the interaction between formation of logistics partnerships and supply chain restructuring in the U.S. computer industry via a survey of 30 ongoing partnerships. Partnerships that have included restructuring are compared to those that have not. Examples of representative partnerships are presented. The survey results indicate that restructurers use partnerships to facilitate restructuring. Restructurers and non-restructurers form partnerships for different reasons and realize different types of benefits. Furthermore, restructurers realize greater benefits than do non-restructurers and view their partnerships as more successful. Restructurers report dramatic improvements in logistics cost (1l-30%) and order cycle time (62%). The research contributes to the existing literature by highlighting restructuring as an important aspect of logistics partnership formation and by presenting empirical data that shows how the two strategies are linked.", "e:keyword": ["LOGISTICS PARTNERSHIPS", "SUPPLY CHAIN RESTRUCTURING", "SURVEY RESEARCH", "COMPUTER INDUSTRY"]}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00430.x", "e:abstract": "Campbell Soup's continuous replenishment (CR) program is a novel innovation designed to improve the efficiency of inventory management throughout the supply chain. With CR (1) retailers pay a constant wholesale price but continue to participate in consumer promotions, (2) retailers transmit to the supplier daily inventory information via electronic data interchange (EDI), and (3) the supplier assumes responsibility for managing retailer inventories, i.e., vendor managed inventories (VMI). We develop simple inventory management rules to operate CR, and we test these rules with a simulation using actual demand data provided by Campbell Soup. On this sample we find that retailer inventories were reduced on average by 66% while maintaining or increasing average fill rates. This improvementreduces a retailer's cost of goods sold by 1.2%, which is significant in the low profitmargin grocery industry. Furthermore, these savings could have been achieved without VMI.", "e:keyword": []}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00431.x", "e:abstract": "Many governments have established, for various reasons, local confent purchasing rules for companies that wish to operate in their country. These requirements force firms to purchase a certain amount of components from suppliers located in that country. This paper describes local content rules and develops models to select suppliers while satisfying local content provisions. The single plant model can be transformed into a knapsack problem that is solved by a ranking procedure, and the solution provides insight as to the manner in which local content rules impact more generalized models. Furthermore, we illustrate possible negative effects to local industry that may result when governments set the local content percentage too high, and we discuss methods for companies to circumvent local content rules. Finally, we address the issue of local content rules in the context of multi-plant global sourcing decisions, and we provide an efficient solution procedure for the classical plant location model extended to include local content rules at each site", "e:keyword": ["LOCAL CONTENT RULES", "GLOBAL SOURCING", "INIERNATIONAL OPERATIONS"]}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00432.x", "e:abstract": "An important aspect of supply chain management is the optimal configuration of the supplier base. We develop a model to determine optimal lot sizes and the optimal number of suppliers when the yield of the product delivered from each supplier is random. While small orders from a large number of suppliers can reduce yield uncertainty, fixed costs associated with each supplier provide a penalty for having too many suppliers. This is the key tradeoff addressed by our model. We look at the cases when the suppliers are identical as well as nonidentical.", "e:keyword": []}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00478.x", "e:abstract": "We study an economic order quantity/reorder point (EOQ/ROP) model with stochastic demand and backorders where options of investing in reducing setup cost, lead time, and variance of demand forecast errors are available. The model is quite comprehensive relative to previous models since it simultaneously addresses the strategic decisions associated with these three investment opportunities as well as the tactical decisions of determining both the lot size and the safety stock. We develop a simple search procedure to obtain the optimal values of setup cost, lead time, variance of demand forecast errors, order quantity, and safety stock multiplier. Computational studies are performed to determine the sensitivity of the optimal solution of the model to changes in the model's parameters.", "e:keyword": ["PRODUCTION", "INVENTORY", "EOQ."]}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00479.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00480.x", "e:abstract": "Design of experiments has been and continues to be employed successfully for the robust design of products/processes. A principle contention in these areas of application concerns whether or not interactive effects should be estimated. The arguments, for and against, hinge on an experimenter's understanding of the interaction concept and on the value added that is derived from the increased effort required for assessing such effects. We propose an interactive graphics approach that assesses whether and which interactive effects to estimate. Our methodology yields several additional benefits to the experimenter that include prototype simulation and unique learning opportunities for augmenting process knowledge in post-analysis.", "e:keyword": ["PRODUCT/PROCESS DESIGN", "DESIGN OF EXPERIMENTS", "INTERACTION EFFECTS", "ELICITATION TECHNIQUES", "VISUALIZATION."]}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00481.x", "e:abstract": "Price and design quality define value for customers and are often used by firms to position products in the marketplace. Setting price and quality level on a new product for the first time and making appropriate changes over time to these variables to reflect changing conditions in the market requires careful coordination of design, manufacturing, and marketing variables. We present a control theoretic model to study the complex interaction among price, quality, and cost during the life cycle of a product. Our model considers the major design-manufacturing-marketing tradeoffs and helps determine optimal pricing, design quality, and production strategies in a dynamic environment with convex production costs.", "e:keyword": ["DESIGN QUALITY", "PRICING", "PRODUCT DEVELOPMENT", "QUALITY MANAGEMENT."]}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00482.x", "e:abstract": "Product design efforts in recent years have focused on standardization and simplification of the product structure. It has been widely argued that savings, tangible and intangible, can be realized by simplifying the product design. In this study, we examine this belief and show that other issues like flexibility of process and design are important as well. We demonstrate that having process flexibility, e.g., of producing a product in two different ways, using two different product structures (as opposed to one), is advantageous with respect to components purchasing costs. This result is in contrast with the notion of standardization since the variety of components in the flexible design is increased. Properties of savings in purchasing costs associated with the use of this flexible design are provided.", "e:keyword": ["PRODUCT DESIGN", "STANDARDIZATION", "COMPONENT COMMONALITY."]}, {"e:year": 1997, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1997.tb00483.x", "e:abstract": "We model choice of dispatching rules in real time (system state dependent) as a pattern recognition problem, using a modified version of Data Envelopment Analysis. A data base of system state and performance values is created from extensive simulation, and this data base is used to train the pattern-recognition model. Our results show that the model is very effective in choosing a mix of dispatching rules over a period of time, varying the mix with system objectives, and performing better than the strategy of using fixed rules. We show how “If-Then” decision rules can be created from the model and portrayed in a decision-tree-like diagram. Since such decision rules are based on rigorous mathematical foundations, optimization will be ensured in our approach.", "e:keyword": ["DYNAMIC RULE SELECTION", "PATTERN RECOGNITION", "DEA POSTULATES", "NESTED RULES", "SIMULATION", "DECISION TREE", "SYSTEM OPTIMIZATION."]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00128.x", "e:abstract": "Competitive pressures and changing production management paradigms have, in recent years, increased the importance of reliable and consistent production equipment. Initially, the Japanese, and now others, have espoused the virtues of a management philosophy known as total productive maintenance (TPM). We are interested in the maintenance-investment decisions for TPM. This paper (1) describes the basic elements of TPM programs, (2) categorizes the relevant research literature using a practitioner's framework for autonomous and planned maintenance activities, and (3) identifies the current gaps between practitioner needs and academic research in the area of TPM and offers suggestions to close the gaps.", "e:keyword": ["MAINTENANCE", "TOTAL PRODUCTIVE MAINTENANCE", "LITERATURE REVIEW"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00129.x", "e:abstract": "This paper compares and contrasts the current state of the art in the theory of quantity discounts with a field study of 39 firms. We start by categorizing and tabulating the literature pertaining to quantity discounts, and by summarizing the various studies and models according to their perspectives, assumptions, and characteristics. Next we describe current trends in industry with respect to the reasons why firms offer quantity discounts, the characteristics of discount schedules, and the effect of quantity discounts on the extent of centralized purchasing, number of suppliers, and just-in-time delivery. Finally, we identify a number of fruitful directions for future research.", "e:keyword": ["QUANTITY DISCOUNTS", "CONTRACTS", "SUPPLY CHAIN MANAGEMENT", "FIELD STUDY"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00130.x", "e:abstract": "This paper considers a model for decentralized control of an inventory system consisting of 1 central warehouse and a number of retailers. The cost structure includes holding costs at both echelons and shortage costs proportional to the time until delivery at the retailers. We analyze a procedure for coordinated but still decentralized control of the system. The procedure is based on a simple approximation, in which the stochastic lead times perceived by the retailers are replaced by their correct averages. The approximation enables us to decompose the considered multiechelon inventory problem into a number of single echelon problems, 1 for each installation. The information about how a certain decision at the warehouse affects the retailers is conveyed through the marginal cost increase with respect to a change of the expected lead time. This information about the retailer costs is used as a shortage cost at the warehouse. We show that a coordination procedure based on this information can be used for finding near-optimal reorder points for the system and provide bounds for the approximation errors.", "e:keyword": ["INVENTORY/PRODUCTION", "MULTIECHELON", "STOCHASTIC", "DECENTRALIZATION"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00131.x", "e:abstract": "The problem of production planning and setup scheduling of multiple products on a single facility is studied in this paper. The facility can only produce one product at a time. A setup is required when the production switches from one type of product to another. Both setup times and setup costs are considered. The objective is to determine the setup schedule and production rate for each product that minimize the average total costs, which include the inventory, backlog, and setup costs. Under the assumption of a constant production rate, we obtain the optimal cyclic rotation schedule for the multiple products system. Besides the decision variables studied in the classical economic lot scheduling problem (ELSP), the production rate is also a decision variable in our model. We prove that our solutions improve the results of the classical ELSP.", "e:keyword": ["PRODUCTION PLANNING", "SETUP SCHEDULING", "CYCLIC ROTATION SCHEDULE", "ECONOMIC LOT SCHEDULING PROBLEM"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00132.x", "e:abstract": "This study examines the effects of using different priority rules at different stages of a multistage, flow-dominant shop. A simulation model is constructed of a manufacturing system comprised of three stages: gateway, intcrmcdiatc, and finishing. As is typical of a flow-dominant shop, the overall flow of the simulated system (gateway to intermediate to finishing) is consistent with a flow shop, but processing in the intermediate stage involves multiple work centers and resembles a job shop.", "e:keyword": ["DISPATCHING RULES", "HYBRID SHOP", "SIMULATION"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00133.x", "e:abstract": "Recently we have developed solution procedures for the optimal replacement problem when the distribution of the time-to-failure (ttf) is partially specified by the first two moments, partial and complete. However, we have later learned, using Monte-Carlo simulation, that when moments are unknown and have to be estimated from sample data, the most accurate procedure developed therein is in practice extremely sensitive to sampling fluctuations.", "e:keyword": ["APPROXIMATIONS", "DISTRIBUTION FITTING", "OPTIMAL PREVENTIVE MAINTENANCE"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00434.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00437.x", "e:abstract": "The assembly of aircraft is a labor-intensive process that exhibits a significant learning-curve effect and that requires long flow times and costly work-in-process inventories. This paper describes the production context, the cost of flow time in this context, and some of the causes for the long flow times. We then develop an argument for a firm to use improvements in labor productivity to reduce flow times. Boeing has implemented the recommendations from this research and has obtained significant benefits from reducing flow times.", "e:keyword": ["FLOW‐TIME REDUCTION", "AIRCRAFT MANUFACTURING"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00438.x", "e:abstract": "This case study of a process improvement project from the Hewlett-Packard Analytic Products Group illustrates a number of important approaches for operations strategy. First, we show how process control in capillary tube manufacturing led to a significant improvement in tubing strength, a quality measure that relates to the frequency of tube defects at a particular stress level. Next, we show how one particular approach used for experimental design and process improvement was considerably more economical than another standard method. In conclusion, we link the process characteristics such as defect frequency to strategic measures such as company revenue and investment to underscore the strategic importance of process control.", "e:keyword": ["PROCESS IMPROVEMENT", "EXPERIMENTAL DESIGN", "STRATEGY", "TAGUCHI"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00439.x", "e:abstract": "A manufacturing optimization strategy is developed and demonstrated, which combines an asset utilization model and a process optimization framework with multivariate statistical analysis in a systematic manner to focus and drive process improvement activities. Although this manufacturing strategy is broadly applicable, the approach is discussed with respect to a polymer sheet manufacturing operation. The asset utilization (AU) model demonstrates that efficient equipment utilization can be monitored quantitatively and improvement opportunities identified so that the greatest benefit to the operation can be obtained. The process optimization framework, comprised of three parallel activities and a designed experiment, establishes the process-product relationship. The overall strategy of predictive model development provided from the parallel activities comprising the optimization framework is to synthesize a model based on existing data, both qualitative and quantitative, using canonical discriminant analysis, to identify main effect variables affecting the principal efficiency constraints identified using AU, operator knowledge and order-of-magni-tude calculations are then employed to refine this model using designed experiments, where appropriate, to facilitate the development of a quantitative, proactive optimization strategy for eliminating the constraints. Most importantly, this overall strategy plays a significant role in demonstrating, and facilitating employee acceptance, that the manufacturing operation has evolved from an experienced-based process to one based on quantifiable science.", "e:keyword": ["MANUFACTURING OPTIMIZATION", "MULTIVARIATE STATISTICAL ANALYSIS", "PROCESS‐PRODUCT RELATIONSHIP", "ASSET UTILIZATION"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00440.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00441.x", "e:abstract": "Having added total quality management (tqm), operations strategy, new product development, and many other topics to its repertoire over the past two decades, operations management is being pushed-by practitioners and students alike-to extend its reach both horizontally (to encompass the whole supply chain and the interface with other functions) and internationally. Moreover, the increasing sophistication of computer technology and the growth of the intemet are expanding the teaching and research methodologies that can be used to address these complex issues. Meeting the challenges posed by this ever-broadening conceptualization of our mission and the new tools available to us will require more than simply new knowledge and new courses. It also will require an influx of new people having very different backgrounds than in the past. We have to learn how to attract such people, how to prepare them to be effective teachers and researchers in production and operations management (pom), and how to work effectively with them. The locations of faculty, students, and potential partners in the learning experience also will be transformed, forcing us to reconsider how we organize to do our work and when and where we do it.", "e:keyword": ["POM's SCOPE", "NEW APPROACHES FOR TEACHING AND RESEARCH", "FACULTY PREPARATION", "RECRUITING", "DEVELOPMENT AND PROMOTION"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00442.x", "e:abstract": "We offer a view of operations management in the future based on a mapping of the field's history. We discuss issues raised by this view of the future that we expect will affect those who will teach and conduct research in operations management.", "e:keyword": ["PRODUCTION AND OPERATIONS MANAGEMENT", "TEACHING", "RESEARCH"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00443.x", "e:abstract": "This paper, addressed to professors of operations management (om) in research institutions, suggests that the long-term academic viability of our discipline requires the generation of a theory uniquely associated with the practice of OM. Such a theory will rest on foundations laid by other disciplines, but must find its own unique synthesis that attends to the problems of OM practice. The paper proposes a framework that recognizes physics, social psychology and philosophy as foundational disciplines for an integrative theoryof OM and suggests which concepts from those disciplines may find voice in such a theory.", "e:keyword": ["OPERATIONS MANAGEMENT", "INTEGRATED OPERATIONS", "CROSS‐FUNCTIONAL", "TEACHING AND RESEARCH"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00444.x", "e:abstract": "A new teaching paradigm, called the information/control/buffer (I/C/B) portfolio is described. The I/C/B portfolio has proven itself effective in introducing students to what managing operations is all about: using information, control, and buffers to manage the production of products and services. Even more important, the I/C/B viewpoint motivates students to think creatively about designing and developing new management systems. The I/C/B portfolio also provides a link between operations management, technology management, and information system management.", "e:keyword": ["TEACHING PARADIGM"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00445.x", "e:abstract": "Recently, there has been much concern over the dumbing down of production and operations management (pom) courses in response to the repudiation of the theory-heavy operations research (or) approach that became dominant during the 1970s. However, although almost everyone agrees that a new POM framework is needed, there is as yet little agreement on what it should be like. As a result, there is currently a huge variance among POM courses at different universities, ranging all the way from traditional OR courses to almost purely anecdotal case-oriented courses. Although academics have struggled with the search for an appropriate level of methodological rigor in POM courses, our customers (i.e., students and the firms that hire them) have been inundated by a blizzard of management buzzwords. Although many of these undoubtedly contain kernels of truth, the very nature of the buzzword approach is such that it provides little balanced guidance as to what methods work well in a given situation. In recognition of these disparities, POM researchers have begun trying to systematically describe the underlying behavior of production systems. The goal is to provide a framework that will help organize educational approaches and business practices in a consistent fashion. In this paper, we describe our attempt at the needed “science of manufacturing,” which we call factory physics, and illustrate how it fits into a new paradigm of POM teaching.", "e:keyword": ["TEACHING POM", "FACTORY PHYSICS"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00446.x", "e:abstract": "This paper postulates that the perception among students that operations management is a tedious, irrelevant subject is a symptom of the lack of a conceptual framework that effectively communicates the importance and relevance of the operations function in a firm. The first half of this paper discusses traditional frameworks, those most frequently found in introductory production and operations management (pom) textbooks, and several alternative approaches to teaching an introductory POM course. The discussion questions whether any of these existing frameworks is sufficient to meet the challenges faced while teaching POM in today's environment and identifies what characteristics an effective framework should possess. These characteristics include defining the scope and bounds of the field, capturing its integrative and system aspects, providing a visible depiction of the framework to aid comprehension, and promoting higher-level thinking (i.e., analysis, synthesis, and criticism) to deepen understanding. This discussion concludes that no current framework meets all of these criteria, therefore there remains a need for a more effective approach for introducing POM. The remainder of the paper describes one approach to conceptualizing the field that satisfies these criteria.", "e:keyword": ["TEACHING AND PEDAGOGY", "PRODUCTION/OPERATIONS MANAGEMENT"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00447.x", "e:abstract": "This paper discusses the benefits of restructuring the introductory undergraduate production and operations management (pom) course to improve its pedagogical effectiveness and to better convey the importance of integrating logistics planning activities. The introduction of a dynamic integrative semester-long case study which involves students in applying pom concepts and tools through a simulation game is reported.", "e:keyword": ["LOGISTICS MANAGEMENT", "ACTIVE LEARNING", "PEDAGOGICAL SIMULATION"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00448.x", "e:abstract": "Manufacturing in Eastern European countries is in transition to open-market competition. One transitional issue is university education for operations managers from the perspective of business practitioners. Survey responses by 203 manufacturing professionals from 83 companies provide recommendations for operations management education at the University of Sibiu in Romania. The recommendations substantially reorient curricula that traditionally prepared students for professions in centrally controlled economies rather than for open-market competition. The redesigned curriculum has an educational advantage in its integration of production, marketing, and engineering, all under one college of engineering. However, the curriculum is inconsistent with some tenets of quality management and just-in-time production. Also, survey data imply a need for coverage of competitive manufacturing strategy that, currently, is underrepresented in the curriculum.", "e:keyword": ["POM EDUCATION", "MANUFACTURING MANAGEMENT"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00449.x", "e:abstract": "Service operations courses are often too concerned with concepts or techniques and not enough with the solution of real-world service problems. This article presents a case study of the successful turnaround of such a course by rebuilding it around a field project. The project is presented in some details. It largely dictates the content and paces the delivery of the course. Strategic and tactical aspects in the design of such a course are discussed with the benefits and limitations of the approach.", "e:keyword": ["SERVICE OPERATIONS", "FIELD PROJECT", "TEACHING", "COURSE IMPROVEMENT"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00450.x", "e:abstract": "Motivating students to learn and apply operations management concepts is an important aspect of the learning process in an operations management class. While an emphasis on techniques and pedagogical technology has some motivational benefits, this paper proposes an emphasis on student/teacher interaction and a deeper understanding of complex situations. To support this approach, publishers should provide the materials to effectively use the new classroom technologies and the tools to support a wide variety of teaching styles. In addition, publishers should provide creative cross-functional simulations so that students can understand the role of operations management in the context of the firm. Finally, rich decision-making environments are needed to put the students in more realistic situations.", "e:keyword": ["MOTIVATION", "CLASSROOM TECHNOLOGlES", "CROSS‐FUNCTIONAL SIMULATION", "DECISION‐MAKING"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00451.x", "e:abstract": "The author, who has written nine textbooks in 26 editions over the past two decades, discusses his ideas of how to bring a production and operations management course alive. He introduces a model that ties together the use of text with both ancillary materials that accompany that book as well as with other tools available independent of the text. Some of these tools are technology driven (e.g., CD ROMS and the Internet), while others bring real business exposure to the course (e.g., field study consultancies, guest speakers, and plant tours).", "e:keyword": ["POM CLASS", "GRADUATE BUSINESS EDUCATION", "TEXTBOOKS", "SOFTWARE"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00455.x", "e:abstract": "In recent years there has been an increased emphasis on the development of manufacturing and business strategies. In spite of that high level of emphasis, limited empirical research has been published on the linkage between manufacturing strategy, business strategy, and organizational performance. Our study examines that linkage. Our main contribution lies in (i) building constructs for some important elements of manufacturing strategy and business strategy and (ii) testing the impact of linkage between manufacturing strategy and business strategy on organizational performance. The study is based on 175 responses from senior executives in manufacturing organizations.", "e:keyword": ["MANUFACTURING", "STRATEGY", "BUSINESS STRATEGY", "ORGANIZATIONAL PERFORMANCE", "LISREL MODEL"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00456.x", "e:abstract": "This paper empirically investigates the effect of advanced manufacturing technology on process stability during flexible production in a process industry. A sample of 61 North American fine paper plants is used to examine the relationship between the level of automation installed for controlling changes between paper grades and the incidence of paper web breaks. These web breaks are catastrophic failures; they require the entire plant to be stopped, reinitialized, and restarted. Because a large fraction of breaks occurs shortly after changeovers, they are an important determinant of the aspect of plant flexibility, called mobility, or the ability to move between products with only small penalties.", "e:keyword": ["MANUFACTURING FLEXIBILITY", "OPERATIONS MANAGEMENT", "MANUFACTURING AUTOMATION", "MAN‐MACHINE INTERACTION"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00457.x", "e:abstract": "We show how a simple normal approximation to Erlang's delay formula can be used to analyze capacity and staffing problems in service systems that can be modeled as M/M/s queues. The numbers of servers, s, needed in an M/M/s queueing system to assure a probability of delay of, at most, p can be well approximated by s ≅ p + z***I-p+, where z1-p, is the (1 - p)th percentile of the standard normal distribution and ρ, the presented load on the system, is the ratio of Λ, the customer arrival rate, to μ, the service rate. We examine the accuracy of this approximation over a set of parameters typical of service operations ranging from police patrol, through telemarketing to automatic teller machines, and we demonstrate that it tends to slightly underestimate the number of servers actually needed to hit the delay probability target—adding one server to the number suggested by the above formula typically gives the exact result. More importantly, the structure of the approximation promotes operational insight by explicitly linking the number of servers with server utilization and the customer service level. Using a scenario based on an actual teleservicing operation, we show how operations managers and designers can quickly obtain insights about the trade-offs between system size, system utilization and customer service. We argue that this little used approach deserves a prominent role in the operations analyst's and operations manager's toolbags.", "e:keyword": ["ERLANG'S DELAY FORMULA", "M/M/s QUEUE", "SERVICE SYSTEM DESIGN", "NORMAL APPROXIMATION", "STAFFING LEVELS"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00459.x", "e:abstract": "We consider a monopolistic situation where the retailer aims to find the profit-maximizing selling price, and the order and backorder quantity of an item. The price and demand are assumed to be inversely related. We develop a simple optimal approach, the proportion-balancing algorithm (PBA), which utilizes the proportions of cost components to sales revenue. We demonstrate that the PBA can handle three commonly used demand functions. However, applicability of the PBA depends on how the price-demand relationship is specified. A sensitivity analysis shows that the effects of changes in cost parameters on the order and backorder quantities can be very different from those of the classical economic order quantity model with backorders.", "e:keyword": ["EOQ", "PRICING", "BACKORDER", "COST‐TO‐REVENUE PROPORTIONS"]}, {"e:year": 1998, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1998.tb00460.x", "e:abstract": "Computer-based manufacturing planning and control (MPC) systems are widely used in industry to gain competitive advantage through integration and coordination of managerial activities. In collegiate business schools, important operations management activities are taught and studied, often by sequential examination of discrete topics such as aggregate production planning, master production scheduling, capacity planning, material planning, and production activity control. This paper explores the potential use of industrial MPC software in the classroom to create experiential learning activities that address the dynamic and integrative nature of operations management. Experiences with this pedagogical approach over the past decade are reported.", "e:keyword": ["MANUFACTURING PLANNING AND CONTROL", "EXPERIENTIAL LEARNING", "EDUCATION"]}, {"e:year": 1999, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1999.tb00058.x", "e:abstract": "In his landmark article on total quality management, Powell (1995) lamented the lack of large scale studies investigating quality management practices and performance. This study begins to fill that void using a large, random sample of manufacturing sites. The results show that quality practices can be categorized into nine dimensions. However, not all of them contribute to superior quality outcomes. “Employee commitment,” “shared vision,” and “customer focus” combine to yield a positive correlation with quality outcomes. Conversely, other “hard” quality practices, such as “benchmarking,” “cellular work teams,” “advanced manufacturing technologies,” and “close supplier relations” do not contribute to superior quality outcomes.", "e:keyword": ["TOTAL QUALITY MANAGEMENT", "QUALITY", "PERFORMANCE", "EMPIRICAL RESEARCH)"]}, {"e:year": 1999, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1999.tb00059.x", "e:abstract": "Proponents of iso 9000 certification claim that it is a low-cost signal of a firm's commitment to quality and a meaningful component of total quality management (TQM). Critics claim that it has little relation to TQM and is a tariff on international trade. We test the hypothesis that firms obtain ISO 9000 certification to comply with government and customer demands by estimating a probit model of the certification decision. The results support the view of proponents of ISO 9000. After controlling for regulatory and customer pressures to obtain ISO 9000, other factors related to quality management and quality-based competition explain the adoption decision.", "e:keyword": ["TOTAL QUALITY MANAGEMENT", "QUALITY ASSURANCE", "QUALITY CONTROL", "MANAGEMENT CONTROL SYSTEM)"]}, {"e:year": 1999, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1999.tb00061.x", "e:abstract": "In this paper we review the use of tradeoff curves in the design of manufacturing systems that can be modeled as open queueing networks. We focus particularly on the tradeoff between expected work-in-process (or product leadtime) and capacity investment in job shops. We review the algorithms in the literature to derive tradeoff curves and illustrate their application in evaluating the efficiency of the system, in deciding how much capacity to have, how to allocate resources between the reduction of uncertainty and the introduction of new technologies, and how to assess the impact of changes in products throughput and product mix. The methodology is illustrated with an example derived from an actual application in the semiconductor industry.", "e:keyword": ["TRADEOFF CURVE ANALYSIS", "MANUFACTURING SYSTEM DESIGN", "OPEN QUEUEING NETWORKS", "OPTIMIZATION AND PERFORMANCE EVALUATION)"]}, {"e:year": 1999, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1999.tb00062.x", "e:abstract": "We consider a single product, single level, stochastic master production scheduling (Mps) model where decisions are made under rolling planning horizons. Outcomes of interest are cost, service level, and schedule stability. The subject of this research is the Mps control system: the method used in determining the amount of stock planned for production in each time period. Typically, Mps control systems utilize a single buffer stock. Here, two Mps dual-buffer stock systems are developed and tested by simulation. We extend the data envelopment analysis (dea) methodology to aid in the evaluation of the simulation results, where Dea serves to increase the scope of the experimental design. Results indicate that the dual-buffer control systems outperform existing policies.", "e:keyword": ["MASTER PRODUCTION SCHEDULING", "DATA ENVELOPMENT ANALYSIS", "PERIODIC REVIEW INVENTORY THEORY", "SIMULATION)"]}, {"e:year": 1999, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1999.tb00304.x", "e:abstract": "", "e:keyword": []}, {"e:year": 1999, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1999.tb00305.x", "e:abstract": "This paper develops a simple but powerful model that relates service satisfaction/dissatisfaction to market share. The model is based on an intuitive service satisfaction framework that relates three service system parameters (service success rate, complaint rate, and service recovery rate) to the percent of satisfied customers. A dynamic model is then posited that relates the defection rate and the addition rate to market share changes. The service satisfaction/market share model yields useful insights into how market share is influenced by these service system parameters. The surprisingly simple model predicts changes in market share due to changes in customer satisfaction.", "e:keyword": ["SERVICE RECOVERY", "COMPLAINT MANAGEMENT", "CUSTOMER SATISFACTION", "SERVICE GUARANTEES"]}, {"e:year": 1999, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1999.tb00306.x", "e:abstract": "Service quality improvement has become an imperative in today's service firms. In this paper, we present a modeling framework that combines marketing and operations viewpoints for resource allocation. The framework can be used to allocate resources to the different stages of a multistage service system, where the manager's goal is to improve customers' perceptions of service quality, given some budget. Optimal allocation guidelines are provided, and the interplay of three factors on the resulting allocation scheme is captured. These factors are the current level of customers' perceptions of service quality at each stage, the cost of implementing a service quality improvement at each stage, and the importance placed by customers at each stage. Sensitivity analysis to provide additional managerial insights is also performed. We demonstrate the applicability of the modeling framework, using data from a real life health care environment. Model limitations and future research are also discussed.", "e:keyword": ["MULTISTAGE SERVICE SYSTEMS", "RESOURCE ALLOCATION", "SERVICE QUALITY"]}, {"e:year": 1999, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1999.tb00307.x", "e:abstract": "This paper opens a new avenue for investigation of quality issues in services. We take the viewpoint that a substantial portion of service failures is the result of human error in the delivery process. Drawing upon the Generic Error Modeling System (gems) from the cognitive science literature, we develop a framework for understanding the role of human error in service failures. An empirical investigation assesses the applicability of this framework to services, identifies which error mechanisms are important sources of service failure, and clarifies how the different roles of customers and providers affect the errors made by each.", "e:keyword": ["SERVICES", "QUALITY", "HUMAN ERROR"]}, {"e:year": 1999, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1999.tb00308.x", "e:abstract": "Data envelopment analysis (dea) has become an increasingly popular method to measure performance for service firms with multiple sites. DEA is superior to many traditional methods for firms that have multiple goals. The promise of DEA is that the complex, multi-objective problem of performance measurement can be reduced to a single number. Unfortunately, the practice of DEA often belies the promise. Misconceptions concerning the purpose and implementation of DEA can cause DEA applications to be less than successful. Here, the technique is explained, and a guide to the implementation of DEA is proposed, utilizing DEA studies of retail bank branches.", "e:keyword": ["SERVICE OPERATIONS", "DATA ENVELOPMENT ANALYSIS", "PRODUCTIVITY"]}, {"e:year": 1999, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1999.tb00310.x", "e:abstract": "This paper proposes an adaptation of quality function deployment (qfd) for services, more specifically extended service transactions. We propose two modifications to service applications of Qfd. One is the inclusion of higher-level customer needs (consequences, benefits, experiences, and personal values) to incorporate the experiential and personal nature of extended service transactions into the process. The second modification is to use customers' knowledge and expertise regarding service production and delivery as input beyond the house of quality. An interviewing method is proposed for a comprehensive assessment of customer needs at multiple levels. Results from an empirical application of this technique to luxury business hotels support the proposed modifications to Qfd to increase its potential for application to services.", "e:keyword": ["SERVICE DESIGN", "CUSTOMER INFORMATION", "QUALITY FUNCTION DEPLOYMENT", "EXTENDED SERVICE TRANSACTIONS"]}, {"e:year": 1999, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1999.tb00311.x", "e:abstract": "Services comprise an ever-expanding source of employment in the world's economies and are of significant interest to both academicians and practitioners. In this study, historical perspectives from which to view service typologies are provided and four decades of service typologies are chronicled. The interest in services demonstrated by academicians is tracked over time as are the purposes for which typologies have been developed. A unified schematic representation of services is developed in which the common themes underlying service typology development are identified from both a macro and micro level. Based on this study, areas for future research are identified.", "e:keyword": ["CLASSIFICATION", "MARKETING", "OPERATIONS MANAGEMENT", "SERVICES"]}, {"e:year": 1999, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1999.tb00312.x", "e:abstract": "This study empirically tests assumptions that underlie operations management (OM) scholars' belief that service operations should be managed differently. Respondents were self-classified into manufacturing and service types. There is a significant statistical difference between the views held by each group with regard to statements such as “service Om should be taught as a separate course” and “service operations should be managed differently from manufacturing.” There was general consensus on the service research agenda with the exception of three research areas: time standards, technology, and productivity. The survey also revealed that customer influence has the greatest impact on service Om strategies and decisions.", "e:keyword": ["SERVICE ASSUMPTIONS", "SERVICE CHARACTERISTICS", "SERVICE OPERATIONS MANAGEMENT", "ACADEMIC VIEW"]}, {"e:year": 1999, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1999.tb00313.x", "e:abstract": "Managing throughput time and its relation to work-in-process (wip) inventory and customer service is the focus of this paper. This research combines theory, simulation results, and the analysis of corporate data in an effort to address the issues associated with how one company (Eli Lilly) managed a reduction in their throughput times and an improvement in their delivery reliability. The results for this company suggest that production control decisions—expediting and de-expediting—can lead to a vicious circle of decisions, which in turn can lead to increased levels of WIP inventory and higher and more unpredictable throughput times.", "e:keyword": ["THROUGHPUT TIME REDUCTION", "PRODUCTIVITY", "EXPEDITING", "PRODUCTION CONTROL"]}, {"e:year": 1999, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1999.tb00315.x", "e:abstract": "This paper describes a periodic review, fixed lead time, single-product, single-facility model with random demand, lost sales and service constraints that was developed for potential application at a Western Canadian retailer. The objective of this study was to determine optimal (s, S) policies for a large number of products and locations. To this end, we evaluate the long run average cost and service level for a fixed (s, S) policy and then used a search procedure to locate an optimal policy. The search procedure is based on an efficient updating scheme for the transition probability matrix of the underlying Markov chain, bounds on S and monotonicity assumptions on the cost and service level functions. A distinguishing feature of this model is that lead times are shorter than review periods so that the stationary analysis underlying computation of costs and service levels requires subtle analyses. We compared the computed policies to those currently in use on a test bed of 420 products and found that stores currently hold inventories that are 40% to 50% higher than those recommended by our model and estimate that implementing the proposed policies for the entire system would result in significant cost savings.", "e:keyword": ["s", "S) POLICIES", "MARKOV CHAINS", "SERVICE LEVELS", "LOST SALES"]}, {"e:year": 1999, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1999.tb00316.x", "e:abstract": "This paper presents actual data (processing times, interarrival times, cycles-between-failures, and time-to-repair) from two automotive body welding lines. The purpose is twofold. First, to help researchers focus their work on realistic problems, we exhibit the nature of randomness actually found in two industrial manufacturing systems and provide a data source for realistic probability distributions. Second, we assess the validity of two common assumptions regarding this randomness in automotive manufacturing. Many queueing network models assume that certain random variables are independent and exponentially distributed. Though often reasonable, the primary motivation for the independence and exponentiality assumptions is mathematical tractability.", "e:keyword": ["PROCESSING TIME", "TIME BETWEEN FAILURES", "REPAIR TIMES", "INTERARRIVAL TIMES"]}, {"e:year": 1999, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1999.tb00317.x", "e:abstract": "We consider the problem of determining the allocation of demand from different customer orders to production batches and the schedule of resulting batches to minimize the total weighted earliness and tardiness penalties in context of batch chemical processing. The problem is formulated as a mixed-integer nonlinear programming model. An iterative heuristic procedure that makes use of the network nature of the problem formulation is presented to approximate an optimal solution. An algorithm polynomial in the number of batches to produce is also presented that optimally solves the problem under special cost structures.", "e:keyword": ["CHEMICAL PROCESSING", "BATCHING", "SCHEDULING", "WEIGHTED EARLINESS/TARDI‐NESS"]}, {"e:year": 1999, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1999.tb00365.x", "e:abstract": "The paper combines perspectives from international business and manufacturing to examine multinational plant location decisions. The location choice in manufacturing is between integrated and independent plants, while the international choice is between a foreign and domestic plant relative to their headquarters' country. The study empirically investigates whether these choices have different plant location determinants using data from a survey of plant managers of large, multinational firms. We find more evidence that the manufacturing choices benefit from consideration of international business issues than vice versa. However, managers rank determinants associated with manufacturing strategy considerably higher than those associated with intemational business.", "e:keyword": ["PLANT LOCATION", "INTERNATIONAL MANAGEMENT", "MANUFACTURING STRATEGY", "PLANT NETWORKS"]}, {"e:year": 1999, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1999.tb00366.x", "e:abstract": "There are many different approaches and conceptualizations of flexibility in the present literature. This lends itself to a lack of clarity and can result in confusion on the central concept. Here we identify shortcomings in the existing literature. To clarify some of the important concepts, we distinguish between flexibility (ability to change states), adaptability (ability to change within a state), and efficiency (resources utilized). To illustrate such distinctions, we present a capacity expansion model that takes flexibility and adaptability into consideration. Numerical examples show how the concepts of flexibility and adaptability can be used in manufacturing.", "e:keyword": ["FLEXIBILITY", "EFFICIENCY", "ADAPTABILITY"]}, {"e:year": 1999, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1999.tb00367.x", "e:abstract": "The research considers the problem of demand management in a firm where the firm's historical delivery service level reputation influences the number of quotation requests from its potential customers. Customers have a maximum and the firm has a minimum net price to due date tradeoff curve for each job. The demand management function bargains with the customer over price and promised due date. Bargaining finishes either with an agreed price and delivery date or with the customer refusing the firm's bid and placing the order elsewhere. The firm's objective is to maximize its long-term net revenue. The firm's demand management negotiation strategy guides this bidding process. The research demonstrates the use of simulation to test different demand management bidding and negotiation strategies for different market and firm scenarios.", "e:keyword": ["DEMAND MANAGEMENT", "DUE DATES"]}, {"e:year": 1999, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1999.tb00368.x", "e:abstract": "This paper examines the reduction in complexity of a product family through product design. By leveraging the commonalities among products in a family, the decision support methodology presented in the paper helps choose components and suppliers that minimize the sum of design, procurement, and usage costs. The problem of integrated component and supplier selection is conceptualized and formulated as an integer-programming model. Analysis of the model yields two properties, complete and continuous replacement, which form the basis of a heuristic procedure. Computational tests show that the heuristic provides results close to the optimal solution and can be used for selecting components and suppliers. Application of the model to an industrial problem is discussed.", "e:keyword": ["PRODUCT DESIGN AND DEVELOPMENT", "PRODUCT VARIETY", "COMPONENT SELECTION", "SUPPLIER SELECTION"]}, {"e:year": 1999, "@id": "http://dx.doi.org/10.1111/j.1937-5956.1999.tb00370.x", "e:abstract": "This paper proposes a realistic queueing model of automated guided vehicle (agv) systems in just-in-time production systems. The model takes into consideration return paths, Erlang distributed service times, and pull-type dispatching rule, assuming finite buffer capacities. Since it has no product-form solution and natural decomposability due to complex nontree fork-cum-join architecture and dynamic dispatching rules, we propose a machine-based decomposition algorithm for the performance evaluation of the model. Each decomposed module consists of the processing machine and its dispatching station. Three flow probabilities, derived from flow conservation analysis, relate the modules, which are updated iteratively until the parameters converge. The numerical results from a real-life Agv system application show that the algorithm is reasonably accurate.", "e:keyword": ["QUEUEING SYSTEM", "DECOMPOSITION ALGORITHM", "AGV SYSTEMS", "LAYOUT DESIGN"]}, {"e:year": 2000, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00135.x", "e:abstract": "This study employs structured interviews in a field setting to develop an in-depth understanding of how a specific human resource decision affected manufacturing performance at 30 plants using advanced manufacturing technologies. Initial results suggested that there is no relationship between the skill level of operational employees and the level of performance of the installations. When a measure of “fit” between environmental characteristics and skills was employed, however, there was a significant relationship between the fit measure and performance.", "e:keyword": ["MANUFACTURING PERFORMANCE", "ADVANCED MANUFACTURING TECHNOLOGY", "HUMAN RESOURCE MANAGEMENT", "INTERDISCIPLINARY RESEARCH"]}, {"e:year": 2000, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00136.x", "e:abstract": "Cyclicality is a well-known and accepted fact of life in market-driven economies. Less well known or understood, however, is the phenomenon of amplification as one looks “upstream” in the industrial supply chain. We examine the amplification phenomenon and its implications through the lens of one upstream industry that is notorious for the intensity of the business cycles it faces: the machine tool industry. Amplification of demand volatility in capital equipment supply chains, e. g., machine tools, is particularly large relative to that seen in distribution and component parts supply chains.", "e:keyword": ["SUPPLY CHAIN", "BUSINESS CYCLE", "MANPOWER PLANNING", "MACHINE TOOL", "SYSTEM DYNAMICS"]}, {"e:year": 2000, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00137.x", "e:abstract": "Flowshop scheduling problems with setup times arise naturally in many practical situations. This paper provides a review of static and deterministic flowshop scheduling research involving machine setup times. The literature is classified into four broad categories, namely sequence independent job setup times, sequence dependent job setup times, sequence independent family setup times, and sequence dependent family setup times. Using the suggested classification scheme, this paper organizes the flowshop scheduling literature involving setup and/or removal times and summarizes the existing research for different flowshop problem types. This review reveals that, while a considerable body of literature on this subject has been created, there still exist several potential areas worthy of further research.", "e:keyword": ["PLANNING AND CONTROL", "FLOWSHOP SCHEDULING", "SETUP TIME INFLUENCE", "PROBLEM COMPLEXITY AND CLASSIFICATION", "REVIEW OF SOLUTION PROCEDURES"]}, {"e:year": 2000, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00138.x", "e:abstract": "We develop analytical models for performance evaluation of Fabrication/Assembly (F/A) systems. We consider an F/A system that consists of an assembly station with input from K fabrication lines. Each fabrication line consists of one or more fabrication stations. The system is closed with a fixed number of items circulating between each fabrication line and the assembly station. We present algorithms to estimate the throughput and mean queue lengths of such systems with exponential processing times. We then extend our approach to analyze F/A systems with general processing time distributions. Numerical comparisons with simulations demonstrate the accuracy of our approach.", "e:keyword": ["ASSEMBLY‐LIKE QUEUES", "CONWIP", "QUEUEING NETWORK APPROXIMATIONS", "SIMULATION"]}, {"e:year": 2000, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00318.x", "e:abstract": "", "e:keyword": []}, {"e:year": 2000, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00320.x", "e:abstract": "This paper presents a variant of the popular beer game. We call the new game the stationary beer game, which models the material and information flows in a production-distribution channel serving a stationary market where the customer demands in different periods are independent and identically distributed. Different players, who all know the demand distribution, manage the different stages of the channel. Summarizing the initial experience with the stationary beer game, the paper provides compelling reasons why this game is an effective teaching tool.", "e:keyword": ["OPERATIONS MANAGEMENT", "SUPPLY CHAIN MANAGEMENT", "TEACHING", "BEER GAME"]}, {"e:year": 2000, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00321.x", "e:abstract": "This paper describes an Internet implementation of the Beer Distribution Game. Many teachers demonstrate the bullwhip effect that is often observed in supply chains by playing this game with their students. This implementation has the advantage of considerably reducing the time required to play the game.", "e:keyword": ["SUPPLY CHAIN MANAGEMENT", "BEER GAME", "INTERNET", "GAME"]}, {"e:year": 2000, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00323.x", "e:abstract": "Siemens Brief Case Game Supply Chain Simulator provides a practical setting for experiential learning exercises about supply chains. The game, drawing upon an actual situation, models the jobs of nine supply chain activities required to transform an order placed by the customer into a delivered product. Using the detail and complexity of the game, instructors can develop learning exercises that focus on a wide range of supply chain management issues. This paper describes two learning exercises with different objectives and for different audiences that we successfully delivered using the Brief Case Game. One exercise provides a concrete example of typical activities in a supply chain and their interactions. The other exercise leads students to discover what creates a need for coordination, what activities in a supply chain require coordination, and what methods work well. These exercises are suited for small upper level undergraduate and graduate courses in logistics and supply chain management. While significant resources were used to develop exercises and deliver the game, students were enthusiastic about the approach and demonstrated that they learned about the complexity inherent in managing supply chains.", "e:keyword": ["SUPPLY CHAINS", "EXPERIENTIAL LEARNING", "SIEMENS BRIEF CASE GAME", "COORDINATION"]}, {"e:year": 2000, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00324.x", "e:abstract": "This paper discusses four experiments and experiences with the use of supply chain management software, in this case the CAPS Logistics software, at different levels of undergraduate and graduate education at the School of Industrial and Systems Engineering at the Georgia Institute of Technology. We hope that the readers will get an idea of the commitment and resources necessary to integrate supply chain software into the classroom as well as the potential rewards.", "e:keyword": ["LOGISTICS GAMES", "SUPPLY CHAIN SOFTWARE", "LOGISTICS EDUCATION"]}, {"e:year": 2000, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00325.x", "e:abstract": "By focusing on the management of entire value chains, supply chain management has gained increasing popularity in management research and in the teaching of global businesses. The right practices can take companies to great heights; lack of attention can draw companies close to peril. In teaching supply chain management to business executives, there are four major issues that need to be highlighted: flawless execution of operations, the change from supply to demand focus, outsourcing and supply base development, and partnership implementation. This article explains these four issues, and the material that is developed at IMD to teach each of them.", "e:keyword": []}, {"e:year": 2000, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00326.x", "e:abstract": "In this article, we describe the Global Project Coordination Course, a course in which project teams composed of three students from each of two overseas universities execute company-sponsored projects dealing with global supply chain management issues. The $75,000 to $100,00 contributed in total by the three to four sponsoring companies funds all course expenses. We assess the benefits and challenges of the use of cross-cultural project teams with diverse educational backgrounds. We conclude that the course provides a unique and effective vehicle for furthering students' knowledge of Supply Chain Management and Information Systems, improving understanding of “soft” issues, and training students to work in diverse, global, cross-cultural project teams.", "e:keyword": ["SUPPLY CHAIN MANAGEMENT", "EDUCATION", "PROJECT COURSE", "INTERNATIONAL"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00327.x", "e:abstract": "The field of POM is steadily expanding its scope. This allows us to pursue interesting new fields of inquiry and makes us ever more relevant to the needs of practitioners. But it also increases the risk that over time our efforts will become fragmented and unfocused, causing us to slowly lose our sense of community and break up into separate camps. In this paper I ask, “What kind of new organizing framework, or ‘architecture,’ will allow us to maintain our sense of community as our interests diverge?” I describe the experience of one academic organization that faced a similar problem several years ago and how the situation was resolved. This experience leads us to propose a possible solution to Pom's emerging problem: engage with real operations managers and focus our efforts on helping them deal with the actual problems they are facing in today's complex and fast-changing world.", "e:keyword": ["POMS", "FOCUS", "PRACTITIONERS", "COMMUNITY"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00328.x", "e:abstract": "Testing and cross-validation of theories and paradigms are necessary to advance the field of manufacturing strategy. When the findings of one study are also obtained in other studies, using entirely different databases, we become more confident in the results. Replication alleviates concerns about spurious results and is one motivation for this study.", "e:keyword": ["MANUFACTURING STRATEGY", "MANUFACTURING CAPABILITIES", "PROCESS CHOICE", "PATH DEPENDENCIES"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00330.x", "e:abstract": "This paper explores the effect that unions have on a firm's ability to reengineer manufacturing processes. We begin by exploring the various effects that a union may have in a manufacturing environment. Next, we briefly review how unions may affect managerial initiatives to reengineer processes and improve manufacturing performance. The third section analyzes an existing database to test for differences in cycle time and manufacturing performance between union and nonunion firms. Finally, we discuss the implications of the study for future operations strategy research and note how a different form of union-management relationships is beginning to evolve.", "e:keyword": ["OPERATIONS STRATEGY", "LABOR RELATIONS", "UNIONS", "REENGINEERING"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00331.x", "e:abstract": "This paper compares flexible automation with labor-intensive manufacturing processes in a batch production environment and considers learning, forgetting, inventory carrying costs, setup costs, production demand volume, previous production experience, and the proportion of material to labor cost. While flexible automation typically can reduce setup times, and therefore inventory carrying costs through smaller optimal batch sizes, the results of this research show that the effect of forgetting on relative cost savings is difficult to predict in some situations. When using optimal lot sizes in both the automated and labor environments, cost savings from flexible automation may be smaller than expected or may occur in different ways than anticipated.", "e:keyword": ["LEARNING", "FLEXIBLE AUTOMATION", "COST", "BATCH PRODUCTION"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00332.x", "e:abstract": "This paper compares several different production control policies in terms of their robustness to random disturbances such as machine failures, demand fluctuations, and system parameter changes. Simulation models based on VLSI wafer fabrication facilities are utilized to test the performance of the policies. Three different criteria, namely, the average total WIP, the average backlog, and a cost function combining these measures, are used to evaluate performance. Among the policies tested, the Two-Boundary Control policy outperforms the others.", "e:keyword": ["SIMULATION", "KANBAN", "TWO‐BOUNDARY CONTROL", "PUSH AND PULL PRODUCTION POLICIES", "RE‐ENTRANT SHOP"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00333.x", "e:abstract": "The future of the global industry lies in the continuous improvement of both products and processes, a renewed commitment to competition, and an aggressive approach to satisfying customers needs in quality, quantity, and timing. In quality management, the degree of customer satisfaction for a given product may be measured in the form of the loss to society. This loss is formulated as a function of the deviation from the target for each of the product's quality characteristics. The greater the variability of uncontrolled factors during manufacturing or production the larger will be that loss.", "e:keyword": ["CONTINUOUS QUALITY IMPROVEMENT", "QUALITY CONTROL", "TAGUCHI LOSS", "QUALITY COSTS"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00334.x", "e:abstract": "This paper describes the supply chain tour, an expansion of the widely used facility tour pedagogy. A supply chain tour is a tour of facilities sequentially related in the creation of value that is designed to expose critical linkages and illustrate Supply Chain Management concepts and theories. Effectively using the supply chain tour pedagogy requires the instructor to create a standardized approach to managing the facility tour; a checklist is provided for this purpose. An example supply chain tour, used in the author's classes, is described.", "e:keyword": ["SUPPLY CHAIN MANAGEMENT", "QUALITY", "FACILITY TOUR", "PEDAGOGY"]}, {"e:year": 2000, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00461.x", "e:abstract": "This paper is concerned with the problem of order picking in mail order companies. Order picking is the retrieval of items from their warehouse storage locations to satisfy customer orders. Five order picking policies, strict order, batch, sequential zone, batch zone, and wave, are evaluated using labor requirements, processing time, and customer service as performance measures. A simulation model was developed to investigate these picking policies in a mail order environment. Prior research has focused on the study of individual picking policies. This study extends the prior research by evaluating multiple picking policies under varying operating conditions. The results of the study seem to indicate that (1) wave picking and batch picking perform well across the range of operating conditions considered in this study, and (2) sequential zone and batch zone picking do not perform well, especially as the order volume increases. However, the benefits and drawbacks to each picking policy must be taken into account. The key to effective implementation of an order picking system is to match the firm's business strategy, capabilities, technology, and space requirements with an order picking policy that maximizes the benefits of order picking to the firm and its customers.", "e:keyword": ["ORDER PICKING AND FULFILLMENT", "WAREHOUSING", "MAIL ORDER", "SIMULATION"]}, {"e:year": 2000, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00462.x", "e:abstract": "This research investigated the value of protecting the continuity of release batchs in a transfer batching environment, by modifying the SPT rule. A simulation model of a job shop was used to test the modified SPT rule. The performance measures evaluated were mean flow time, flow time variance, and mean lateness. Conditions under which the SPT modification improved results were as follows: large number of transfer batches, small setup time to process time ratio, and large variation in process times from station to station. The results suggest that shop loading is not a significant factor affecting performance of the modified SPT rule.", "e:keyword": ["OPERATIONS SCHEDULING", "TRANSFER BATCHING", "SIMULATION"]}, {"e:year": 2000, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00466.x", "e:abstract": "The purpose of this paper is to model and analyze supply contracts with periodical commitment, in which the order quantities are fixed and stationary, with limited flexibility to change the order quantity at a cost to the buyer. A solution methodology is provided for the general, stochastic problem, and consideration is given to specific demand distributions. The deterministic model is also investigated, formulating the problem as a mixed-integer linear program and as a network flow problem. Computational analyses are conducted, and the extension of the basic problem to the multiple-product, multiple-constraint problem is discussed.", "e:keyword": ["INVENTORY", "SUPPLY CONTRACTS"]}, {"e:year": 2000, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2000.tb00467.x", "e:abstract": "In this article we pass on advice for getting through a dissertation that we found useful in our roles as dissertation advisors and doctoral students. We have also included some other hints on starting and getting through a doctoral program, as well as beginning an academic career. We hope that readers in a position to advise Ph.D. students will convey the recommendations stated here to their students. Since the final responsibility for completing the degree rests with the student, the advice given here is, by and large, addressed directly to students and can be passed on to them in its current form.", "e:keyword": ["DISSERTATION", "DOCTORAL PROGRAM", "ABD"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00064.x", "e:abstract": "The importance of evaluating the effectiveness of the purchasing function in firms along multiple criteria has attracted considerable attention. However, few studies have identified the defining elements that constitute purchasing competence. This paper introduces the construct of purchasing competence using a second-order factor structure derived from purchasing practices identified from the literature. The validity of the construct (purchasing competence) is tested using data from a sample of 179 firms. The results indicate (1) the construct validity of purchasing competence and (2) the predictive validity of purchasing competence, which has a significant positive influence on total quality management performance and customer satisfaction. The implications of these findings for additional research are discussed.", "e:keyword": ["SECOND‐ORDER FACTOR ANALYSIS", "PURCHASING COMPETENCE", "STRUCTURAL EQUATION MODELS"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00065.x", "e:abstract": "After several years of use of electronic data interchange (EDI) in various industries, the literature is still inconclusive regarding the benefits gained from its usage. We investigated contextual factors of two types: non-managerial (product diversity, product customization, production instability, and organizational size) and managerial (just-in-time and quality management), that might have confounded past results. Our results indicate that the extent of EDI use is significantly related to delivery performance after controlling for the above-mentioned factors. Furthermore, the data set supported the moderating effect of production instability on the relationship between the extent of EDI use and delivery performance achieved, but failed to support the moderating effect of organizational size.", "e:keyword": ["ELECTRONIC DATA INTERCHANGE", "MANAGERIAL PRACTICES", "SUPPLY CHAIN MANAGEMENT", "DELIVERY PERFORMANCE"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00066.x", "e:abstract": "Using the latest information technology, powerful retailers like Wal-Mart have taken the lead in forging shorter replenishment-cycles, automated supply systems with suppliers. With the objective to reduce cost, these retailers are directing suppliers to take full responsibility for managing stocks and deliveries. Suppliers' performance is measured according to how often inventory is shipped to the retailer, and how often customers are unable to purchase the product because it is out of stock. This emerging trend also implies that suppliers are absorbing a large part of the inventory and delivery costs and, therefore, must plan delivery programs including delivery frequency to ensure that the inherent costs are minimized.", "e:keyword": ["INVENTORY CONTROL", "VENDOR‐MANAGED INVENTORY", "DELIVERY FREQUENCY", "PROBABILISTIC MODELS"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00069.x", "e:abstract": "Manufacturing history is too often neglected in operations management and its lessons lost. Its usefulness for testing theory is under-appreciated. This paper uses critical aspects of the history of manufacturing to provide support for the Theory of Swift, Even Flow as an explanation of productivity gain. The rise of Britain in the Industrial Revolution and the rapid overtaking of Britain by the United States and Germany are argued to be thoroughly consistent with Swift, Even Flow, thereby vindicating both theory and the usefulness of history.", "e:keyword": ["PRODUCTIVITY", "THEORY", "MANUFACTURING HISTORY"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00070.x", "e:abstract": "Two simultaneous developments took place during the so-called Industrial Revolution (1760–1830): the industrialization of Britain and other countries in Europe and the deindustrialization of a number of non-European countries, including India. I identify international relations as a major driver of the three components—demand, innovations, and capital formation—of the Industrial Revolution. I also offer an alternate perspective on hypotheses proposed by Schmenner in the preceding article in this issue.", "e:keyword": ["BRITAIN", "BUSINESS HISTORY", "ECONOMIC HISTORY", "HISTORY OF MANUFACTURING", "HISTORY OF TECHNOLOGY", "INDIA", "INDUSTRIAL REVOLUTION"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00071.x", "e:abstract": "", "e:keyword": []}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00072.x", "e:abstract": "", "e:keyword": []}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00073.x", "e:abstract": "This article describes the first fully integrated material planning system to facilitate the management of a remanufacturing facility. A number of firms are already engaged in this activity. They remanufacture automobile, truck, and other vehicle components, like starters, alternators, transmissions, and so forth. These firms take in used components, disassemble them, and assemble saleable products from the good parts they find. There is considerable uncertainty in the supply of used components, the good parts in those components, and the demand for remanufactured products. Our system is based on material requirements planning logic, something that many firms in the industry are already familiar with. Meetings with experts in the industry were used to set the parameters of the system and evaluate its approach.", "e:keyword": ["MATERIAL REQUIREMENTS PLANNING", "PRODUCT RECOVERY", "REMANUFACTURING", "RECYCLING"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00074.x", "e:abstract": "We present a two-period model of remanufacturing in the face of competition. In our model, an original equipment manufacturer (OEM) competes with a local remanufacturer (L) under many reverse logistics configurations for the returned items. After establishing the Nash Equilibrium in the second period sub-game, we use numerical experiments for comparative statics. OEM wants to increase L'S remanufacturing cost. Surprisingly, while L competes in the sales market, she has incentives to reduce oem's remanufacturing cost. A social planner who wants to increase remanufacturing can give incentives to the OEM to increase the fraction available for remanufacturing, or reduce his remanufacturing costs.", "e:keyword": ["REMANUFACTURING", "COMPETITION", "REVERSE LOGISTICS"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00075.x", "e:abstract": "Firms are often encouraged to offer environmentally friendly products as a demonstration of corporate citizenship. However, this may prove to be an unrealistic expectation since a rational firm will only engage in profitable ventures; those that increase shareholder wealth. We develop a framework for analyzing the profitability of reuse activities and show how the management of product returns influences operational requirements. We show that the acquisition of used products may be used as the control lever for the management and profitability of reuse activities. These activities, termed product acquisition management, affect several important business decisions. First, if a firm is to pursue reuse activities, these reuse activities must be value-creating. Second, if a firm is to compete by offering remanufactured products, then we show how product returns management influences the overall profitability of such activities via a trial and error EVA approach. Third, we show how operational issues are strongly affected by the approach used to manage product returns. There is a need for future research specifying the mathematical relationship between acquisition price and the nominal quality of the returned product.", "e:keyword": ["REMANUFACTURING", "ECONOMIC VALUE‐ANALYSIS", "PRODUCT ACQUISITION MANAGEMENT"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00076.x", "e:abstract": "Efficient implementation of closed-loop supply chains requires setting up appropriate logistics structures for the arising flows of used and recovered products. In this paper we consider logistics network design in a reverse logistics context. We present a generic facility location model and discuss differences with traditional logistics settings. Moreover, we use our model to analyze the impact of product return flows on logistics networks. We show that the influence of product recovery is very much context dependent. While product recovery may efficiently be integrated in existing logistics structures in many cases, other examples require a more comprehensive approach redesigning a company's logistics network in an integral way.", "e:keyword": ["REVERSE LOGISTICS", "PRODUCT RECOVERY", "SUPPLY CHAIN MANAGEMENT", "NETWORK DESIGN", "FACILITY LOCATION"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00077.x", "e:abstract": "Managers realize that they should avoid complex green supply initiatives when they do not have the capabilities to implement them. However, they have little guidance on how these capabilities can be developed. This paper provides an initial analysis of the role of supply management capabilities in green supply. We argue that the implementation of green supply is better explained by focusing on the development and deployment of an organization's specialized internal resources, rather than by the more usual focus on external environmental pressures on a firm. Further, we argue that capabilities appropriate for green supply are developed by a proactive corporate environmental stance and by a more strategic purchasing and supply management approach.", "e:keyword": ["RESOURCE‐BASED", "ENVIRONMENTAL MANAGEMENT", "PURCHASING AND SUPPLY MANAGEMENT"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00078.x", "e:abstract": "Product stewardship is the set of practices related to reducing risks from chemical and process hazards in a company's supply chain. This paper develops an economic framework for evaluating supply chain liability as a driver for adopting product stewardship. Companies that outsource production may face residual liability for damages from use of their products, when liabilities are large enough to exceed supply chain partners' assets. The resulting potential liabilities can be mitigated through product stewardship. This paper shows that extended supply chain liabilities provide incentives for investing in reducing environmental hazards throughout the supply chain.", "e:keyword": ["LIABILITY", "PRODUCT STEWARDSHIP", "MITIGATION", "ENVIRONMENTAL DAMAGE"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00079.x", "e:abstract": "Companies are increasingly being held accountable for the life-cycle impact of their products and services. Transportation is frequently a major component of this life-cycle impact. Hence, to reduce total environmental impact, logistics managers will have to become more sophisticated in their understanding of how they can reduce the environmental impact of their transportation operations, without negatively affecting the cost or effectiveness of these operations. In line with this mandate, we quantify the dynamic impact of road vehicles on the environment. In most emission models, a constant speed is used depending only on the specific road type. Using such a model will lead to an underestimation of the effective emissions. It turns out that the differences with a more realistic dynamic assessment model are significant. The analysis here suggests that the policy consequences of these differences for both public sector managers and private companies are potentially quite important.", "e:keyword": ["TRAFFIC LOGISTICS", "ENVIRONMENTAL IMPACT", "ROAD TRAFFIC", "QUEUEING THEORY", "LIFE CYCLE MANAGEMENT IMPACT"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00080.x", "e:abstract": "", "e:keyword": []}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00081.x", "e:abstract": "", "e:keyword": []}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00082.x", "e:abstract": "Since 1980, practitioner interest in the field of quality management (qm) has grown significantly, resulting in academic researchers embracing QM as a legitimate discipline of study. One approach to evaluating the intellectual health of a discipline is an examination of doctoral dissertation research. This work both complements and extends other published reviews of the quality management discipline by analyzing doctoral dissertation research since 1981, categorizing this research, examining shifts in major research themes, evaluating data collection and analysis methodologies, and discussing general trends in this research area. Our findings suggest that the challenges in QM have become more interdisciplinary and integrated, and reveal an encouraging trend toward more rigorous research methodologies and the increased use of theories from other disciplines, leading to a more mature body of research in this field.", "e:keyword": ["QUALITY MANAGEMENT", "BALDRIGE AWARD", "RESEARCH METHODOLOGY"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00083.x", "e:abstract": "Quality management has often been advocated as being universally applicable to organizations. This is in contrast with the manufacturing strategy contingency approach of Operations Management that advocates internal and external consistency between manufacturing strategy choices. This article empirically investigates whether quality management practices are contingent on a plant's manufacturing strategy context, by examining the use of process quality management practices—a critical and distinctive subset of the whole set of quality management practices—across plants representative of different manufacturing strategy contexts. The study strongly suggests that process quality management practices are contingent on a plant's manufacturing strategy, and identifies mechanisms by which this takes place.", "e:keyword": ["QUALITY MANAGEMENT", "MANUFACTURING STRATEGY", "CONTINGENCY RESEARCH", "EMPIRICAL RESEARCH"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00084.x", "e:abstract": "This paper develops a theoretical framework that relates a service guarantee to service quality. The framework hypothesizes that a service guarantee can positively affect service quality through its positive effect on both learning through service failure and employee motivation and vision. A longitudinal, empirical study was conducted to test these hypotheses. Surprisingly, the service guarantee was not found to have a direct effect on learning through service failure. However, the service guarantee clearly had a positive effect on service quality primarily through its positive effect on employee motivation and vision. The research strongly supports using a service guarantee to improve service quality.", "e:keyword": ["SERVICE RECOVERY", "COMPLAINT MANAGEMENT", "CUSTOMER SATISFACTION", "SERVICE GUARANTEES", "EMPIRICAL RESEARCH"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00085.x", "e:abstract": "Prior literature has examined product quality and service quality separately as antecedents of customer loyalty. In the context of the automotive industry, we present a framework that examines the simultaneous impact of product and service quality on consumers' purchase intentions. The framework is operationalized as several hypotheses that posit relationships between service quality, service satisfaction, product quality, and customer loyalty. The hypotheses are tested using three sources of data: (i) archival data on product quality and customer purchases, (ii) consumersíresponses to a survey instrument, and (iii) Consumer Reports. Results indicate general support for main hypotheses proposed.", "e:keyword": ["SERVICE QUALITY", "PRODUCT QUALITY", "CUSTOMER LOYALTY", "AUTOMOTIVE INDUSTRY"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00087.x", "e:abstract": "Quality has been in the limelight as organizations have sought to create a competitive advantage and theorists have sought to understand the implications of quality management. This paper examines the synergistic effects of the quality emphasis in the organizations, the use of appropriate work force management practices, and the managerial performance outcomes as interactive phenomena. Using data from multiple levels of employees in manufacturing units in various industries, we tested hypotheses regarding the managerial performance impact of the synergy in work force management practices and the quality emphasis. The results indicate that the effectiveness of work force management practices in enhancing managerial performance varies with the emphasis on quality that is manifested by meeting and exceeding customer needs and preferences through accurate, consistent, reliable, and durable products, and by making design changes in the products as desired by the customer.", "e:keyword": ["OPERATIONS STRATEGY", "QUALITY", "WORK FORCE MANAGEMENT", "PERFORMANCE"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00088.x", "e:abstract": "This paper is based on the cumulative or synergies theory of manufacturing performance, as opposed to the trade-off perspective. The paper compares the cases of two British contract electronics assemblers, the first one having achieved a high level of performance on productivity, quality, and dependability, and the second one having achieved a lower level of performance on these criteria but higher flexibility. The case material is used to develop a “high school” analogy that helps to understand why companies come to achieve cumulative manufacturing performance in an industrial sector where competitive pressure is particularly high.", "e:keyword": ["MANUFACTURING PERFORMANCE", "CASE STUDIES", "QUALITY MANAGEMENT", "ELECTRONICS INDUSTRY", "BENCHMARKING"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00089.x", "e:abstract": "Much of the early literature in the area of quality management literature is anecdotal, prescriptive, and methodologically suspect. As such, theory construction and rigorous empirical testing is a relatively recent development with the emphasis very much on quality practices. However, the various dimensions of quality performance and the relationship between them have received less attention from the research community. More specifically, the role of design quality has not been fully addressed in empirical studies. To address this gap we developed a path model incorporating quality practices, design quality, conformance quality, external quality-in-use, product cost, time-to-market, customer satisfaction and business performance. The model was tested with data collected from 200 suppliers in the electronics sector in the Republic of Ireland. Data analysis of the data indicated considerable support for the conceptual model.", "e:keyword": ["QUALITY PRACTICES AND PERFORMANCE", "DESIGN QUALITY", "PATH ANALYSIS", "EMPIRICAL RESEARCH"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00090.x", "e:abstract": "This paper investigates the relationship between aspects of quality and long run profitability and growth of a firm. The paper first determines whether a stable relationship among price, aspects of quality, and the sales rate exists, by examining the equilibrium properties of a dynamic model. Then, we use the derived equilibrium expressions to develop insights into the strategic nature of “quality reputation” and, how to integrate marketing (i.e., pricing) and quality related decisions. The paper shows under certain conditions it might be more advantageous to manipulate “quality reputation” through advertising and product innovations than to increase product quality. We comment on quality based strategic options a firm must consider to ensure long run growth and profitability.", "e:keyword": ["QUALITY", "QUALITY REPUTATION", "SALES RATE", "EQUILIBRIUM ANALYSIS", "DYNAMIC MODELS"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00371.x", "e:abstract": "", "e:keyword": []}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00372.x", "e:abstract": "We examine the relationship between lean manufacturing practices and environmental performance as measured in terms of air emissions and resource use. We draw on two unique surveys of 31 automobile assembly plants in North America and Japan, which contain information on manufacturing practice and environmental performance, as well as in-depth interviews with 156 plant level employees at 17 assembly plants. Our survey results and interviews suggest that lean management and reduction of air emissions of volatile organic compounds (vocs) are associated negatively. Lean manufacturing practices contribute to more efficient use of paints and cleaning solvents, but these in-process changes are not sufficient to meet the most stringent air regulations. We found some evidence to support the link between lean practices and resource efficiency. While our survey results were in hypothesized direction, they were not statistically significant. In-depth semi-structured interviews, however, suggest a more robust relationship, and we use them to describe some mechanisms by which all three aspects of lean management (buffer minimization, work systems, and human resource management) may be related to environmental management practices and performance.", "e:keyword": ["LEAN MANUFACTURING", "ENVIRONMENTAL PERFORMANCE", "HIGH‐INVOLVEMENT WORK", "RESOURCE USE"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00373.x", "e:abstract": "Lean production may have a significant public good spillover—improved environmental performance. However, empirical evidence of the link between lean production practices and environmental performance has not resolved the nature of the relationship. To explore this issue, we conduct an empirical analysis of the environmental performance of 17,499 U.S. manufacturing establishments during the time period 1991–1996. We find that those establishments that adopt the quality management standard ISO 9000 are more likely to adopt the environmental management standard ISO 14000. We also find strong evidence that lean production, as measured by ISO 9000 adoption and low chemical inventories, is complementary to waste reduction and pollution reduction.", "e:keyword": ["LEAN PRODUCTION", "ENVIRONMENTAL PERFORMANCE", "ISO 9000", "ISO 14000"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00375.x", "e:abstract": "This study assesses internal drivers of a firm's level of environmental awareness, including methods for incorporating environmental objectives into the strategic planning of operations, communication of objectives throughout the organization, and deployment of accountability to operating personnel and managers for environmental performance. Challenges firms may encounter in motivating and holding employees and process owners accountable for environmental performance are discussed, as well as a potential for inconsistencies between management's espoused theories and theories in use. A case study of a steel manufacturer is used to determine how accountability for and awareness of environmental objectives can be operationally implemented.", "e:keyword": ["ENVIRONMENTAL MANAGEMENT", "ACCOUNTABILITY", "COMMUNICATION", "ESPOUSED THEORIES VERSUS THEORIES IN USE", "CASE STUDY"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00376.x", "e:abstract": "Since “Normal Accidents: Living With High-Risk Technologies” was first published in 1984, there have been very few tests of its validity or its application to different classes of technology or organizations. This paper describes a robust, parametric test of Normal Accident Theory applied to a class of high-risk systems: petrochemical plants and refineries. The theory has important implications for scholars interested in the relationship of organizations to the natural environment and managers responsible for safe, socially responsible, and environmentally appropriate operation of high-consequence systems.", "e:keyword": ["NORMAL ACCIDENTS", "TECHNOLOGY", "RISK", "REFINERIES"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00377.x", "e:abstract": "Can best-practice quality firms leverage their quality programs for environmental management? This paper explores this question by comparing the implementation of successful and unsuccessful quality and environmental initiatives in five manufacturing- and five service-sector Malcolm Baldrige National Quality Award (mbnqa) winners. The results lead to a series of propositions to guide future research. While the literature suggests that quality and environmental programs are closely related, this study finds that drivers of successful environmental initiatives are not the same as those for successful quality initiatives.", "e:keyword": ["TQM", "MBNQA", "ENVIRONMENT", "OPERATIONS", "STRATEGY"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00378.x", "e:abstract": "The ISO 9000 series of quality management systems standards and the more recent ISO 14000 environmental management systems standards have generated much controversy among practitioners. Although ISO 9000 has become a de facto requirement for many firms, its effects are poorly understood, and similarly the value and domain of applicability of ISO 14000 have been questioned. This paper reports on an exploratory study into the global spread of ISO 14000. We interviewed practitioners worldwide to identify factors that they believe explain differences between national ISO 14000 certification counts. We then collected quantititive data for these factors and, using regression analysis, we found that exports, environmental attitudes (combined with economic development), and ISO 9000 certification count were significant. The fact that ISO 9000 appears as an important factor explaining diffusion of ISO 14000 certifications suggests that the drivers behind the two have significant overlap. This indicates that, although ISO 14000 is an environmental standard, many of the factors driving national certification patterns are not at all environmental in nature, and that ISO 14000 therefore needs to be studied from a broader perspective than from a purely environmental point of view.", "e:keyword": ["ISO 9000", "ISO 14000", "ENVIRONMENTAL MANAGEMENT SYSTEMS", "QUALITY MANAGEMENT", "INTERNATIONAL DIFFUSION"]}, {"e:year": 2001, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2001.tb00379.x", "e:abstract": "This paper integrates a stakeholder perspective into the resource-based view of the firm, to analyze the mechanisms that link the adoption of the international Environmental Management Standard ISO 14001 to firms' competitive advantage. This paper shows that the perceived competitiveness impact of the standard depends mostly on the involvement of firms' external stakeholders (distributors, customers, community members, and regulatory agencies) in its design. ISO 14001 is a process standard, and it is difficult for stakeholders to get credible information on the effectiveness of the standard if they are not involved in its design. Stakeholders' involvement in a firm's ISO 14001 standard becomes a valuable organizational capability, which is difficult to imitate by competitors. The analysis is supported by primary data collected from a questionnaire mailed to 152 firms, resulting in 55 observations representing 30% of the total number of firms certified in the U.S. in August 1998.", "e:keyword": ["STAKEHOLDERS", "COMPETITIVE ADVANTAGE", "NATURAL ENVIRONMENT", "RESOURCE‐BASED VIEW", "ORGANIZATIONAL CAPABILITY", "STRUCTURAL EQUATION MODELING"]}, {"e:year": 2002, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2002.tb00180.x", "e:abstract": "", "e:keyword": []}, {"e:year": 2002, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2002.tb00182.x", "e:abstract": "A growing number of sophisticated observers are coming to believe that the forces driving the so-called New Economy are fundamentally reshaping world industry. Moreover, the combination of fast growth and the excitement associated with leading edge technologies has made New Economy companies magnets for management talent—and particularly for the ambitious young people who attend our management programs. Are we providing these potential managers with a good foundation for managing operations in such companies? Are the principles that we traditionally have taught in operations management (om) courses sufficiently robust that they can still be applied to New Economy operations? In this paper we argue that, although some of our familiar concepts and techniques continue to be applicable to information-intensive operations, many are not. We sketch out a way to think conceptually about the important differences between the Old and the New Economies, and their implications for operations management teaching and research.", "e:keyword": ["NEW ECONOMY", "INFORMATION TECHNOLOGY", "NETWORKS", "OUTSOURCING", "POM PEDAGOGY"]}, {"e:year": 2002, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2002.tb00183.x", "e:abstract": "This paper presents the results of a natural experiment conducted at a U.S. high-tech manufacturer. The experiment had as its treatment the adoption, at a single point in time, of a comprehensive enterprise information system throughout the functional groups charged with customer order fulfillment. This information technology (it) adoption was not accompanied by substantial contemporaneous business process changes. Immediately after adoption, lead time and on-time delivery performance suffered, causing a “performance dip” similar to those observed after the introduction of capital equipment onto shop floors. Lead times and on-time delivery percentages then improved along a learning curve. After several months, performance in these areas improved significantly relative to preadoption levels. These observed performance patterns could not be well explained by rival causal factors such as order, production, and inventory volumes; head count; and new product introductions. Thus, this longitudinal research presents initial evidence of a causal link between IT adoption and subsequent improvement in operational performance measures, as well as evidence of the timescale over which these benefits appear.", "e:keyword": ["INFORMATION TECHNOLOGY ADOPTION", "PERFORMANCE IMPACT OF INFORMATION", "TECHNOLOGY", "OPERATIONAL EFFECTIVENESS"]}, {"e:year": 2002, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2002.tb00184.x", "e:abstract": "We developed a taxonomy of service processes in electronic retailing using data from 255 electronic food retailers. The taxonomy is comprised of eight service process configurations. Analysis of publicly available data on on-line customer ratings for 52 retailers in the study sample shows that the ordering of the configurations in the taxonomy on a continuum of low to high flexibility is associated positively with (i) customer satisfaction with web site aesthetics, web site navigation, product selection, product information, customer support, and ease of return, and (ii) customer loyalty.", "e:keyword": ["SERVICE PROCESS", "ELECTRONIC RETAILING", "TAXONOMY", "CUSTOMER SATISFACTION", "CUSTOMER LOYALTY"]}, {"e:year": 2002, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2002.tb00186.x", "e:abstract": "In this issue, Robert Hayes has written provocatively about the implications of the digital economy for Operations Management (om). Here I examine and illustrate a simple four-stage framework for thinking about these implications: advances in digital technology (stage 1) lead to business developments (stage 2), which impact the views of OM-relevant thought leaders (stage 3), which influence the conduct of OM activities (stage 4). This framework provides a perspective for viewing the evolution of OM and indicates how educators, researchers, and practitioners can steal the march on mainstream thinking.", "e:keyword": ["OPERATIONS MANAGEMENT", "DIGITAL ECONOMY", "INTERNET", "INFORMATION TECHNOLOGY", "PROFESSIONAL EVOLUTION"]}, {"e:year": 2002, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2002.tb00187.x", "e:abstract": "", "e:keyword": []}, {"e:year": 2002, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2002.tb00189.x", "e:abstract": "By including the effects of learning over time on both the production of components and their integration into complete products, we develop an engineering-based model of outsourcing. This model provides an alternative explanation for much of what other outsourcing theories predict, as well as making several new predictions. In particular, we show that outsourcing decisions can create a path-dependent outsourcing trap in which a firm experiences higher long-run costs after an immediate cost benefit. We also describe conditions under which outsourcing a small fraction of component production may dominate either complete insourcing or complete outsourcing. Finally, we show that, with discounting, there is a convex, curvilinear relationship between the optimal outsourcing fraction and the rate of technological change.", "e:keyword": ["LEARNING", "INTEGRATION", "LEARNING CURVE", "PRODUCT DEVELOPMENT", "VERTICAL INTEGRATION", "MODULARITY", "PRODUCT DESIGN"]}, {"e:year": 2002, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2002.tb00190.x", "e:abstract": "Customer satisfaction can be achieved by providing rapid delivery of a wide variety of products. High levels of product variety require correspondingly high levels of inventory of each item to quickly respond to customer demand. Delayed product differentiation has been identified as a strategy to reduce final product inventories while providing the required customer service levels. However, it is done so at the cost of devoting large production capacities to the differentiation stage. We study the impact of this postponement capacity on the ability to achieve the benefits of delayed product differentiation. We examine a single-period capacitated inventory model and consider a manufacturing system that produces a single item that is finished into multiple products. After assembly, some amount of the common generic item is completed as non-postponed products, whereas some of the common item is kept as in-process inventory, thereby postponing the commitment to a specific product. The non-postponed finished-goods inventory is used first to meet demand. Demand in excess of this inventory is met, if possible, through the completion of the common items. Our results indicate that a relatively small amount of postponement capacity is needed to achieve all of the benefits of completely delaying product differentiation for all customer demand. This important result will permit many firms to adopt this delaying strategy who previously thought it to be either technologically impossible or prohibitively expensive to do so.", "e:keyword": ["DELAYED PRODUCT DIFFERENTIATION", "POSTPONEMENT", "FLEXIBLE MANUFACTURING", "MASS CUSTOMIZATION"]}, {"e:year": 2002, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2002.tb00191.x", "e:abstract": "This paper was motivated by the operational problems faced by Northco, a school uniform manufacturer in the Northeastern United States. Northco was facing high working capital costs while also incurring high stockout and markdown costs. This paper models the impact of inventory holding cost and reactive capacity on Northco's targeted understocking and overstocking cost and offers a solution methodology for such problems. We quantify the impact of varying inventory carrying costs (and hence, high working capital costs) on stockout costs and the value of additional capacity. Our results illustrate that apparel manufacturers with high working capital costs, and hence high inventory carrying costs, should target higher stockout costs and achieve lower capacity utilization. The results presented have application beyond Northco because high working capital cost is endemic to many supply chains.", "e:keyword": ["INVENTORY PLANNING", "INVENTORY MANAGEMENT", "WORKING CAPITAL MANAGEMENT", "CAPACITY MANAGEMENT", "DYNAMIC PROGRAMMING"]}, {"e:year": 2002, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2002.tb00193.x", "e:abstract": "Delivery guarantees are an important element in a customer satisfaction program. When setting delivery guarantees, a firm must consider customer expectations as well as operational constraints. We develop a profit-maximization model in which a firm's sales organization, with incomplete information on operations' status, solicits orders and quotes delivery dates. If obtained, orders are processed in a make-to-order facility, after which revenue is received, minus tardiness penalty if the delivery was later than quoted. We specify conditions for an optimal log-linear decision rule and provide exact expressions for its effect on arrival rate, mean processing time, and mean cycle time.", "e:keyword": ["DUE‐DATE", "LEAD‐TIME", "PERFORMANCE GUARANTEE", "QUEUE"]}, {"e:year": 2002, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2002.tb00471.x", "e:abstract": "This paper investigates inventory-rationing policies of interest to firms operating in a direct market channel. We model a single product with two demand classes, where one class requests a lower order fulfillment lead time but pays a higher price. Demand for each class follows a Poisson process. Inventory is fed by a production system with exponentially distributed build times. We study rationing policies in which the firm either blocks or backlogs orders for the lower priority customers when inventory drops below a certain level. We compare the performance of these rationing policies with a pure first-come, first-serve policy under various scenarios for customer response to delay: lost sales, backlog, and a combination of lost sales and backlog.", "e:keyword": ["DIRECT MARKET CHANNELS", "SUPPLY CHAIN MANAGEMENT", "MARKOV PROCESSES/CHAINS", "STOCHASTIC INVENTORY RATIONING MODELS"]}, {"e:year": 2002, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2002.tb00473.x", "e:abstract": "The development of the Internet as a business tool over the past 5 years has been phenomenal, causing a period of chaos and creative destruction. E-commerce has been hyped as a catalyst for vast streamlining of the supply chain. Yet, in a time of such phenomenal change, the focus tends to be on the large picture. Many details of how a new technology should be or is employed tend to be unknown or ignored. However, as the technology matures and stabilizes, one of the primary factors that separate winners from losers is the way in which the technology is implemented and operated on a daily basis. This study examines the ways in which companies utilize the Internet to streamline their purchasing process.", "e:keyword": ["E‐COMMERCE", "PURCHASING", "SUPPLY CHAIN MANAGEMENT", "TECHNOLOGY MANAGEMENT", "OPERATIONS STRATEGY"]}, {"e:year": 2002, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2002.tb00476.x", "e:abstract": "We consider a supply chain with one manufacturer in the upstream and two competing retailers in the downstream. The retailers sell differentiated goods and are endowed with some private demand information. The paper shows that the manufacturer's optimal strategy is independent of the type of downstream competition, Cournot or Bertrand, and that no information will be shared with the manufacturer on a voluntary basis. However, complete information sharing, which benefits all three parties, can be achieved through side payment when the retailers' information is statistically less accurate or when the leakage effect is more beneficial to the retailers.", "e:keyword": ["INFORMATION SHARING", "SUPPLY CHAIN", "COMPETITION", "EQUILIBRIUM", "EXPECTED PROFIT"]}, {"e:year": 2002, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2002.tb00485.x", "e:abstract": "I analyzed the contributions made by members of the following constituencies in terms of the number of articles published in the Journal of Operations Management (JOM), Manufacturing and Service Operations Management (M&SOM), and Production and Operations Management (POM): the top 20 U.S. business schools and the top 7 non-U.S. business schools as ranked by Business Week or U.S. News and World Report, business and government organizations, U.S. business schools ranked between 21 and 50, non-U.S. business schools not included above, and U.S. business schools not included above. I also analyzed the contributions made by U.S. business schools with top 10 programs in production and operations management; 9 of which are also in the list of top 20 U.S. business schools.", "e:keyword": ["JOURNALS IN POM", "QUALITY OF JOURNALS", "RELEVANCE OF JOURNALS", "RESEARCH IN POM."]}, {"e:year": 2002, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2002.tb00486.x", "e:abstract": "Recent advances in predictive maintenance technologies have led many manufacturers to abandon traditional periodic maintenance policies and replace them with predictive maintenance policies. The models in this paper explicitly evaluate the decision to utilize both predictive and periodic maintenance when the objective is to minimize expected maintenance costs per unit time. Renewal theory is used to obtain optimal policies as unique solutions of integral equations that depend on the failure distribution and prediction capabilities. Based on this research, we recommend that practitioners do not abandon the traditional maintenance methods but follow our guidelines for utilizing periodic maintenance in conjunction with the new technologies.", "e:keyword": ["PREDICTIVE MAINTENANCE", "MAINTENANCE MANAGEMENT."]}, {"e:year": 2002, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2002.tb00487.x", "e:abstract": "This paper studies issues associated with designing process control systems when the testing equipment is subjected to random shifts. We consider a production process with two states: in control and out of control. The process may shift randomly to the out-of-control state over time. The process is monitored by periodically sampling finished items from the process. The equipment used to test sampled items also is assumed to have two states and may shift randomly during the testing process. We formulate a cost model for finding the optimal process control policy that minimizes the expected unit time cost. Numerical results show that shifts of the testing equipment may significantly affect the performance of a process control policy. We also studied the effects of the testing equipment's shifts on the selection of process control policies.", "e:keyword": ["QUALITY CONTROL", "SAMPLING", "RANDOM TESTING EQUIPMENT SHIFT", "COST MINI‐MIZATION."]}, {"e:year": 2002, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2002.tb00490.x", "e:abstract": "This paper investigates the operational characteristics of a pooling group consisting of two stocking locations, supplied periodically by a central warehouse. The two locations may collaborate by moving inventory between them. The lateral transshipment times are shorter than the regular replenishment lead times, but they are not negligible. Several alternative types of ordering and transshipment policies are examined. Extensive experimentation by simulation leads to the conclusion that the benefits of risk pooling are substantial only when demand is highly variable. Moreover, the type and variability of the demand distributions are key determinants of the appropriate transshipment policy and pooling groups design.", "e:keyword": ["DISTRIBUTION", "INVENTORY CONTROL", "LATERAL TRANSSHIPMENT", "SIMULATION."]}, {"e:year": 2002, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2002.tb00492.x", "e:abstract": "We treat a three-stage hybrid flowshop for the production of printed circuit boards (PCB), suggested to us by a real-life production situation. The problem is to determine a schedule that minimizes the makespan for a given demand profile over a finite planning horizon. We propose a global procedure that utilizes genetic algorithms and three subproblems. The performance of the procedure is evaluated via experimentation over thousands of problem realizations that are randomly generated. The experimental results show the efficiency of the global procedure and provides qualitative answers to the allocation of machines to the various stages.", "e:keyword": ["HYBRID FLOWSHOPS", "SCHEDULING", "PRINTED CIRCUIT BOARD ASSEMBLY", "HEURIS‐TICS"]}, {"e:year": 2002, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2002.tb00493.x", "e:abstract": "This research examines production planning and control for a remanufacturer that can sell returned items on a graded as-is basis or remanufacture the returned items. Using a GI/G/1 queuing network, we model the firms decision to remanufacture an optimal product mix over the long run that maximizes profits while maintaining a desired service level. We further use simulation to explore dispatching heuristics that can be used at the shop-floor level to achieve the desired optimal product mix, while meeting the service level constraint. Our research is grounded in actual practice and the results provide key insights into the decision-making process required to maximize profits and minimize average flow times for remanufactured products.", "e:keyword": ["REMANUFACTURING", "REVERSE LOGISTICS", "PRODUCTION PLANNING AND CON‐TROL", "QUEUING", "SIMULATION."]}, {"e:year": 2002, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2002.tb00496.x", "e:abstract": "In just-in-time inventory management in any manufacturing setting, the general idea has been to release jobs as late as possible (to reduce inventory costs) while still having them arrive at bottleneck machines in time to maintain the desired throughput (by not starving a bottleneck machine). When a cyclic schedule is employed, the throughput is determined by a cyclic sequence of operations known as the cyclic critical path. These operations are not, in general, all performed on a single bottleneck machine. We present an algorithm for releasing jobs that treats this cyclic critical path as the bottleneck. Although this algorithm has the somewhat complex task of not delaying any of these operations on the cyclic critical path, it is greatly simplified by being able to take advantage of the fixed sequence of the cyclic schedule. The result is that the algorithm is relatively simple to implement. Although it uses a simulation-based analysis, this analysis can all be done and the necessary results stored in advance of its use. We test the algorithm in a job shop environment with stochastic operation times. This algorithm is shown to be effective at reducing inventory while avoiding decreases in throughput.", "e:keyword": ["CYCLIC SCHEDULING", "JOB RELEASE CONTROL", "INVENTORY MANAGEMENT", "CRITI‐CAL PATH", "BOTTLENECK."]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00194.x", "e:abstract": "We examine the impact of point of sale (POS) data sharing on ordering decisions in a multi-echelon supply chain. In particular, we focus on how exposure to POS data may help reduce the “bullwhip effect,” the tendency of orders to increase in variability as one moves up a supply chain. Theoretical studies have shown that exposure to POS data can lead to a reduction in the bullwhip effect when suppliers have no prior knowledge of the demand distribution. The benefit of sharing POS data in stable industries, where the demand distribution is commonly known, is less clear. We study this phenomenon from a behavioral perspective in the context of a simple, serial, supply chain subject to information lags and stochastic demand. We find, using a controlled simulation experiment, that sharing POS information does help reduce some components of the bullwhip effect in a stable demand setting, namely the order oscillation of upstream members. We offer one possible explanation for this improvement by examining the relationship between order decisions and demand line information.", "e:keyword": ["BULLWHIP EFFECT", "SUPPLY CHAIN MANAGEMENT", "POS DATA", "EXPERIMENTAL ANALYSIS"]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00195.x", "e:abstract": "Several approaches to the widely recognized challenge of managing product variety rely on the pooling effect. Pooling can be accomplished through the reduction of the number of products or stock-keeping units (SKUs), through postponement of differentiation, or in other ways. These approaches are well known and becoming widely applied in practice. However, theoretical analyses of the pooling effect assume an optimal inventory policy before pooling and after pooling, and, in most cases, that demand is normally distributed. In this article, we address the effect of nonoptimal inventory policies and the effect of nonnormally distributed demand on the value of pooling. First, we show that there is always a range of current inventory levels within which pooling is better and beyond which optimizing inventory policy is better. We also find that the value of pooling may be negative when the inventory policy in use is suboptimal. Second, we use extensive Monte Carlo simulation to examine the value of pooling for nonnormal demand distributions. We find that the value of pooling varies relatively little across the distributions we used, but that it varies considerably with the concentration of uncertainty. We also find that the ranges within which pooling is preferred over optimizing inventory policy generally are quite wide but vary considerably across distributions. Together, this indicates that the value of pooling under an optimal inventory policy is robust across distributions, but that its sensitivity to suboptimal policies is not. Third, we use a set of real (and highly erratic) demand data to analyze the benefits of pooling under optimal and suboptimal policies and nonnormal demand with a high number of SKUs. With our specific but highly nonnormal demand data, we find that pooling is beneficial and robust to suboptimal policies. Altogether, this study provides deeper theoretical, numerical, and empirical understanding of the value of pooling.", "e:keyword": ["POOLING", "STOCK KEEPING UNIT", "SKU", "RATIONALIZATION", "PRODUCT VARIETY", "INVENTORY MANAGEMENT", "SUBOPTIMAL INVENTORY POLICY"]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00197.x", "e:abstract": "Many telephone call centers that experience cyclic and random customer demand adjust their staffing over the day in an attempt to provide a consistent target level of customer service. The standard and widely used staffing method, which we call the stationary independent period by period (SIPP) approach, divides the workday into planning periods and uses a series of stationary independent Erlang-c queuing models—one for each planning period—to estimate minimum staffing needs. Our research evaluates and improves upon this commonly used heuristic for those telephone call centers with limited hours of operation during the workday. We show that the SIPP approach often suggests staffing that is substantially too low to achieve the targeted customer service levels (probability of customer delay) during critical periods. The major reasons for SIPP‘ s shortfall are as follows: (1) SIPP's failure to account for the time lag between the peak in customer demand and when system congestion actually peaks; and (2) SIPP’ s use of the planning period average arrival rate, thereby assuming that the arrival rate is constant during the period. We identify specific domains for which SIPP tends to suggest inadequate staffing. Based on an analysis of the factors that influence the magnitude of the lag in infinite server systems that start empty and idle, we propose and test two simple “lagged” SIPP modifications that, in most situations, consistently achieve the service target with only modest increases in staffing.", "e:keyword": ["CALL‐CENTERS", "STAFFING", "QUEUING", "NON‐STATIONARY", "SIPP"]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00198.x", "e:abstract": "This paper describes the changes that are forcing property and casualty insurance firms to rethink their service system design and in particular their distribution strategies. A set of questions related to distribution that are uppermost in the minds of executives in this industry are presented along with a literature survey of models that can be used to answer some of these questions. Based on the survey, a normative framework for designing the distribution system is proposed. Qualitative and quantitative analysis based on the proposed framework is presented along with empirical data to demonstrate the usefulness of the framework. The paper concludes with an agenda for further research.", "e:keyword": ["INSURANCE INDUSTRY", "SERVICE STRATEGY", "SERVICE SYSTEM DESIGN", "DISTRIBUTION SYSTEM DESIGN"]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00199.x", "e:abstract": "Variety management has emerged as a crucial dimension of successful business practice. In this paper, I first provide a framework for managerial decisions about variety. Variety-creation decisions determine the amount, type, and timing of end-product variety, while variety-implementation decisions focus on the design and operation of internal processes and a supply chain to support a firm's variety-creation strategy. I organize variety-related decisions into four key decision themes in variety creation: 1) dimensions of variety, 2) product architecture, 3) degree of customization, and 4) timing; and three key decision themes in variety implementation: 1) process capabilities, 2) points of variegation, and 3) day-to-day decisions. I describe each theme and review the relevant literature on each theme, with a focus on research that provides insight to problems faced in practice. Finally, I identify untapped avenues for future research that would be of value to the practicing manager, paying special attention to interdependencies among decision themes.", "e:keyword": ["MANAGING PRODUCT VARIETY", "PRODUCT VARIETY", "VARIETY CREATION", "VARIETY IMPLEMENTATION", "PRODUCT CUSTOMIZATION", "FUTURE RESEARCH STREAMS"]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00200.x", "e:abstract": "We develop a stochastic programming model to aid manufacturing firms in making strategic decisions in technology acquisition. The proposed model maximizes the firm's expected profit under the condition of the uncertainty in technological progress and development. To solve this large-scale problem, we decompose future uncertainties through scenarios and then develop an algorithm to solve the resulting non-linear subproblems efficiently. Finally, we develop a heuristic to eliminate the infeasibility in the master problem and obtain best solutions. Numerical results show that our heuristic solutions are very close to the optimal solutions and meaningful insights are derived.", "e:keyword": ["TECHNOLOGY PROGRESS", "TECHNOLOGY AND CAPACITY ACQUISITION", "ECONOMIES OF SCALE", "SCENARIO ANALYSIS", "STOCHASTIC PROGRAMMING"]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00202.x", "e:abstract": "Firms capable of reducing the time required to bring new products to the marketplace realize significant competitive gains. In this context, the existing literature on capacity expansion is limited because it does not consider the lead time required to construct and operationalize new capacity. Models are introduced here that capture the capacity expansion lead time as well as two types of learning. Specifically, learning may reduce the lead time or cost required to complete an expansion. Analytic and numerical results show that the optimal solution can be significantly affected by the explicit treatment of the lead time and learning.", "e:keyword": ["CAPACITY EXPANSION", "LEAD TIME", "LEARNING", "TIME‐BASED COMPETITION"]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00203.x", "e:abstract": "", "e:keyword": []}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00204.x", "e:abstract": "An important issue being discussed for Chilean pine plantation policies is the application of environmental protection measures when managing its timber areas. Typical measures, already in place in more developed countries, include imposing riparian strips and protecting fragile soils from the use of heavy machinery. While environmental protection measures have been considered vital for decades, so far there has been almost no attempt to quantify both the benefits and costs of these measures. This paper attempts to measure the costs associated with the main measures which can help both the forestry firms and the government evaluate the cost impact of the new environmental protection regulations being studied. The analysis for different environmental scenarios is carried out by modifying a mixed integer LP, currently used for tactical planning by one forestry firm.", "e:keyword": ["FOREST MANAGEMENT", "ENVIRONMENT", "PLANNING MODEL"]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00206.x", "e:abstract": "In this paper we consider the problem of designing a mixed assembly-disassembly line for remanufacturing. That is, parts from the disassembly and repair of used products can be used to build “new” products. This is a problem common to many OEM remanufacturers, such as Xerox or Kodak. We study two main configurations, under the assumption that the disassembly sequence is exactly the reverse of the assembly sequence. Under a parallel configuration, there exist two separate dedicated lines, one for assembly and one for disassembly, which are decoupled by buffers—from both disassembly operations, which have preference, as well as parts from an outside, perfectly reliable supplier. Under a mixed configuration, the same station is used for both disassembly and assembly of a specific part. The problem is studied using GI/G/c networks, as well as simulation. Due to a loss of pooling, we conclude that the parallel configuration outperforms the mixed line only when the variability of both arrivals and processing time are significantly higher for disassembly and remanufacturing than for assembly. Via a simulation, we explore the impact of having advanced yield information for the remanufacturing parts. We find that advanced yield information generally improves flow times; however, there are some instances where it lengthens flow times.", "e:keyword": ["REMANUFACTURING", "ASSEMBLY LINES", "QUEUING", "SIMULATION"]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00210.x", "e:abstract": "This paper explores the relationship between environmental practices and performance in services and the impact of such practices on the external portion of the service profit chain. Using structural equation modeling, it tests the hypotheses developed with data from the European hospitality industry. The findings suggest that environmental practices are positively related to performance through the mediating effect of enhanced customer satisfaction and loyalty. The paper's contributions include: the conceptual development of the relationship between environmental practices and performance in services, the incorporation of environmental practices within the service profit chain, and the testing of their impact on customer satisfaction.", "e:keyword": ["CUSTOMER LOYALTY", "CUSTOMER SATISFACTION", "ENVIRONMENTAL MANAGEMENT PRACTICES", "SERVICE PROFIT CHAIN"]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00211.x", "e:abstract": "We explore theoretically and empirically how efforts to enhance environmental performance may enable other types of manufacturing improvements. Drawing on a unique data set comprised of detailed surveys of 42 automotive assembly plants, associated quality metrics, and in-depth qualitative data from 17 automotive assembly plants, we show that attaining superior environmental performance can be a significant driver of superior quality. We highlight the synergistic and reciprocal nature of environmental and broader manufacturing improvement efforts, and show that environmental improvement tools and know-how can be an important source of competitive advantage.", "e:keyword": ["ENVIRONMENT", "QUALITY", "TQM", "LEAN PRODUCTION", "COMPETITIVE ADVANTAGE"]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00212.x", "e:abstract": "To date, it is unclear as to how Environmental Management Systems (EMS) are implemented and what effects these systems have on other environmental and operational practices. This study reports empirical insights to EMS practices based on the largest EMS survey of manufacturing firms in the United States. The objective of the study is to test for a relationship between environmental management systems and perceived operations performance while considering direct and indirect effects of various environmental practices. The results of this study are supported by several field studies and provide a new source of information regarding EMS theory development. The results also indicate a positive relationship between an EMS, the environmental practices a firm engages, and operations performance measures.", "e:keyword": ["ENVIRONMENTAL MANAGEMENT SYSTEMS", "ENVIRONMENTAL PRACTICES", "ENVIRONMENTAL PERFORMANCE", "MULTIMETHODS", "STRUCTURAL EQUATION MODELING"]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00213.x", "e:abstract": "We develop a dynamic prioritization policy to optimally allocate a scarce resource among K projects, only one of which can be worked on at a time. When the projects' delay costs differ, the problem (a “restless bandit”) has not been solved in general. We consider the policy of working on the project with the highest expected delay loss as if the other project was completely finished first (although recourse is allowed). This policy is optimal if: (1) the delay cost increases with the delay regardless of the performance state, (2) costs are not discounted (or, discounting is dominated by delay costs), (3) projects are not abandoned based on their performance state during processing at the scarce resource, and (4) there are no stochastic delays. These assumptions are often fulfilled for processing at specialized resources, such as tests or one-off analyses.", "e:keyword": ["PROJECT PRIORITIZATION", "PORTFOLIO SELECTION", "PRODUCT DEVELOPMENT", "RESOURCE ALLOCATION", "DYNAMIC PROGRAMMING"]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00214.x", "e:abstract": "We present a tool to diagnose the behavior of planners in complex production processes and to establish improvement potential for the delivery performance by changing the planning behavior. Scientific literature on production control offers valuable knowledge, but the complexity of real-life processes makes it impossible to directly apply this knowledge in real-life. The presented tool identifies possible deficiencies in the current way of managing the business processes, by matching the scientific knowledge on order planning with data reflecting the real-life processes via logistic regression. A case study at a maintenance organization illustrates the diagnosis tool.", "e:keyword": ["ORDER PLANNING", "DUE DATE PERFORMANCE", "PERFORMANCE FEEDBACK", "THEORY DRIVEN EMPIRICAL RESEARCH", "LOGISTIC REGRESSION"]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00215.x", "e:abstract": "Cyclic inventory is the buffer following a machine that cycles over a set of products, each of which is subsequently consumed in a continuous manner. Scheduling such a machine is interesting when the changeover times from one product to another are non-trivial—which is generally the case. This problem has a substantial literature, but the common practices of “lot-splitting” and “maximization of utilization” suggest that many practitioners still do not fully understand the principles of cyclic inventory. This paper is a tutorial that demonstrates those principles. We show that cyclic inventory is directly proportional to cycle length, which in turn is directly proportional to total changeover time, and inversely proportional to machine utilization. We demonstrate the virtue of “maximum changeover policies” in minimizing cyclic inventory—and the difficulty in making the transition to an increased level of demand. In so doing, we explicate the different roles of cyclic inventory, transitional inventory, and safety stock. We demonstrate the interdependence of the products in the cycle—the lot-size for one product cannot be set independently of the remaining products. We also give necessary conditions for consideration of improper schedules (i.e., where a product can appear more than once in the cycle), and demonstrate that both lot-splitting and maximization of utilization are devastatingly counter-productive when changeover time is non-trivial.", "e:keyword": ["INVENTORY", "LOT‐SIZING", "SCHEDULING", "CYCLIC SCHEDULES", "CHANGEOVER"]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00216.x", "e:abstract": "This paper presents a theoretical framework for measuring volume flexibility and relating these measures to firm performance. We develop four metrics using the principle that a volume flexible firm can handle similar levels of uncertainty (as measured by sales variability) with smaller fluctuations in inputs (as measured by variability in cost of goods sold and variability in inventory levels). Then, using 20 years of Compustat data on 550 firms in the capital goods industry, we find that on three of four process-based measures, small firms are more volume flexible. However, when we incorporate financial performance into our fourth metric, we find that large firms are more volume flexible. We conclude that, to be volume flexible is one thing, but to benefit from this flexibility, firms need to focus on the cost of being flexible.", "e:keyword": ["VOLUME FLEXIBILITY", "OPERATIONS STRATEGY", "SMALL VERSUS LARGE FIRMS", "SECONDARY DATA", "EMPIRICAL RESEARCH"]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00217.x", "e:abstract": "We investigate the revenue impact of a new Price Setting Method (PSM) and compare it with the industry standard Bid Price Method (BPM). This comparison is performed via a simulation that was validated by a major hotel chain. In 27 out of the 32 cases, the PSM outperformed the BPM based on statistically significant tests. The PSM produces an average revenue increase of 34%, which can be thought of as an upper bound on the realistic revenue increase.", "e:keyword": ["PRICING", "YIELD MANAGEMENT", "HEURISTICS", "SIMULATION", "SERVICE OPERATIONS"]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00218.x", "e:abstract": "This paper provides a comprehensive survey of research on appointment scheduling in outpatient services. Effective scheduling systems have the goal of matching demand with capacity so that resources are better utilized and patient waiting times are minimized. Our goal is to present general problem formulation and modeling considerations, and to provide taxonomy of methodologies used in previous literature. Current literature fails to develop generally applicable guidelines to design appointment systems, as most studies have suggested highly situation-specific solutions. We identify future research directions that provide opportunities to expand existing knowledge and close the gap between theory and practice.", "e:keyword": ["HEALTH CARE", "SERVICE OPERATIONS", "APPOINTMENT SCHEDULING", "OUTPATIENT SERVICES", "QUEUING SYSTEMS", "SIMULATION"]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00497.x", "e:abstract": "", "e:keyword": []}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00498.x", "e:abstract": "This paper offers insights regarding an agenda for service operations management (SOM) research. First, we motivate the need for an SOM research agenda. Second, we offer a research framework that paints a broad-based picture of key architectural elements in the SOM research landscape. The framework builds upon prior and emerging research for designing, delivering and evaluating services. Third, in order to stimulate future research in SOM, we use this framework to hone in on five understudied and emerging research themes that underpin our proposed SOM research agenda.", "e:keyword": ["SERVICE OPERATIONS MANAGEMENT", "SERVICE STRATEGY", "SERVICE MANAGEMENT RESEARCH."]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00501.x", "e:abstract": "Evidence on the impact of amplification effects on supply chain performance primarily has been derived from studies in manufacturing industries. In this article we reported on a case study from the telecommunication industry and aimed to analyze relevant root causes and associated countermeasures of the amplification phenomenon in service supply chains. Our case findings confirm the occurrence of upstream amplification of workload in the service supply chain, workload being a more appropriate measure for amplification effects in service supply chains than inventory levels. Not all of the root causes for amplification effects known from research in manufacturing environments were found to apply in this particular service context, especially those related to the use of inventory.", "e:keyword": ["SUPPLY CHAIN", "SERVICE OPERATIONS", "AMPLIFICATION", "CASE STUDY."]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00502.x", "e:abstract": "The ability of telecommunication operators to focus successfully on the customer has proven to be one of the most competitive issues toward the end of the 20th century. The services management literature is short of theoretical and empirical studies on customer satisfaction measurement in the telecommunications industry. This, however, is contrary to the industry practice since almost all major telecommunications companies around the world gather information about customer satisfaction and other related information about the quality of their services. Our research focuses on the customer satisfaction function of residential customers of a major European telecommunications company. Customer satisfaction is seen as the overall performance of the telecommunications company stemming from adequate service provision, value for money, loyalty, and relationship management. The antecedents of the performance of the organization are obtained from the contact points between the customers and the service points of the telecommunications company.", "e:keyword": ["CUSTOMER SATISFACTION", "CONSUMER BEHAVIOUR", "TELECOMMUNICATIONS", "DECISION MAKING."]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00503.x", "e:abstract": "This paper addresses the issue of service design, specifically that of designing the service encounter for improved quality. We introduce a framework based on the three T's of task, treatment, and tangibles as a means of organizing the application of the diverse and growing body of service quality literature to encounter design. The framework is consistent with how successful service managers disaggregate the design problem. More importantly, we show that mutually supportive interrelationships between the three T's produce an opportunity for designing in a robustness to service failure. The framework is supported by case based evidence.", "e:keyword": ["SERVICE QUALITY", "SERVICE DESIGN", "SERVICE ENCOUNTER", "SERVICE MANAGEMENT", "QUALITY MANAGEMENT."]}, {"e:year": 2003, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2003.tb00504.x", "e:abstract": "In this paper we review the literature on appointment policies, specifically in terms of the objective function commonly used and the assumptions made about the behavior of demand. First, we provide an economic framework to analyze the problem. Based on this framework we make a critical analysis of the objective functions used in the literature. We also question the validity of the assumption made throughout the literature that demand is exogenous and independent of customers' waiting times. We conclude that the objective functions used in the literature are appropriate only in the case of a central planner facing a demand that is unresponsive to waiting time. For other scenarios, such as a private server facing a demand that does react to waiting time, these objective functions are only shortcuts for the real objective functions that must be used. A more general model is then proposed that fits these scenarios well. Finally, we determine the impact of using the literature's objective functions on optimal appointment policies.", "e:keyword": ["SERVICE OPERATIONS", "APPOINTMENT POLICIES", "PRIVATE SERVER AND CENTRAL PLANNER."]}, {"e:year": 2004, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2004.tb00141.x", "e:abstract": "We consider a market with two competing supply chains, each consisting of one wholesaler and one retailer. We assume that the business environment forces supply chains to charge similar prices and to compete strictly on the basis of customer service. We model customer service competition using game-theoretical concepts. We consider three competition scenarios between the supply chains. In the uncoordinated scenario, individual members of both supply chains maximize their own profits by individually selecting their service and inventory policies. In the coordinated scenario, wholesalers and retailers of each supply chain coordinate their service and inventory policy decisions to maximize supply chain profits. In the hybrid scenario, competition is between one coordinated and one uncoordinated supply chain. We discuss the derivation of the equilibrium service strategies, resulting inventory policies, and profits for each scenario, and compare the equilibria in a numerical study. We find that coordination is a dominant strategy for both supply chains, but as in the prisoner's dilemma, both supply chains are often worse off under the coordinated scenario relative to the uncoordinated scenario. The consumers are the only guaranteed beneficiaries of coordination.", "e:keyword": ["Supply chain management", "Duopoly", "Customer service competition", "Inventory management", "Coordination", "Prisoner's dilemma"]}, {"e:year": 2004, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2004.tb00143.x", "e:abstract": "In this paper, the supplier of a key component to a global manufacturer offers a one-time price discount; we study the firm's optimal response to the discount under two different strategies. In the first strategy, the firm does not pass along the discount to its customers (sales subsidiaries); the firm simply coordinates purchasing and production among the different factories to take advantage of this one-time price discount. In the second strategy, the firm offers price discounts for its most profitable products in different sales subsidiaries to increase their demand. We carried out experiments for the two strategies based on a mathematical programming model, built around Toshiba's global notebook supply chain. Model constraints include, among others, material constraints, bill-of-materials, capacity and transportation constraints, minimum lot size constraints, and a constraint on minimum fill rate (service level constraint). Unlike most models of this type in the literature, which define variables in terms of single arc flows, we employ path variables, which allow for direct identification and manipulation of profitable and non-profitable products.", "e:keyword": ["Supply chain management", "Production planning", "Global operations", "Mathematical programming"]}, {"e:year": 2004, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2004.tb00144.x", "e:abstract": "Retailers often stock competing products from multiple manufacturers. When the retailer stocks out of a particular item, customers who prefer the item are likely, with some probability, to switch to a substitute product from another manufacturer at the same store. In such an event, a “lost sale” for the manufacturer is not a “lost sale” for the retailer. This exacerbates differences in manufacturer's and retailer's stockout costs for the item. Such differences in stockout cost influence the optimal contract between the manufacturer and the retailer and also impose agency costs on the channel. Such contracts, in turn, determine equilibrium inventory levels and fill rates. We study these issues in a single-period supply chain, consisting of a manufacturer and a retailer, under three different scenarios (when the two firms are integrated into a single entity, when the retailer makes stocking decisions, and when the manufacturer makes stocking decisions). We compare, and present a methodology for comparing, stocking quantities, manufacturer efforts, and supply chain profits across different scenarios. We find that VMI performs better when manufacturer effort is a substantial driver of consumer demand and when consumers are unlikely to substitute to another brand in case of a stockout. On the other hand, if non-contractible manufacturer effort is unimportant, or when substitution is significant, VMI can exacerbate, rather than mitigate, channel inefficiencies, and can perform worse than traditional Retailer Managed Inventory.", "e:keyword": ["Supply chain management", "Incentives", "Substitute products", "Vendor‐managed inventory"]}, {"e:year": 2004, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2004.tb00146.x", "e:abstract": "This paper gives an overview of the theory and practice of planning and scheduling in supply chains. It first gives an overview of the various planning and scheduling models that have been studied in the literature, including lot sizing models and machine scheduling models. It subsequently categorizes the various industrial sectors in which planning and scheduling in the supply chains are important; these industries include continuous manufacturing as well as discrete manufacturing. We then describe how planning and scheduling models can be used in the design and the development of decision support systems for planning and scheduling in supply chains and discuss in detail the implementation of such a system at the Carlsberg A/S beerbrewer in Denmark. We conclude with a discussion on the current trends in the design and the implementation of planning and scheduling systems in practice.", "e:keyword": ["Planning", "Scheduling", "Supply chain management", "Enterprise resource planning  systems", "Multi‐echelon inventory control"]}, {"e:year": 2004, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2004.tb00151.x", "e:abstract": "The Bullwhip Effect is problematic: order variability increases as orders propagate along the supply chain. The fundamental differential delay equations for a retailer's inventory reacting to a surge in demand are solved exactly. Much of the rich and complex inventory behavior is determined by the replenishment delay. The analytical solutions agree with numerical integrations and previous control theory results. Managerially useful ordering strategies are proposed. Exact expressions are derived for the retailer's orders to the manufacturer, and the Bullwhip Effect arises naturally. The approach is quite general and applicable to a wide variety of supply chain problems.", "e:keyword": ["Bullwhip Effect", "Supply chain management", "Ordering policy"]}, {"e:year": 2004, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2004.tb00152.x", "e:abstract": "An electronic marketplace typically provides industrial suppliers an alternative option for selling their capacity in addition to the traditional open market. However, suppliers face different sets of costs and risks in open market and in electronic market. Consequently, suppliers participating in an electronic market are likely to offer their capacity at a different price compared with traditional open market. We analyze this problem and derive the price-capacity function for the supplier. We also derive a basis for allocating buyer's requirements among multiple suppliers so as to minimize his cost. Our model shows that suppliers with large capacities would quote a lower price in the electronic market. It also predicts that the unit bid price increases with bid quantity in the electronic market. Based on the price-capacity curve, we model a scenario where the buyer announces, a priori, the number of suppliers to be selected for award of a contract that will minimize its costs.", "e:keyword": ["Capacity allocation", "Multiple sourcing", "Electronic market", "Vendor selection", "Supply chain management", "e‐commeroe"]}, {"e:year": 2004, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2004.tb00154.x", "e:abstract": "The decision of a firm to set up a plant network is influenced by a number of factors, including demand fluctuations across its portfolio of products, logistics costs, and service level requirements. Product plant networks offer the benefits of consolidated production and reduced transshipment costs; on the other hand, process plant networks allow intensive dedication to process expertise and economies of scale. In this paper, we show that, aside from these benefits, process plant networks offer significant risk pooling advantages under a wide range of conditions. We analytically demonstrate that, even without accounting for economies of scale advantages, firms may prefer the process plant network configuration due to the risk pooling benefits offered.", "e:keyword": ["Process and product plants", "Plant network configuration", "Two‐stage optimization", "Operations strategy", "Risk‐pooling"]}, {"e:year": 2004, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2004.tb00155.x", "e:abstract": "This erratum contains the appendix that was omitted from the original paper by H. Akkermans and B. Vos, “Amplification in service supply chains: an exploratory study from the telecom industry”, Production and Operations Management, 12, 2, 204–223.", "e:keyword": ["Supply chain management", "Service operations", "Amplification", "Case study", "Service supply chains", "Services"]}, {"e:year": 2004, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2004.tb00220.x", "e:abstract": "Service failures do not need to result in permanent negative consequences as long as effective recovery activities are undertaken. Unfortunately, existing research has been limited in providing information to support prescriptive approaches for applying specific service recovery techniques. By using data from a large sample (n = 861) of service failure incidents and employing the use of hierarchical and non-hierarchical cluster analysis, this exploratory study creates and analyzes empirical types of service failures. The derived failure types, or common situations faced by service providers, focus on customer loyalty and the severity of the failure, and may be visualized in a two-by-two matrix. Regression analysis is then used to demonstrate how effective recovery strategies and supporting activities should vary, based on the location of the failure within the matrix. The approach and results offer important implications for strategy and service support activities as well as a foundation for systematizing service recovery efforts.", "e:keyword": ["Service operations", "Service recovery", "Survey research/design", "Critical incident technique", "Cluster analysis/hierarchical grouping"]}, {"e:year": 2004, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2004.tb00224.x", "e:abstract": "This research develops the notion of environmental fit and flexibility and illustrates the importance of such fit empirically using survey data from 101 manufacturing firms. Two dimensions of environmental dynamism are identified and the fit between them and different approaches to flexibility are assessed. Hierarchical regressions provide evidence that flexibility is a stronger predictor of performance in more dynamic environments. Specifically, presence of the unpredictability or the volatility aspects of environmental dynamism each warrant the use of different types of manufacturing flexibility strategies. Statistical results are interpreted with the caveat that while implemented capability must be used to study performance effects, this study uses perceived importance scales for flexibility.", "e:keyword": ["Environmental dynamism", "Flexibility", "Fit"]}, {"e:year": 2004, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2004.tb00225.x", "e:abstract": "Low-earth orbit satellite (LEO) systems continue to provide mobile communication services. The issue of cost containment in system maintenance is a critical factor for continued operation. Satellite finite life-times follow a stochastic process, and since satellite replenishment cost is the most significant on-going cost of operation, finding optimal launch policies is of paramount importance. This paper formulates the satellite launch problem as a Markovian decision model that can be solved using dynamic programming. The policy space of the system is enormous and traditional action space dominance rules do not apply. In order to solve the dynamic program for realistic problem sizes, a novel procedure for limiting the state space considered in the dynamic program is developed. The viability of the proposed solution procedure is demonstrated in example problems using realistic system data. The policies derived by the proposed solution procedure are superior to those currently considered by LEO system operators, and result in substantial annual cost savings.", "e:keyword": ["Scheduling and sequencing", "Replenishment", "Inventory management"]}, {"e:year": 2004, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2004.tb00226.x", "e:abstract": "", "e:keyword": ["Stakeholders", "Competitive advantage", "Natural environment", "Resource‐based view", "Organizational capability", "Structural equation modeling"]}, {"e:year": 2004, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2004.tb00505.x", "e:abstract": "", "e:keyword": ["Service operations", "Technology", "Service operations strategy"]}, {"e:year": 2004, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2004.tb00508.x", "e:abstract": "The prevalence of fluctuating demand is increasingly seen as a serious and ongoing issue facing the health services industry. Volume flexibility in a health care setting represents a means to improve service delivery and it allows organizations to leverage their scarce resources for optimal utilization in response to fluctuations in patient demand. This paper develops a research framework that describes four volume flexible strategies based on literature reviews and structured field interviews of health care administrators at a Carnegie I research and teaching hospital. This prescriptive framework and the propositions that are developed create a foundation to help guide future research on the important relationships between demand uncertainty, volume flexible strategies, and organizational performance.", "e:keyword": ["Services", "Demand uncertainty", "Volume flexibility", "Technology", "Health care", "Service operations"]}, {"e:year": 2004, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2004.tb00510.x", "e:abstract": "This replication study of the drivers of ISO 14000 certifications extends the work of Corbett and Kirsch (2001) and provides a different and simpler predictive model of the factors contributing to the growth of ISO 14000 certifications. The main finding is that at national level ISO 14000 certification densities can be explained by two factors: the installed base of ISO 9000 certificates and the number of environmental treaties signed and ratified. The first factor, considering the common elements of the two standards, points to conditions of infrastructural convenience, while the second highlights the importance of political-economic considerations. The study uses a new set of tools (graphical displays, distribution-free computer intensive methods) that are better suited for exploratory research when discontinuities and existence of subgroups in the data set may make findings from a linear regression suspect.", "e:keyword": ["ISO 14000 certification", "Exploratory data analysis", "Graphical displays"]}, {"e:year": 2004, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2004.tb00511.x", "e:abstract": "In Corbett and Kirsch (2001), we used a simple regression in an exploratory investigation of drivers of global diffusion of ISO 14000 certification. We found that ISO 9000 certification levels, environmental treaties ratified, and exports as a proportion of GDP were the main significant variables, where the environmental measure may be moderated by GDP per capita. In his replication study, Vastag (2004, in this issue) analyzes the same data using more visual techniques, specifically regression trees, and finds support for the significance of ISO 9000 certification levels and environmental treaties ratified, but not for export-propensity. Vastag raises a number of relevant methodological issues, to which we add some perspectives here.", "e:keyword": ["Replication study", "ISO 14000", "Global diffusion"]}, {"e:year": 2004, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2004.tb00512.x", "e:abstract": "There is little understanding as to why firms have various degrees of cell usage. The intent of this study was to identify factors that had arrested continued implementation of cells at surveyed manufacturing plants. We found no dominant factor that had prevented the firms from continued cellularization. However, by sub-dividing the plants into those with low and high degrees of direct labor hours spent in cells, short and long experience with cells, and those with and without plans for further cells, a clearer pattern emerged. The inability to find families with high and stable demand, lack of time to implement more cells, the existence of service processes, and the difficulty of cost justifying new cells were the most important factors, although their relative importance varied. The findings support the notion that cellular manufacturing has broad applicability as a form of work organization and that cell users pursue further implementations until no more viable cells with sufficient utilization, demand stability, or economic value can be found.", "e:keyword": ["Cellular manufacturing", "Implementation obstacles", "Survey study", "Manufacturing"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00005.x", "e:abstract": "", "e:keyword": ["Hedging", "Operations and risk", "Operating risk", "Real options", "Risk management"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00006.x", "e:abstract": "This paper studies the impact of learning on a multi-staged investment scenario. In contrast to other models in the real options literature in which learning is viewed as a passive consequence of the delay period, this paper quantifies information acquisition by merging statistical decision theory with the real options framework. In this context, real option attributes are discussed from a Bayesian perspective, thresholds are identified for improved decision-making, and information's impact on downstream decision-making is discussed. Using real data provided by a firm in the aerospace maintenance, repair, and overhaul industry, the methodology is used to guide a multi-phased irreversible investment decision involving process design and capacity planning.", "e:keyword": ["Real options", "Process design", "Capacity planning", "Bayesian", "Valuation"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00007.x", "e:abstract": "We study the effect of financial risk on the economic evaluation of a project with capacity decisions. Capacity decisions have an important effect on the project̂s value through the up-front investment, the associated operating cost, and constraints on output. However, increased scale also affects the financial risk of the project through its effect on the operating leverage of the investment. Although it has long been recognized in the finance literature that operating leverage affects project risk, this result has not been incorporated in the operations management literature when evaluating projects.", "e:keyword": ["Capacity planning", "Project risk", "Technology investments"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00009.x", "e:abstract": "There are two broad categories of risk affecting supply chain design and management: (1) risks arising from the problems of coordinating supply and demand, and (2) risks arising from disruptions to normal activities. This paper is concerned with the second category of risks, which may arise from natural disasters, from strikes and economic disruptions, and from acts of purposeful agents, including terrorists. The paper provides a conceptual framework that reflects the joint activities of risk assessment and risk mitigation that are fundamental to disruption risk management in supply chains. We then consider empirical results from a rich data set covering the period 1995–2000 on accidents in the U. S. Chemical Industry. Based on these results and other literature, we discuss the implications for the design of management systems intended to cope with supply chain disruption risks.", "e:keyword": ["Disruptive risks", "Operational risks", "Supply chain management"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00010.x", "e:abstract": "We consider the problem of managing demand risk in tactical supply chain planning for a particular global consumer electronics company. The company follows a deterministic replenishment-and-planning process despite considerable demand uncertainty. As a possible way to formally address uncertainty, we provide two risk measures, “demand-at-risk” (DaR) and “inventory-at-risk” (IaR) and two linear programming models to help manage demand uncertainty. The first model is deterministic and can be used to allocate the replenishment schedule from the plants among the customers as per the existing process. The other model is stochastic and can be used to determine the “ideal” replenishment request from the plants under demand uncertainty. The gap between the output of the two models as regards requested replenishment and the values of the risk measures can be used by the company to reallocate capacity among different products and to thus manage demand/inventory risk.", "e:keyword": ["Consumer electronics", "Demand uncertainty", "Stochastic programming", "Demand allocation", "Risk measures"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00012.x", "e:abstract": "The purpose of this paper is to develop a general framework for supply contracts in which portfolios of contracts can be analyzed and optimized. We focus on a multi-period environment with convex contract, spot market, and inventory holding costs. We specialize the model to the case of a portfolio consisting of option contracts. We characterize the optimal replenishment policy and show that it has a simple structure. Namely, the use of every different option contract and the spot market is dictated by a modified base-stock policy. In addition, we derive conditions to determine when an option is relatively attractive compared to other options or the spot market. Finally, we present our computational study, where we report the sensitivity of the results to the parameters of the model. Our experiments indicate that portfolio contracts not only increase the manufacturer's expected profit, but can also reduce its financial risk.", "e:keyword": ["Procurement", "Supply contracts", "Capacity options", "Sourcing diversification"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00013.x", "e:abstract": "", "e:keyword": ["Collaborative research", "New product development", "Clockspeed", "Inter‐functional collaboration", "Manufacturing operations", "Changeover flexibility", "Capacity planning", "Quality management", "Setup time reduction", "Service operations", "After sales support", "Service design", "Supply chain operations", "Capacity reservation contract", "Supplier selection", "High tech industry", "Personal computer industry", "Aerospace industry", "Semiconductor industry", "Electronics industry", "Telecommunications industry", "Management consulting", "Technology vendor", "Trade association"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00014.x", "e:abstract": "Recent empirical literature describes an industry's clockspeed as a measure of the evolutionary life cycle, which captures the dynamic nature of the industry. Among other factors, the rate of new product development is found to be associated with an industry's clockspeed. Yet the notion of an industry clockspeed and the essential factors driving suitable decision making in this area have remained relatively unexplored. We develop a simple definition and a corresponding analytic model which explains the interdependent relationship between a firm's own new product development activities and an industry clockspeed. Results from the single firm model show the conditions under which particular firms have an incentive to accelerate their new product development activities. Moreover, we link the single firm's NPD clockspeed decisions to the industry level by creating appropriate metrics which characterize different types of industries. Examples from high-tech industries such as the personal computer and aerospace industries are included to illustrate our findings. Our intention is not only to offer analytical insights into factors driving the clockspeed for these industries, but also to establish a fundamental structured decision making approach, thereby stimulating future research on this important topic.", "e:keyword": ["Clockspeed", "New product development", "Technology management"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00015.x", "e:abstract": "We present an integrated framework for measuring product development performance. The framework consists of a three stage model for exploring the relationships between metrics used by design, manufacturing, marketing functions, and overall commercial success. Using a cross-sectional survey of 383 product development professionals working on 38 product development projects in the high-tech electronic assembled goods manufacturing sector, we provide empirical evidence of the proposed framework. The findings indicate that in the high-tech manufacturing sector (1) commercial success of new product development projects is primarily determined by market share, (2) gain in market share is primarily driven by lower unit cost and not by technical performance, and (3) reduction in unit cost is primarily driven by the increased speed of new product development and not by the R&D budget. The study failed to identify any significant association between R&D budget and technical performance, and development speed and technical performance.", "e:keyword": ["High‐tech manufacturing", "Performance metrics", "New product development", "Technology management", "Engineering‐manufacturing‐marketing interface"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00017.x", "e:abstract": "We study incentive issues that arise in semiconductor capacity planning and allocation. Motivated by our experience at a major U. S. semiconductor manufacturer, we model the capacity-allocation problem in a game-theoretic setting as follows: each product manager (PM) is responsible for a certain product line, while privately owning demand information through regular interaction with the customers. Capacity-allocation is carried out by the corporate headquarters (HQ), which allocates manufacturing capacity to product lines based on demand information reported by the PMs. We show that PMs have an incentive to manipulate demand information to increase their expected allocation, and that a carefully designed coordination mechanism is essential for HQ to implement the optimal allocation. To this end, we design an incentive scheme through bonus payments and participation charges that elicits private demand information from the PMs. We show that the mechanism achieves budget-balance and voluntary-participation requirements simultaneously. The results provide important insights into the treatment of misaligned incentives in the context of semiconductor capacity-allocation.", "e:keyword": ["Semiconductor manufacturing", "Capacity planning", "Supply chain coordination", "Game theory", "Capacity‐allocation game"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00018.x", "e:abstract": "Much of the empirical research in the past two decades has suggested that quality management (QM) is context dependent. This research develops an empirical QM model in a technology-based sector—electronics manufacturing. Based on quantitative and qualitative investigations of 225 electronics firms in Hong Kong and the Pearl River Delta (PRD) region of China, a path analytic model is developed. The empirical model shows that a typical quality management system (QMS) in the electronics industry is composed of four major modules, namely leadership, cultural elements, operational support systems, and process management. These modules create a series of chain effects on organizational performance, rather than acting as parallel elements with an equal impact. By quantifying their effects on organizational performance and comparing the model to others in the literature, we identify those QM constructs that are context dependent. In electronics manufacturing, process management and customer focus are more important than other elements (e.g., cultural factors) for garnering business results. This study contributes to contingency theory and research by identifying the key constructs and their relationships in a competitive, volatile, and technology-based industry with complex supply networks.", "e:keyword": ["Quality management models", "Electronics industry", "Organizational performance", "Empirical research"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00020.x", "e:abstract": "We consider a service system with two types of customers. In such an environment, the servers can either be specialists (or dedicated) who serve a specific customer type, or generalists (or flexible) who serve either type of customers. Cross-trained workers are more flexible and help reduce system delay, but also contribute to increased service costs and reduced service efficiency. Our objective is to provide insights into the choice of an optimal workforce mix of flexible and dedicated servers. We assume Poisson arrivals and exponential service times, and use matrix-analytic methods to investigate the impact of various system parameters such as the number of servers, server utilization, and server efficiency on the choice of server mix. We develop guidelines for managers that would help them to decide whether they should be either at one of the extremes, i.e., total flexibility or total specialization, or some combination. If it is the latter, we offer an analytical tool to optimize the server mix.", "e:keyword": ["Service system design", "Queuing models", "Flexibility", "Cross‐training", "Matrix analytic method", "Optimization"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00022.x", "e:abstract": "In this paper, we study the performance of a sourcing mechanism gaining popularity in industrial procurement environments; a tournament. Under a tournament, a buyer initially procures her parts from two suppliers with possibly different quality levels, for T time periods, i.e., she parallel sources. During this time, the buyer is able to observe noisy signals about the suppliers' quality. At time T, she selects the supplier with the highest observed performance and awards it the remainder of her business. We characterize the optimal duration of the tournament as a function of various market parameters, including information and investment costs. Furthermore, we demonstrate that a tournament can be more profitable for the buyer than selecting the highest quality supplier at time T = 0 and sole sourcing entirely.", "e:keyword": ["Parallel or dual sourcing", "Procurement", "Quality", "Asymmetric information", "Investment"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00023.x", "e:abstract": "", "e:keyword": ["Product innovation", "Product development", "Product diffusion", "Axiomatic design", "Make‐or‐buy", "Time‐to‐market", "Information exchange", "Hierarchical planning", "Technology incorporation"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00024.x", "e:abstract": "Diffusion theory has typically focused on how communication, internal or external to a social system, leads to adoptions and diffusion of an innovation. We develop a diffusion and substitution model based on a somewhat different perspective. In some cases, progressive improvements in product attributes and/or continual cost reduction seem to be a key driver of the diffusion process. For example, after introduction of the 5.25-inch disk drive, its capacity continually increased, and accordingly, so did customer willingness-to-pay. Our model is based on a linear reservation price framework, in which a product is described by its depth (defined as the difference between a product̂s maximum reservation price and its production cost), and its breadth (related to the slope of its reservation price curve), indicating how broadly it appeals across various customer segments. Because of changes in product depths and breadths over time, customers who previously preferred the old product may later prefer the new product, thus creating the diffusion process. While the Bass model describes diffusion as a function of the coefficients of innovation and imitation, in our model, it is described by the coefficients of depth and breadth (the rates of change in relative depth and breadth), along with an S-coefficient that we associate with the technology S-curve. We fit our model to data from the disk-drive and the microprocessor industries.", "e:keyword": ["Diffusion", "Substitution", "Reservation price", "Innovation"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00025.x", "e:abstract": "This paper describes a structured methodology for decomposing the conceptual design problem in order to facilitate the design process and result in improved conceptual designs that better satisfy the original customer requirements. The axiomatic decomposition for conceptual design method combines Alexander's network partitioning formulation of the design problem with Suh's Independence Axiom. The axiomatic decomposition method uses a cross-domain approach in a House of Quality context to estimate the interactions among the functional requirements that are derived from a qualitative assessment of customer requirements. These interactions are used in several objective functions that serve as criteria for decomposing the design network. A new network partitioning algorithm is effective in creating partitions that maximize the within-partition interactions and minimize the between-partition interactions with appropriate weightings. The viability, usability, and value of the axiomatic decomposition method were examined through analytic comparisons and qualitative assessments of its application. The new method was examined using students in engineering design capstone courses and it was found to be useable and did produce better product designs that met the customer requirements. The student-based assessment revealed that the process would be more effective with individuals having design experience. In a subsequent assessment with practicing industrial designers, it was found that the new method did facilitate the development of better designs. An important observation was the need for limits on partition size (maximum of four functional requirements.) Another issue identified for future research was the need for a means to identify the appropriate starting partition for initiating the design.", "e:keyword": ["New product development", "Conceptual design", "Design process decomposition", "Axiomatic design", "Network partitioning"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00026.x", "e:abstract": "Several firms are interested in manufacturing and selling new products based on a new process technology. Before manufacturing can begin, either these Original Equipment Manufacturers (OEMs), or a Contract Manufacturer (CM) needs to adopt the process technology, i. e., make a capacity investment in it. Due to market uncertainty, the timing of capacity investment is crucial. In such a setting, we investigate how the timing of process adoption, an important determinant of time-to-market, is impacted by the make/buy decision. We first characterize the optimal time for process adoption and show that this delay depends on competitive intensity, cost structure and the rate of forecast improvement. Due to differing cost structures, incentives and risks, an OEM and a CM may invest in a new process technology at different times. We show that while there are conditions where outsourced manufacturing can be advantageous for the OEM from a time-to-market perspective, there are also cases where the OEM would be disadvantaged. In these cases, the OEM can accelerate process adoption by risk sharing through joint investment. Finally, the right choice of CM is extremely important for an OEM that faces a short time window for product introduction: An efficient CM not only provides low costs but also rapid access to new process technologies, and therefore higher revenues.", "e:keyword": ["Process adoption", "Capacity investment", "Outsourced manufacturing", "Time‐to‐market"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00028.x", "e:abstract": "Business processes have become more simultaneous and collaborative in the recent past. In simultaneous processes, multiple parties must adapt to one another in real time as decisions evolve. For example, New Product Development (NPD) requires collaboration in the context of Concurrent Engineering, and Supply Chain Management (SCM) in the context of collaborative planning.", "e:keyword": ["Preliminary information", "Information transfer", "Supply chains", "Concurrent engineering"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00029.x", "e:abstract": "Uncertainty in new product development (NPD) planning embraces market, creative, technological, and process dimensions to a much greater extent than in non-NPD project planning. Yet, NPD management is becoming increasingly decentralized, both within the firm and across the supply chain. Hence, planning for NPD uncertainty often results in path-dependent scenarios cutting across the strategic, tactical, and operational levels of planning. To coordinate this resulting complexity, we propose a stochastic hierarchical product development planning framework with multiple recourses, i. e., corrective actions, to maximize performance across a firm's entire NPD program. We also argue the necessity for a fourth planning level, the infrastructural, that reestablishes norms for market projections, technological forecasts, scheduling, and requirements as latent uncertainty in the environment is continually revealed. An illustration from the automotive industry is presented to demonstrate a deployment of our framework. We additionally discuss the applicability of this framework for managing NPD capabilities over time.", "e:keyword": ["Contingency", "Distributed product development", "Hierarchical planning", "Path dependence", "Recourse"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00228.x", "e:abstract": "Manufacturing capability has often been viewed to be a major obstacle in achieving higher levels of customization. Companies follow various strategies ranging from equipment selection to order process management to cope with the challenges of increased customization. We examined how the customization process affects product performance and conformance in the context of a design-to-order (DTO) manufacturer of industrial components. Our competing risk hazard function model incorporates two thresholds, which we define as mismatch and manufacturing thresholds. Product performance was adversely affected when the degree of customization exceeded the mismatch threshold. Likewise, product conformance eroded when the degree of customization exceeded the manufacturing threshold. Relative sizes of the two thresholds have management implications for the subsequent investments to improve customization capabilities. Our research developed a rigorous framework to address two key questions relevant to the implementation of product customization: (1) what degrees of customization to offer, and (2) how to customize the product design process.", "e:keyword": ["Customization", "Design‐to‐order", "Product performance", "Product conformance", "Competing risk hazard function model"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00229.x", "e:abstract": "Recently, innovation-oriented firms have been competing along dimensions other than price, lead time being one such dimension. Increasingly, customers are favoring lead time guarantees as a means to hedge supply chain risks. For a make-to-order environment, we explicitly model the impact of a lead time guarantee on customer demands and production planning. We study how a firm can integrate demand and production decisions to optimize expected profits by quoting a uniform guaranteed maximum lead time to all customers. Our analysis highlights the increasing importance of lead time for customers, as well as the tradeoffs in achieving a proper balance between revenue and cost drivers associated with lead-time guarantees. We show that the optimal lead time has a closed-form solution with a newsvendor-like structure. We prove comparative statics results for the change in optimal lead time with changes in capacity and cost parameters and illustrate the insights using numerical experimentation.", "e:keyword": ["Manufacturing strategy", "Marketing‐manufacturing interface", "Make to order", "Uniform lead time", "Lead‐time sensitive demand"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00231.x", "e:abstract": "We present a retrospective look at the articles on New Product Development that appeared in the first 50 issues of Production and Operations Management (POM). We discuss some of the strengths and weaknesses of this POM literature stream. This article is not intended to be a literature review or an exhaustive review of the articles. Rather, we seek to identify new opportunities for rigorous and relevant research, research that has the potential of differentiating and enhancing POM within the Operations Management literature.", "e:keyword": ["New product development", "Production and operations management", "Research agenda"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00232.x", "e:abstract": "In this paper, we examine the operations strategy literature in the POMS journal to determine what has been learned and to suggest new directions for further study in this important area of research. Our review of this literature resulted in the selection of thirty-one relevant articles, many of which draw upon multiple theoretical perspectives. We identify eight such theoretical perspectives, and go on to classify these perspectives in terms of the scope of inquiry employed in the research (focused versus aggregated) and the researcher's assumptions about choice processes (behavioral versus rational). In doing so, we show that this body of work is dominated by papers that draw upon theoretical perspectives enabling a more holistic scope of inquiry, with a bias towards a view of strategy as a highly rational process. Building on our systematic review and integration of the literature, we suggest multiple areas for future research.", "e:keyword": ["Operations strategy", "Theory development", "Areas for future research"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00233.x", "e:abstract": "We review the manuscripts accepted for publication by the Manufacturing Operations Department of Production and Operations Management (POM) over 13 years (1992–2004). The manuscripts managed by this department deal with topics including scheduling, manufacturing systems management, inventory control and capacity management, maintenance management, and teaching and applications. In the process of this review, we highlight the significant contribution of POM to the field of operations management and illustrate how this body of work has served to further the mission of the journal and department. We then offer comments regarding characterizations of these manuscripts and a few ideas on how to expand this body of work in the future to further the mission of the journal.", "e:keyword": ["OM Research", "Journals in OM", "Literature review", "Trends and directions in OM research Submissions and Acceptance: Accepted by Kalyan Singhal"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00234.x", "e:abstract": "Many contributions have been made to the field of quality since the inaugural issue of Production and Operations Management in 1992. The first issue called for more research and teaching on TQM, which resulted in two special issues dedicated to TQM. Many other articles related to quality have also been published in the first fifty issues of the journal on topics ranging from technical methods to the Baldrige Award and ISO 9000. As we review these articles, we assess their contribution and the progression of the field of quality. Although past research has advanced our understanding of quality, there still exists many research opportunities in developing more theory, using additional research methodologies, and studying emerging topics in this field.", "e:keyword": ["Quality", "Performance", "Baldrige", "ISO 9000", "TQM"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00235.x", "e:abstract": "Operations management researchers and practitioners face new challenges in integrating issues of sustainability with their traditional areas of interest. During the past 20 years, there has been growing pressure on businesses to pay more attention to the environmental and resource consequences of the products and services they offer and the processes they deploy. One symptom of this pressure is the movement towards triple bottom line reporting (3BL) concerning the relationship of profit, people, and the planet. The resulting challenges include integrating environmental, health, and safety concerns with green-product design, lean and green operations, and closed-loop supply chains. We review these and other “sustainability” themes covered in the first 50 issues of Production and Operations Management and conclude with some thoughts on future research challenges in sustainable operations management.", "e:keyword": ["Sustainable operations", "Closed‐loop supply chains", "Green products", "Lean and green operations", "Environmental management and operations", "Eco‐logistics", "Competitive advantage"]}, {"e:year": 2005, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2005.tb00236.x", "e:abstract": "We review and discuss the evolution of interdisciplinary and interorganizational research in operations management and suggest directions for future investigations. The proposed operations management research focus is one that embraces a more holistic view of an “extended enterprise” which involves working with a new business model—the organization as a network. This methodology starts by treating the organization as a system that is enabled by information technology and is characterized by ubiquitous information sharing across traditional enterprise. Proper integration of technology, business processes and people factors needs to be developed to create higher value from networked enterprises. Operations management research future lies in establishing this science from an interdisciplinary perspective. We analyze this perspective in the context of papers published in the first 50 issues of Production and Operations Management and the related literature.", "e:keyword": ["Operations management", "Interorganizational", "Interdisciplinary", "Research agenda", "Information technology", "Network‐centric enterprise", "Enterprise transformation", "Enterprise networks", "Organizational behavior", "Business processes"]}, {"e:year": 2006, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2006.tb00033.x", "e:abstract": "We perform an analysis of various queueing systems with an emphasis on estimating a single performance metric. This metric is defined to be the percentage of customers whose actual waiting time was less than their individual waiting time threshold. We label this metric the Percentage of Satisfied Customers (PSC.) This threshold is a reflection of the customers' expectation of a reasonable waiting time in the system given its current state. Cases in which no system state information is available to the customer are referred to as “hidden queues.” For such systems, the waiting time threshold is independent of the length of the waiting line, and it is randomly drawn from a distribution of threshold values for the customer population. The literature generally assumes that such thresholds are exponentially distributed. For these cases, we derive closed form expressions for our performance metric for a variety of possible service time distributions. We also relax this assumption for cases where service times are exponential and derive closed form results for a large class of threshold distributions. We analyze such queues for both single and multi-server systems. We refer to cases in which customers may observe the length of the line as “revealed” queues.“ We perform a parallel analysis for both single and multi-server revealed queues. The chief distinction is that for these cases, customers may develop threshold values that are dependent upon the number of customers in the system upon their arrival. The new perspective this paper brings to the modeling of the performance of waiting line systems allows us to rethink and suggest ways to enhance the effectiveness of various managerial options for improving the service quality and customer satisfaction of waiting line systems. We conclude with many useful insights on ways to improve customer satisfaction in waiting line situations that follow directly from our analysis.", "e:keyword": ["Waiting lines", "Customer satisfaction", "Management of customer queues"]}, {"e:year": 2006, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2006.tb00158.x", "e:abstract": "Motivated by a case study of a company that produces car parts, we study the multi-product economic lot scheduling problem for a hybrid production line with manufacturing of new products and remanufacturing of returned products. For this economic lot scheduling problem with returns (ELSPR), we consider policies with a common cycle time for all products, and with one manufacturing lot and one remanufacturing lot for each product during a cycle. For a given cycle time, the problem is formulated as a mixed integer linear programming (MIP) problem, which provides the basis for an exact solution. The application of this model for one of the core products of the case study company indicates a 16% reduction in cost compared to the current lot scheduling policy.", "e:keyword": ["ELSP", "Returns", "Remanufacturing", "Reverse logistics"]}, {"e:year": 2006, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2006.tb00161.x", "e:abstract": "Companies are increasingly realizing the need to coordinate their manufacturing and remanufacturing operations. This can be a challenge due to the inherent variability in the condition and amount of returns, which has a direct impact on remanufacturing costs and leadtimes. In this paper, we develop a modeling framework to compare two alternative strategies that use either manufacturing or remanufacturing as the primary means of satisfying customer demand. Of course, in the event that the demand cannot be met by the prioritized process, the secondary process is used as a contingency. In our basic model, the priority decisions are made at the component level in replenishing the serviceable inventory, while the disposal and new component ordering decisions are made independently. The second model represents the coordination of remanufacturable and new component inventory control decisions. Using simulation-based optimization on a large number of experiments, we observe that when prioritization is in the upstream echelon and there is no coordination in managing component stocks, there exists a critical return ratio, below which it is beneficial to give priority to manufacturing and above which it is beneficial to give priority to remanufacturing. We also see that coordinated control of the component inventories considerably reduces the importance of prioritization. These observations remain valid when congestion in the shop floor is also taken into account. We also study the benefits of state-dependent dispatching policies in a realistic case.", "e:keyword": ["Inventory", "Reverse logistics", "Remanufacturing", "Simulation‐based optimization"]}, {"e:year": 2006, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2006.tb00162.x", "e:abstract": "The Federal Reserve System of the United States is making changes to its cash recirculation policy to reduce depository institutions' (banks') overuse of its cash processing services. These changes will affect operating policies and costs at many institutions having large cash businesses and, in turn, impact cash transportation and logistics providers. This study provides the framework to study the cash supply chain structure and analyzes it as a closed-loop supply chain. Additionally, it describes the cash flow management system used by banks in the U.S.", "e:keyword": ["Cash supply chain", "Federal Reserve System", "Depository institutions"]}, {"e:year": 2006, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2006.tb00238.x", "e:abstract": "Elwood Spencer Buffa, a pioneer in production and operations management (P/OM), passed away in the summer of 2005, leaving his legacy behind. During his academic career Buffa made lasting contributions to teaching and research of P/OM. We review those contributions and their impact on the evolution of the P/OM discipline.", "e:keyword": ["Elwood Spencer Buffa", "Operations management", "Empirical research"]}, {"e:year": 2006, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2006.tb00239.x", "e:abstract": "We develop an analytical framework for studying the role capacity costs play in shaping the optimal differentiation strategy in terms of prices, delivery times, and delivery reliabilities of a profit-maximizing firm selling two variants (express and regular) of a product in a capacitated environment. We first investigate three special cases. The first is an existing model of price and delivery time differentiation with exogenous reliabilities, which we only review. The second focuses on time-based (i.e., length and reliability) differentiation with exogenous prices. The third deals with deciding on all features for an express variant when a regular product already exists in the marketplace. We subsequently address the integrative framework of time-and-price-based differentiation for both products in a numerical study. Our results shed light on the role that customer preferences towards delivery times, reliabilities and prices, and the capacity costs (absolute and relative) have on the firm's optimal product positioning policy.", "e:keyword": ["Product differentiation", "Capacity management", "Time‐based customer service", "Delivery time guarantee", "Pricing"]}, {"e:year": 2006, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2006.tb00240.x", "e:abstract": "Investments in dedicated and flexible capacity have traditionally been based on demand forecasts obtained under the assumption of a predetermined product price. However, the impact on revenue of poor capacity and flexibility decisions can be mitigated by appropriately changing prices. While investment decisions need to be made years before demand is realized, pricing decisions can easily be postponed until product launch, when more accurate demand information is available. We study the effect of this price decision delay on the optimal investments on dedicated and flexible capacity. Computational experiments show that considering price postponement at the planning stage leads to a large reduction in capacity investments, especially in the more expensive flexible capacity, and a significant increase in profits. Its impact depends on demand correlation, elasticity and diversion, ratio of fixed to variable capacity costs, and uncertainty remaining at the times the pricing and production decisions are made.", "e:keyword": ["Dedicated and flexible capacity investments", "Pricing", "Stochastic programming"]}, {"e:year": 2006, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2006.tb00241.x", "e:abstract": "What determines which manufacturing flexibility strategies are feasible and which are not? In this paper, I build both theoretical and empirical understanding of task-environmental contingencies that may either enable or constrain the selection of various flexibility strategies. The special emphasis is on the various plant-level actions that are used to seek manufacturing flexibility. Demand uncertainty and variability, technology, and competitive strategy emerge as the most important contingencies, although not in ways that are immediately apparent. Finally, managerial implications at both the corporate as well as manufacturing unit levels are discussed.", "e:keyword": ["Manufacturing flexibility", "Manufacturing strategy", "Case study", "Contingency theory"]}, {"e:year": 2006, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2006.tb00242.x", "e:abstract": "Many retailers are increasingly turning to home delivery as a new arena of operational competition. This study controlled for industry by investigating the online home delivery grocery business, and an analysis of 1,919 customers of home delivery grocers identified four groups of online customers based on reasons for selecting this service. These four groups were next linked to operational execution in terms of service, product, and Internet quality, and found to vary in predicable ways. Subsequent to the initial data collection, five month's of post hoc longitudinal purchasing history was collected on the four groups of online customers to determine the relative profitability. Finally, as a follow-on analysis, the study used regression to predict future consumer purchases based upon operational execution. Time savings and service quality emerged as the two most important independent variables in terms of future buying from such online home delivery services.", "e:keyword": ["Supply chain management", "Operations strategy", "e‐services", "Service operations", "Empirical research"]}, {"e:year": 2006, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2006.tb00243.x", "e:abstract": "We study conflict and cooperation issues arising in a supply chain where a manufacturer makes products which are shipped to customers by a distributor. The manufacturer and the distributor each has an ideal schedule, determined by cost and capacity considerations. However, these two schedules are in general not well coordinated, which leads to poor overall performance. In this context, we study two practical problems. In both problems, the manufacturer focuses on minimizing unproductive time. The distributor minimizes customer cost measures in the first problem and minimizes inventory holding cost in the second problem. We first evaluate each party's conflict, which is the relative increase in cost that results from using the other party's optimal schedule. Since this conflict is often significant, we consider several practical scenarios about the level of cooperation between the manufacturer and the distributor. These scenarios define various scheduling problems for the manufacturer, the distributor, and the overall system. For each of these scheduling problems, we provide an algorithm. We demonstrate that the cost saving provided by cooperation between the decision makers is usually significant. Finally, we discuss the implications of our work for how manufacturers and distributors negotiate, coordinate, and implement their supply chain schedules in practice.", "e:keyword": ["Supply chain scheduling", "Distribution system", "Cooperation in decision making", "Algorithms"]}, {"e:year": 2006, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2006.tb00245.x", "e:abstract": "We develop a new, unified approach to treating continuous-time stochastic inventory problems with both the average and discounted cost criteria. The approach involves the development of an adjusted discounted cycle cost formula, which has an appealing intuitive interpretation. We show for the first time that an (s, S) policy is optimal in the case of demand having a compound Poisson component as well as a constant rate component. Our demand structure simultaneously generalizes the classical EOQ model and the inventory models with Poisson demand, and we indicate the reasons why this task has been a difficult one. We do not require the surplus cost function to be convex or quasi-convex as has been assumed in the literature. Finally, we show that the optimal s is unique, but we do not know if optimal S is unique.", "e:keyword": ["s", "S) policy", "Stochastic inventory model", "EOQ model", "Compound Poisson process", "Average discounted‐cost formula"]}, {"e:year": 2006, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2006.tb00246.x", "e:abstract": "In this paper, we investigate a one-warehouse multiple-retailer system, where the inventory control decisions are coordinated using a near optimal induced backorder cost, β*. All installations use continuous review installation-stock (R, Q) policies. The analysis builds on an approximation model where the stochastic warehouse delays are replaced by their correct averages. The contributions include insights as to how β* is influenced by system parameters, and the determination of simple closed form β* estimates. The latter offering a practical means to achieve coordinated control of large size systems.", "e:keyword": ["Inventory", "Supply chain", "Coordination", "Decentralized", "Stochastic"]}, {"e:year": 2006, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2006.tb00248.x", "e:abstract": "Diverse businesses, such as garbage collection, retail banking, and management consulting are often tied together under the heading of “services”, based on little more than a perception that they are intangible and do not manufacture anything. Such definitions inadequately identify managerial and operational implications common among, and unique to, services. We present a “Unified Services Theory” (UST) to clearly delineate service processes from non-service processes and to identify key commonalities across seemingly disparate service businesses. The UST defines a service production process as one that relies on customer inputs; customers act as suppliers for all service processes. Non-services (such as make-to-stock manufacturing) rely on customer selection of outputs, payment for outputs, and occasional feedback, but production is not dependent upon inputs from individual customers. The UST reveals principles that are common to the wide range of services and provides a unifying foundation for various theories and models of service operations, such as the traditional “characteristics of services” and Customer Contact Theory. The UST has significant operational corollaries pertaining to capacity and demand management, service quality, services strategy, and so forth. The UST provides a common reference point to which services management researchers can anchor future theory-building and theory-testing research.", "e:keyword": ["Services management theory", "Service operations", "Business process models"]}, {"e:year": 2006, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2006.tb00250.x", "e:abstract": "Manufacturers often face a choice of whether to recover the value in their end-of-life products through remanufacturing. In many cases, firms choose not to remanufacture, as they are (rightly) concerned that the remanufactured product will cannibalize sales of the higher-margin new product. However, such a strategy may backfire for manufacturers operating in industries where their end-of-life products (cell phones, tires, computers, automotive parts, etc.) are attractive to third-party remanufacturers, who may seriously cannibalize sales of the original manufacturer. In this paper, we develop models to support a manufacturer's recovery strategy in the face of a competitive threat on the remanufactured product market. We first analyze the competition between new and remanufactured products produced by a monopolist manufacturer and identify conditions under which the firm would choose not to remanufacture its products. We then characterize the potential profit loss due to external remanufacturing competition and analyze two entry-deterrent strategies: remanufacturing and preemptive collection. We find that a firm may choose to remanufacture or preemptively collect its used products to deter entry, even when the firm would not have chosen to do so under a pure monopoly environment. Finally, we discuss conditions under which each strategy is more beneficial.", "e:keyword": ["Remanufacturing", "Competition", "Pricing", "Entry‐deterrent strategies"]}, {"e:year": 2006, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2006.tb00251.x", "e:abstract": "Many retail product returns can be refurbished and resold, typically at a reduced price. The price set for the refurbished products affects the demands for both new and refurbished products, while the refurbishment and resale activities incur costs. To maximize profit, a manufacturer in a competitive market must carefully choose the proportion of returned products to refurbish and their sale price. We model the sale, return, refurbishment, and resale processes in an open queueing network and formulate a mathematical program to find the optimal price and proportion to refurbish. Examination of the optimality conditions reveals the different situations in which it is optimal to refurbish none, some, or all of the returned products. Refurbishing operations may increase profit or may be required to relieve a manufacturing capacity bottleneck. A numerical study identifies characteristics of the new product market and refurbished products that encourage refurbishing and some situations in which small changes in the refurbishing cost and quality provoke large changes in the optimal policy.", "e:keyword": ["Reverse logistics", "Refurbishment", "Queueing networks", "Optimization"]}, {"e:year": 2006, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2006.tb00252.x", "e:abstract": "The condition of the used items acquired by remanufacturers is often highly variable, and sorting is an important aspect of remanufacturing operations. Sorting policies—the rules specifying which used products should be remanufactured and which should be scrapped—have received limited attention in the literature. In this paper, we examine the case of a remanufacturer who acquires unsorted used products as needed from third party brokers. As more used items are acquired for a given demand, the remanufacturer can be more selective when sorting. Thus, two related decisions are made: how many used items to acquire, and how selective to be during the sorting process. We derive optimal acquisition and sorting policies in the presence of used product condition variability for a remanufacturer facing both deterministic and uncertain demand. We show the existence of a single optimal acquisition and sorting policy with a simple structure and show that this policy is independent of production amount when acquisition costs are linear.", "e:keyword": ["Remanufacturing", "Product acquisition management", "Used product sorting"]}, {"e:year": 2006, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2006.tb00253.x", "e:abstract": "We explore the value of information (VOI) in the context of a firm that faces uncertainty with respect to demand, product return, and product recovery (yield). The operational decision of interest in matching supply with demand is the quantity of new product to order. Our objective is to evaluate the VOI from reducing one or more types of uncertainties, where value is measured by the reduction in total expected holding and shortage costs.", "e:keyword": ["Value of information", "Inventory control", "Supply chain management"]}, {"e:year": 2006, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2006.tb00255.x", "e:abstract": "We address the problem of determining the optimal retailer order quantities from a manufacturer who makes new products in conjunction with ordering remanufactured products from a remanufacturer using used and unsold products from the previous product generation. Specifically, we determine the optimal order quantity by the retailer for four systems of decision-making: (a) the three firms make their decisions in a coordinated fashion, (b) the retailer acts independently while the manufacturer and remanufacturer coordinate their decisions, (c) the remanufacturer acts independently while the retailer and manufacturer coordinate their decisions, and (d) all three firms act independently. We model the four options described above as centralized or decentralized decision-making systems with the manufacturer being the Stackelberg leader and provide insights into the optimal order quantities. Coordination mechanisms are then provided which enable the different players to achieve jointly the equivalent profits in a coordinated channel.", "e:keyword": []}, {"e:year": 2006, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2006.tb00257.x", "e:abstract": "We reviewed the manuscripts focused on Supply Chain Management that had been published in Production and Operations Management (POM) over roughly 15 years (1992 to 2006). The manuscripts covered dealt with topics including supply chain design, uncertainty and the bullwhip effect, contracts and supply chain coordination, capacity and sourcing decisions, applications and practice, and teaching supply chain management. In the process of this review, we highlight the significant contribution of POM to the field of supply chain management, and illustrate how this body of work has served to further the mission of the journal. We then highlight works from this group along with the discussion of selected papers from other top journals in an effort to provide a reasonably complete overview of important issues addressed in recent supply chain management research. Using our research survey and conceptual overview of the area as a foundation, we offer comments which highlight opportunities and suggest ideas on how to usefully expand the body of work in the supply chain management area.", "e:keyword": ["Supply chain management research", "Literature review", "Research opportunities in supply chain management"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00163.x", "e:abstract": "Martin K. Starr facilitated the creation of an identity for production and operations management (POM) as an academic discipline. This paper aims to summarize Starr's substantial contributions to scholarly inquiry on system integration and interfunctional coordination, modular production, and catastrophe avoidance. Even after four decades, we describe how his legacy in these areas continues to define several major drivers of operations and supply chain management research and practice. Starr has influenced several generations of students, professors, and executives with his writings, teaching, and leadership roles in the POM community that include 32 years on the faculty of the Columbia School of Business, 15 years as Editor-in-Chief of Management Science, and presidency of the Production and Operations Management Society.", "e:keyword": ["Martin  Kenneth Starr", "Production and operations management", "System integration", "Interdisciplinary research", "Modular production", "Catastrophe and risk"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00165.x", "e:abstract": "RFID (Radio-Frequency Identification) technology has shown itself to be a promising technology to track movements of goods in a supply chain. As such, it can give unprecedented visibility to the supply chain. Such visibility can save labor cost, improve supply chain coordination, reduce inventory and increase product availability. Industry reports and white papers are now filled with estimates and proclamations of the benefits and quantified values of RFID. Early adopters are now rallying more and more followers. However, most such claims are educated guesses at best and are not substantiated, that is, they are not based on detailed, model-based analysis. This paper argues that there is a huge credibility gap of the value of RFID, and that a void exists in showing how the proclaimed values are arrived at, and how those values can be realized. The paper shows that this credibility gap must be filled with solid model analysis, and therefore presents a great opportunity for the Production and Operations Management (POM) research community. The paper reviews some of the ongoing research efforts that attempt to close the credibility gap, and suggests additional directions for further strengthening the POM's contribution to help industry realize the full potentials of RFID.", "e:keyword": ["Supply chain management", "Value of visibility", "Inventory management", "Radio‐frequency identification", "Value of information technology"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00167.x", "e:abstract": "Improving performance of production systems is a critical but often unstructured activity. To help managers convert ad hoc or trial & error improvement efforts into efficient and systematic reviews, we develop a diagnostic tree which decomposes a performance improvement objective into successively more concrete sub-objectives and finally into potential improvement strategies. Based on principles from the Operations Management literature, this tree is structured to enable a non-specialist to better understand the links between corrective actions and performance. It also provides an important foundation for a principles-based knowledge management system that couples the decision tree with a search engine for locating relevant documents within an intranet.", "e:keyword": ["Knowledge management", "Factory physics", "Diagnostic tree"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00168.x", "e:abstract": "This paper addresses the problem of how to determine the composition and price of a bundle so as to maximize the total expected profit. To motivate the problem, we use as a setting a high-tech manufacturing company that operates in a competitive environment, is not a leader in the industry, and is constantly reacting to bundles introduced by the leader. Bundles are sets of components that must meet technical constraints. The company's objective is to build a bundle and offer it in a market where it will compete with other bundles. Consumers purchase the bundle that maximizes their utility after examining all available bundles. The company selection of the bundle's components and its price is made in light of the bundles against which it will be competing and the uncertainty in the consumer choice process. The optimal decision could be found by solving a nonlinear mixed integer program, which is difficult to solve. Instead, we propose an efficient solution procedure to determine the optimal composition of the bundle and the price at which it should be offered. The paper concludes with a brief discussion of extensions of the research to cases that consider multiple segments of customers and/or multiple bundles.", "e:keyword": ["Bundling", "Consumer choice models", "Pricing", "Product line selection"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00171.x", "e:abstract": "Starr and Rubinson (1978) develop a model to establish the relationship between product demand and relative prices. The notion of relative prices motivates us to consider a situation in which a retailer would either charge the same retail price for all products if he adopts a ‘fixed’ pricing strategy or charge different prices for different products if he adopts a ‘variable’ pricing strategy. In this paper, we develop a base model with deterministic demand that is intended to examine how a retailer should jointly determine the order quantity and the retail price of two substitutable products under the fixed and variable pricing strategies. Our analysis indicates that the optimal retail price under the variable pricing strategy is equal to the optimal retail price under the fixed pricing strategy plus or minus an adjustment term. This adjustment term depends on product substitutability and price sensitivity. We also present two different extensions of our base model. In the first extension, our analysis indicates that the underlying structure of the optimal retail price and order quantity is preserved when there is a limit on the total order quantity. The second extension deals with the issue of retail competition. Relative to the base case, we show that the underlying structure of the optimal retail price and order quantity is preserved in a duopolistic environment. Moreover, our analysis suggests that both retailers would adopt the variable pricing strategy at the equilibrium.", "e:keyword": ["Ordering and pricing", "Substitutable products", "Marketing and manufacturing interfaces", "Mathematical models"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00172.x", "e:abstract": "The purpose of this paper is to introduce supply chain management researchers to industry cluster theory within the context of supply chain management decisions. Industry cluster theory emphasizes the explicit and implicit benefits that accrue to various economic players due to geographic proximity. As such, it provides a contrasting view to the current pressure on supply chains to seek out the “best” partners, regardless of location. We review the theory behind industry clusters, and illustrate it using the example of the New England cotton textile industry. Incorporating these concepts into future research has the potential to improve our understanding of how decisions regarding supply chain location and sourcing decisions are currently made, and what role location-based benefits should play in these decisions.", "e:keyword": ["Industry cluster theory", "Supply chain management", "Textile industry"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00173.x", "e:abstract": "The enormous contributions of Bob Hayes to Operations Management (OM) are reviewed. His early work made innovative contributions to probability theory and utility estimation that enabled existing Operations Research theory to be applicable to real problems. Later, inspired by field trips to Japanese and German manufacturers, he joined Kim Clark to conduct an ambitious study of 12 plants in three companies, establishing the impact on productivity of factors such as reject rate, work-in-process, and production rate variation. In the 1980s, when adoption of advanced manufacturing automation was in vogue, Bob joined Jai Jaikumar to offer a caution, that new manufacturing technologies required new ways of managing and that advanced technology coupled with obsolete management would produce poorer, not better, results. Perhaps Bob's greatest contribution was to raise OM to a more strategic level. With numerous coauthors, notably Steve Wheelwright, he provided a framework for corporate and manufacturing strategy and showed how to achieve alignment between the two, particularly in the choice of production processes. Recent papers articulated a vision for OM in which a focus on the issues of operating managers provides a consistent framework, but enables our research agenda to evolve as the world's economy changes.", "e:keyword": ["Bob Hayes", "Inventory management", "Technology management", "Manufacturing strategy", "New research directions"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00175.x", "e:abstract": "Although customer convenience should be rightfully considered a central element in field services, the customer experience suggests that service enterprises rarely take the customer's preferred time into account in making operational and scheduling decisions. In this paper we present the results of our exploratory research into two interrelated topics: the explicit inclusion of customer time in nonemergency field service delivery decisions and the analysis of trade-off between the customer's convenience and field service provider's cost. Based on prior research in service quality we identify and illustrate two time-based performance metrics that are particularly appropriate for assessing service quality in nonemergency field services: performance and conformance quality. To determine vehicle routes, we develop a hybrid heuristic derived from the existing and proven heuristic methods. A numerical example closely patterned after real-life data is generated and used within a computational experiment to investigate alternate policies for promise time windows. Our experiment shows that over a reasonable range of customer cost parameters the policy of shorter promise time windows reduces the combined total cost incurred by the provider and the customers and should be considered a preferred policy by the field service provider. Managerial implications of this result are discussed.", "e:keyword": ["Field service", "Customer service", "Service quality", "Service operations"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00176.x", "e:abstract": "A key driver of the recent wave of enterprise resource planning (ERP) implementations was the assumption that the integration of business information would provide firms with a competitive advantage, yet concrete business benefits have been uneven across adopting firms. A possible explanation is that although the resource-based view holds that competitive advantage is derived from inimitable resources, ERP software has become a commodity. Socio-technical theory suggests that internal organizational resources based on a foundation of ERP technology may be the true drivers of ERP benefits. A firm's strategic configuration is posited to influence the portfolio of organizational competencies available to leverage the benefits of integrated business information, and a number of hypotheses are developed based on the notion that firms with different strategic objectives will realize different operational benefits from the adoption of ERP systems. Survey data from North American manufacturing firms that have implemented ERP systems demonstrate that ERP adopters seeking operational performance improvements are likely to realize these benefits. On the other hand, those seeking external market and supply chain performance improvements must first establish a foundation of internal operational performance improvements before customer satisfaction and supply chain benefits can be realized.", "e:keyword": ["Enterprise resource planning", "Information technology adoption", "Operations strategy", "Resource‐based view", "Cumulative capabilities"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00178.x", "e:abstract": "Information delays exist when the most recent inventory information available to the Inventory Manager (IM) is dated. In other words, the IM observes only the inventory level that belongs to an earlier period. Such situations are not uncommon, and they arise when it takes a while to process the demand data and pass the results to the IM. We introduce dynamic information delays as a Markov process into the standard multiperiod stochastic inventory problem with backorders. We develop the concept of a reference inventory position. We show that this position along with the magnitude of the latest observed delay and the age of this observation are sufficient statistics for finding the optimal order quantities. Furthermore, we establish that the optimal ordering policy is of state-dependent base-stock type with respect to the reference inventory position (or state-dependent (s, S) type if there is a fixed ordering cost). The optimal base stock and (s, S) levels depend on the magnitude of the latest observed delay and the age of this observation. Finally, we study the sensitivity of the optimal base stock and the optimal cost with respect to the sufficient statistics.", "e:keyword": ["Dynamic information delays", "Partial observations", "Stochastic inventory problem", "Base‐stock policies", "Sufficient statistics"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00179.x", "e:abstract": "The widespread adoption of supply chain management principles suggests that managers recognize the importance of evaluating operational decisions holistically. However, it is often difficult to link specific operational practices to strategic level outcomes and in turn to corporate financial results. This presents problems for both managers and academic researchers attempting to justify the often high cost of operational improvement initiatives in terms of objective accounting metrics. This study provides evidence that it is possible to demonstrate linkages between carefully chosen portfolios of tactical, strategic, and financial metrics. Survey data from 118 manufacturers are used to evaluate hypotheses linking multilevel metrics of performance across three well-established strategic foci. We present portfolios of metrics drawn from the literature and from the Supply Chain Counciľs supply-chain operations reference model and related design and customer chain models. Our analysis suggests that metric portfolios in which tactical metrics are designed to match strategic-level metrics, based on alignment with a specific strategic focus, provide clearer mechanisms for understanding performance linkages.", "e:keyword": ["Performance measurement systems", "Metrics", "Operations strategy", "Empirical research"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00261.x", "e:abstract": "Firms selling goods whose quality level deteriorates over time often face difficult decisions when unsold inventory remains. Since the leftover product is often perceived to be of lower quality than the new product, carrying it over offers the firm a second selling opportunity, a product line extension to new and unsold units, and the ability to price discriminate. By doing so, however, the firm subjects sales of its new product to competition from the leftover product. We present a two period model that captures the effect of this competition on the firm's production and pricing decisions. We characterize the firm's optimal strategy and find conditions under which the firm is better off carrying all, some, or none of its leftover inventory. We also show that, compared to a firm that acts myopically in the first period, a firm that takes into account the effect of first period decisions on second period profits will price its new product higher and stock more of it in the first period. Thus, the benefit of having a second selling opportunity dominates the detrimental effect of cannibalizing sales of the second period new product.", "e:keyword": ["Pricing", "Perishable inventory", "Quality", "Internal competition", "Product line"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00262.x", "e:abstract": "We study a single-period two-stage service-constrained supply chain with an information update. The buyer has two procurement opportunities with the second one after observing a market signal, which updates the demand forecast. He also commits to a service level after observing the market signal. We derive his optimal ordering decisions and show that the critical market signal, the optimal first-stage order quantity, and the optimal expected profit are monotone with respect to the target service level. We also discuss the impact of the forecast quality on the optimal decisions. We show that the optimal first-stage order quantity may not be monotone with respect to information accuracy, as is in the case without the service constraint. In addition, we extend our analysis to the situation when an order cancellation is allowed upon the observation of the market signal. We also compare the results obtained for the problems with and without an order cancelation. Finally, we discuss the supply chain coordination issue and find that a buyback contract can also coordinate the supply chain in the presence of the service constraint.", "e:keyword": ["Supply chain", "Information update", "Customer service level", "Dynamic programming"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00263.x", "e:abstract": "We study the benefit obtained by exploiting modular product design in fulfilling exogenous demand for both a complete assembly and its components in a service parts inventory system. Our goal is to reduce overall service system costs by allowing assembly and/or disassembly (A/D) to occur at some unit cost per A/D action. In an extensive set of computational experiments, we compare a naïve stocking and operating policy that treats all items independently and ignores the modular product structure and related A/D capability to the optimal base stock policy, and to a policy that allows A/D from the naïve stocking levels. While extensive computational analysis shows that the optimal base stock policy improves the system cost between 3 to 26% over the naïve approach, simply allowing A/D from the naïve stocking levels captures a significant portion (an average of 67%) of the naïve–optimal gap. Our computational results demonstrate that the optimization shifts the component-assembly mix from the naïve levels and that limiting A/D capacity affects this mix. Limiting A/D capacity can actually increase the expected number of A/D actions (versus the uncapacitated case), since the optimization shifts stocking levels to reduce the probability that “too many” actions will be required.", "e:keyword": ["Inventory", "Service systems", "Modular products", "Base stock policies"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00264.x", "e:abstract": "Information delays exist when the most recent inventory information available to the Inventory Manager (IM) is dated. Such situations arise when it takes a while to process the demand data, count the inventory, and pass the results to the IM. We show that the optimal total inventory-related cost decreases when the length of the information delay decreases. The amount of the decrease is an important datum for an IM interested in considering whether or not to invest in reducing the delay. The investment is required to finance design and acquisition of an information (collection and dissemination) system that can reduce the information delay. Such systems include phone calls, business meetings, and the use of information collection mechanisms such as radiofrequency identification tags.", "e:keyword": ["Information delays", "Delay evaluation", "Basestock policy", "Partially observed inventory"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00270.x", "e:abstract": "A wide variety of electronic marketplace formats are used in the Truckload (TL) transportation industry, including combinatorial auctions, private and public exchanges, and electronic catalogs. Combinatorial multi-attribute auctions are commonly used strategically to populate electronic catalogs, commonly called “routing guides,” with pricing, assignments, and priority logic. Private and public exchanges are used to complement the electronic catalogs in cases where the catalog fails. This paper discusses the TL transportation market, places the procurement of services in the context of electronic marketplace formats, and illustrates how these are currently used.", "e:keyword": ["Freight transportation", "Auctions", "Electronic markets", "Electronic catalogs", "Transportation management"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00274.x", "e:abstract": "We investigate the role of timing in ascending auctions under the premise that time is a valuable resource. Traditional models of the English auction ignore timing issues by assuming that the auction occurs instantaneously. However, when auctions are slow, as Internet auctions used for procurement often are, there are significant opportunity or monitoring costs to bidders, and the choice of the size of the jump bid becomes a strategic decision. We study the choice in the experimental laboratory by systematically varying the opportunity costs associated with fast bidding. When time is more valuable bidders respond by choosing larger jump bids. Surprisingly, the economic performance of the auction is not significantly affected. We develop a simple model of ascending auctions with impatient bidders that provides insights into the effect jump bids have on auction performance.", "e:keyword": ["Auctions", "Experimental economics", "Jump bidding", "Procurement", "Behavioral issues in operations management"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00276.x", "e:abstract": "We study auctions for a set of commonly-ranked items where each buyer has unit demand. This setting has promising applications in areas such as keyword auctions in the search engine advertising industry, the sale of quality-ranked raw materials, etc. An auction mechanism suitable for this setting is the simultaneous pooled auction (SPA), where each bidder simultaneously submits a single bid and is allocated an object based on the rank of his bid among all the bids. We study how to improve the seller's expected revenue by enforcing a reserve price in an SPA. We find that the use of an appropriate reserve price may significantly increase the seller's revenue, especially when the number of items for sale is relatively large compared to the number of participating bidders. One inherent problem in the SPA is that some bidders may incur ex post losses; that is, they pay more than what they value the received objects. We propose a tailored VCG mechanism that generates the same expected revenue as the SPA does, while bidders do not incur any ex post loss. We also discuss the potential applications of this research to keyword auctions.", "e:keyword": ["Ranked items auctions", "Revenue maximization", "Online advertisement", "Reserve price", "Optimal cutoff type"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00277.x", "e:abstract": "This special issue of the Production and Operations Management journal offers a sample of ongoing research arising from the deployment of radiofrequency identification technology in organizational operations. The articles were selected to cover a spectrum of application areas and methodologies. There is also an attempt to identify interesting open areas for further investigation.", "e:keyword": ["RFID", "Operations management", "Value assessment", "Incentives", "Implementation", "Modeling", "Experiments", "Survey methods"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00278.x", "e:abstract": "This paper reviews Paul Kleindorfer's contributions to Operations Management (OM), with a special focus on his research on risk management. An annotated bibliography of selected other contributions reviews the breadth of topics that have occupied Kleindorfer's research attention over his now 45 + years of research. These include optimal control theory, scheduling theory, decision sciences, investment planning and peak load pricing, plus a number of important applications in network industries and insurance. In the area of operations risk management, we review recent work that Kleindorfer and his colleagues in the Wharton Risk Center have undertaken on environmental management and operations, focusing on process safety and environmental risks in the chemical industry. This work is directly related to Kleindorfer's work in the broader area of “sustainable operations”, which he, Kal Singhal and Luk Van Wassenhove recently surveyed as part of the new initiative at POMS to encompass sustainable management practices within the POMS community. Continuing in the area of supply chain risks, the paper reviews Kleindorfer's contributions to the development of an integrated framework for contracting and risk hedging for supply management. The emphasis on alignment of pricing, performance and risk management in this framework is presaged in the work undertaken by Kleindorfer and his co-authors in the 1980s on after-sales support services for high-technology products. This work on supply chain risk, and its successors, is reviewed here in light of its growing importance in managing the unbundled and global supply chains characteristic of the new economy.", "e:keyword": ["Paul Kleindorfer", "Risk management", "Environmental management", "After sales service support", "Supply chain risk management"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00279.x", "e:abstract": "Most retailers suffer from substantial discrepancies between inventory quantities recorded in the system and stocks truly available to customers. Promising full inventory transparency, radio frequency identification (RFID) technology has often been suggested as a remedy to the problem. We consider inventory record inaccuracy in a supply chain model, where a Stackelberg manufacturer sets the wholesale price and a retailer determines how much to stock for sale to customers. We first analyze the impact of inventory record inaccuracy on optimal stocking decisions and profits. By contrasting optimal decisions in a decentralized supply chain with those in an integrated supply chain, we find that inventory record inaccuracy exacerbates the inefficiencies resulting from double marginalization in decentralized supply chains. Assuming RFID technology can eliminate the problem of inventory record inaccuracy, we determine the cost thresholds at which RFID adoption becomes profitable. We show that a decentralized supply chain benefits more from RFID technology, such that RFID adoption improves supply chain coordination.", "e:keyword": ["Inventory record inaccuracy", "RFID", "Supply chain coordination"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00281.x", "e:abstract": "Using a theory-building approach based on case studies, this research explores the responses of four decentralized business units to institutional pressure to adopt Radiofrequency Identification (RFID) technology. The institutional pressure emanates from the Department of Defense, and the affected decentralized business units operate in a large defense contractor. Institutional theory explains how organizations respond to external pressures to adopt new procedures, policies, and technologies. The case studies show how business units vary in their response to the RFID mandate and how different internal dynamics manifest. The responses range from complying faithfully, primarily concerned with satisfying the external constituent, to completely ignoring the mandate and focusing on internal efficiency initiative utilizing RFID. A number of propositions are developed to better understand the organizational responses to exogenous pressure to implement RFID. The paper concludes by proposing future research directions and issues that must be considered further.", "e:keyword": ["RFID", "Case studies", "Theory development", "Technology adoption", "Organizational behavior"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00282.x", "e:abstract": "RFID technology provides in-depth, real-time visibility into the status of assets throughout the supply chain. However, the deployment of RFID technology may have collateral value in the high-quality data generated by these assets. This study explores the potential value of RFID data for tactical and strategic purposes and the redesign of processes within supply chain through the deployment of simulation modeling and analysis. We present a simulation study conducted at a regional hospital for which data related to trauma patient movement was collected with an RFID-based system. We find that not only does this data serve as the basis for successful simulation modeling, but that RFID technology may address several data-related challenges previously identified in the simulation literature.", "e:keyword": ["RFID", "Simulation modeling and analysis", "Business process improvement"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00283.x", "e:abstract": "Radio Frequency Identification (RFID) technology promises to transform supply chain management. Building on previous research in information systems and supply chain management, this paper proposes a theoretical framework for RFID adoption and benefits, and tests the framework using data on u. s. firms. Our analysis suggests that there is a positive association between information technology (IT) application deployment and RFID adoption. We find that RFID implementation spending and partner mandate are associated with an expectation of early return on RFID investment, and a perceived lack of industry-wide standards is associated with an expectation of delayed return on RFID investment. These results suggest that firms with broad IT application deployment and a critical mass of RFID implementation spending are more likely to report early returns from RFID deployments. This paper extends previous research to understand the relationship between organization characteristics and adoption and expected benefits of the emerging RFID technology.", "e:keyword": ["RFID", "Information technology", "Adoption", "Benefits", "Business value of IT"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00286.x", "e:abstract": "As RFID technology matures and organizations seek to deploy it in their business operations, a basic objective in the endeavor is that of extracting business value from the technology. This paper examines three dimensions of the value proposition of RFID and attempts to identify areas for further investigation. The first dimension consists of the generic architecture of RFID implementations and the drivers of value that can result from its components. The second consists of measurement issues associated with quantification of value. Since the complete benefits of RFID will only result when multiple independent organizations deploy the technology and coordinate the resulting information flows, the third dimension addresses incentives for achieving that diffusion. The collection of issues identified through this exercise offers an initial roadmap to view ongoing research and recognize additional problems for further investigation.", "e:keyword": ["RFID", "Architecture", "Value assessment", "Incentives", "Implementation"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00287.x", "e:abstract": "John A. Buzacott is a pioneering and premier contributor to the field of production and operations management. He has been a principal architect of the development of a unified framework and a rigorous engineering foundation for many of the major approaches currently used in the design, planning, and control of manufacturing and service systems. His innovative use of stochastic models to explain many phenomena occurring in manufacturing and service organizations has distinguished him not only as a great researcher but also as a great teacher. His contributions have inspired scholars throughout the world. We provide an overview of John's research works and accomplishments.", "e:keyword": ["John Buzacott", "Flow lines", "Job shops", "Manufacturing flexibility", "Queueing models", "Service systems", "Transfer lines"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00289.x", "e:abstract": "Surgical suites are a key driver of a hospital's costs, revenues, and utilization of postoperative resources such as beds. This article describes some commonly occurring operations management problems faced by the managers of surgical suites. For three of these problems, the article also provides preliminary models and possible solution approaches. Its goal is to identify open challenges to spur further research by the operations management community on an important class of problems that have not received adequate attention in the literature, despite their economic importance.", "e:keyword": ["Surgical suites'", "Capacity management", "Elective surgery booking control", "Surgery sequencing and scheduling", "Health care operations"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00291.x", "e:abstract": "Customer behavior modeling has been gaining increasing attention in the operations management community. In this paper we review current models of customer behavior in the revenue management and auction literatures and suggest several future research directions.", "e:keyword": ["Customer behavior", "Revenue management", "Dynamic pricing", "Auctions"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00292.x", "e:abstract": "Asuccessful revenue management system requires accurate demand forecasts for each customer segment. The forecasts are used to set booking limits for lower value customers to ensure an adequate supply for higher value customers. The very use of booking limits, however, constrains the historical demand data needed for an accurate forecast. Ignoring this interaction leads to substantial penalties in a firm's potential revenues. We review existing unconstraining methods and propose a new method that includes some attractive properties not found in the existing methods. We evaluate several of the common unconstraining methods against our proposed method by testing them on intentionally constrained simulated data. Results indicate our proposed method outperforms other methods in two of three data sets. We also test the revenue impact of our proposed method, expectation maximization (EM), and “no unconstraining” on actual booking data from a hotel/casino. We show that performance varies with the initial starting protection limits and a lack of unconstraining leads to significant revenue losses.", "e:keyword": ["Revenue management", "Truncated demand", "Forecasting", "Unconstrained demand", "Simulation"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00293.x", "e:abstract": "This paper develops a conceptual model to study the role of outsourcing strategies and plant-level information technology (IT) application infrastructure in the outsourcing of production and support business processes, as well as their subsequent impact on overall plant performance. We validate this model empirically using cross-sectional survey data from U.S. manufacturing plants. We find that some IT applications are more effective at enabling the outsourcing of business processes than others. For example, the implementation of enterprise management systems is associated with the outsourcing of both production and support processes, whereas operations management systems are not associated with the outsourcing of plant processes. Plants with a low-cost outsourcing strategy are more likely to outsource support processes than plants with a competency-focused outsourcing strategy. However, both cost- and competency-based strategies have a positive and similar impact on the outsourcing of production processes. In terms of implications for plant performance, our findings indicate that the outsourcing of production and support processes is associated with higher gross margins. Although plant IT infrastructure is positively associated with favorable on-time delivery rates, there is no positive association between the incidence of plant outsourcing and on-time delivery rates. These results have implications for crafting plant-level outsourcing strategies and for investments in IT systems to facilitate the outsourcing of business processes for enhanced plant performance.", "e:keyword": ["IT infrastructure", "Production process outsourcing", "Support process outsourcing", "Outsourcing strategy", "Profitability", "Plant performance", "Business value of information technology"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00294.x", "e:abstract": "We characterize the trade-offs among firms' compliance strategies in a market-based program where a regulator interested in controlling emissions from a given set of sources auctions off a fixed number of emissions permits. We model a three-stage game in which firms invest in emissions abatement, participate in a share auction for permits, and produce output. We develop a methodology for a profit-maximizing firm to derive its marginal value function for permits and translate this value function into an optimal bidding strategy in the auction. We analyze two end-product market scenarios independent demands and Cournot competition. In both scenarios we find that changing the number of available permits influences abatement to a lesser extent in a dirty industry than in a cleaner one. In addition, abatement levels taper off with increasing industry dirtiness levels. In the presence of competition, firms in a relatively clean industry can, in fact, benefit from a reduction in the number of available permits. Our findings are robust to changes in certain modeling assumptions.", "e:keyword": ["Environmental compliance", "Pollution permits", "Market‐based mechanisms", "Auctions", "Game theory"]}, {"e:year": 2007, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2007.tb00295.x", "e:abstract": "We present an empirical assessment of the productivity of individuals and institutions in terms of service operations management (SOM) research. We reviewed five mainstream operations management journals over a 17-year time period to generate a sample of 463 articles related to service operations. The results indicate that SOM research has been growing and key contributions are being made by an array of researchers and institutions.", "e:keyword": ["Research productivity", "Research review", "Service operations"]}, {"e:abstract": "We consider two substitutable products and compare two alternative measures of product substitutability for linear demand functions that are commonly used in the literature. While one leads to unrealistically high prices and profits as products become more substitutable, the results obtained using the other measure are in line with intuition. Using the more appropriate measure of product substitutability, we study the optimal investment mix in flexible and dedicated capacities in both monopoly and oligopoly settings. We find that the optimal investment in manufacturing flexibility tends to decrease as the products become closer substitutes; this is because (1) pricing can be used more effectively to balance supply and demand, and (2) the gains obtained by shifting production to the more profitable product are reduced due to increased correlation between the price potentials of the substitutable products. The value of flexibility always increases with demand variability. We also show that, as long as the optimal investments in dedicated capacity for both products are positive, the optimal expected prices and production quantities do not depend on the cost of the flexible capacity. Manufacturing flexibility simply allows the firm to achieve those expected values with lower capacity, while leading to higher expected profits.", "e:volume": "18", "@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01001.x", "e:issue": "1", "e:keyword": ["Demand modeling", "Product substitutability", "Capacity and flexibility planning", "Pricing"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01003.x", "e:abstract": "To date, little research has been done on managing the organizational and political dimensions of generating and improving forecasts in corporate settings. We examine the implementation of a supply chain planning process at a consumer electronics company, concentrating on the forecasting approach around which the process revolves. Our analysis focuses on the forecasting process and how it mediates and accommodates the functional biases that can impair the forecast accuracy. We categorize the sources of functional bias into intentional, driven by misalignment of incentives and the disposition of power within the organization, and unintentional, resulting from informational and procedural blind spots. We show that the forecasting process, together with the supporting mechanisms of information exchange and elicitation of assumptions, is capable of managing the potential political conflict and the informational and procedural shortcomings. We also show that the creation of an independent group responsible for managing the forecasting process, an approach that we distinguish from generating forecasts directly, can stabilize the political dimension sufficiently to enable process improvement to be steered. Finally, we find that while a coordination system—the relevant processes, roles and responsibilities, and structure—can be designed to address existing individual and functional biases in the organization, the new coordination system will in turn generate new individual and functional biases. The introduced framework of functional biases (whether those biases are intentional or not), the analysis of the political dimension of the forecasting process, and the idea of a coordination system are new constructs to better understand the interface between operations management and other functions.", "e:keyword": ["Forecasting", "Marketing/operations interface", "Sales and operations planning", "Organizational issues", "Case/field study"]}, {"e:abstract": "The economic approach to determining the optimal control limits of control charts requires estimating the gradient of the expected cost function. Simulation is a very general methodology for estimating the expected costs, but for estimating the gradient, straightforward finite difference estimators can be inefficient. We demonstrate an alternative approach based on smoothed perturbation analysis (SPA), also known as conditional Monte Carlo. Numerical results and consequent design insights are obtained in determining the optimal control limits for exponentially weighted moving average and Bayes charts. The results indicate that the SPA gradient estimators can be significantly more efficient than finite difference estimators, and that a simulation approach using these estimators provides a viable alternative to other numerical solution techniques for the economic design problem.", "e:volume": "18", "@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01005.x", "e:issue": "1", "e:keyword": ["Quality management", "Statistical process control", "Economic design of control charts", "Monte Carlo simulation", "Gradient estimation"]}, {"e:abstract": "Cooperative (co-op) advertising is an important instrument for aligning manufacturer and retailer decisions in supply chains. In this, the manufacturer announces a co-op advertising policy, i.e., a participation rate that specifies the percentage of the retailer's advertising expenditure that it will provide. In addition, it also announces the wholesale price. In response, the retailer chooses its optimal advertising and pricing policies. We model this supply chain problem as a stochastic Stackelberg differential game whose dynamics follows Sethi's stochastic sales-advertising model. We obtain the condition when offering co-op advertising is optimal for the manufacturer. We provide in feedback form the optimal advertising and pricing policies for the manufacturer and the retailer. We contrast the results with the advertising and price decisions of the vertically integrated channel, and suggest a method for coordinating the channel.", "e:volume": "18", "@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01006.x", "e:issue": "1", "e:keyword": ["Co‐op advertising", "Sales‐advertising dynamics", "Differential games", "Sethi model", "Distribution channel"]}, {"e:abstract": "Life-cycle mismatch occurs when the life cycles of parts end before the life cycles of the products in which those parts are used. Lifetime buys are one tactic for mitigating the effect of part obsolescence, where a quantity of parts is purchased for the remaining life of a product. We extend prior work that determines optimal lifetime buy quantities for one product with one obsolete part by providing an analytic solution and two simple heuristic policies for the optimal lifetime buy quantities when many parts become obsolete over a product's life cycle. We determine which of our two heuristics is most accurate for different product life cycles, which yields a metaheuristic with increased accuracy. That analysis also reveals critical perspectives in making lifetime buy decisions with nonstationary life-cycle demand patterns.", "e:volume": "18", "@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01007.x", "e:issue": "1", "e:keyword": ["Life cycle", "Inventory", "Procurement", "Sourcing"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01008.x", "e:abstract": "We model a situation where a firm wishes to balance workload requirements by creating a portfolio of recurrent insourcing and outsourcing contracts. We use harmonic analysis to decompose an input workload profile into a portfolio of insourcing and outsourcing contracts using rectangular-wave basis functions to better achieve some desired constant workload level. However, this initial selection of contracts may result in impractical options. Therefore, we also develop mathematical programs using principles from goal programming and integer programming to refine the portfolio of contracts to more accurately reflect a realistic environment by placing constraints on the available contracts and explicitly considering operational costs. We consider several modeling extensions including the ability to hold limited amounts of inventory and the use of one-shot contracts to supplement our portfolio of recurrent contracts.", "e:keyword": ["Subcontracting", "Workload balancing", "Recurrent decision‐making", "Walsh basis functions", "Mathematical programming"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01009.x", "e:abstract": "One way to coordinate workers along an assembly line that has fewer workers than work stations is to form a bucket brigade. The throughput of a bucket brigade on discrete work stations may be compromised due to blocking even if workers are sequenced from slowest to fastest. For a given work distribution on the stations we find policies that maximize the throughput of the line. When workers have very different production rates, fully cross-training the workers and sequencing them from slowest to fastest is almost always the best policy. This policy outperforms other policies for most work distributions except for some cases in which limiting the work zones of workers produces higher throughput. In environments where the work can be adjusted across stations, we identify conditions for a line to prevent blocking.", "e:keyword": ["Bucket brigades", "Assembly lines", "Work stations", "Cross‐training", "Work sharing"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01010.x", "e:abstract": "We study a continuous-review acquisition problem, in which the raw material price follows a discrete-state Markov process and demand is compound Poisson. We show that one optimal policy is of the order-up-to type. Under our mean reversion and time continuity conditions, we further show that the order-up-to levels are decreasing at the current price level. At the same time, our computational study verifies that both conditions are indispensable for the monotonicity result. The study also hints at the connection between discrete- and continuous-state price processes.", "e:keyword": ["Price fluctuation", "Inventory management", "Make‐to‐order", "Continuous‐time Markov process"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01012.x", "e:abstract": "We study a supply chain where an original equipment manufacturer (OEM) buys subassemblies, comprised of two complementary sets of components, from a contract manufacturer (CM). The OEM provides a demand forecast at the time when the CM must order the long lead-time set of components, but must decide whether or not to provide updated forecasts as a matter of practice. Forecast updates affect the CM's short lead-time purchase decision, and the anticipation of updates may also affect the long lead-time purchase decision. While the OEM and CM both incur lost sales costs, the OEM can decide whether or not to share the overage costs otherwise fully borne by the CM. We investigate when the OEM is better served by committing to provide updated forecasts and/or committing to share overage costs. For a distribution-free, two-stage forecast-update model, we show that (1) the practice of providing forecast updates may be harmful to the OEM and (2) at the OEM's optimal levels of overage risk sharing, the CM undersupplies relative to the supply chain optimal quantity. For a specific forecast-update model, we computationally investigate conditions under which forecast updating and risk sharing are in the best interest of the OEM.", "e:keyword": ["Supply contracts", "Forecast updating", "Production outsourcing"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01013.x", "e:abstract": "This paper examines the incentives of a manufacturer and a retailer to share their demand forecasts. The demand at the retailer is a linearly decreasing function of price. The manufacturer sets the wholesale price first, and the retailer sets the retail price after observing the wholesale price. Both players set their prices based on their forecasts of demand. In the make-to-order scenario, the manufacturer sets the production quantity after observing the actual demand; in the make-to-stock scenario, the manufacturer sets the production quantity before the demand is realized. In the make-to-order scenario, we show that sharing the forecast unconditionally by the retailer with the manufacturer benefits the manufacturer but hurts the retailer. We also demonstrate that a side payment contract cannot induce Pareto-optimal information sharing equilibrium, but a discount based wholesale price contract can. The social welfare as well as consumer surplus is higher under the discount contract, compared with under no information sharing. In the make-to-stock scenario, the manufacturer realizes additional benefits in the form of savings in inventory holding and shortage costs when forecasts are shared. If the savings from inventory holding and shortage costs because of information sharing are sufficiently high, then a side payment contract that induces Pareto-optimal information sharing is feasible in the make-to-stock scenario. We also provide additional managerial insights with the help of a computational study.", "e:keyword": ["Information sharing", "Supply chain", "Pricing", "Inventory"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01014.x", "e:abstract": "We study a distribution channel where a manufacturer relies on a sales agent for selling the product, and for investing in the most appropriate marketing effort. The agent's effort is hard to monitor. In addition, the cost of effort is the agent's private information. These impose challenges to the manufacturer in its endeavor to influence the agent's marketing effort provisions and to allocate profit between the two parties. We propose two contract forms. The franchise fee contract is a two-part price schedule specifying a variable wholesale price and a fixed franchise fee. The retail price maintenance contract links the allowed retail price that the agent charges customers with total payment to the manufacturer and sales level. Under information asymmetry, for implementing either contract form, the manufacturer needs to offer a menu of contracts, hoping to invoke the “revelation principle” when the agent picks a certain contract from that menu. We show that the two contract forms perform differently, and each party's preference toward a particular contract form is linked with the total reservation profit level and/or the sales agent's cost type. We provide managerial guidelines for the manufacturer in selecting a better contract form under different conditions.", "e:keyword": ["Sales agent", "Retail contracts", "Distribution channel", "Supply chain", "Game theory"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01015.x", "e:abstract": "Designing incentive contracts that constructively guide employee efforts is a particularly difficult challenge in novel innovation initiatives, where unforeseen events may occur. Empirical studies have observed a variety of incentive structures in innovation settings: “time and material contracts” (compensation for executing orders), “downside protection” (target-driven incentives with protection from unexpected risks), and “upside rewards” (additional remuneration for pursuing opportunities). This paper develops a model of incentives in presence of unforeseen events and offers a theoretical prediction of which of the empirically observed incentive structures should be used under which circumstances. The combination of three key influences drives the shape of the best incentive contract. First, the presence of unforeseeable uncertainty, or the occurrence of events that cannot possibly be foreseen at the outset. These may force a change in the project's plan, making pure target setting insufficient. Second, fairness concerns dictate that the employee's expected compensation cannot be shifted downward by unforeseen events, because it would cause demotivation, hostility, and defection. Third, management may not be able to observe the detailed actions of the employee (moral hazard) nor whether a positive or negative unforeseen event has occurred (asymmetric information).", "e:keyword": ["Incentives", "Incomplete contracts", "Unforeseeable uncertainty", "Adjustment clause"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01016.x", "e:abstract": "This paper examines supply chain design strategies for a specific type of perishable product—fresh produce—using melons and sweet corn as examples. Melons and other types of produce reach their peak value at the time of harvest; product value deteriorates exponentially post-harvest until the product is cooled to dampen the deterioration. Using the product's marginal value of time (MVT), the rate at which the product loses value over time in the supply chain, we show that the appropriate model to minimize lost value in the supply chain is a hybrid of a responsive model from post-harvest to cooling, followed by an efficient model in the remainder of the chain. We also show that these two segments of the supply chain are only loosely linked, implying that little coordination is required across the chain to achieve value maximization. The models we develop also provide insights into the use of a product's MVT to develop supply chain strategies for other perishable products.", "e:keyword": ["Supply chain management", "Perishable products", "Fresh produce", "Marginal value of time", "Harvest strategy"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01017.x", "e:abstract": "Our research addresses a firm that sells a product to consumers who are sensitive to both price and return policy. The operational decisions of interest are the selling price, return policy, and quantity of new product to purchase. We model a single selling season that is split into two periods where the boundary between periods is delineated by the opportunity to recover product returns and resell them. That is, returns in the first period can be recovered and sold in the second period. Returns also arise in the second period, but these may only be salvaged. We first analyze both deterministic and stochastic models, finding that the deterministic results largely carry over to the stochastic case. In addition, our results indicate that the model is quite insensitive to errors in the estimates of the parameter values, except for purchase cost and parameters related to demand. Finally, we perform an analysis on the value of various investments to improve financial performance. Results indicate that investments to reduce the recovery cost of returns or reduce returns uncertainty are minimal, while investments to increase recovery speed, reduce market uncertainty, and reduce the return rate can be quite valuable.", "e:keyword": ["Product returns", "Inventory management", "Pricing"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01018.x", "e:abstract": "Extended Producer Responsibility (EPR) legislation focuses on the life-cycle environmental performance of products and has significant implications for management theory and practice. In this paper, we examine the influence of EPR policy parameters on product design and coordination incentives in a durable product supply chain. We model a manufacturer supplying a remanufacturable product to a customer over multiple periods. The manufacturer invests in two design attributes of the product that impact costs incurred by the supply chain—performance, which affects the environmental impact of the product during use, and remanufacturability, which affects the environmental impact post-use. Consistent with the goals of EPR policies, the manufacturer and the customer are required to share the environmental costs incurred over the product's life cycle. The customer has a continuing need for the services of the product and optimizes between the costs of product replacement and the costs incurred during use. We demonstrate how charges during use and post-use can be used as levers to encourage environmentally favorable product design. We analyze the impact of supply chain coordination on design choices and profit and discuss contracts that can be used to achieve coordination, both under symmetric and asymmetric information about customer attributes.", "e:keyword": ["Extended Producer Responsibility", "Product design", "Supply chain coordination", "Information asymmetry", "Contracts"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01019.x", "e:abstract": "Assembly lines function best when every worker is present. When a worker is absent, management must scramble to quickly find a replacement. Usually, the replacement will not be as proficient as the absent worker. This can reduce quality and throughput. We present two assembly line work-systems models (one for lines with Andon and one for lines without Andon) that show one mechanism whereby absenteeism could impact quality and throughput. We exercise these models to provide insights into absenteeism's impact on quality and throughput. While the paper is written in the concrete terms of automotive assembly, the concepts and results apply to manual assembly lines in general.", "e:keyword": ["Work team", "Andon", "Automotive", "Queueing"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01021.x", "e:abstract": "Outpatient health care service providers face increasing pressure to improve the quality of their service through effective scheduling of appointments. In this paper, a simulation optimization approach is used to determine optimal rules for a stochastic appointment scheduling problem. This approach allows for the consideration of more variables and factors in modeling this system than in prior studies, providing more flexibility in setting policy under various problem settings and environmental factors. Results show that the dome scheduling rule proposed in prior literature is robust, but practitioners could benefit from considering a flatter, “plateau-dome.” The plateau–dome scheduling pattern is shown to be robust over many different performance measures and scenarios. Furthermore, because this is the first application of simulation optimization to appointment scheduling, other insights are gleaned that were not possible with prior methodologies.", "e:keyword": ["Appointment scheduling", "Outpatient services", "Simulation optimization"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01022.x", "e:abstract": "Supplier sourcing strategies are a crucial factor driving supply chain success. In this paper, we investigate the implications of uncertain supplier reliability on a firm's sourcing decisions in an environment with stochastic demand. In particular, we characterize specific conditions under which a firm should choose a single versus multiple supplier sourcing strategy. In an environment with both uncertain demand and supply, we characterize the total order quantity, the number of suppliers selected for order placement, and the allocation of the total order quantity among these selected suppliers. For deeper managerial insight, we also examine the sensitivity of the optimal sourcing decisions to interactions between uncertainties in product demand and supply reliability. We show that sourcing from a single supplier is an optimal strategy for environments characterized by high levels of demand uncertainty or high salvage values. A numerical analysis based on data obtained from an office products retailer further reinforces our analytical results. In addition, we also find that when minimal order quantities are imposed, there are situations where it is not optimal to place an order with the lowest cost supplier.", "e:keyword": ["Sourcing", "Supplier selection", "Supply chain management"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01025.x", "e:abstract": "We develop variations of the M|G|1 queue to model the process of software maintenance within organizations and use these models to compute the optimal allocation of resources to software maintenance. User requests are assumed to arrive following a Poisson process and a binomial distribution is used to model duplication of requests. We obtain expressions for expected queue lengths with an exponential server using an N-policy for an integer N≥1. We also obtain the optimal batching size and mean service rate by minimizing the total cost consisting of the cost of the server, the cost of waiting, and the fixed cost of maintenance, if applicable.", "e:keyword": ["Software maintenance", "Resource allocation", "Batching", "Queuing"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01027.x", "e:abstract": "The objectives of this research are first to empirically replicate Advanced Manufacturing Technology (AMT) utilization taxonomies identified in foregoing research, second to investigate the relationship between patterns of AMT utilization and manufacturing capabilities attainment, and third to explore differences in context, and performance across AMT groups. Theories of performance frontiers and capability progression provide the basis for our hypotheses. Data were collected from 224 U.S. manufacturing plants in industries considered to have potential utilizations of AMTs. A cluster analysis of the data yields a solution that closely resembles a previous AMT utilization taxonomy, including four groups labeled, respectively, as Traditionalists, Generalists, High Investors, and Designers. Significant manufacturing capability differences across these four groups indicate that plants that utilize a broader scope of AMTs enjoy a greater breadth of manufacturing capabilities. The implied capability attainment pattern is consistent with cumulative capability theory. However, the results suggest that cost capability is not included in the capability mix when broad-based AMT utilization is the enabler of capability gains. A post hoc exploration of the AMT groups indicates significant differences in performance across the groups. Collectively, the results extend prior research by providing added insights into the possible rationale and impact of AMT utilization patterns.", "e:keyword": ["Advanced Manufacturing Technologies", "Taxonomy", "Manufacturing capabilities"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01028.x", "e:abstract": "Information delays exist in an inventory system when it takes time to collect, process, validate, and transmit inventory/demand data. A general framework is developed in this paper to describe information flows in an inventory system with information delays. We characterize the sufficient statistics for making optimal decisions. When the ordering cost is linear, the optimality of a state-dependent base-stock policy is established even when information flows are allowed to cross over time. Additional insights into the problem are obtained via a comparison between our models and the models with stochastic order lead times. We also show that inventory can substitute for information and vice versa.", "e:keyword": ["Destination and origin determined dynamic delays", "Information flow crossing", "Stochastic inventory control", "Base‐stock policies"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01029.x", "e:abstract": "We consider an integrated production–distribution scheduling model in a make-to-order supply chain consisting of one supplier and one customer. The supplier receives a set of orders from the customer at the beginning of a planning horizon. The supplier needs to process all the orders at a single production line, pack the completed orders to form delivery batches, and deliver the batches to the customer. Each order has a weight, and the total weight of the orders packed in a batch must not exceed the capacity of the delivery batch. Each delivery batch incurs a fixed distribution cost. The problem is to find jointly a schedule for order processing and a way of packing completed orders to form delivery batches such that the total distribution cost (or equivalently, the number of delivery batches) is minimized subject to the constraint that a given customer service level is guaranteed. We consider two customer service constraints—meeting the given deadlines of the orders; or requiring the average delivery lead time of the orders to be within a given threshold. Several problems of the model with each of those constraints are considered. We clarify the complexity of each problem and develop fast heuristics for the NP-hard problems and analyze their worst-case performance bounds. Our computational results indicate that all the heuristics are capable of generating near optimal solutions quickly for the respective problems.", "e:keyword": ["Make‐to‐order supply chain", "Integrated production–distribution scheduling", "Order packing", "Heuristics", "Worst‐case analysis"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01030.x", "e:abstract": "The computer software industry is an extreme example of rapid new product introduction. However, many consumers are sophisticated enough to anticipate the availability of upgrades in the future. This creates the possibility that consumers might either postpone purchase or buy early on and never upgrade. In response, many software producers offer special upgrade pricing to old customers in order to mitigate the effects of strategic consumer behavior. We analyze the optimality of upgrade pricing by characterizing the relationship between magnitude of product improvement and the equilibrium pricing structure, particularly in the context of user upgrade costs. This upgrade cost (such as the cost of upgrading complementary hardware or drivers) is incurred by the user when she buys the new version but is not captured by the upgrade price for the software. Our approach is to formulate a game theoretic model where consumers can look ahead and anticipate prices and product qualities while the firm can offer special upgrade pricing. We classify upgrades as minor, moderate or large based on the primitive parameters. We find that at sufficiently large user costs, upgrade pricing is an effective tool for minor and large upgrades but not moderate upgrades. Thus, upgrade pricing is suboptimal for the firm for a middle range of product improvement. User upgrade costs have both direct and indirect effects on the pricing decision. The indirect effect arises because the upgrade cost is a critical factor in determining whether all old consumers would upgrade to a new product or not, and this further alters the product improvement threshold at which special upgrade pricing becomes optimal. Finally, we also analyze the impact of upgrade pricing on the total coverage of the market.", "e:keyword": ["Pricing", "Market segmentation", "Upgrades", "Software industry"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01033.x", "e:abstract": "In this paper we consider a tactical production-planning problem for remanufacturing when returns have different quality levels. Remanufacturing cost increases as the quality level decreases, and any unused returns may be salvaged at a value that increases with their quality level. Decision variables include the amount to remanufacture each period for each return quality level and the amount of inventory to carry over for future periods for both returns (unremanufactured), and finished remanufactured products. Our model is grounded with data collected at Pitney-Bowes from their mailing systems remanufacturing operations. We derive some analytic properties for the optimal solution in the general case, and provide a simple greedy heuristic to computing the optimal solution in the case of deterministic returns and demand. Under mild assumptions, we find that the firm always remanufactures the exact demand in each period. We also study the value of a nominal quality-grading system in planning production. Based on common industry parameters, we analyze, via a numerical study, the increase in profits observed by the firm if it maintains separate inventories for each quality grade. The results show that a grading system increases profit by an average of 4% over a wide range of parameter values commonly found in the remanufacturing industry; this number increases as the returns volume increases. We also numerically explore the case where there are capacity constraints and find the average improvement of a grading system remains around 4%.", "e:keyword": ["Remanufacturing", "Production planning", "Quality grading"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01034.x", "e:abstract": "We consider two capacity choice scenarios for the optimal location of facilities with fixed servers, stochastic demand, and congestion. Motivating applications include virtual call centers, consisting of geographically dispersed centers, walk-in health clinics, motor vehicle inspection stations, automobile emissions testing stations, and internal service systems. The choice of locations for such facilities influences both the travel cost and waiting times of users. In contrast to most previous research, we explicitly embed both customer travel/connection and delay costs in the objective function and solve the location–allocation problem and choose facility capacities simultaneously. The choice of capacity for a facility that is viewed as a queueing system with Poisson arrivals and exponential service times could mean choosing a service rate for the servers (Scenario 1) or choosing the number of servers (Scenario 2). We express the optimal service rate in closed form in Scenario 1 and the (asymptotically) optimal number of servers in closed form in Scenario 2. This allows us to eliminate both the number of servers and the service rates from the optimization problems, leading to tractable mixed-integer nonlinear programs. Our computational results show that both problems can be solved efficiently using a Lagrangian relaxation optimization procedure.", "e:keyword": ["Service facility system design", "Capacity choice", "Customer choice", "Stochastic facility location", "Social optimum"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01036.x", "e:abstract": "The Outsourcing Game is a role-play simulation that has been deployed in industry and academic training courses worldwide. It incorporates the concepts of hidden actions, hidden information, and misaligned incentives, and conveys messages about power, trust, and reputation. The game depicts the adventures of Acme, the brand owner of a product manufactured by an outsourced supply chain. Through a series of negotiations, Acme attempts to influence its partners (two suppliers and two service providers) by distributing its procurement “spend.” These partners, in turn, sway each other via side payments. To simulate the non-linear shifts in power that occur as outsourcing increases, we represent decision-making by a voting scheme with uneven vote allocations. This paper analyzes a database of game results to reveal behavioral factors that can undermine conspicuous win–win process improvements. For instance, preferences can be sensitive to the sequence in which the alternatives are encountered; decision-makers might value not only their own rewards, but also fairness in the allocation of total gains; and effectiveness of negotiation tactics will vary with community norms of acceptable behavior. Along the way we extend the political economics literature about power in block-based voting by proposing a heuristic approach for incorporating voter preferences.", "e:keyword": ["Supply chain management", "Procurement", "Negotiation", "Simulation", "Cognitive biases"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01037.x", "e:abstract": "In this special issue, the contributing authors address several emerging marketing and operations interface problems and develop innovative approaches for solving them. Specifically, by explicitly modeling active consumer behavior under different pricing schemes, the papers in this special issue examine how firms can coordinate their marketing and operations to improve their competitiveness and profit. The papers also provide insights on how to develop and operate new and innovative market mechanisms.", "e:keyword": ["Marketing and operations management", "Game theory", "Supply‐chain management", "Revenue management", "e‐auctions"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01038.x", "e:abstract": "This paper introduces a decision model of consumer inertia. Consumers exhibit inertia when they have an inherent bias to delay purchases. Inertia may induce consumers to wait even when it is optimal to buy immediately. We embed our decision model within a dynamic pricing context. There is a firm that sells a fixed capacity over two time periods to an uncertain number of both rational and inertial consumers. We find that consumer inertia has both positive and negative effects on profits: it decreases demand (in period one) but intensifies competition among consumers for the product (in period two). We show that our model of inertia is consistent with well-established behavioral regularities, such as loss aversion and probability weighting in the sense of prospect theory, and hyperbolic time preferences. We offer practical recommendations for firms to influence the level of consumer inertia. These include offering returns policies (to mitigate potential consumer losses), providing decision aids (to avoid perception errors), and offering flexible payment options (to lower transaction costs).", "e:keyword": ["Inertia", "Behavioral decision‐making", "Dynamic pricing", "Customer behavior"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01039.x", "e:abstract": "Large numbers of new products introduced annually by manufacturers may strain the relationship between retailers and manufacturers regarding assortments carried by retailers. For example, many retailers in the grocery industry will agree to broaden their assortments only if the manufacturer agrees to pay slotting fees for the new products. We investigate the role played by slotting fees in coordinating the assortment decisions in a supply chain. To do so, we study a single-retailer, single-manufacturer supply chain, where the retailer decides what assortment to offer to end customers. Double marginalization results in a discrepancy between the retailer's optimal assortment and the assortment that maximizes total supply chain profits. We consider a payment scheme that is analogous to slotting fees used in the grocery industry: the manufacturer pays the retailer a per-product fee for every product offered by the retailer in excess of a certain target level. We show that, if the wholesale price is below some threshold level, this payment scheme induces the retailer to offer the supply-chain-optimal assortment and makes both parties better off.", "e:keyword": ["Supply chain management", "Assortment planning", "Operations/marketing interface", "Slotting fees"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01040.x", "e:abstract": "We study the newsvendor problem when consumers are heterogeneous either in their valuations of the newsvendor's product, in their valuations of an outside option available to them, or in both valuations. In this context, we observe that the outside option, which represents the value that a given consumer associates with choosing not to purchase the newsvendor's product, may be interpreted as a search cost. Taking into consideration whether consumers' valuations differ on either one dimension of heterogeneity or on both dimensions, we develop a framework for classifying newsvendor models that incorporate demand-management effects. In particular, we show that this framework includes both the newsvendor model with price-dependent demand and the newsvendor model with endogenous demand as special cases. In addition to making a conceptual contribution by developing and drawing insights from this framework, we make technical contributions by providing more general sufficient conditions under which the underlying optimization problems are well behaved.", "e:keyword": ["Newsvendor", "Heterogeneous consumers", "Pricing", "Inventory effects"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01041.x", "e:abstract": "This paper considers the sale of a seasonal product in the face of strategic customers. At the beginning of the selling season, the retailer announces both the price ph at which the product will be sold during the selling season and the post-season clearance price p<ph for unsold items. We analyze two operating regimes: The “no reservation regime” allows a buyer either to purchase the product at price ph when he arrives or to enter a lottery to purchase at price p if the product remains unsold. The “reservation regime” offers each buyer one extra option than the no reservation regime: reserve the product for purchase at the clearance price p. If the buyer reserves the product under the reservation regime and if it remains unsold at the end of the selling season, then he is obligated to purchase it at price p. We consider a situation in which heterogeneous customers with probabilistic valuation arrive in accord with a Poisson process. We characterize the rational purchasing behavior wherein each arriving customer is strategic; each customer takes other customers' purchasing behavior into consideration. By considering the Nash equilibrium of this game, we show that strategic customer behavior can render the customer to be worse off and the retailer to be better off under the reservation regime, despite the fact that this regime offers one extra option (reservation) to a customer. Hence, more purchasing options do not necessarily benefit customers.", "e:keyword": ["Retailing", "Reservation", "Contingent sales", "Callable products", "Revenue management"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01043.x", "e:abstract": "In durable goods markets, such as those for automobiles or computers, the coexistence of selling and leasing is common as is the existence of both corporate and individual consumers. Leases to corporate consumers affect the price of used goods on the second-hand market which in turn affect the buying and leasing behavior of individual consumers. The setting of prices (or volumes) for sale and lease to individual and corporate consumers is a complicated problem for manufacturers. We consider a manufacturer who concurrently sells and leases a finitely durable good to both individual and corporate consumers. The interaction between the manufacturer and consumers is modeled as a dynamic sequential game, where each player seeks to maximize its own payoff over an infinite horizon. We study how the corporate channel substitutability of new goods and used goods and transaction costs in the second-hand market affect the manufacturer's pricing decisions, consumer behavior, and social welfare in the retail market. Making a number of simplifying assumptions, including two-period lifetime for the finitely durable goods, we consider Markov Perfect Equilibrium as the solution concept. We show that the manufacturer can maximize her profit by segmenting consumers according to their willingness to pay. Selling and leasing are the mechanisms used for price discrimination in the retail market. We show that as she leases a larger share of her production to the corporate consumer, (1) the manufacturer does not necessarily have to adjust the optimal selling price of new goods to individual consumers, and the volume of sales of new goods to individual consumers can stay the same; (2) the manufacturer does increase the retail lease price, and the number of individual leases decreases; (3) the net supply of used goods on the market increases, leading to a lower market price for used goods; and (4) more individual consumers are able to participate in the market, and their collective welfare or net utility improves. We also show that as production costs increase the manufacturer increases prices, reducing volumes across all channels. When transaction costs increase, the manufacturer reduces leasing in both corporate and retail channels.", "e:keyword": ["Channels of distribution", "Selling and leasing", "Durable goods", "Game theory", "Market segmentation"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01046.x", "e:abstract": "We introduce a dynamic pricing model for a monopolistic company selling a perishable product to a finite population of strategic consumers (customers who are aware that pricing is dynamic and may time their purchases strategically). This problem is modeled as a stochastic dynamic game in which the company's objective is to maximize total expected revenues, and each customer maximizes the expected present value of utility. We prove the existence of a unique subgame-perfect equilibrium pricing policy, provide equilibrium optimality conditions for both customer and seller, and prove monotonicity results for special cases. We demonstrate through numerical examples that a company that ignores strategic consumer behavior may receive much lower total revenues than one that uses the strategic equilibrium pricing policy. We also show that, when the initial capacity is a decision variable, it can be used together with the appropriate pricing policy to effectively reduce the impact of strategic consumer behavior. The proposed model is computationally tractable for problems of realistic size.", "e:keyword": ["Customer behavior", "Dynamic pricing", "Strategic consumers", "Stochastic games"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01047.x", "e:abstract": "This paper develops a novel framework to evaluate the integral performance of order picking systems with different combinations of storage and order picking policies. The warehousing literature on order picking mostly considers minimizing either elapsed time or distance as the sole objective, whereas warehouse managers in a supply chain have to look beyond single-dimensional performance and consider trade-offs among different criteria. Thus managers still need a unified and efficient framework to select a portfolio of appropriate order picking policies from a multi-criteria and contextual perspective. Our framework—combining data envelopment analysis, ranking and selection, and multiple comparisons—provides an efficient methodology to simultaneously analyze several interrelated problems in order picking systems with multiple performance attributes, such as service levels and operational costs. We demonstrate our approach through comprehensive evaluations of order picking policies in three low-level, picker-to-parts rectangular warehouses facing demand variations.", "e:keyword": ["Warehouse management", "Order picking", "Process design", "Performance evaluation", "Data envelopment analysis"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01050.x", "e:abstract": "Managers are increasingly faced with pressure to think not just about profits, but also about their organization's environmental and social performance. This research provides a first examination of operational managers' experiences with and attitudes about employee well-being and environmental issues, how these factors impact employee well-being and environmental performance, and how the three performance measures interrelate. We use violations of Occupational Safety and Health Administration regulations and Toxic Release Inventory reports of emissions as proxies for employee well-being and environmental performance. Our findings suggest that operational managers do not (yet) think in sustainability terms. However, employee well-being and environmental performance do interact in a significant way with operational performance. Hence, operational managers would benefit from a more complete understanding of the relationships among the elements of the triple bottom line.", "e:keyword": ["Sustainable operations management", "Employee well‐being", "The natural environment", "Secondary measures of performance", "Qualitative data"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01051.x", "e:abstract": "It is common for suppliers operating in batch-production mode to deal with patient and impatient customers. This paper considers inventory models in which a supplier provides alternative lead times to its customers: a short or a long lead time. Orders from patient customers can be taken by the supplier and included in the next production cycle, while orders from impatient customers have to be satisfied from the on-hand inventory. We denote the action to commit one unit of on-hand inventory to patient or impatient customers as the inventory-commitment decision, and the initial inventory stocking as the inventory-replenishment decision. We first characterize the optimal inventory-commitment policy as a threshold type, and then prove that the optimal inventory-replenishment policy is a base-stock type. Then, we extend our analysis to models to consider cases of a multi-cycle setting, a supply-capacity constraint, and the on-line charged inventory-holding cost. We also evaluate and compare the performances of the optimal inventory-commitment policy and the inventory-rationing policy. Finally, to further investigate the benefits and pitfalls of introducing an alternative lead-time choice, we use the customer-choice model to study the demand gains and losses, known as demand-induction and demand-cannibalization effects, respectively.", "e:keyword": ["Capacitated inventory models", "Lead‐time flexibility", "Demand induction", "Demand cannibalization."]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01067.x", "e:abstract": "The condition of the used products acquired by remanufacturing firms often varies widely. A firm can manage this variation by acquiring a quantity of used items that exceeds demand, enabling it to remanufacture a subset of the acquired items in the best condition. As more excess items are acquired, the firm can increase its selectivity and lower its remanufacturing costs. In this paper, we examine the tradeoff of acquisition and scrapping costs vs. remanufacturing costs when used product condition is widely varying and uncertain. We derive acquisition quantities that minimize total expected costs for several representations of condition variability and remanufacturing cost structures. We find that, when costs are linear, the optimal acquisition quantity has a closed form and increases with the square root of the degree of condition variability. Our models are based on experience with remanufacturers of cell phones and imaging supplies, and application of our results is illustrated using example data from industry.", "e:keyword": ["Remanufacturing", "Used product acquisition", "Lot sizing", "Order statistics"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01068.x", "e:abstract": "We consider the scheduling of truck arrivals at an air cargo terminal. By coordinating arrivals of cargo delivery trucks with outbound flight departure schedules, some of the shipments can be transferred directly to the departing flights, while others will be stored at the terminal's storage facility and incur extra handling and storage costs. The objective is to obtain a feasible schedule so as to minimize the total cost of operations. We formulate the problem as a time-indexed integer program and show that, even with limited number of unloading docks at the terminal, the problem is non-trivial (NP-hard in the strong sense). Our solution method includes an exact solution procedure to determine an optimal unloading sequence for the shipments carried by each truck, together with a Lagrangian relaxation-based heuristic for assigning trucks to truck docks and determining truck arrival times. We conducted computational experiments to test the performance of our solution method. Computational results show that our method can generate near-optimal solutions efficiently. Our simulation results indicate that the scheduling approach proposed in this paper has the potential to generate significant cost savings over a first-come, first-served approach currently used at the air cargo terminal that we observed.", "e:keyword": ["Air cargo", "Logistics", "Scheduling", "Lagrangian relaxation"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01069.x", "e:abstract": "This paper investigates the impacts of competition and market uncertainty on airlines' network structures and capacity investment. The airlines choose their network structures and construct capacities while demands are unknown. After uncertainty is resolved, they determine the total number of seats to offer in each leg constrained by their capacities built earlier. We conclude that market uncertainty is the driving force of hub-and-spoke networks, whereas the market mean is the driving force of point-to-point networks. Which of the two countervailing forces dominates determines the equilibrium network structures. Moreover, we find that the airlines' total expected profits in the mixed equilibrium in which the airlines employ different networks are larger than in the pure hub-and-spoke network equilibrium in which each airline employs the hub-and-spoke network. However, the mixed equilibrium does not necessarily yield larger profits than the pure point-to-point equilibrium in which each airline employs the point-to-point network.", "e:keyword": ["Hub‐and‐spoke", "Point‐to‐point", "Cost advantage", "Flexibility", "Uncertainty"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01070.x", "e:abstract": "", "e:keyword": []}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01076.x", "e:abstract": "We examine the use of consumer cash mail-in rebates offered by a manufacturer in a Stackelberg game where the manufacturer is the leader and the retailer is the follower. Our analysis indicates that rebates are profitable for manufacturers if consumers are inconsistent in the sense that their rebate valuation when they make purchase decisions is independent of their redemption probabilities when they make redemption decisions. If the manufacturer keeps the wholesale price unchanged, then the rebate increases the retailer's profit by a larger amount than the increase in the manufacturer's profit. If the manufacturer jointly optimizes the wholesale price and rebate, then the increase in the manufacturer's profit is twice the increase in the retailer's profit. The retailer responds to rebates by increasing the retail price, which increases the margin paid by consumers who do not redeem the rebate. On average, consumer surplus decreases when it is optimal for manufacturers to offer rebates. We suggest incentive schemes that make it worthwhile for retailers to limit the price increase. In these incentive schemes, the manufacturer imposes a negative relationship between the rebate value and the retail price. We show that such incentives increase supply chain profits.", "e:keyword": ["Marketing/operations interface", "Rebates and promotions", "Supply chain incentives"]}, {"e:year": 2009, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01145.x", "e:abstract": "", "e:keyword": []}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01091.x", "e:abstract": "The replacement of an existing product with a new one presents many challenges. In particular, uncertainties in a new product introduction often lead to extreme cases of demand and supply mismatches. This paper addresses inventory planning decisions for product upgrades when there is no replenishment opportunity during the transition period. We allow product substitution: when a company runs out of the old product, a customer may be offered the new product as a substitute. We show that the optimal substitution decision is a time-varying threshold policy and establish the optimal planning policy. Further, we determine the optimal delay in a new product introduction, given the initial inventory of the old product.", "e:keyword": ["Inventory planning", "Substitution", "Product transition", "New product introduction"]}, {"e:year": 2010, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01094.x", "e:abstract": "This paper considers a general industrial setting where multiple manufacturers each produce a different product and sell it to the markets. These products are partially complementary in the sense that there is a common demand stream that requests all these products as complementary sets and there are streams of individual demands each requesting only one of the products. All demands are uncertain and may follow any general, joint distributions. Facing demand uncertainties, the manufacturers each choose a production quantity for its product with an objective to maximize its own expected profit. We formulate the problem as a non-cooperative game to study the strategic interactions of such firms and their implications to supply chain performance. We show that such a game may have numerous equilibria. Among all the possible equilibria, however, we prove that there always exists a unique one that maximizes each and every manufacturer's profit, and we derive an explicit solution for this Pareto-optimal equilibrium point. We further study the optimal solution for a centralized system and compare it with the decentralized solution. Managerial insights are drawn as to how system parameters and control mechanisms affect firms' decisions and performance.", "e:keyword": ["Supply chain management", "Complementary products", "Production decisions", "Uncooperative game theory", "Multivariate stochastic demands"]}, {"e:year": 2010, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01095.x", "e:abstract": "Resource flexibility is an important tool for firms to better match capacity with demand so as to increase revenues and improve service levels. However, in service contexts that require dynamically deciding whether to accept incoming jobs and what resource to assign to each accepted job, harnessing the benefits of flexibility requires using effective methods for making these operational decisions. Motivated by the resource deployment decisions facing a professional service firm in the workplace training industry, we address the dynamic job acceptance and resource assignment problem for systems with general resource flexibility structure, i.e., with multiple resource types that can each perform different overlapping subsets of job types. We first show that, for systems containing specialized resources for individual job types and a versatile resource type that can perform all job types, the exact policy uses a threshold rule. With more general flexibility structures, since the associated stochastic dynamic program is intractable, we develop and test three optimization-based approximate policies. Our extensive computational tests show that one of the methods, which we call the Bottleneck Capacity Reservation policy, is remarkably effective in generating near-optimal solutions over a wide range of problem scenarios. We also consider a model variant that requires dynamic job acceptance decisions but permits deferring resource assignment decisions until the end of the horizon. For this model, we discuss an adaptation of our approximate policy, establish the effectiveness of this policy, and assess the value of postponing assignment decisions.", "e:keyword": [": flexible service resources", "Overlapping flexibility structure", "Dynamic resource allocation", "Heuristics", "Revenue management"]}, {"e:year": 2010, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01098.x", "e:abstract": "ABC inventory classifications are widely used in practice, with demand value and demand volume as the most common ranking criteria. The standard approach in ABC applications is to set the same service level for all stock keeping units (SKUs) in a class. In this paper, we show (for three large real life datasets) that the application of both demand value and demand volume as ABC ranking criteria, with fixed service levels per class, leads to solutions that are far from cost optimal. An alternative criterion proposed by Zhang et al. performs much better, but is still considerably outperformed by a new criterion proposed in this paper. The new criterion is also more general in that it can take criticality of SKUs into account. Managerial insights are obtained into what class should have the highest/lowest service level, a topic that has been disputed in the literature.", "e:keyword": ["Inventory management", "ABC inventory classification"]}, {"e:year": 2009, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01145.x", "e:abstract": "", "e:keyword": []}, {"@id": "http://dx.doi.org/10.3401/poms.1080.01137", "e:abstract": "", "e:keyword": []}, {"e:year": 2010, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01108.x", "e:abstract": "Whenever intrepid researchers venture into new terrain, they find that they require knowledge outside of their formal training. This paper reviews bodies of knowledge for operations management (OM) researchers interested in the new area of Behavioral Operations. We highlight theoretical constructs and empirical phenomena from cognitive psychology, social psychology, group dynamics, and system dynamics. We also provide a guide for where to go to learn more about each body of knowledge. Our overall goal is to lower the startup costs for new researchers in Behavioral Operations.", "e:keyword": ["Heuristics", "Biases", "Motivation", "Groupthink", "Feedback"]}, {"e:year": 2010, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01109.x", "e:abstract": "Determining appropriate inventory levels has been a subject of interest for both researchers and practitioners. Standard practice is to treat lead time demand as a random sum of random numbers and rely on established probability theory to calculate both reorder point and safety stock levels. A key assumption in these calculations, however, is that lead time and demand are not correlated. In this paper, we first explore situations where this assumption is untrue and then develop equations to determine the reorder point and the safety stock when lead time and demand are correlated. More specifically, we (1) derive formulas for the average and variance of the demand in a lead time, which can then be used to calculate the reorder point and the safety stock, (2) apply these formulas to two distributions for which there is a closed-form solution: normal and Poisson, and (3) examine the effect of correlation on safety stock requirements under the normal distribution.", "e:keyword": ["Inventory", "Safety stock", "Lead time", "Demand", "Correlation"]}, {"e:year": 2010, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01110.x", "e:abstract": "An exploratory analysis of verbal protocols from a think-aloud newsvendor experiment provided deeper insights into the decision-making process, enabling us to formulate a number of questions that are worth answering in future research. In a think-aloud experiment, subjects verbalize their cognitions while performing a task; responses are then recorded, transcribed, and analyzed. A majority of the subjects struggled with the abstractness of the business setting and were keen to know information on the product type, industry setting, decisions taken in the past, competitor's situation, etc. A large portion of the participants correctly identified the overage and underage costs, but failed to convert that information into the optimal order quantity. Finally, the bias in the order quantity was significantly influenced by the specific type of risk (overage or underage) that was identified closer to the decision, alluding to the presence of a recency effect. As a first application of verbal protocol analysis to inventory decision making, this study gives us an opportunity to highlight the strengths and weaknesses of this research methodology.", "e:keyword": ["Newsvendor", "Verbal protocol analysis", "Behavioral operations", "Inventory control", "Decision making"]}, {"e:year": 2010, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01114.x", "e:abstract": "This paper considers two parallel supply chains with interacting demand streams. Each supply chain consists of one supplier and one retailer. The two demand streams are jointly described with a vector autoregressive time-series process in which they interact and their respective innovation errors correlate contemporaneously. For each supply chain, we develop insights into when and how much the supplier and the retailer can improve on their forecasting accuracy if the external demand history of the other supply chain is utilized. When this external demand history is not available or made available after a time lag, we develop a partial process and a delayed process to characterize the demand structure that the retailer can recover from the available demand histories. Our results show that the external demand history of the other supply chain always helps the retailer make better forecasts when demand streams interact; however, the enhanced information alters the retailer's order process, which may produce larger forecasting errors for the supplier. Conditions are established for the supplier to benefit from the external demand history of the other supply chain.", "e:keyword": ["Forecasting", "Interacting supply chains", "Inventory control", "Time‐series", "Joint demand processes"]}, {"e:year": 2010, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01116.x", "e:abstract": "This paper examines the choice of supply chain structure for a proprietary component manufacturer (PCM). The PCM, who is the sole supply source of a critical component used to assemble an end product, can either provide its component to an original equipment manufacturer (OEM) in the end-product market (component supplier structure), develop the end product exclusively under its own brand (monopoly structure), or provide the component to the OEM as well as develop the end product under its own brand (dual distributor structure). Typically, the end products of the PCM and the OEM will be differentiated, and the OEM tends to have a capability advantage (compared with the PCM) in producing the end product. Our paper studies the impact of this degree of differentiation and capability advantage on the optimal choice of distribution structure. We then investigate how investing in component branding, enhancing the value of the end product, using alternative supply contracts, and product valuation uncertainty influence the PCM's optimal choice of distribution structure.", "e:keyword": ["Supply chain design", "Proprietary component manufacturer", "Marketing‐operations interface", "Dual distribution", "Component supplier"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01117.x", "e:abstract": "This study investigates the role of organizational structure in facilitating the development of mass customization (MC) capability in various manufacturing settings. Specifically, three dimensions of organizational structure are considered—flatness, centralization, and employee multifunctionality. We model organizational structure as a second-order factor whose value is captured on a mechanistic-organic continuum, where the organic form is characterized by a flat, decentralized structure with a wide use of multifunctional employees. We propose that a positive relationship exists between the organic organizational structure and MC capability. Additionally, building upon contingency theory, we argue that this positive relationship is moderated by mass customizer type—full mass customizers, which customize products at the design or fabrication stage of the production cycle, versus partial customizers, which customize products only at the assembly or delivery stages. Based on a study of 167 manufacturing plants from three industries and eight countries, we find that, for the overall sample, organic structure plays a significant role in enabling firms to pursue MC capability. However, an analysis of full versus partial mass customizers shows that the positive impact of organic structure on MC capability is statistically significant only for full mass customizers, not for partial mass customizers.", "e:keyword": ["Mass customization", "Organizational structure", "Contingency theory"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01118.x", "e:abstract": "In this paper, we propose a new dynamic programming decomposition method for the network revenue management problem with customer choice behavior. The fundamental idea behind our dynamic programming decomposition method is to allocate the revenue associated with an itinerary among the different flight legs and to solve a single-leg revenue management problem for each flight leg in the airline network. The novel aspect of our approach is that it chooses the revenue allocations by solving an auxiliary optimization problem that takes the probabilistic nature of the customer choices into consideration. We compare our approach with two standard benchmark methods. The first benchmark method uses a deterministic linear programming formulation. The second benchmark method is a dynamic programming decomposition idea that is similar to our approach, but it chooses the revenue allocations in an ad hoc manner. We establish that our approach provides an upper bound on the optimal total expected revenue, and this upper bound is tighter than the ones obtained by the two benchmark methods. Computational experiments indicate that our approach provides significant improvements over the performances of the benchmark methods.", "e:keyword": ["Network revenue management", "Customer choice", "Approximate dynamic programming", "Pricing", "Airline"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2009.01119.x", "e:abstract": "A key strategic issue in pre-disaster planning for humanitarian logistics is the pre-establishment of adequate capacity and resources that enable efficient relief operations. This paper develops a two-stage stochastic optimization model to guide the allocation of budget to acquire and position relief assets, decisions that typically need to be made well in advance before a disaster strikes. The optimization focuses on minimizing the expected number of casualties, so our model includes first-stage decisions to represent the expansion of resources such as warehouses, medical facilities with personnel, ramp spaces, and shelters. Second-stage decisions concern the logistics of the problem, where allocated resources and contracted transportation assets are deployed to rescue critical population (in need of emergency evacuation), deliver required commodities to stay-back population, and transport the transfer population displaced by the disaster. Because of the uncertainty of the event's location and severity, these and other parameters are represented as scenarios. Computational results on notional test cases provide guidance on budget allocation and prove the potential benefit of using stochastic optimization.", "e:keyword": ["Humanitarian logistics", "Relief operations", "Stochastic optimization"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01120.x", "e:abstract": "We examine the effects of product variety and inventory levels on store sales. Using 4 years of data from stores of a large retailer, we show that increases in product variety and inventory levels are both associated with higher sales. We also show that increasing product variety and inventory levels has an indirect negative effect on store sales through their impact on phantom products—products that are physically present at the store, but only in storage areas where customers cannot find or purchase them. Our study highlights a consequence of increased product variety and inventory levels that has previously been overlooked in studies of retail product variety and inventory management. It also quantifies the impact of phantom products on store sales. In addition, our study provides empirical evidence to support earlier claims that higher product variety and inventory levels lead to an increase in defect rate. We discuss the implications of our findings for retail inventory and assortment planning and for the design of retail stores.", "e:keyword": ["Retail inventory management", "Assortment management", "Product variety", "Misplaced products", "Quality management"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.01137", "e:abstract": "", "e:keyword": []}, {"e:year": 2010, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01145.x", "e:abstract": "", "e:keyword": []}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01132.x", "e:abstract": "Mass customization has been viewed as desirable but difficult to achieve in the volume automotive sector. Here we consider flexibility in automotive order fulfillment systems to enhance the ability to satisfy customers with their desired vehicle variants within acceptable delivery lead times. Two types of flexibility are compared in a Virtual-Build-to-Order system—reconfiguration in the planning pipeline and interdealer trading. A representative simulation model is used to investigate the impact of the two types of flexibility across a wide spectrum of product variety levels. The impacts on major stakeholders in the system—the producer, dealers, and customers—are considered. The study shows that both types of flexibilities can bring significant benefits in terms of reductions in lead time and inventory holding. The level of product variety strongly influences the observed effects—an important finding in the mass customization context. Upstream reconfiguration flexibility brings greater benefits than downstream trading flexibility. Reconfiguration tends to dominate trading as a fulfillment mechanism when both are in operation. The findings have implications for the design and management of automotive order fulfillment systems in improving their ability to offer mass customization. The study has relevance for companies in other sectors with high levels of variety that seek to combine efficiency, speed, and flexibility in order fulfillment.", "e:keyword": ["Mass customization", "Flexibility", "Trading", "Automotive industry", "Virtual‐build‐to‐order"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.01137", "e:abstract": "", "e:keyword": []}, {"e:year": 2010, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01145.x", "e:abstract": "", "e:keyword": []}, {"e:year": 2010, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01146.x", "e:abstract": "", "e:keyword": []}, {"e:year": 2010, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01145.x", "e:abstract": "", "e:keyword": []}, {"e:year": 2010, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01146.x", "e:abstract": "", "e:keyword": []}, {"e:year": 2010, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01147.x", "e:abstract": "", "e:keyword": []}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01149.x", "e:abstract": "As service failures are inevitable, firms must be prepared to recover and learn from service failures. Yet, the majority of customers are still dissatisfied with the way firms resolve their complaints. Can learning to reduce service failures reduce customer dissatisfaction, and to what extent are such reductions sustainable? Previous research showed that organizational learning curves for customer dissatisfaction (i) follow a U-shaped function of operating experience and (ii) are heterogeneous across firms. In this paper, I tease out where the U-shaped learning-curve effect and learning-curve heterogeneity originate: service failure or customers' propensity to complain with a third party given the occurrence of a service failure. Using quarterly data for nine major US airlines over 11 years, I find that the U-shaped learning-curve effect and the learning-curve heterogeneity originate in the propensity to complain. In the long term, reductions in service failure did not translate in sustainable reductions in customer dissatisfaction. Customers' propensity to complain eventually went up. Managing the propensity to complain provides more opportunity for a firm to distinguish itself from competitors.", "e:keyword": ["Customer dissatisfaction", "Learning curve", "Organizational learning", "Marketing", "Service failure"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01152.x", "e:abstract": "This paper builds a dynamic programming model to optimize the collections process in consumer credit. It determines which collections actions should be undertaken and how long they should be performed, including theoretical results about the form of the optimal policy under certain conditions. Finally, a case study is described based on data from the collections department of a European bank.", "e:keyword": ["Collection process", "Optimization", "Operations management", "Dynamic programming", "Consumer credit"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01153.x", "e:abstract": "The overuse of its currency processing operations by depository institutions (DIs) has motivated the Federal Reserve (Fed) to propose new currency recirculation guidelines. The Fed believes that DIs should play a more active role in recirculating fit (i.e., usable) currency so that the societal cost of providing currency to the public is minimized. The Fed characterizes the overuse by the extent of cross shipping, a practice in which the same DI deposits and withdraws currency of the same denomination within five business days in the same geographic region. The Fed's proposal encourages DIs to fit sort and reuse deposited currency through two components: a custodial inventory program and a recirculation fee that would be charged on withdrawals of cross-shipped currency. Given the geographical network of the various branches of a DI, the extent of its participation in the proposed programs depends on a variety of factors: the nature of demand and supply of currency, number and locations of the processing centers, and the resulting fit-sorting, holding, and transportation costs. The interrelated nature of these decisions motivates the need for an integrated model that captures the flow of currency in the entire network of the DI. Based on our work with Brink's Inc., a leading secure-logistics provider, we develop a mixed-integer linear programming (MILP) model to provide managers of DIs with a decision-making tool under the Fed's new guidelines. Broadly, we analyze the following questions: (i) Over all typical practical realizations of the demand for currency that a DI may face, and over all reasonable cost implications, is there a menu of “good” operating policies? (ii) What is the monetary impact of fit-sorting and custodial inventories on a DI? and (iii) To what extent will the Fed's new guidelines address its main goal, namely, a reduction in the practice of cross shipping by encouraging DIs to recirculate currency?", "e:keyword": ["Cash supply chain", "Cash recirculation", "Cross shipping", "Cash inventory"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01154.x", "e:abstract": "Driven by market pressures, financial service firms are increasingly partnering with independent vendors to create service networks that deliver greater profits while ensuring high service quality. In the management of call center networks, these partnerships are common and form an integral part of the customer care and marketing strategies in the financial services industry. For a financial services firm, configuring such a call center service network entails determining which partners to select and how to distribute service requests among vendors, while incorporating their capabilities, costs, and revenue-generating abilities. Motivated by a problem facing a Fortune 500 financial services provider, we develop and apply a novel mixed integer programming model for the service network configuration problem. Our tactical decision support model effectively accounts for the firm's costs by capturing the impact of service requirements on vendor staffing levels and seat requirements, and permits imposing call routing preferences and auxiliary service costs. We implemented the model and applied it to data from an industry partner. Results suggest that our approach can generate considerable cost savings and substantial additional revenues, while ensuring high service quality. Results based on test instances demonstrate similar savings and outperform two rule-based methods for vendor assignment.", "e:keyword": ["Financial services", "Applied optimization", "Call center management", "Mathematical modeling"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01156.x", "e:abstract": "Consumer delinquencies are a major problem for banks and other credit card issuers. These firms have collection centers across the country to collect outstanding balances from delinquent accounts. Their main strategy is to first send reminder notices and, if that does not work, to telephone delinquent customers and request payment. The latter often becomes necessary, resulting in high costs of collection. Automated dialers are used to make the calls, and when the call goes through, it is directed to one of several hundred associates manning computer workstations. In this operation, it is important to contact the account holder in order to discuss payment options. Simply getting someone on the line is not sufficient, because such calls would require follow-up calls. The objective of efficient collections is to maximize dollars collected while minimizing costs, which generally translates to making a “right party contact (RPC)” in the minimum number of attempts. We developed and tested an algorithm that increased the RPC rates by over 10%. This increase translates to annual savings of several million dollars for an average credit card company. Although the focus of our paper is collections, the methodology developed is equally applicable for improving telemarketing efficiency.", "e:keyword": ["Call centers", "Contact rates", "Optimization", "Heuristics"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01157.x", "e:abstract": "This paper models the cross-selling problem of a call center as a dynamic service rate control problem. The question of when and to whom to cross sell is explored using this model. The analysis shows that, under the optimal policies, cross-selling targets may be a function of the operational system state. Sufficient conditions are established for the existence of preferred calls, i.e., calls that will always generate a cross-sell attempt. These provide guidelines in segment formation for marketing managers, and lead to a static heuristic policy. Numerical analysis establishes the value of different types of information, and different types of automation available for cross selling. Increased staffing for the same call volume is shown to have a positive and increasing return on revenue generation via cross selling, suggesting the need to staff for lower loads in call centers that aim to be revenue generators. The proposed heuristic leads to near optimal performance in a wide range of settings.", "e:keyword": ["Dynamic programming", "Call center", "Customer relationship management", "Cross‐selling heuristic"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01160.x", "e:abstract": "This paper considers a supply chain with one supplier and multiple retailers that face exogenous heterogeneous end-customer demands, where all parties utilize base-stock policies. Each retailer is restricted to order once in every order cycle and their orders are replenished in a balanced manner within the cycle. Our study investigates the impact of information sharing and advance order information (AOI) on the supply chain. We find that the supplier benefits from the two mechanisms via two important factors, the information about observed end-customer demands and the decision on re-establishing the replenishment sequence. We derive the supplier's optimal sequence for stochastically comparable end-customer demands with AOI and propose a sequencing rule for the setting with information sharing. Our numerical study examines the cost impacts of two proposed mechanisms on the entire supply chain.", "e:keyword": ["Balanced ordering", "Information sharing", "Advance order information", "Sequencing", "Supply chain management"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01161.x", "e:abstract": "We consider a two-echelon supply chain with a manufacturer supplying to multiple downstream retailers engaged in differentiated Cournot competition. Each retailer has private information about uncertain demand. The manufacturer is the Stackelberg leader who sets the contract terms with the retailers, and benefits from retailers sharing their private information. When all retailers are given the same wholesale price, truthful information sharing is not an equilibrium outcome. We propose two variants of differential pricing mechanisms that induce truthful information sharing by all retailers. The first variant rewards a retailer for providing optimistic information and achieves truthful information sharing as a unique equilibrium. The differential pricing mechanism is optimal in the class of linear-price, incentive-compatible, direct mechanisms. The second variant, which incorporates provision for a fixed payment in addition to wholesale prices, preserves all the equilibrium properties of the first variant and additionally “nearly coordinates” the supply chain. Our analysis of differential pricing with a fixed payment provides interesting observations regarding the relationship between product substitutability, number of retailers, information precision, and market power. As products become closer substitutes and/or number of retailers increase, the manufacturer's market power increases, enabling her to extract a larger fraction of the supply chain surplus.", "e:keyword": ["Cournot competition", "Supply chain management", "Information sharing"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01162.x", "e:abstract": "We examine the drivers of project performance and customer satisfaction in outsourced software projects using a proprietary panel dataset. The data cover 822 customer observations related to 182 unique projects executed by an India-based software services vendor. Adopting a multidisciplinary perspective, we investigate how project planning, team stability, and communication effectiveness impact project performance and customer satisfaction. We delineate the direct and interactive influences of the antecedent variables. We also examine how these influences are moderated by two important project contexts: (a) the nature of software work (maintenance and development vs. testing projects) and (b) project maturity (new vs. mature projects). Among other results, we demonstrate that, when project planning capabilities are high, the positive impact of team stability and communication effectiveness on project performance is even higher. In addition, our results suggest that the impact of communication on project performance is muted when team stability is high. Finally, we also demonstrate that the impact of the antecedent variables on project performance varies with the nature of software work. Our findings offer specific and actionable insights to managers that can help them manage outsourced projects better, and open up new research perspectives in the context of outsourced project management.", "e:keyword": ["Outsourcing", "Software projects", "Project planning", "Customer satisfaction", "Operations management"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01164.x", "e:abstract": "In this paper, we analyze the impact of two forms of commonly used threshold-based incentive schemes on the observed sales variability. The first form of the incentive comprises an additional marginal payment on crossing a specified sales threshold and the second form of the incentive scheme comprises a lumpsum bonus payment on crossing the predetermined sales threshold. We model the effect of such incentives under two specific scenarios: an exclusive dealership selling a single product and a non-exclusive dealer selling two competing products. For an exclusive dealer, we show that a bonus contract not only increases the expected sales, but, more importantly, decreases the sales (order) variance. Consequently, the bonus-based scheme allows the manufacturer to regulate sales variance better. With a non-exclusive dealer, the sales variance increases substantially with an additional marginal payment contract. However, our analysis suggests that the bonus contract continues to perform better in this case, too, if the threshold level is set appropriately using the underlying demand distribution.", "e:keyword": ["Threshold incentives", "Service and supply chain operations", "Sales variance"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01165.x", "e:abstract": "Managing development decisions for new products based on dynamically evolving technologies is a complex task, especially in highly competitive industries. Product managers often have to choose between introducing an incrementally better, safe new product early and a superior, yet highly risky, product later. Recommendations for managing such performance vs. time-to-market trade-offs often ignore competitive reactions to development decisions. In this paper, we study how a firm could incorporate the presence of a strategic competitor in making technology selection and investment decisions regarding new products. We consider a model in which an innovating firm and its rival can introduce a new product immediately or pursue a more advanced product for later launch. Further, the firm can reduce the uncertainty surrounding product development by dedicating more resources; the effectiveness of this investment depends on the firm's innovative capacity. Our model generates two sets of insights. First, in highly competitive industries, firms can adopt different technologies and effectively use introduction timing to mitigate the effects of price competition. More importantly, the firm could strategically invest in the advanced product to influence its rival's technology choice. We characterize equilibrium development and investment decisions of the firms, and derive innovative capacity hurdles that govern a firm's choice between the risky and safe alternatives. The effects of development flexibility—where firms might have the option to revert to the safe product if the advanced product fails—are also considered.", "e:keyword": ["Development uncertainty", "Innovative capacity", "Competition", "Introduction timing"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01166.x", "e:abstract": "We consider the distribution planning problem in the motion picture industry. This problem involves forecasting theater-level box office revenues for a given movie and using these forecasts to choose the best locations to screen a movie. We first develop a method that predicts theater-level box office revenues over time for a given movie as a function of movie attributes and theater characteristics. These estimates are then used by the distributor to choose where to screen the movie. The distributor's location selection problem is modeled as an integer programming-based optimization model that chooses the location of theaters in order to optimize profits. We tested our methods on realistic box office data and show that it has the potential to significantly improve the distributor's profits. We also develop some insights into why our methods outperform existing practice, which are crucial to their successful practical implementation.", "e:keyword": ["Motion picture industry", "Forecasting", "Distribution planning", "Theater selection", "Optimization"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01167.x", "e:abstract": "Trade regulations are an important driver of supply chain strategy in many industries. For example, the textile, paper, chemical, and steel industries grapple with significant levels of non-tariff barriers (NTBs) such as safeguard controls and countervailing duties. We explore three often observed supply chain strategies in industries subject to NTBs; direct procurement, split procurement, and outward processing arrangements (OPAs). We characterize the optimal procurement quantities for each of these three strategies, and examine how industry and country characteristics influence the firm's strategy preference. For example, we establish that the direct and split strategy profits increase in the NTB price variance but decrease in the mean price. These effects are sufficiently large that NTB price characteristics can dictate which supply chain strategy is preferred. Both the cost disadvantage and lead-time advantage of domestic production are also significant influencers of the preferred strategy, as is the domestic-country mandated production constraint associated with the OPA strategy.", "e:keyword": ["Regulatory trade risk", "Non‐tariff barrier", "Dual sourcing", "Supply chain"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01204.x", "e:abstract": "", "e:keyword": []}, {"e:year": 2010, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01146.x", "e:abstract": "", "e:keyword": []}, {"e:year": 2010, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01147.x", "e:abstract": "", "e:keyword": []}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01172.x", "e:abstract": "This paper examines the roles of three elements of intellectual capital in implementing process innovations. Building upon prior literature, we develop a model describing how worker expertise, information sharing quality, and psychological safety work together as elements of the human, structural, and social dimensions of intellectual capital to influence the technical success of manufacturing process innovation (MPI) projects. Results of an analysis of data describing 179 MPI projects in US firms strongly support a multidimensional, process-oriented view of intellectual capital's effects on MPI project technical performance. We also find that the incrementalness of an MPI project plays a moderating role over the relationship between worker expertise and MPI performance. Our study provides insights on how intellectual capital can be more effectively accumulated in a project environment.", "e:keyword": ["Manufacturing process innovation", "Project management", "Intellectual capital", "Worker expertise", "Psychological safety"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01173.x", "e:abstract": "Under group buying, quantity discounts are offered based on the buyers' aggregated purchasing quantity, instead of individual quantities. As the price decreases with the total quantity, buyers receive lower prices than they otherwise would be able to obtain individually. Previous studies on group buying focus on the benefit buyers receive in reduced acquisition costs or enhanced bargaining power. In this paper, we show that buyers can instead get hurt from such cooperation. Specifically, we consider a two-level distribution channel with a single manufacturer and two retailers who compete for end customers. We show that, under linear demand curves, group buying is always preferable for symmetric (i.e., identical) retailers. For asymmetric retailers (i.e., differing in market base and/or efficiency), group buying is beneficial to the smaller (or less efficient) player. However, it can be detrimental to the larger (or more efficient) one. Despite the lower wholesale price under group buying, the manufacturer can receive a higher revenue. Interestingly, group buying is more likely to form when retailers are competitive in different dimensions. These insights are shown to be robust under general nonlinear demand curves, except for constant elastic demand with low demand elasticity.", "e:keyword": ["Group buying", "Competition", "Distribution channel", "Quantity discounts", "Retailing"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01174.x", "e:abstract": "Consider a buyer, facing uncertain demand, who sources from multiple suppliers via online procurement auctions (open descending price-only auctions). The suppliers have heterogeneous production costs, which are private information, and the winning supplier has to invest in production capacity before the demand uncertainty is resolved. The buyer chooses to offer a push or pull contract, for which the single price and winning supplier are determined via the auction. We show that, with a pull contract, the buyer does not necessarily benefit from a larger number of suppliers participating in the auction, due to the negative effect of supplier competition on the incentive of supplier capacity investment. We thus propose an enhanced pull mechanism that mitigates this effect with a floor price. We then analyze and compare the outcomes of auctions for push and (enhanced) pull contracts, establishing when one form is preferred over the other based on the buyer's profits. We also compare our simple, price-only push and pull contract auctions to the optimal mechanisms, benchmarking the performance of the simple mechanisms as well as establishing the relative importance of auction design and contract design in procurement auctions.", "e:keyword": ["Procurement", "Auctions", "Supply contracts", "Push", "Pull"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01189.x", "e:abstract": "An abundance of flawed software has been identified as the main cause of the poor security of computer networks because major viruses and worms exploit the vulnerabilities of such software. As an incentive mechanism for software security quality improvement, software liability has been intensely discussed among both academics and practitioners for a long time. An alternative approach to managing software security is patch release, which has been widely adopted in practice. In this paper, we examine these two different ways of mitigating customer risk in the software market: liability and patch release. We study the impact of both mechanisms on a monopolistic software vendor's decision on security quality. We find the conditions under which each mechanism is effective in terms of improving security quality and increasing social surplus. The heterogeneous nature of loss is identified to be a key factor for the effectiveness of the liability mechanism. On the other hand, patch release can be effective and welfare-enhancing regardless of the nature of loss as long as customers incur low patching cost, and/or the vendor incurs low patch development cost. We also examine the impact of customer misperception of the outcome from vulnerable software on the effectiveness of liability.", "e:keyword": ["Software security", "Liability", "Patch release", "Security awareness", "Monopoly"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01191.x", "e:abstract": "We study an inventory system in which a supplier supplies demand using two mutually substitutable products over a selling season of T periods, with a single replenishment opportunity at the beginning of the season. As the season starts, customer orders arrive in each period, for either type of products, following a nonstationary Poisson process with random batch sizes. The substitution model we consider combines the usual supplier-driven and customer-driven schemes, in that the supplier may choose to offer substitution, at a discount price, or may choose not to; whereas the customer may or may not accept the substitution when it is offered. The supplier's decisions are the supply and substitution rules in each period throughout the season, and the replenishment quantities for both products at the beginning of the season. With a stochastic dynamic programming formulation, we first prove the concavity of the value function, which facilitates the solution to the optimal replenishment quantities. We then show that the optimal substitution follows a threshold rule, and establish the monotonicity of the thresholds over time and with respect to key cost parameters. We also propose a heuristic exhaustive policy, and illustrate its performance through numerical examples.", "e:keyword": ["Inventory control", "Production substitution", "Revenue maximization", "Concavity"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01192.x", "e:abstract": "Although, ceteris paribus, reducing lead times may be desirable from an overall system perspective, an upstream party (e.g., a manufacturer) may have strong disincentives to offer shorter lead times, even if this came at no cost. We consider a setting in which the downstream party has the ability to exert a costly effort to increase demand (e.g., through sales promotions, advertising, etc.) during the selling season, and compare two situations: one where there is zero lead time (i.e., all demand can be satisfied after observing the demand realization), and one where orders need to be made before demand is realized. We identify two interacting effects that may inhibit shorter lead times. A so-called “safety stock effect” can be observed when a lower risk of stocking out under short lead times induces the downstream party to alter her order quantity. A second effect, termed as “effort effect,” arises if shorter lead times impact the downstream party's optimal sales effort, and, as a consequence, lead to different order quantities. We provide a formal characterization of both effects, insight into how these effects interact, and show under which conditions the manufacturer has an incentive to offer shorter lead times.", "e:keyword": ["Lead time reduction", "Retailer effort", "Safety stock effect", "Effort effect", "Manufacturer's sales to retailer"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01194.x", "e:abstract": "In this research, we apply robust optimization (RO) to the problem of locating facilities in a network facing uncertain demand over multiple periods. We consider a multi-period fixed-charge network location problem for which we find (1) the number of facilities, their location and capacities, (2) the production in each period, and (3) allocation of demand to facilities. Using the RO approach we formulate the problem to include alternate levels of uncertainty over the periods. We consider two models of demand uncertainty: demand within a bounded and symmetric multi-dimensional box, and demand within a multi-dimensional ellipsoid. We evaluate the potential benefits of applying the RO approach in our setting using an extensive numerical study. We show that the alternate models of uncertainty lead to very different solution network topologies, with the model with box uncertainty set opening fewer, larger facilities. Through sample path testing, we show that both the box and ellipsoidal uncertainty cases can provide small but significant improvements over the solution to the problem when demand is deterministic and set at its nominal value. For changes in several environmental parameters, we explore the effects on the solution performance.", "e:keyword": ["Facility location", "Robust optimization", "Uncertainty", "Robust counterpart"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01198.x", "e:abstract": "Transshipment, the sharing of inventory among parties at the same echelon level of a supply chain, can be used to reduce costs. The effectiveness of transshipment is in part determined by the configuration of the transshipment network. We introduce chain configurations in transshipment settings, where every party is linked in one connected loop. Under simplifying assumptions we show analytically that the chain configuration is superior to configurations suggested in the literature. In addition, we demonstrate the efficiency and robustness of chain configurations for more general scenarios and provide managerial insights regarding preferred configurations for different problem parameters.", "e:keyword": ["Inventory transshipment", "Network design", "Inventory pooling", "Supply chain design", "Retail collaboration"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01201.x", "e:abstract": "Two factors that their influence on the demand has been investigated in many papers are (i) the shelf space allocated to a product and to its complement or supplement products and (ii) the instantaneous inventory level seen by customers. Here we analyze the joint shelf space allocation and inventory decisions for multiple items with demand that depends on both factors. The traditional approach to solve inventory models with a state-dependent demand rate uses a time domain approach. However, this approach often does not lead to closed-form expressions for the profit rate with both dependencies. We analyze the problem in the inventory domain via level crossing theory. This approach leads to closed-form expressions for a large set of demand rate functions exhibiting both dependencies. These closed-form expressions substantially simplify the search for optimal solutions; thus we use them to solve the joint inventory control and shelf space allocation problem. We consider examples with two products to investigate the significance of capturing both demand dependencies. We show that in some settings it is important to capture both dependencies. We consider two heuristics, each one of them ignores one of the two dependencies. Using these heuristics it seems that ignoring the dependency on the shelf space might be less harmful than ignoring the dependency on the inventory level, which, based on computational results, can lead to profit losses of more than 6%. We demonstrate that retailers should use their operational control, e.g., reorder point, to promote higher demand products.", "e:keyword": ["Shelf space allocation", "Inventory control", "Observed inventory level", "Demand dependencies", "Level crossing theory"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01202.x", "e:abstract": "Aggregation of corporate social performance (CSP) metrics poses a major challenge to researchers and practitioners. This study provides a critical evaluation of current aggregation approaches and proposes a new methodology based on data envelopment analysis (DEA) to compute a CSP index. DEA is independent of subjective weight specifications and provides an efficiency index to benchmark the CSP of firms. Using CSP data from 2190 firms in three major industries from the Kinder, Lydenberg, and Domini, Inc. database in 2007, our study presents the first application of the DEA model for CSP and ordinal data and opens up a new path for future empirical CSP research.", "e:keyword": ["Corporate social performance", "KLD", "Efficiency", "Data envelopment analysis"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01204.x", "e:abstract": "", "e:keyword": []}, {"e:year": 2010, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01146.x", "e:abstract": "", "e:keyword": []}, {"e:year": 2010, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01147.x", "e:abstract": "", "e:keyword": []}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01208.x", "e:abstract": "In their recent paper, Nagarajan and Sošić study an assembly supply chain in which n suppliers sell complementary components to a downstream assembler, who faces a price-sensitive deterministic demand. Suppliers may form alliances, and each alliance then sells a kit of components to the assembler and determines the price for that kit. The assembler buys the components (kits) from the alliances and sets the selling price of the product. Nagarajan and Sošić consider three modes of competition—supplier Stackelberg, vertical Nash (VN), and assembler Stackelberg models—which correspond to different power structures in the market, and study stable supplier alliances when the assembler faces linear and isoelastic demand. In this paper, we study the impact that demand uncertainty has on stability results obtained in Nagarajan and Sošić. We first analyze models in which all decisions are made before the uncertainty is resolved, and show that the alliance of all suppliers remains stable when demand is isoelastic, or under Stackelberg models when demand is linear. However, demand uncertainty may change stability results when both parties make decisions simultaneously (VN model) and demand is linear. We then extend our results by considering scenarios in which some decisions may be postponed and made after the actual demand is known. When the ordering quantity can be determined after observing the true demand, we show that stable outcomes correspond to those obtained in the deterministic case and uncertainty has no impact on coalition stability; if only the assembler's pricing decision is postponed, we need additional conditions for stability results to carry over in the additive demand model.", "e:keyword": ["Assembly models", "Coalition stability", "Stochastic demand"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01210.x", "e:abstract": "In the delivery of health care services, variability in the patient arrival and service processes can cause excessive patient waiting times and poor utilization of facility resources. Based on data collected at a large primary care facility, this paper investigates how several sources of variability affect facility performance. These sources include ancillary tasks performed by the physician, patient punctuality, unscheduled visits to the facility's laboratory or X-ray services, momentary interruptions of a patient's examination, and examination time variation by patient class. Our results indicate that unscheduled visits to the facility's laboratory or X-ray services have the largest impact on a physician's idle time. The average patient wait is most affected by how the physician prioritizes completing ancillary tasks, such as telephone calls, relative to examining patients. We also investigate the improvement in system performance offered by using increasing levels of patient information when creating the appointment schedule. We find that the use of policies that sequence patients based on their classification improves system performance by up to 25.5%.", "e:keyword": ["Health care operations", "Service operations management", "Appointment scheduling"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01212.x", "e:abstract": "We formally review the Author Affiliation Index (AAI) method as originally conceived by David Harless and Robert J. Reilly from the Economics Department at the Virginia Commonwealth University School of Business and as subsequently developed and interpreted by Gorman and Kanet in their 2005 article. Through this formal review, we first highlight and discuss two important informational inputs that can impact the stability of the AAI scores for journals in any given set of to-be-evaluated journals. We then identify and challenge interpretations related to these scores (one theoretical, one statistical) offered by Gorman and Kanet that result in misleading conclusions about journal quality and that may potentially motivate inappropriate editorial behavior. For important professional decisions of hiring, performance evaluation, promotion, and tenure, we conclude by cautioning against sole reliance on the AAI method for ranking journals and against exclusive interpretation of the score computed via the AAI method as an indicator of journal quality.", "e:keyword": ["Author affiliation index", "Journal quality", "Journal evaluation"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01213.x", "e:abstract": "In models of optimal decision making, assumptions about managerial behavior are often made with the hope that the prescriptions offered by these models will be effective in practice, even if actual behavior occasionally strays from these assumptions. However, recent revenue management (RM) research has demonstrated what appear to be systematic deviations from normative models of decision making. These deviations can even be observed in relatively simple RM contexts. We suggest that technical errors in capacity allocation decisions are linked to issues such as arousal and stress associated with state conditions of RM tasks. Our study goes beyond existing findings by considering behavioral phenomena in concurrent task settings, where the decision maker is faced with managing decisions for more than one product or service. Physiological measures of eye dilation and blink rate are used as markers of arousal and stress in subjects engaged in RM tasks. Our analysis shows that physiological responses are indeed associated with both the state conditions of RM tasks and the number of capacity blocks managed concurrently by an individual. Deviations from modeled decision making appear to be significantly dependent upon these physiological responses. We conclude with a discussion of implications for further research and practice.", "e:keyword": ["Behavioral operations", "Experiment", "Physiology", "Motivation"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01214.x", "e:abstract": "This paper considers pricing and remanufacturing strategy of a firm that decides to offer both new and remanufactured versions of its product in the market and is concerned with demand cannibalization. We present a model of demand cannibalization and a behavioral study that estimates a key modeling parameter: a fraction of consumers who switch from new to remanufactured product. As we show, this fraction has an inverted-U shape, and, thus, the underlying consumer behavior cannot be modeled using the standard methodologies that rely on consumers' willingness to pay (WTP). We find that by incorporating the inverted-U-shaped consumer behavior, the firm remanufactures under broader conditions, charges a much lower price, and typically remanufactures more units—leading to an increase of profits from remanufacturing by up to a factor of two as compared with making decisions based on the WTP only. Lastly, we find that the behavior of the low-price market segment plays an important role because the firm reacts to it differently than the WTP-based logic would suggest.", "e:keyword": ["Behavioral operations", "Environmental sustainability", "Remanufacturing", "Demand cannibalization", "Revenue management"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01215.x", "e:abstract": "We develop an optimal control model to maximize the net value provided by a software system over its useful life. The model determines the initial number of features in the system, the level of dynamic enhancement effort, and the lifetime of the system. The various factors affecting these optimal choices are systems characteristics (e.g., complexity, age, quality), user learning, and process maturity. We also consider that there is a time lag between the addition of a feature and the realization of its benefit to users. The basic model is extended to consider the decision of replacing the existing system by a new one.", "e:keyword": ["Software enhancement", "Lifetime", "Features", "Replacement", "Optimal control theory"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.001262.x", "e:abstract": "Installed base management is the policy in which the manufacturer leases the product to consumers, and bundles repair and maintenance services along with the product. In this article, we investigate for the optimal leasing price and leasing duration decisions by a monopolist when the production and servicing capacity are constrained. The effect of diffusion of consumers in the installed base is considered, with the ownership of the product resting with the monopolist during the product lifecycle. The monopolist operating the installed base jointly optimizes the profits from leasing the product/service bundle along with maintenance revenues and remanufacturing savings. We formulate the manufacturer's problem as an optimal control problem and show that the optimal pricing strategy of the firm should be a skimming strategy. We also find that the effect of remanufacturing savings on the pricing decision and the length of the leasing duration changes significantly depending on the duration of the product's lifecycle. If the product lifecycle is long and remanufacturing savings are low, the firm should offer a shorter leasing duration, whereas if the remanufacturing savings are high, the firm should optimally offer a higher leasing duration. In contrast, if the time duration of the product lifecycle is low and remanufacturing savings are low, the firm prefers to offer a shorter leasing duration, whereas if the remanufacturing savings are high, the firm should optimally have a longer leasing duration. The article also shows that if the production capacity is small, the manufacturer increases the leasing duration. If the production capacity is very small, the manufacturer sets the leasing duration to be equal to the product lifecycle and does not use remanufacturing.", "e:keyword": ["Installed base management", "Operational leasing", "Remanufacturing", "Lifecycle pricing", "Product/service bundle"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01218.x", "e:abstract": "There is a natural order to most events in life: Everything from learning to read to DNA sequences in molecular biology follows some predetermined, structured methodology that has been refined to yield improved results. Likewise, it would seem that firms could benefit by adopting and implementing technologies in some logical way so as to increase their overall performance. In this study of 555 hospitals, we investigate the order in which medical technologies are transformed into information technologies through a process of converting them from stand-alone technologies to interoperable, integrated information systems and whether certain configurations of sequences of integration yield additional value. We find that sequence does matter and that hospitals that integrated foundational technologies first—which in this case are known to be more complex—tend to perform better. Theoretical and practical implications of this finding and others are discussed.", "e:keyword": ["Sequence", "Healthcare technology", "Interoperability", "Technology integration", "Healthcare performance"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01220.x", "e:abstract": "In outpatient healthcare clinics, capacity, patient flow, and scheduling are rarely managed in an integrated fashion, so a question of interest is whether clinic performance can be improved if the policies that guide these decisions are set jointly. Despite the potential importance of this issue, we find surprisingly few studies that look at how the allocation of capacity, paired with various appointment scheduling policies and different patient flow configurations, affects patient flow and clinical efficiency. In this paper, we develop an empirically based discrete-event simulation to examine the interactions between patient appointment policies and capacity allocation policies (i.e., the number of available examination rooms) and how they jointly affect various performance measures, such as resource utilization and patient waiting time. Findings suggest that scheduling lower-variance, shorter appointments earlier in the clinic (and, conversely, higher-variance, longer appointments later) results in less overall patient waiting without reducing physician utilization or increasing clinic duration. Additionally, exam rooms exhibited classic bottleneck behavior: there was no effect on physician utilization by adding exam rooms beyond a certain threshold, but too few exam rooms were devastating to clinic throughput. Some significant interactions between these variables were observed, but were not influential to the level of managerial concern. Clinicians' intuition about managing capacity in healthcare settings may differ substantially from best policies.", "e:keyword": ["Healthcare", "Patient flow", "Outpatient", "Simulation"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01221.x", "e:abstract": "This paper reviews the general problem of surgical scheduling. We organize the literature based on the time frame or planning horizon of the schedule into six categories: capacity planning, process reengineering/redesign, the surgical services portfolio, procedure duration estimation, schedule construction, and schedule execution, monitoring, and control. We survey past work and suggest topics for potential future research in each of those areas.", "e:keyword": ["Surgical scheduling", "Resource planning"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01226.x", "e:abstract": "High surgical bed occupancy levels often result in heightened staff stress, frequent surgical cancellations, and long surgical wait times. This congestion is in part attributable to surgical scheduling practices, which often focus on the efficient use of operating rooms but ignore resulting downstream bed utilization. This paper describes a transparent and portable approach to improve scheduling practices, which combines a Monte Carlo simulation model and a mixed integer programming (MIP) model. For a specified surgical schedule, the simulation samples from historical case records and predicts bed requirements assuming no resource constraints. The MIP model complements the simulation model by scheduling both surgeon blocks and patient types to reduce peak bed occupancies. Scheduling guidelines were developed from the optimized schedules to provide surgical planners with a simple and implementable alternative to the MIP model. This approach has been tested and delivered to planners in a health authority in British Columbia, Canada. The models have been used to propose new surgical schedules and to evaluate the impact of proposed system changes on ward congestion.", "e:keyword": ["Surgical scheduling", "Mixed integer programming", "Monte Carlo simulation", "Scheduling guidelines", "Hospital bed management"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01227.x", "e:abstract": "This paper examines the effect of the common practice of reserving slots for urgent patients in a primary health care practice on two service quality measures: the average number of urgent patients that are not handled during normal hours (either handled as overtime, referred to other physicians, or referred to the emergency room) and the average queue of non-urgent or routine patients. We formulate a stochastic model of appointment scheduling in a primary care practice. We conduct numerical experiments to optimize the performance of this system accounting for revenue and these two service quality measures as a function of the number of reserved slots for urgent patients. We compare traditional methods with the advanced-access system advocated by some physicians, in which urgent slots are not reserved, and evaluate the conditions under which alternative appointment scheduling mechanisms are optimal. Finally, we demonstrate the importance of patient arrival dynamics to their relative performance finding that encouraging routine patients to call for same-day appointments is a key ingredient for the success of advanced-access.", "e:keyword": ["Advanced‐access", "Primary care", "Appointment scheduling", "Urgent patients"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01228.x", "e:abstract": "This paper contributes to research on quality drivers in healthcare settings by examining the relationships between patient volume, teaching mission, and process quality in US hospitals. To develop a model that accurately assesses the impact of patient volume and teaching status on quality, we draw on three related research streams pertaining to the volume–quality relationship, the comparative quality of care in teaching and non-teaching hospitals, and quality drivers in service institutions. We propose the impact of patient volume on process quality varies across hospitals with different teaching intensities. The test of this proposition uses a large data set that measures process quality for treatments for heart attacks and heart failures in all major US hospitals. Our results suggest that, as hospital teaching intensity increases, greater patient volume is associated with decreased process quality. Never before was such a relationship uncovered. This initial finding has important practical implications. First, the regionalization policy of hospitals should be re-evaluated in light of their teaching function. Second, the root causes for the lower quality scores of large, high resident-to-bed ratio teaching hospitals, compared with smaller versions, must be found.", "e:keyword": ["Volume", "Teaching status", "Process quality", "Healthcare operations"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01230.x", "e:abstract": "We consider the problem of optimal capacity allocation in a hospital setting, where patients pass through a set of units, for example intensive care and acute care (AC), or AC and post-acute care. If the second stage is full, a patient whose service at the first stage is complete is blocked and cannot leave the first stage. We develop a new heuristic for tandem systems to efficiently evaluate the effects of such blocking on system performance and we demonstrate that this heuristic performs well when compared with exact solutions and other approaches presented in the literature. In addition, we show how our tandem heuristic can be used as a building block to model more complex multi-stage hospital systems with arbitrary patient routing, and we derive insights and actionable capacity strategies for a real hospital system where such blocking occurs between units.", "e:keyword": ["Queuing networks", "Blocking", "Healthcare", "Capacity allocation"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01231.x", "e:abstract": "Variability in hospital occupancy negatively impacts the cost and quality of patient care delivery through increased emergency department (ED) congestion, emergency blockages and diversions, elective cancelations, backlogs in ancillary services, overstaffing, and understaffing. Controlling inpatient admissions can effectively reduce variability in hospital occupancy to mitigate these problems. Currently there are two major gateways for admission to a hospital: the ED and scheduled elective admission. Unfortunately, in highly utilized hospitals, excessive wait times make the scheduled gateway undesirable or infeasible for a subset of patients and doctors. As a result, this group often uses the ED gateway as a means to gain admission to the hospital. To better serve these patients and improve overall hospital functioning, we propose creating a third gateway: an expedited patient care queue. We first characterize an optimal admission threshold policy using controls on the scheduled and expedited gateways for a new Markov decision process model. We then present a practical policy based on insight from the analytical model that yields reduced emergency blockages, cancelations, and off-unit census via simulation based on historical hospital data.", "e:keyword": ["Health care operations", "Patient flow modeling", "Markov decision processes", "Admission control"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01233.x", "e:abstract": "Deciding to open the source code of a software product has advantages and disadvantages. The disadvantage is that the firm loses the revenue from the software. The advantage is that the users' network can contribute to the quality of the software code, which increases the demand for the software and for a complementary product. Demand for the complementary product also goes up, because demand for a product increases when the price of its complement decreases, and under open source, the price of the software product drops down to zero. This paper examines the strategic interactions at work here, within a duopoly framework, and tries to determine the circumstances under which it is optimal for a firm to open its code. We find that firms open the source code when there is a competitive software-product market, a less competitive complementary-product market, and when the complementary product is of high quality. Furthermore, it is more profitable for the firm to open the source code if its competitor also does so. When this happens the incentive to open the code can even be higher than in a monopoly situation. More intense competition induces symmetric equilibria in which both firms choose the same strategy.", "e:keyword": ["Open source", "Complementary product", "Competition", "Software", "Stage game"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01283.x", "e:abstract": "", "e:keyword": []}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01283.x", "e:abstract": "", "e:keyword": []}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01247.x", "e:abstract": "We consider a buyer who outsources the manufacturing of a product to multiple symmetric make-to-stock suppliers who compete on price and service (fill rate). The buyer allocates demand to the suppliers using a score function with an exponential form, which specifies the relative importance of price vs. service, in order to minimize his costs, while the suppliers choose their prices and fill rates to maximize their profits. For the case of dual-sourcing, we characterize the optimal parameter of the exponential score function, considering the impact of the buyer's decisions on the suppliers, and considering how the suppliers compete against each other to earn a portion of the buyer's demand. We prove the existence of a unique equilibrium and characterize the equilibrium behavior of the system. We then consider a general number of suppliers and show that the equilibrium prices and fill rates, and the buyer's cost, are increasing in the number of suppliers. We compare these results to a model of single-sourcing, in which the buyer is the Stackelberg leader and extracts all profits from the supplier. We find that the buyer always prefers single-sourcing to multisourcing. Finally, we study a centralized system and use the results to develop a coordinating contract for the decentralized system.", "e:keyword": ["Single‐sourcing", "Multisourcing", "Competition", "Pricing", "Coordination"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01250.x", "e:abstract": "Previous work has considered the simultaneous (as opposed to sequential) optimization of a maintenance policy and a production policy in a multi-product setting with random yield and product mix constraints. One of the sequential approaches to which the simultaneous approach is compared is a so-called first-come-first-served (FCFS) approach, i.e., an approach that generates randomized production policies that do not depend on the deterioration state of the machine. However, the model formulation for this approach does not generate policies consistent with this FCFS notion. Therefore, we present a revised FCFS model and analyze its performance using an existing experimental design. The results suggest that previous work overestimates the degree to which a FCFS approach is suboptimal, and underestimates the value of simultaneously optimizing the maintenance and production decisions. Lastly, we conduct additional experiments which suggest that the joint impact of using both simultaneous optimization and a deterioration dependent production policy is quite significant.", "e:keyword": ["Production scheduling", "Equipment maintenance", "Markov decision processes", "First‐come‐first‐serve"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01254.x", "e:abstract": "Examination of team productivity finds that team familiarity, i.e., individuals' prior shared work experience, can positively impact the efficiency and quality of team output. Despite the attention given to team familiarity and its contingencies, prior work has focused on whether team members have worked together, not on which team members have worked together, and under what conditions. In this paper, I parse overall team familiarity to consider effects of geographic location and the hierarchical roles of team members. Using data on all software-development projects completed over 3 years at a large Indian firm in the global outsourced software services industry, I find that team familiarity gained when team members work together in the same location has a significantly more positive effect on team performance compared with team familiarity gained while members were collaborating in different locations. Additionally, I find that hierarchical team familiarity (a manager's experience with front-line team members) and horizontal team familiarity (front-line team members' experience gained with one another) have differential effects on project team performance. These findings provide insight into the relationship between team experience and team performance.", "e:keyword": ["Distributed teams", "Knowledge work", "Software", "Team familiarity", "Team productivity"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01255.x", "e:abstract": "In this paper, we study a single-product periodic-review inventory system that faces random and price-dependent demand. The firm can purchase the product either from option contracts or from the spot market. Different option contracts are offered by a set of suppliers with a two-part fee structure: a unit reservation cost and a unit exercising cost. The spot market price is random and its realization may affect the subsequent option contract prices. The firm decides the reservation quantity from each supplier and the product selling price at the beginning of each period and the number of options to exercise (inventory replenishment) at the end of the period to maximize the total expected profit over its planning horizon. We show that the optimal inventory replenishment policy is order-up-to type with a sequence of decreasing thresholds. We also investigate the optimal option-reservation policy and the optimal pricing strategy. The optimal reservation quantities and selling price are shown to be both decreasing in the starting inventory level when demand function is additive. Building upon the analytical results, we conduct a numerical study to unveil additional managerial insights. Among other things, we quantify the values of the option contracts and dynamic pricing to the firm and show that they are more significant when the market demand becomes more volatile.", "e:keyword": ["Dynamic pricing", "Portfolio procurement", "Option contracts", "Optimal policies"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01283.x", "e:abstract": "", "e:keyword": []}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01258.x", "e:abstract": "We analyze a supply chain consisting of a supplier and a retailer. The supplier's unit production cost, which characterizes his type, is only privately known to him. When trading with the retailer, the supplier demands a reservation profit that depends on his unit production cost. We model this problem as a game of adverse selection. In this model, the retailer offers a menu of contracts, each of which consists of two parameters: the ordering quantity and the supplier's share of the channel profit. We show that the optimal contract depends critically on a surrogate measure—the ratio of the types’ reservation profit differential to their production cost differential. An important implication from our analysis is that information asymmetry alone does not necessarily induce loss in channel efficiency. The optimal contract can coordinate the supply chain as long as the low-cost supplier's cost efficiency is neither much overvalued nor much undervalued in the outside market. We further discuss the retailer's preference of the supplier's type under different market conditions, as well as evaluate the effects of the supplier's reservation profit, the retail price, and the demand uncertainty on the optimal contract.", "e:keyword": ["Adverse selection", "Type‐dependent reservation profit", "Contracting", "Supply chain efficiency", "Demand uncertainty"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01259.x", "e:abstract": "We consider the problem of a retailer managing a category of vertically differentiated products. The retailer has to pay a fixed cost for each product included in the assortment and a variable cost per product sold. Quality levels, fixed, and variable costs are exogenously determined. Customers differ in their valuation of quality and choose the product (if any) that maximizes their utility. First, we consider a setting in which the selling prices are also fixed. We find that the optimal set of products to offer depends on the distribution of customer valuations and might include dominated products, that is, products which are less attractive than at least one other product, on every possible dimension. We develop an efficient algorithm to identify an optimal assortment. Second, we consider a setting in which the retailer also determines the selling prices. We show that in this case the optimal assortment does not include any dominated product and does not vary with the distribution of customer valuations when there is no fixed cost. We develop several efficient algorithms to identify an optimal assortment and optimally price the products. We also test the applicability of our methods with realistic data for two product categories.", "e:keyword": ["Assortment planning", "Vertical differentiation", "Quality", "Pricing"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01261.x", "e:abstract": "In this paper, we consider data-driven approaches to the problem of inventory control. We first consider the approach of operational statistics and review related results which enable us to maximize a priori expected profit uniformly over all parameter values, when the demand distribution is known up to the location and scale parameters. For the case of the unknown shape parameter, we first suggest a heuristic approach based on operational statistics to obtain improved ordering policies and illustrate the same for the case of a Pareto demand distribution. In more general cases where the heuristic is not applicable, we suggest linear correction and support vector regression approaches to better estimate ordering policies, and illustrate these using a Gamma demand distribution. In certain cases, our proposed approaches are found to yield significant improvements.", "e:keyword": ["Newsvendor model", "Model uncertainty", "Demand ambiguity", "Operational statistics"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01263.x", "e:abstract": "Make-to-order (MTO) manufacturers must ensure concurrent availability of all parts required for production, as any unavailability may cause a delay in completion time. A major challenge for MTO manufacturers operating under high demand variability is to produce customized parts in time to meet internal production schedules. We present a case study of a producer of MTO offshore oil rigs that highlights the key aspects of the problem. The producer was faced with an increase in both demand and demand variability. Consequently, it had to rely heavily on subcontracting to handle production requirements that were in excess of its capacity. We focused on the manufacture of customized steel panels, which represent the main sub-assemblies for building an oil rig. We considered two key tactical parameters: the planning window of the master production schedule and the planned lead time of each workstation. Under the constraint of a fixed internal delivery lead time, we determined the optimal planning parameters. This improvement effort reduced the subcontracting cost by implementing several actions: the creation of a master schedule for each sub-assembly family of the steel panels, the smoothing of the master schedule over its planning window, and the controlling of production at each workstation by its planned lead time. We report our experience in applying the analytical model, the managerial insights gained, and how the application benefits the oil-rig producer.", "e:keyword": ["Make‐to‐order", "Production smoothing", "Master production schedule", "Planned lead times", "Oil‐rig building"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01264.x", "e:abstract": "In this article, we introduce the notion of operational entrepreneurship—the selection and management of transformation processes for recognizing, evaluating, and exploiting opportunities for potential value creation—to offer examples of research opportunities at the interface of entrepreneurship and operations management. Specifically, we believe that operations management has been under-utilized for gaining a deeper understanding of (i) the knowledge and motivation required for opportunity recognition, (ii) evaluations of a recognized opportunity to determine if it represents an opportunity for the specific entrepreneur, and (iii) the role that feedback from an exploitation of a current opportunity plays in the recognition and evaluation of subsequent opportunities. We also introduce (but not develop) the notion of entrepreneurial operations.", "e:keyword": ["Opportunity recognition", "Opportunity evaluation", "Opportunity exploitation", "Operational entrepreneurship", "Entrepreneurial operations"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01267.x", "e:abstract": "Bucket brigade order picking is a method for retrieving orders from a storage rack where workers follow a fixed sequence and dynamically adjust to variability in work content along the rack. The method is simple and has been shown to provide superior performance in many applications. In this article, we analyze how the location in which products are stored in the rack affects throughput. We identify conditions where storage decisions have a large impact on throughput (e.g., a 20% increase in productivity) and conditions where the impact is minimal. Conditions associated with high impact are high variation in worker skill, high variation in SKU volume, and a moderate level of walking-to-picking work content per pick list.", "e:keyword": ["Warehouse management", "Storage assignment", "Order picking", "Bucket brigade"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01269.x", "e:abstract": "We consider a manufacturer serving two competing retailers that sell their products over a single selling season. The retailers place their regular orders before the season starts. In addition to this initial order, quick response (QR) provides a retailer with an additional replenishment opportunity after demand uncertainty is resolved. The manufacturer determines the unit price for QR replenishment. We characterize the retailers’ ordering, and the manufacturer's pricing decisions in equilibrium when none, only one, and both of the retailers have QR ability. We study how the profitability of the manufacturer, the retailers, and the channel depend on QR and competition. We find it may be optimal for the manufacturer to offer QR to only one of the ex ante identical retailers when demand variability is sufficiently, but not overly high. The manufacturer may also find it optimal to offer QR to both or none of the retailers, depending on demand variability. Finally, while QR ability is always attractive for a retailer when competition is ignored, we find QR may prove detrimental when its impact on competition is taken into account.", "e:keyword": ["Quick response", "Competition", "Pricing", "Supply chain"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01282.x", "e:abstract": "", "e:keyword": []}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01283.x", "e:abstract": "", "e:keyword": []}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01284.x", "e:abstract": "Drawing on behavioral research, we construct a multi-period model with which to examine the role of trust and other social characteristics in a supply chain. Specifically, we focus on trust building in the context of a salesperson who acts as a representative of a manufacturer and shares demand forecast information with a retailer. The actions of the salesperson affect both her immediate economic gain and her future credibility as determined by retailer's trust. Our analysis reveals that, in such environments, although salespersons of widely varying types (e.g., honest, self-serving, benevolent, loyal) lie some extent about their forecast information, they tend to be trusted in long relationships, provided their forecasting accuracy is higher than that of the retailer. Furthermore, while the presence of a salesperson can improve the profits of both the retailer and manufacturer, there are cost structures under which the manufacturer is better off without a salesperson. Finally, we make the general observation that the appropriate salesperson compensation scheme depends on her social characteristics, and the specific observation that when the salesperson cares for the retailer, the linear compensation scheme commonly suggested in the literature as the optimal compensation scheme for the salesperson is no longer optimal.", "e:keyword": ["Supply chain", "Trust", "Information sharing", "Salesperson", "Social characteristics"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01286.x", "e:abstract": "We analyze the value of and interaction between production postponement and information sharing, which are two distinct strategies to reduce manufacturers’ uncertainty about demand. In both single-level and two-level supply chains, from the manufacturer's perspective, while information sharing is always valuable, production postponement can sometimes be detrimental. Furthermore, the value of production postponement is not merely driven by savings in inventory holding cost as postponement enables the manufacturer to avoid both excess and shortfall in production. We find that production postponement and information sharing strategies may substitute, complement, or conflict with each other, depending on the extent of the increase in the unit production cost when production is postponed. In a two-level supply chain, from the retailer's perspective, information sharing and production postponement can be beneficial or detrimental. When information sharing is beneficial to the retailer, the retailer always shares her demand information with the manufacturer voluntarily. In addition, this voluntary information sharing is truthful because inflated or deflated demand information hurts the retailer through a higher wholesale price or a stock-out. However, the retailer never shares her demand information voluntarily if the manufacturer has already adopted production postponement because production postponement and information sharing strategies always conflict with each other. Even when the retailer does not benefit from information sharing, we show that the manufacturer can always design an incentive mechanism to induce the retailer to share the demand information, irrespective of whether the manufacturer has already implemented production postponement or not. The above findings underscore the need for a careful assessment of demand uncertainty-reduction strategies before the supply chain players embark upon them.", "e:keyword": ["Information sharing", "Production postponement", "Supply chain management", "Demand uncertainty", "Pricing"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01287.x", "e:abstract": "A recent article by Oliver Williamson essentially comprises a critique of supply chain management (SCM) from the perspective of his own field, transaction-cost economics. Here is one reader's response. SCM can indeed be faulted for inflated rhetoric, among other sins. I believe, however, that the two fields have much to learn from each other.", "e:keyword": ["Supply chain management", "Transaction‐cost economics"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01288.x", "e:abstract": "In this article, we study the joint pricing and inventory control problem for perishables when a retailer does not sell new and old inventory at the same time. At the beginning of a period, the retailer makes replenishment and pricing decisions, and at the end of a period, the retailer decides whether to dispose of ending inventory or carry it forward to the next period. The objective of the retailer is to maximize the long-run average profit. Assuming zero lead time, we propose an efficient solution approach to the problem, which is also generalized to solve three extensions to the basic model. A feature of the present study is that we consider explicitly the influence of perishability on the demand. Among the insights gathered from the numerical analysis, we find that dynamic pricing aids extending shelf life and when disposal incurs a lower cost, or even a positive salvage value, the retailer is induced to dispose earlier since the benefit of selling new inventory offsets the loss due to disposal. We also observe that the faster the perceived rate of deterioration, the lower the threshold of the ending inventory for disposal. Perhaps a bit counter-intuitive, maximizing profits does not mean eliminating disposals or expirations.", "e:keyword": ["Pricing and inventory control", "Perishable products", "Pricing", "Interface between operations and marketing"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01290.x", "e:abstract": "We study the impact of product recovery on a firm's product quality choice, where quality is defined as an observable performance measure that increases a consumer's valuation for the product. We consider three general forms of product recovery: (i) when product recovery reuses (after reprocessing) quality inducing components or material (e.g., remanufacturing), (ii) when product recovery does not reuse quality inducing components or material but it is overall profitable (e.g., cell phone recycling), and (iii) when product recovery is costly (but mandated by legislation, e.g., recycling of small appliances in the European Union). Using a stylized economic model, we show that the form of product recovery, recovery cost structure, and the presence of product take-back legislation play an important role in quality choice. Generally speaking, product recovery increases the firm's quality choice, except for some instances of recovery form (ii). In addition, we find that product take-back legislation can lead to higher quality choice as opposed to voluntary take-back. We further demonstrate that both the firm and the consumers benefit from recovery form (ii), while both are worse off with recovery form (iii). However, environmental implications of the three recovery modes differ from their impact on consumer surplus and firm profit. While recovery forms (i) and (iii) reduce consumption and increase environmental benefits, the same is not true with recovery form (ii), which can increase consumption, potentially resulting in higher environmental impact.", "e:keyword": ["Quality choice", "Remanufacturing", "Recycling", "Take‐back legislation"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01295.x", "e:abstract": "We study the dynamic assignment of cross-trained servers to stations in understaffed lines with finite buffers. Our objective is to maximize the production rate. We identify optimal server assignment policies for systems with three stations, two servers, different flexibility structures, and either deterministic service times and arbitrary buffers or exponential service times and small buffers. We use these policies to develop server assignment heuristics for Markovian systems with larger buffer sizes that appear to yield near-optimal throughput. In the deterministic setting, we prove that the best possible production rate with full server flexibility and infinite buffers can be attained with partial flexibility and zero buffers, and we identify the critical skills required to achieve this goal. We then present numerical results showing that these critical skills, employed with an effective server assignment policy, also yield near-optimal throughput in the Markovian setting, even for small buffer sizes. Thus, our results suggest that partial flexibility is sufficient for near-optimal performance, and that flexibility structures that are effective for deterministic and infinite-buffered systems are also likely to perform well for finite-buffered stochastic systems.", "e:keyword": ["Throughput maximization", "Finite buffers", "Partial and full server flexibility", "Tandem production systems", "Line balancing"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01282.x", "e:abstract": "", "e:keyword": []}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01300.x", "e:abstract": "We study the design of extended warranties in a supply chain consisting of a manufacturer and an independent retailer. The manufacturer produces a single product and sells it exclusively through the retailer. The extended warranty can be offered either by the manufacturer or by the retailer. The party offering the extended warranty decides on the terms of the policy in its best interest and incurs the repair costs of product failures. We use game theoretic models to answer the following questions. Which scenario leads to a higher supply-chain profit, the retailer offering the extended warranty or the manufacturer? How do the optimum price and extended warranty length vary under different scenarios? We find that, depending on the parameters, either party may provide better extended warranty policies and generate more system profit. We also compare these two decentralized models with a centralized system where a single party manufactures the product, sells it to the consumer, and offers the extended warranty. We also consider an extension of our basic model where either the manufacturer or the retailer resells the extended warranty policies of a third party (e.g., an independent insurance company), instead of offering its own policy.", "e:keyword": ["Extended warranty", "Supply chain management", "Warranty", "Game theory"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01301.x", "e:abstract": "Supply contracts are used to coordinate the activities of the supply chain partners. In many industries, service level-based supply contracts are commonly used. Under such a contract, a company agrees to achieve a certain service level and to pay a financial penalty if it misses it. The service level used in our study refers to the fraction of a manufacturer's demand filled by the supplier. We analyze two types of service level-based supply contracts that are designed by a manufacturer and offered to a supplier. The first type of contract is a flat penalty contract, under which the supplier pays a fixed penalty to the manufacturer in each period in which the contract service level is not achieved. The second type of contract is a unit penalty contract, under which a penalty is due for each unit delivered fewer than specified by the parameters of the contract. We show how the supplier responds to the contracts and how the contract parameters can be chosen, such that the supply chain is coordinated. We also derive structural results about optimal values of the contract parameters, provide numerical results, and connect our service level measures to traditional service level measures. The results of our analyses can be used by decision makers to design optimal service level contracts and to provide them with a solid foundation for contract negotiations.", "e:keyword": ["Service level", "Contracts", "Supply chain", "Financial penalty"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01304.x", "e:abstract": "We consider a system of two service providers each with a separate queue. Customers choose one queue to join upon arrival and can switch between queues in real time before entering service to maximize their spot utility, which is a function of price and queue length. We characterize the steady-state distribution for queue lengths, and then investigate a two-stage game in which the two service providers first simultaneously select service rates and then simultaneously charge prices. Our results indicate that neither service provider will have both a faster service and a lower price than its competitor. When price plays a less significant role in customers’ service selection relative to queue length or when the two service providers incur comparable costs for building capacities, they will not engage in price competition. When price plays a significant role and the capacity costs at the service providers sufficiently differ, they will adopt substitutable competition instruments: the lower cost service provider will build a faster service and the higher cost service provider will charge a lower price. Comparing our results to those in the existing literature, we find that the service providers invest in lower service rates, engage in less intense price competition, and earn higher profits, while customers wait in line longer when they are unable to infer service rates and are naive in service selection than when they can infer service rates to make sophisticated choices. The customers’ jockeying behavior further lowers the service providers’ capacity investment and lengthens the customers’ duration of stay.", "e:keyword": ["Queues", "Customer behavior", "Price and service rate competition", "Two‐stage game"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01306.x", "e:abstract": "Early writings in economics describe the entrepreneur's role in terms of bearing the uncertainty inherent in new undertakings. Much of the research published in the pages of Production and Operations Management deals with management under uncertainty. The shared concerns over the impacts of multiple types of uncertainty suggest that research on Operations Management (OM) can play a role in the development of theory in entrepreneurship. We discuss aspects of such a role from two perspectives. First, we consider several topics in the OM literature that have clear applications or parallels in entrepreneurship. These topics include innovation, the management of technology, new product development, flexibility, and hedging strategies. Understanding these topical connections should aid in the development of tools and applications central to the practice of entrepreneurship. On another level, when we consider how the approaches to many of these topics in OM are grounded in theory adapted from Operations Research and Economics we argue that these same roots can be used as starting points for the development of theory in entrepreneurship. As examples, we will argue that the theoretical bases supporting robust optimization, stochastic dynamic programming, and even Total Quality Management can also serve as foundations of theories about the roles, practice, and behaviors of entrepreneurs.", "e:keyword": ["Entrepreneurship", "OM research"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01308.x", "e:abstract": "The problem of no-shows (patients who do not arrive for scheduled appointments) is particularly significant for health care clinics, with reported no-show rates varying widely from 3% to 80%. No-shows reduce revenues and provider productivity, increase costs, and limit patient access by reducing effective clinic capacity. In this article, we construct a flexible appointment scheduling model to mitigate the detrimental effects of patient no-shows, and develop a fast and effective solution procedure that constructs near-optimal overbooked appointment schedules that balance the benefits of serving additional patients with the potential costs of patient waiting and clinic overtime. Computational results demonstrate the efficacy of our model and solution procedure, and connect our work to prior research in health care appointment scheduling.", "e:keyword": ["Service operations", "Appointment scheduling", "Overbooking"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01309.x", "e:abstract": "Supplier default is common in emerging markets. Suppliers under the threat of default have different objectives from profit-seeking companies. This paper analytically tests how profit-seeking or survival-seeking behavior, single-period or two-period consideration, and buyer's subsidy influence the supplier's and buyer's final utilities. The results show that under single-period consideration, the supplier's survival-seeking strategy in fact drives more start-ups or small suppliers out of business when the competition becomes severe; under two-period consideration, no matter which strategy (profit-seeking or survival-seeking) the supplier selects, the second-period price and profit are always higher than those of the first period. Furthermore, we find that providing subsidy is an effective way for buyer to keep suppliers’ competition at a certain level on the behalf of buyer's interest. By numerically estimating the benefits associated with the cost of subsidy, we provide a basis for understanding the cost–benefit analysis of buyer's subsidy strategy.", "e:keyword": ["Supplier competition", "Buyer subsidy", "Survival‐seeking strategy", "Profit‐seeking strategy", "Game theory"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01310.x", "e:abstract": "With supply chains distributed across global markets, ocean container transport now is a critical element of any such supply chain. We identify key characteristics of ocean container transport from a supply chain perspective. We find that unlike continental (road) transport, service offerings tend to be consolidated in few service providers, and a strong focus exists on maximization of capital intensive resources. Based on the characteristics of ocean container transport as part of global supply chains, we list a number of relevant and challenging research areas and associated questions.", "e:keyword": ["Supply chain management", "Transport", "Ocean containers", "Research agenda"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01311.x", "e:abstract": "Realizing potential benefits from emerging market penetration requires firms to address inherent supply chain challenges. A major challenge is for firms to manage costly inventories to address demand and supply risks in emerging markets. However, emerging market penetration may offer opportunities for firms to lower inventory levels, reduce costs, and improve operating performance. Using data for 482 manufacturing firms over the 5-year period, 2003–2007, obtained from the COMPUSTAT Industrial and Segment Databases, this article examines the relationships between emerging market penetration, inventory supply, and financial performance. Our results show that a multinational firm's sales penetration into emerging markets is associated with fewer days of inventory supply and improved financial performance. As emerging market penetration may allow firms to operate with lower inventory supply, the positive effect from emerging market penetration, such as labor cost reductions, may be enhanced due to inventory cost savings.", "e:keyword": ["Emerging markets", "Inventory", "Financial performance", "Multinational firms", "Manufacturing"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01312.x", "e:abstract": "This paper studies the impact of logistics performance on global bilateral trade. Taking a supply chain perspective, logistics performance refers to cost, time, and complexity in accomplishing import and export activities. We draw on a data set compiled by the World Bank containing specific quantitative metrics of logistics performance in terms of time, cost, and variability in time. Numerous researchers have shown that logistics performance is statistically significantly related to the volume of bilateral trade. Our research calibrates the impact of specific improvements in logistics performance (time, cost, and reliability) on increased trade. Our findings can spur public and private agencies that have direct or indirect influence over logistics performance to focus attention on altering the most relevant aspects of logistics performance to improve their country's ability to compete in today's global economy. Moreover, as our logistics metrics are directly related to operational performance, countries can use these metrics to target actions to improve logistics and monitor their progress.", "e:keyword": ["Logistics", "Logistics improvements", "Global trade"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01313.x", "e:abstract": "We study a remanufacturing system that involves the ordering of a serviceable product and the remanufacturing of multiple types of returned products (cores) into the serviceable product. In addition to random demand for the serviceable product and random returned quantities of different types of cores in each time period, the remanufacturing yield of each type of core is also uncertain. By analyzing a multi-period stochastic dynamic program, we derive several properties of the optimal ordering/remanufacturing policy. In addition to some insights, these properties can be used to reduce the search effort of the optimal policy. We also demonstrate that some existing results derived from related models no longer hold in remanufacturing systems with random yield. Recognizing the optimal ordering/remanufacturing policy is highly complex, we examine three simple heuristics that can be efficiently solved and implemented in practice. Among these three heuristics, our numerical analysis suggests that the heuristic that captures most of the yield uncertainty and future system evolvement as well as some of the properties of the optimal ordering/remanufacturing policy outperforms the other two heuristics.", "e:keyword": ["Remanufacturing", "Random yield", "Optimal policy", "Heuristics"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01314.x", "e:abstract": "As emerging markets increasingly rely on service businesses through offshore outsourcing, we examine the role of governance control mechanisms in improving performance among business process outsourcing (BPO) service providers in India. Using data collected from 205 emerging market-based BPO service providers in India, we examine the antecedents and consequences of establishing governance control mechanisms in BPO service providers. Specifically, we examine how structural (use of contracts with the client), administrative (effective allocation and demarcation of responsibilities within the firm), and relational (collaboration and information sharing with the client) mechanisms drive the performance of a BPO service provider operating in an emerging market. We also examine how key task-related (task connectivity and task security) and client-related (end customer orientation and global control) antecedents influence the use of different governance control approaches in this environment. Our analysis finds that both task connectivity and task security significantly impact use of structural and administrative mechanisms, whereas end customer orientation is significantly associated with the strength of the relational mechanisms governing the emerging market-based BPO service provider and its client. Further global control significantly influences the strength of the structural mechanisms between the client and the BPO service provider. Finally, the three mechanisms have a complementary influence in driving the BPO service provider's performance.", "e:keyword": ["Business process outsourcing", "Emerging markets", "Buyer–supplier relationships", "Governance control mechanisms"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01315.x", "e:abstract": "Many people in developing countries do not have access to effective vaccines, medicines, and other life-saving health technologies. Shortage of health care workers, severe financial constraints, and lack of awareness are some of the major obstacles that prevent higher access. However, ineffective and poorly designed supply chains for purchasing and distributing the medicines, vaccines, and health technologies are one of the most important barriers to increasing access. We argue that the ineffectiveness of the global health supply chain can be attributed largely to: coordination problems across multiple stakeholders with widely divergent objectives, lack of careful supply chain design, and use of myopic operational objectives and metrics. The operations management research community can contribute to improving this by applying existing knowledge to the field of global health delivery and by researching new frameworks of analysis which would then become the cornerstones for policy advice to those who design, operate, or finance these supply chains.", "e:keyword": ["Global health supply chain", "Public health", "Vaccines", "Essential medicines"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01316.x", "e:abstract": "This article studies 4 × 4 vehicle replacement within the International Committee of the Red Cross (ICRC), one of the largest humanitarian organizations. ICRC policy sets the replacement of vehicles at 5 years or 150,000 km, whichever comes first. Using field data collected at the ICRC headquarters and national level we study the ICRC policy. Our results suggest that the organization can make considerable savings by adjusting its replacement policy. This study contributes to the area of logistics and transportation research in humanitarian operations.", "e:keyword": ["Humanitarian logistics", "Vehicle replacement", "Transportation", "Decentralized supply chains"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2011.01282.x", "e:abstract": "", "e:keyword": []}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01320.x", "e:abstract": "With the outsourcing of manufacturing activities from Western countries, China has gradually become the global manufacturing hub. In the presence of increased competition from both inside and outside of China, many Chinese manufacturers have turned to scientific management approaches and implemented various enterprise systems. In academia, there has been a growing interest in quantifying the impacts of such efforts on the corporate performance of Chinese firms, and research has been carried out in areas such as finance and accounting. However, due to limited visibility of operational decisions and data, there seems to be a lack of investigation into the impacts on the firms’ operational performance in the literature. In this article, we apply an empirical method to investigate the inventories of 1286 firms listed on the two stock exchanges in China, the Shanghai Stock Exchange and the Shenzhen Stock Exchange. We find that on average the inventory levels have declined over time and that the firm-level data is consistent with several implications derived from classical inventory models.", "e:keyword": ["Inventory performance", "Empirical study", "Emerging markets"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01325.x", "e:abstract": "We consider a large original equipment manufacturer (OEM) who relies on a contract manufacturer (CM) to produce her product. In addition to the OEM's product, the CM also produces for a smaller OEM. Both the larger OEM and the CM can purchase the component from the supplier, but their purchase prices may differ and remain unknown to each other. The main question we address is whether the larger OEM should retain component procurement by purchasing components from the supplier and reselling to the CM (buy–sell), or outsource component procurement by letting the CM purchase directly from the supplier (turnkey). We show that, under buy–sell, the larger OEM's optimal strategy is to resell components at the highest possible component purchase price of the CM (i.e., the street price). By comparing buy–sell and turnkey, we find that a CM with low component price is better off under turnkey, even though under buy–sell he receives more profits through the products sold to the smaller OEM. Furthermore, the larger OEM's preference between buy–sell and turnkey depends on her component price, the volatility of the CM's component price and substitutability between the two products.", "e:keyword": ["Buy–sell", "Price masking", "Turnkey", "Information asymmetry"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01328.x", "e:abstract": "There exist capital constraints in many distribution channels. We examine a channel consisting of one manufacturer and one retailer, where the retailer is capital constrained. The retailer may fund its business by borrowing credit either from a competitive bank market or from the manufacturer, provided the latter is willing to lend. When only one credit type (either bank or trade credit) is viable, we show that trade credit financing generally charges a higher wholesale price and thus becomes less attractive than bank credit financing for the retailer. When both bank and trade credits are viable, the unique equilibrium is trade credit financing if production cost is relatively low but is bank credit financing otherwise. We also study the case where both the retailer and the manufacturer are capital constrained and demonstrate that, to improve the overall supply chain efficiency, the bank should finance the manufacturer if production cost is low but finance the retailer otherwise. Our analysis further suggests that the equilibrium region of trade credit financing shrinks as demand variability or the retailer's internal capital level increases.", "e:keyword": ["Capital constraint", "Distribution channel", "Financing", "Trade credit"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01329.x", "e:abstract": "High technology organizations need to develop new products or processes that address the dual goals of exploration and exploitation. The competing viewpoints and the asymmetric nature of market returns associated with these goals in R&D projects can heighten stress levels among project team members and reduce their psychological safety. While current research calls for greater focus on task design for improving psychological safety, we know little about how team contextual factors affect this relationship. This study develops and tests a conceptual framework that examines the moderating role of R&D team contextual factors, namely, relative exploration and project-organization metric alignment on the relationship between a key task design variable, namely, team autonomy, and psychological safety. Relative exploration captures the extent to which exploration goals are emphasized over exploitation goals in an R&D project, while project-organization metric alignment measures the extent to which project metrics are aligned with broader organizational metrics. Furthermore, we examine the performance consequences of psychological safety in R&D projects. The empirical analysis is conducted using primary data collected from multiple informants across 110 R&D projects in 34 high technology business units. Our results indicate that relative exploration and project-organization metric alignment have contrasting moderating effects. Furthermore, the effect of psychological safety on project performance is found to be indirect and mediated through team turnover. Implications of the study findings, limitations, and directions for future research are discussed.", "e:keyword": ["R&D project management", "Psychological safety", "Exploration", "Exploitation", "Team turnover"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01330.x", "e:abstract": "Most models of product reuse do not consider the fact that firms might be required to innovate their products over time in order to continue to appeal to the tastes of customers. We consider how the rate of this required innovation, which might be fast or slow depending on the product, affects reuse decisions. We consider two types of reuse—remanufacturing to original specifications, and upgrading used items by replacing components that have experienced innovation since the item was originally produced. We find that optimal reuse decreases with the rate of innovation, implying that models that ignore innovation overestimate the optimal amount of reuse that a company should pursue. Furthermore, we show that reuse can be encouraged in two ways—the intuitive approach of increasing end-of-life costs, and the less intuitive approach of raising the cost to make items reusable. We also examine the environmental impact of reuse, measured in terms of virgin material usage, finding that reuse can actually increase total virgin material usage in some cases. In an extension, we show how the results and insights change when the rate of innovation is uncertain.", "e:keyword": ["Innovation", "Reusability", "Product design", "Remanufacturing", "Upgrading"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01331.x", "e:abstract": "Technology entrepreneurship is an important driver of economic growth, although entrepreneurs must maintain cooperative ties with the owners of any technology they hope to bring to market. Existing studies show that fairness perceptions have a great influence on this cooperation, but no research investigates its precise mechanisms or dynamic patterns. This study explores the development of 17 ventures that cooperated with a university-owner of technology and thereby identifies different cooperation patterns in which fairness perceptions influence the degree of cooperation. These perceptions also change over time, partly as a function of accumulated experience and learning. A system dynamics model integrates insights from existing literature with the empirical findings to reveal which cooperation mechanisms relate to venture development over time; the combinations of individual experience, fairness perceptions, and market circumstances lead to four different patterns. This model can explain changes in entrepreneurial cooperation as a result of changes in fairness perceptions, which depend on learning effects and entrepreneurial experience. Each identified cooperation pattern has implications for research and offers insights for practitioners who need to manage relationships in practice.", "e:keyword": ["Technology commercialization", "Cooperation", "System dynamics", "Fairness", "Spin‐offs"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01332.x", "e:abstract": "Online marketplaces, such as those operated by Amazon, have seen rapid growth in recent years. These marketplaces serve as an intermediary, matching buyers with sellers, whereas control of the good is left to the seller. In some cases, e.g., the Amazon marketplace system, the firm that owns and manages the marketplace system will also sell competing products through the marketplace system. This creates a new form of channel conflict, which is a focus of this article. We consider a setting in which a marketplace firm operates an online marketplace through which retailers can sell their products directly to consumers. We consider a single retailer, who currently sells its product only through its own website, but who may choose to contract with Amazon to sell its product through the marketplace system. Selling the product through the marketplace expands the available market for the retailer, but comes at some expense, e.g., a fixed participation fee or a revenue sharing requirement. Thus, a key question for the retailer is whether she should choose to sell through the marketplace system, and if so, at what price. We analyze the optimal decisions for both the retailer and the marketplace firm and characterize the system equilibrium.", "e:keyword": ["e‐Business", "Online marketplace", "Coordination", "Competition", "Game theory"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01333.x", "e:abstract": "This paper focuses on the issues of coalition formation and cost allocation in a joint replenishment system involving a set of independent and freely interacting retailers purchasing an item from one supplier to meet a deterministic demand. The papers dealing with this problem are mainly focused on supperadditive games, where the cost savings associated with a coalition increase with the number of players in the coalition. The most relevant question addressed then is how to allocate the savings to the players. In this paper, we propose to go further by dealing with a non-supperadditive game, where a set of independent retailers have the common understanding to share the cost savings according to the cost-based proportional rule. In this setting, the global cost optimization is no longer a relevant approach to identify appealing coalitions for any retailer. Here, we provide an iterative procedure to form the so-called efficient coalition structure and we show that this coalition structure has the nice properties of being (i) weakly stable in the sense of the coalition structure core and (ii) strongly stable under a given assumption. An exact fractional programming based solution is also given to generate such efficient coalitions.", "e:keyword": ["Joint replenishment", "Cooperative game theory", "Proportional allocations", "Coalition formation", "Coalition structure core", "Fractional programming"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01337.x", "e:abstract": "We synthesize research from operations management, entrepreneurship, organizational science, and strategy to investigate the performance-enhancing benefits of knowledge management activities throughout the entrepreneurial process of a high-tech venture from idea conception to commercialization. We adopt a dynamic learning perspective of entrepreneurship to understand how knowledge management activities change throughout four phases of the venture's life cycle. We introduce a framework that identifies a set of knowledge-based capabilities that enhance the entrepreneurial venture's success. In the context of the first phase, we discuss knowledge as a key driver of entrepreneurial alertness and creativity, both of which impact the quality and quantity of opportunities and innovations discovered. Second, we describe how knowledge enables the entrepreneur to make decisions under uncertainty such as determining which opportunity to pursue. For Phase 3 of the life cycle, we explore the challenges of managing knowledge during the development of the product or technology including the trade-off between exploration and exploitation. In the final phase, we explore how knowledge impacts the market entry decision, survival, and the value captured at commercialization. We conclude the article with suggestions for future research.", "e:keyword": ["Entrepreneurship", "Knowledge management", "Venture life cycle"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01339.x", "e:abstract": "This article studies a three-layer supply chain where a manufacturer sells a product through a reseller who then relies on its own salesperson to sell to the end market. The reseller has superior capability in demand forecasting relative to the manufacturer. We explore the main trade-offs between the risk-reduction effect and the information–asymmetry–aggravation effect of the improved forecasting accuracy. We show that under the optimal wholesale price contract, both the manufacturer and the reseller are always better off as the reseller's forecasting accuracy improves. Nevertheless, under the menu of two-part tariffs, the manufacturer prefers the reseller to be either uninformed or perfectly informed about the market condition. We further find that the improved forecasting accuracy is beneficial for the reseller if its current forecasting system is either very poor or very good.", "e:keyword": ["Forecasting accuracy", "Multi‐tier channel", "Mechanism design", "Salesforce compensation"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01344.x", "e:abstract": "Many emerging entrepreneurial applications and services connect two or more groups of users over Internet-based information technologies. Commercial success of such technology products requires astute business practices related to product line design, price discrimination, and launch timing. We examine these issues for a platform firm that serves two markets—labeled as user and developer markets—such that the size of each market positively impacts participation in the other. In addition, our model allows for sequential unfolding of consumer and developer participation, and for uncertainty regarding developer participation. We demonstrate that product versioning is an especially attractive strategy for platform firms, that is, the trade-off between market size and margins is tilted in the direction of more versions. However, when expanding the product line carries substantial fixed costs (e.g., marketing cost, cost of additional plant, increased distribution cost), then the uncertainty in developer participation adversely impacts the firm's ability to offer multiple versions. We show that for established firms with lower uncertainty about developer participation, the choice is essentially between an expanded or minimal product line. Startups and firms that are entering a new product category are more likely to benefit from a “wait and see” deferred expansion strategy.", "e:keyword": ["Technology commercialization", "Product launch strategy", "Platform technology", "Versioning", "Uncertainty"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01347.x", "e:abstract": "Diverting large quantities of goods from authorized distribution channels to unauthorized or “gray market” channels, albeit legal, significantly affects both firms and consumers due to effects on price, revenue, service and warranty availability, and product availability. In this paper we consider mechanisms by which the uncertainty surrounding inventory ordering decisions drives gray markets. We start with a minimal stochastic supply chain model composed of a producer and a retailer; then we restructure the model to add a distributor whereby the distributor and authorized retailer have the option of diverting inventory to a gray market. Our analysis sheds light on three issues: impacts of diversion on the various supply chain participants, strategies producers could use to combat or exploit gray markets, and important considerations for authorized retailers trying to set optimal order quantities in the presence of a gray market. Our analysis yields new insights into the behavior and impact of gray markets, which can inform management strategies and policies for confronting them.", "e:keyword": ["Distribution channels", "Decisions under uncertainty", "Retailing and wholesale", "Gray markets"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01352.x", "e:abstract": "We consider settings in which a revenue manager controls bookings over a sequence of flights. The revenue manager uses a buy-up model to select booking limits and updates estimates of the model parameters as data are accumulated. The buy-up model we consider is based upon a simple model of customer choice, wherein each low-fare customer who is not able to purchase a low-fare ticket will, with a fixed probability, “buy up” to the high fare, independent of everything else. We analyze the evolution of the parameter estimates (e.g., the buy-up probability) and chosen booking limits in situations where the buy-up model is misspecified, that is, in situations where there is no setting of its parameters for which its objective function gives an accurate representation of expected revenue as a function of the booking limit. The analysis is motivated by the common situation in which a revenue manager does not know precisely how customers behave but nevertheless uses a parametric model to make decisions. Under some assumptions, we prove that the booking limits and parameter estimates converge and we compare the actual expected revenue at the limiting values with that associated with the booking limits that would be chosen if the revenue manager knew the actual behavior of customers. The analysis shows that the buy-up model often works reasonably well even when it is misspecified, and also reveals the importance of understanding how parameter estimates of misspecified models vary as functions of decisions.", "e:keyword": ["Revenue management", "Yield management", "Choice Models", "Misspecification"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01353.x", "e:abstract": "Improvements in information technologies provide new opportunities to control and improve business processes based on real-time performance data. A class of data we call individualized trace data (ITD) identifies the real-time status of individual entities as they move through execution processes, such as an individual product passing through a supply chain or a uniquely identified mortgage application going through an approval process. We develop a mathematical framework which we call the State-Identity-Time (SIT) Framework to represent and manipulate ITD at multiple levels of aggregation for different managerial purposes. Using this framework, we design a pair of generic quality measures—timeliness and correctness—for the progress of entities through a supply chain. The timeliness and correctness metrics provide behavioral visibility that can help managers to grasp the dynamics of supply chain behavior that is distinct from asset visibility such as inventory. We develop special quality control methods using this framework to address the issue of overreaction that is common among managers faced with a large volume of fast-changing data. The SIT structure and its associated methods inform managers on if, when, and where to react. We illustrate our approach using simulations based on real RFID data from a Walmart RFID pilot project.", "e:keyword": ["Supply chain behavior visibility monitoring"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01354.x", "e:abstract": "Explicit formal mechanisms dominate the discussion about incentives in Operations Management, yet many other mechanisms exist. Social comparison between peers may provide strong implicit incentives for individuals. Social comparison arises naturally in all social settings and may thus be unintended; however, many companies deliberately use it to motivate employees. In this study, we model a social context in which purchasers evaluate their performance relative to their peers; a feeling of inferiority results in a negative contribution to utility, whereas a feeling of superiority results in a positive contribution. We find that social comparison induces characteristic deviations from the newsvendor optimum ordering decision: if fear of inferiority outweighs anticipation of superiority, then purchasers herd together; the converse scenario incites actors to polarize away from each other. In both cases, actors will deviate from ordering the newsvendor optimum in order to satisfy social goals. Demand correlation and profit margins moderate the extent of the deviation.", "e:keyword": ["Purchasing", "Organizing purchasing", "Newsvendor", "Social comparison"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01355.x", "e:abstract": "We consider the allocation of limited production capacity among several competing agents through auctions. Our focus is on the contribution of flexibility in market good design to effective capacity allocation. The application studied is a capacity allocation problem involving several agents, each with a job, and a facility owner. Each agent generates revenue by purchasing capacity and scheduling its job at the facility. Ascending auctions with various market good designs are compared. We introduce a new market good that provides greater flexibility than those previously considered in the literature. We allow ask prices to depend both on agents’ utility functions and on the number of bids at the previous round of the auction, in order to model and resolve resource conflicts. We develop both optimal and heuristic solution procedures for the winner determination problem. Our computational study shows that flexibility in market good design typically increases system value within auctions. A further increase is achieved if each agent is allowed to bid for multiple market goods at each round. On average, the multiple flexible market goods auction provides over 95% of the system value found by centralized planning.", "e:keyword": ["Noncooperative game", "Auction", "Market good flexibility", "Capacity allocation"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01357.x", "e:abstract": "In a controlled field experiment, we examine pairs of auctions for identical items under different conditions. We find that auction design features that are under the control of the auctioneer—including information transparency, number of simultaneous auctions, and the degree of overlap between simultaneous auctions—affect bidder search and choice. Clickstream data show that a significant relationship between information transparency and price dispersion can be linked to search. Specifically, the effect of information transparency on price dispersion is fully mediated by lookup behavior. Combining these findings, we make auction design recommendations regarding the provision of product and value information.", "e:keyword": ["Auctions", "Field experiments", "Search", "Clickstream data"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01363.x", "e:abstract": "Failure modes and effects analysis (FMEA) is one of the most frequently used tools in process and product design: it is used in quality and reliability planning, and event and failure mode analysis. It has a long history of use and is a formally prescribed procedure by a number of prominent standards organizations. In addition, it's popular use has evolved as a less formal and widely interpreted tool in the area of Lean/Six Sigma (LSS) process improvement. This paper investigates one of the most important issues related to FMEA practice—the quality of individual vs. group performance in ranking failure modes. In particular, we compare FMEA rankings generated by: (i) individuals, (ii) group consensus, and (iii) non-collaborative aggregation of group input (a synthesized group ranking). We find that groups outperform individuals and that synthetic groups perform as well as group consensus. We explain the implications of this result on the coordination of the design of products and processes amongst distributed organizations. The increasing distribution of product design efforts, both in terms of geography and different organizations, presents an opportunity to improve coordination using distributed synthetic group-based FMEA.", "e:keyword": ["FMEA", "Risk analysis", "Virtual groups", "Product design", "Distributed product development"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01365.x", "e:abstract": "We experimentally study the role of reputation in procurement using two common mechanisms: price-based and buyer-determined auctions. While buyers are bound to buy from the lowest bidder in price-based auctions, they can choose between bidders in buyer-determined auctions. Only the latter buyers can consider the reputation of bidders. We find that bidders supply higher quality in buyer-determined auctions leading to higher market efficiencies in these auctions. Accordingly, buyers prefer the buyer-determined auction over the price-based auction, while only half of the bidders do so. A more detailed analysis of buyers' and bidders' behavior and profits provides insights into their mechanism choice.", "e:keyword": ["Buyer‐determined and price‐based procurement", "Supplier reputation", "Auction choice", "Experimental economics"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01366.x", "e:abstract": "The impact of information technology (IT) on the performance of distributed projects is not well understood. Although prior research has documented that dispersion among project teams has an adverse effect on project performance, the role of IT as an enabler of communication to bridge the spatial distance among team members in distributed networks has not been empirically studied. We focus on the role of IT as a moderator of the relationship between team dispersion and project performance using projects as the unit of analysis. We find that IT mitigates the negative effect of team dispersion on project performance, especially in high information volume projects. Our central contribution is the development of an empirically tested model to improve the understanding of the operational impact of IT as a vehicle to bridge spatial dispersion among distributed teams that are engaged in knowledge-intensive work.", "e:keyword": ["Team dispersion", "Information technology", "Project performance", "Moderation", "Project management"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01367.x", "e:abstract": "Open innovation, fuelled by the rise of the Internet, has made it feasible and cheaper for firms to open themselves up to a wide range of external sources of innovative ideas. The explosive growth of open innovation intermediary networks, such as InnoCentive or Linked-in, enables the rapid pairing of firms seeking knowledge to address a wide range of business challenges (seekers) with other firms or individuals who already have relevant knowledge (solvers or knowledge brokers). These intermediary networks allow procurement departments to source codified and un-codified knowledge from firms or individuals outside their traditional supplier networks using one-off transactional relationships. Although sourcing ideas in this way theoretically poses problems for knowledge search and transfer, we have found that companies can draw on processes and integration mechanisms developed by procurement and design engineering to develop effective organizational learning routines. These routines are strategically vital to source new ideas through open innovation using intermediary networks and create competitive advantage.", "e:keyword": ["Open innovation", "Intermediary networks", "Procurement", "Supply chain management"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01368.x", "e:abstract": "Despite the widely held belief of the importance of innovation, the connection between innovation and firm performance is empirically inconclusive, partially owing to the limitations of existing innovation measures, which tend to ignore the effectiveness of innovation programs. In this study, we use the winning of innovation awards as a proxy for the effective execution of innovation. We conducted event-study analyses based on data from more than 1000 publicly traded firms that won innovation awards between 1998 and 2003. Our statistical tests provide strong evidence that the performance of award-winning firms is significantly higher as compared with several sets of control firms. Over an 8-year period, starting from 4 years before to 3 years after the year of winning the first innovation award, the test sample's mean (median) change in return on assets is nearly 33% (24%) higher than that of a control sample. The evidence also suggests that effective innovation programs can increase firms' revenue, cost efficiency, and market valuation. Over the period, the control-adjusted mean (median) change in sales, cost per dollar of sales, and Tobin's Q are 39.28% (20.71%), −5.52% (−3.80%), and 23.70% (3.16%), respectively. Panel data regression analysis provides additional insights on the performance impact of effective innovation programs. The results show that award winners are not only financially more successful but also enjoy an indirect benefit through better R&D execution, which increases firm profitability in both the short term and long term.", "e:keyword": ["Innovation awards", "Effective innovation programs", "Operational and financial performance", "Empirical analysis"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01369.x", "e:abstract": "We study sourcing and pricing decisions of a firm with correlated suppliers and a price-dependent demand. With two suppliers, the insight—cost is the order qualifier while reliability is the order winner—derived in the literature for the case of exogenously determined price and independent suppliers, continues to hold when the suppliers' capacities are correlated. Moreover, a firm orders only from one supplier if the effective purchase cost from him, which includes the imputed cost of his unreliability, is lower than the wholesale price charged by his rival. Otherwise, the firm orders from both. Furthermore, the firm's diversification decision does not depend on the correlation between the two suppliers' random capacities. However, its order quantities do depend on the capacity correlation, and, if the firm's objective function is unimodal, the total order quantity decreases as the capacity correlation increases in the sense of the supermodular order. With more than two suppliers, the insight no longer holds. That is, when ordering from two or more suppliers, one is the lowest-cost supplier and the others are not selected on the basis of their costs. We conclude the paper by developing a solution algorithm for the firm's optimal diversification problem.", "e:keyword": ["Supply diversification", "Responsive pricing"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01370.x", "e:abstract": "Modular design allows several generations of products to co-exist in the installed base as product designs change to take advantage of improved performance via modular upgrades. Use of a common base platform and modular design approach allows a firm to offer updates for improved performance and flexibility via remanufacturing when products have multiple lifecycles. However, as the product evolves through multiple lifecycles, the large pool of product variants leads to the curse of product proliferation. In practice, product proliferation causes high levels of line congestion and results in longer lead times, higher inventory levels, and lower levels of customer service. To offer insights into the product proliferation problem, the authors employ a delayed differentiation model in a multiple lifecycle context. The delayed differentiation model gives flexibility to balance trade-offs between disassembly and reassembly costs by adaptively changing the push-pull boundary. An adaptive, evolving push-pull boundary provides flexibility for a remanufacturing firm to meet changing customer demands. The delayed differentiation model includes both a mixed-integer linear program and an analytical investigation of the evolutionary nature of the push-pull boundary. Both field observations and experimental results show that the nature of product proliferation and changing demand structures play significant roles in the cost and flexibility of the evolving delayed differentiation system.", "e:keyword": ["Multiple lifecycle", "Delayed differentiation", "CLSC", "Modular design", "Remanufacturing"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01372.x", "e:abstract": "The use of screening contracts is a common approach to solve supply chain coordination problems under asymmetric information. One main assumption in this context is that managers without specific incentives would rather use their private information strategically than reveal it truthfully. This harms supply chain performance. This study investigates the impact of information sharing in a principal-agent setting that is typical for many supply chain transactions. We conduct a laboratory experiment to test whether information sharing has an influence on supply chain coordination. We find that information sharing within the supply chain has two positive effects. First, information sharing reduces the inefficiencies resulting from information deficits if there is a certain amount of trust in the supply chain. Second, communication can limit out-of-equilibrium behavior with a small impact on the firm's own payoff, but a large impact on the supply chain partner. Furthermore, we find that both effects are amplified when communication takes place in an environment that allows the less informed supply chain party to punish or to reward the better informed party. Although our extended mechanisms substantially enhance the poor performance of the theoretically optimal coordination contract menu, we find no mechanism that implements supply chain performance superior to the theoretically predicted second-best level.", "e:keyword": ["Cheap talk", "Experimental economics", "Principal‐agent theory", "Screening contracts", "Supply chain coordination"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01373.x", "e:abstract": "Consider a supply chain with one supplier and multiple retailers. The supplier produces a single product and sells it to the retailers, who in turn sell the product to consumers. The supplier has limited production capacity, and the retailers are engaged in a Cournot competition at the consumer/market level. When the sum of the retailer orders exceeds the capacity, the supplier allocates her capacity according to a pre-announced allocation mechanism. Two mechanisms are considered: proportional allocation and lexicographic allocation. An extensive study of the two allocation mechanisms shows that the lexicographic mechanism has the ability to dampen the competition at the retail level, increasing the profits for both the supplier and the supply chain.", "e:keyword": ["Supply chains", "Retail competition", "Capacity allocation", "Proportional mechanism", "Lexicographic mechanism", "Equilibrium analysis", "Wholesale pricing"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01376.x", "e:abstract": "Although project portfolio management has been an active research area over the past 50 years, budget allocation models that consider competition are sparse. Faced with the competition, firms contemplating budget allocation for their project portfolio cannot limit their attention to the returns from their projects' target markets, as is the case for monopoly firms, but must also anticipate the competitive effects on these returns. Assuming firms allocate their budgets between projects offering incremental innovation targeting a mature market and projects offering radical innovation targeting an emerging market, we show that while the monopoly firm bases its budget allocation decision solely on the marginal returns of the markets, competing firms—as they take into account their counterparts' investment decisions—need to also consider the projects' average returns from their respective markets. This drives competing firms into incrementalism: faced with competition, firms invest larger portions of their budgets into projects targeting mature markets. This effect is amplified as the number of competing firms increases and firms allocate an even greater share of their budget into projects targeting a mature market. We further demonstrate the effects that changes to firms' individual budgets, as well as to market characteristics, have on firms' budget allocation decision.", "e:keyword": ["Project portfolio management", "Resource allocation", "R&D investments", "Game theory", "Competition"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01377.x", "e:abstract": "This study addresses the challenges of finding and implementing profitable energy efficiency (EE) projects, a critical foundation for sustainable operations. We focus on manufacturing enterprises, but many of our findings apply also to the back office of service operations. Our starting point is that, in nearly every industrial enterprise, there are many profitable EE projects that could be implemented but are not. An oft-cited hindrance to implementation is the lack of an internal management framework in which to find, value, and execute these projects. Using a conceptual approach, we rely on proven sustainable operations tools to develop such a framework. We identify three major value drivers of EE projects: savings intensity, “green” image, and project complexity. We then describe a framework for understanding the context of EE projects in industry, with an underlying analytic foundation in optimal portfolio analysis. A case study of a large manufacturing site is used to illustrate emerging best practices—based on Kaizen management principles—for integrating EE project management with operations, engineering, and strategy.", "e:keyword": ["Sustainable operations", "Energy efficiency", "Kaizen", "Carbon footprinting"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01378.x", "e:abstract": "", "e:keyword": []}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01382.x", "e:abstract": "This study examines the effect that verbal scripts have on customer perceived service quality for two distinct service process types. We designed a video experiment that varied the level of verbal scripting for standardized and customized service encounters. We found that in standardized service encounters, an increase in the level of verbal scripting had no effect on perceived service quality. However, for customized encounters, perceived service quality was impacted. More specifically, a predominantly scripted encounter for customized service processes, on average, resulted in the lowest perception of service quality by respondents. Since verbal scripting was shown to impact customer perceptions of service quality, we suggest that a service provider's decision regarding the degree of verbal scripting is an important service design consideration.", "e:keyword": ["Service script", "Service design", "Service quality", "Service encounter", "Video experiment"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01383.x", "e:abstract": "Collaboration is an essential element of new product development (NPD). This research examines the associations between four types of information technology (IT) tools and NPD collaboration. The relationships between NPD practices and NPD collaboration are also examined. Drawing on organizational information processing theory, we propose that the relationships between IT tools and NPD collaboration will be moderated differently by three project complexity dimensions, namely, product size, project novelty, and task interdependence, due to the differing nature of information processing necessitated by each project complexity dimension. Likewise, the moderation effects of the project complexity dimensions on the relationship between NPD practices and NPD collaboration will also be different. We test our hypotheses using data from a sample of NPD projects in three manufacturing industries. We find that IT tools are associated with collaboration to a greater extent when product size is relatively large. In contrast, IT tools exhibit a smaller association with collaboration when project novelty or task interdependence is relatively high. NPD practices are found to be more significantly associated with NPD collaboration under the contingency of high project novelty or high task interdependence. The findings provide insights about circumstances where several popular IT tools are more likely to facilitate collaboration, thus informing an NPD team's IT adoption and use decisions.", "e:keyword": ["Collaboration", "Product development", "Information technology", "NPD practices", "Project complexity"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01384.x", "e:abstract": "In this article, we study behavior in a series of two-player supply chain game experiments. Each player simultaneously chooses a capacity before demand is realized, and sales are given by the minimum of realized demand and chosen capacities. We focus on the differences in behavior under fixed pairs and random rematching. Intuition suggests that long-run relations should lead to more profitable outcomes. However, our results go against this intuition. While subjects' capacity choices are better aligned (i.e., closer together) under fixed pairs, average profits are more variable. Moreover, learning is slower under fixed pairs—so much so that over the last five periods, average profits are actually higher under random rematching. The underlying cause for this finding appears to be a “first-impressions” bias, present only under fixed matching, in which the greater the misalignment in initial choices, the lower are average profits.", "e:keyword": ["Long‐run relationships", "Coordination", "Supply chains", "Experiment"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01386.x", "e:abstract": "Click tracking is gaining in popularity, and the practice of web analytics is growing fast. Whether strategic customers are willing to visit a website when they know their clicks may be tracked is an important yet complex problem, which depends on various factors. Using a newsvendor framework, we examine this problem by focusing on the operational factor: how product availability induces strategic customers to voluntarily provide advance demand information. We find that a strong Nash equilibrium exists where every customer is willing to click, and customer incentives to click are robust to noise. Hence, we demonstrate the promise of strategic customer behavior in the context of click tracking, contrary to the conventional wisdom that it is typically a peril for the firm. Notably, click tracking is typically advantageous to both the firm and its customers, compared with other strategies such as advance selling, quantity commitment, availability guarantees, and quick response. Lastly, we extend to two settings by including marketing decisions, price-sensitive demand and markdown pricing, and discuss how operations and marketing decisions interact in influencing the value of click tracking.", "e:keyword": ["Click tracking", "Customer behavior", "Advance demand information", "Game theory"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01387.x", "e:abstract": "We study the stock market reaction to announcements of global green vehicle innovation over a 14-year time span (1996–2009) using the event study methodology. We document that the stock market generally reacts positively to automakers' announcements of environmental innovations, consistent with prior research on the wealth effects of innovation announcements. Our results indicate that crucial green product development decisions such as innovation type and market segment choices exert direct influence on a firm's market value. These results hold after controlling for firm size, leverage, profitability, R&D intensity, and oil price changes.", "e:keyword": ["Automobile industry", "Corporate sustainability", "Event study", "Green innovation", "New product development"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01388.x", "e:abstract": "This article studies the performance of wholesale pricing when the supply chain partners' fairness concerns are private information. We find that some properties of wholesale pricing established under complete information hold under incomplete information as well. First, wholesale pricing can coordinate the supply chain, despite the information asymmetry, when fairness concerns are strong enough. Second, in the case when an equitable profit split does not imply that the retailers profit must be higher than that of the supplier, the suppliers' equilibrium offer is never rejected. Overall, the study makes two primary contributions. First, it provides a partial characterization of the equilibrium when the conditions required for coordination do not hold, that is, when fairness concerns are mild. In this case, the model predicts that the expected market price must be exactly the same as under complete information. The channel efficiency, nevertheless, is strictly lower than under complete information. The distribution-free lower bound on channel efficiency suggests that this efficiency loss should be quite small, though. Second, it provides an experimental test of the models' predictions as well as a direct validation of the assumptions of preferences heterogeneity and mildness by obtaining the empirical distribution of the preferences.", "e:keyword": ["Fairness", "Preferences heterogeneity", "Supply chain coordination", "Wholesale pricing", "Behavioral operations"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01390.x", "e:abstract": "An important difference between both manufacturing and wholesaling vs. retail is the information available concerning inventory. Typically, far less information characterizes retail. Here, an extreme environment of information shortfall is examined. The environment is technically termed “unattended points of sale,” but colloquially called vending machines. Once inventory is loaded into a machine, information on demand and inventory level is not observed until the scheduled reloading date. Technological advances and business process changes have drawn attention to the value of information (VOI) in retail inventory in many venues. Moreover, technology is now available that allows unattended points of sale to report inventory information. Capturing the value of this information requires changes in current business practice. We demonstrate the value of capturing information analytically in an environment with restrictive demand assumptions. Experiments in an environment with realistic demand assumptions and parameter values show that the VOI depends greatly on operating characteristics and can range from negligible effects to increasing profitability 30% or more in actual practice.", "e:keyword": ["Retail", "Value of information", "Vending machines", "Inventory management"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01391.x", "e:abstract": "In this article, we study the price partitioning decisions of online retailers regarding shipping and handling (S&H) fees. Specifically, we analyze two partitioning formats used by retailers in this context. In the first scenario, retailers present customers with a price that is partitioned into a product price and a separate S&H surcharge (the PS strategy); in the second, customers are offered free shipping through a non-partitioned format where the product price already includes the shipping cost (the ZS strategy). We first develop a stylized game-theoretic model that captures the competitive dynamics between (and within) these two formats. Analysis of the model provides insights into how both firm and product level characteristics drive a retailer's strategic choice regarding which partitioning format to adopt and, hence, determines the equilibrium market structure in terms of proportion of ZS and PS retailers. Subsequently, we conduct empirical analyses, based on product and S&H prices data for two different product categories (digital cameras and printers) collected from online retailers, to validate all the results of our theoretical model. We establish that PS retailers charge lower product prices than ZS ones, but the total price (product + S&H) charged is higher for the first group. The S&H charge for PS retailers can be significant—it is, on average, 5.4% (printers) and 3.0% (digital cameras) for our two product categories. Furthermore, retailers which are popular and/or face risky cost environment are more likely to opt for the ZS strategy, while retailers whose portfolio mostly includes large or heavy products with high cost (S&H)-to-price ratios usually choose the PS strategy. Lastly, our empirical study also illustrates that the price adjustment behavior of retailers is affected by their shipping-fee policies—for example, ZS retailers change their product prices almost 1.5 times more frequently than PS ones.", "e:keyword": ["Retail", "E‐commerce pricing strategy", "Price partitioning", "Free shipping", "Shipping and handling costs"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01392.x", "e:abstract": "There is a growing trend in the retail industry to improve customer experience. In this article, we study retailer-initiated strategies to increase consumer valuation for a product under duopoly. In such a setting, it is possible that a consumer's valuation may be increased by one retailer; however, the consumer may decide to buy the product from the competitor. We consider a two-stage game where retailers first decide whether to invest in improvements in customer valuation and then engage in price competition. We computationally explore the Nash equilibria in terms of both investment and pricing. We find that in the majority of cases retailers price in a manner to discourage their local customers to buy from the competitor. Next, we focus on the pricing game and theoretically characterize the pricing Nash equilibrium. We find that a retailer could overcome competitive effects by improving consumer valuation beyond a certain threshold. We also find that a retailer who does not invest could benefit from competition in situations where his competitor increases consumer valuation beyond a threshold. Finally, we explore through a computational study the Nash equilibria of the two-stage game using an alternate model to establish the robustness of our findings.", "e:keyword": ["Retail operations", "Consumer valuation", "Consumer search", "Free riding"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01393.x", "e:abstract": "Traditional inventory models fail to take into account the dynamics between the retail sales floor and the backroom, commonly used by retailers for extra storage. When a replenishment order for a given item arrives at a retail store, it may not fit on the allocated shelf space, making backroom storage necessary. In this article, we introduce the backroom effect (BRE) as a consequence of misalignment of case pack size, shelf space, and reorder point. This misalignment results from the fragmented nature of inventory policy decision making in the retail industry and affects basic trade-offs in inventory models. We specify conditions under which the BRE exists, quantify the expected amount of backroom inventory, derive an optimal short-term inventory policy, and assess the impact of the BRE on the optimal inventory policy and total costs. Our results indicate that ignoring the BRE leads to artificially high reorder points and higher total costs. The paper concludes with a discussion of theoretical and managerial implications.", "e:keyword": ["Backroom effect", "Case pack quantity", "Reorder point", "Inventory management", "Retail operations"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01410.x", "e:abstract": "To achieve technology innovation and commercialization (TIC) success under complex, protracted, and uncertain product development cycles, entrepreneurial firms engage in downstream alliance partnerships with mainstream industry players. In this study, we examine two specific characteristics of the entrepreneurial firm's downstream alliance portfolio (depth and scope) and their impact on TIC success. Employing a sample of 728 biotech firms and their partnerships with pharmaceutical companies, we find that while portfolio depth and scope separately have positive impact on success, the relationship between portfolio scope and success is additionally moderated by portfolio depth. Further, insights from post hoc interviews also suggest that though it is challenging for entrepreneurial firms to incorporate both depth and scope in alliance partnerships, those that optimally combine both can achieve higher TIC success.", "e:keyword": ["Technology commercialization success", "Alliance portfolio", "Depth and scope", "Biotech industry"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01411.x", "e:abstract": "We consider a setting of two firms and one capacity agent. Each firm serves a primary market, and the capacity agent sustains a common market to draw demand for capacity from the external firms. The firms can partner with the capacity agent under her contract to serve the common market. When they use the common market mainly as an outlet for their unused capacities, the capacity agent will only specify a variable fee for each capacity unit deployed through her, and prefer to partner with one firm in most circumstances. When the firms adjust capacities to accommodate the businesses created by serving the common market, the capacity agent will specify a lump-sum payment and a variable fee, and will be more likely to incentivize only one firm to partner with her, when the common market is sufficiently large or the demands in the common and primary markets are strongly correlated. She will always use a fixed fee to extract, while not necessarily all, the profit gains to the firms serving the common market, but will use a variable fee only when partnering with both firms. The key results are robust with respect to market configuration and contract type.", "e:keyword": ["Supply chain management", "Capacity agent", "Market equilibrium", "Contract design"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01412.x", "e:abstract": "This article examines the choice of pricing policy (posted pricing or negotiation) toward end customers in a supply chain. Many retailers actively decide whether or not to encourage negotiation on the shop floor. Of course, the retailer's pricing policy influences not only the retailer's profit, but also the profits of the manufacturers who sell through the retailer. However, little is known about the forces that shape the pricing policy when two self-interested parties interact in a supply chain. We consider two alternative models depending on who has the power to decide the pricing policy: the manufacturer or the retailer. We find that an increase in the wholesale price weakens the retailer's ability to price discriminate through negotiation. Therefore, the retailer prefers negotiation at lower wholesale prices and posted pricing at higher wholesale prices. We also find that whenever the retailer prefers negotiation, the manufacturer does too. Therefore, the retailer's discretion over the pricing policy causes friction only when the retailer wants to use posted pricing, while the manufacturer wishes the retailer to use negotiation. We show that such friction arises only when product availability or the cost of negotiation is moderate. In this case, we show that the manufacturer may offer a substantial discount to persuade the retailer to negotiate. Surprisingly, in this region of friction, a decrease in the supply chain's capacity or an increase in negotiation costs (both of which are typically considered as worsening the retailer's business environment) translates into higher profit for the retailer.", "e:keyword": ["Supply‐chain management", "Pricing", "Negotiation", "Retailing"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01415.x", "e:abstract": "We analyze the market entry problem faced by startups that must integrate their service or product with one or more complementary technologies. The problem is especially challenging when the complementary technologies have uncertain cost reduction potentials. The entrepreneurship literature suggests that startups should pursue focused strategies for various reasons, including bounded rationality and budget constraints, but generally overlooks startups entering markets with complementary technologies. The advice for mature firms investing in complementary technologies is often to diversify investment across multiple complements to manage technological uncertainty. Given competing guidance, we seek to extend the entrepreneurship literature by modeling startups' entry decisions for markets in which complementary technologies exhibit strong learning effects. We find that, consistent with the extant entrepreneurship literature, startups generally achieve higher expected returns by channeling their integration investment to only one complementary technology. However, the mechanisms driving our results differ significantly by hinging on nonlinear feedback effects that occur when firms concentrate integration investment in only one complementary technology. Interestingly, this focused strategy often does not yield the highest market share or the lowest likelihood of bankruptcy. We characterize the situations under which each finding holds and describe the implications of these findings for theory, practice, and policy.", "e:keyword": ["Startups", "Complementary technologies", "Integration", "Renewable energy", "System dynamics"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01416.x", "e:abstract": "This special issue contains articles that exemplify the role of operations management across the entrepreneurial value chain. This value chain encompasses all stages of the entrepreneurial phenomenon, including technology commercialization, where discovery, commitment, organization, and growth must take place. We report on a literature search that identifies research questions categorized with respect to topics crucial to operations management scholars and classify these questions under each stage of this value chain. The search guides the development of an evolutionary path for the use of resources, routines, and reputation (3Rs), often lacking in this process, and enables us to propose modeling and topical gaps in the literature. We offer a framework to set up exemplars for operational tradeoffs uniquely associated with the entrepreneurial value chain. We also articulate how five contributed articles in this issue tackle some of these tradeoffs, prior to introducing four perspective pieces. We hope this discussion motivates follow-on work and triggers a significant increase in the flow of articles that make it to both entrepreneurship and operations management top-tier academic and practitioner publications.", "e:keyword": ["Operations management", "Entrepreneurship", "Technology commercialization", "Discovery", "Commitment", "Organization", "Growth"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01417.x", "e:abstract": "We analyze contracting behaviors in a two-tier supply chain system consisting of competing manufacturers and competing retailers. We contrast the contracting outcome of a Stackelberg game, in which the manufacturers offer take-it-or-leave-it contracts to the retailers, with that of a bargaining game, in which the firms bilaterally negotiate contract terms via a process of alternating offers. The manufacturers in the Stackelberg game possess a Stackelberg-leader advantage in that the retailers are not entitled to make counteroffers. Our analysis suggests that whether this advantage would benefit the manufacturers depends on the contractual form. With simple contracts such as wholesale-price contracts, which generally do not allow one party to fully extract the trade surplus, the Stackelberg game replicates the boundary case of the bargaining game with the manufacturers possessing all the bargaining power. In contrast, with sophisticated contracts such as two-part tariffs, which enable full surplus extraction, the two games lead to distinct outcomes. We further show that the game structure being Stackelberg or bargaining critically affects firms' preferences over contract types and thus their equilibrium contract choices. These observations suggest that the Stackelberg game may not be a sufficient device to predict contracting behaviors in reality where bargaining is commonly observed.", "e:keyword": ["Bilateral bargaining", "Stackelberg game", "Competition", "Contracting"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01418.x", "e:abstract": "Using predictive global sensitivity analysis, we develop a structural equations model to abstract from the details of a large-scale mixed integer program (MIP) to capture essential design trade-offs of global manufacturing and distribution networks. We provide a conceptual framework that describes a firm's network structure along three dimensions: market focus, plant focus, and network dispersion. Normalized dependent variables are specified that act as proxies for a company's placement into our conceptual network classification via the calculation of just a few key independent variables. We provide robust equation sets for eight cost structure clusters. Many different product types could be classified into one of these groups, which would allow managers to use the equations directly without needing to run the MIP for themselves. Our numerical tests suggest that the formulas representing the network structure drivers—economies of scale, complexity costs, transportation costs, and tariffs—may be sufficient for managers to design their strategic network structures, and perhaps more importantly, to monitor them over time to detect potential need for adjustment.", "e:keyword": ["Global network design", "Plant location", "Structural equations modeling", "Supply chain management"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01419.x", "e:abstract": "In this note, we study the price-setting newsvendor problem. We use three conditions, the log-convexity of the coefficient of variation, the log-concavity of the deterministic profit function, and the log-convexity of the random noise's expectation conditional on having leftover inventory to establish the log-concavity of the retailer's expected profit function. This new result is complementary to existing results and removes some assumptions in the pricing and inventory coordination literature. It also addresses the conjecture made by Petruzzi and Dada (1999), and can be applied in the pricing game.", "e:keyword": ["Newsvendor with price effect", "Log‐concavity", "Pricing game"]}, {"@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01422.x", "e:abstract": "The bullwhip effect describes the tendency for the variance of orders in supply chains to increase as one moves upstream from consumer demand. We report on a set of laboratory experiments with a serial supply chain that tests behavioral causes of this phenomenon, in particular the possible influence of coordination risk. Coordination risk exists when individuals' decisions contribute to a collective outcome and the decision rules followed by each individual are not known with certainty, for example, where managers cannot be sure how their supply chain partners will behave. We conjecture that the existence of coordination risk may contribute to bullwhip behavior. We test this conjecture by controlling for environmental factors that lead to coordination risk and find these controls lead to a significant reduction in order oscillations and amplification. Next, we investigate a managerial intervention to reduce the bullwhip effect, inspired by our conjecture that coordination risk contributes to bullwhip behavior. Although the intervention, holding additional on-hand inventory, does not change the existence of coordination risk, it reduces order oscillation and amplification by providing a buffer against the endogenous risk of coordination failure. We conclude that the magnitude of the bullwhip can be mitigated, but that its behavioral causes appear robust.", "e:keyword": ["Bullwhip effect", "Behavioral operations", "Supply chain management", "Beer distribution game"]}, {"e:abstract": "This article studies a joint stocking and product offer problem. We have access to a number of products to satisfy the demand over a finite selling horizon. Given that customers choose among the set of offered products according to the multinomial logit model, we need to decide which sets of products to offer over the selling horizon and how many units of each product to stock so as to maximize the expected profit. We formulate the problem as a nonlinear program, where the decision variables correspond to the stocking quantity for each product and the duration of time that each set of products is offered. This nonlinear program is intractable due to its large number of decision variables and its nonseparable and nonconcave objective function. We use the structure of the multinomial logit model to formulate an equivalent nonlinear program, where the number of decision variables is manageable and the objective function is separable. Exploiting separability, we solve the equivalent nonlinear program through a dynamic program with a two dimensional and continuous state variable. As the solution of the dynamic program requires discretizing the state variable, we study other approximate solution methods. Our equivalent nonlinear program and approximate solution methods yield insights for good offer sets.", "e:volume": "22", "@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01423.x", "e:issue": "5", "e:keyword": ["Product variety", "Customer choice", "Assortment", "Multinomial logit"]}, {"e:abstract": "We consider the retail planning problem in which the retailer chooses suppliers and determines the production, distribution, and inventory planning for products with uncertain demand to minimize total expected costs. This problem is often faced by large retail chains that carry private-label products. We formulate this problem as a convex-mixed integer program and show that it is strongly NP-hard. We determine a lower bound by applying a Lagrangian relaxation and show that this bound outperforms the standard convex programming relaxation while being computationally efficient. We also establish a worst-case error bound for the Lagrangian relaxation. We then develop heuristics to generate feasible solutions. Our computational results indicate that our convex programming heuristic yields feasible solutions that are close to optimal with an average suboptimality gap at 3.4%. We also develop managerial insights for practitioners who choose suppliers and make production, distribution, and inventory decisions in the supply chain.", "e:volume": "22", "@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01424.x", "e:issue": "5", "e:keyword": ["Retailing", "Facility location", "Inventory management", "Stochastic demand", "Nonlinear integer programming"]}, {"e:abstract": "In the industry with radical technology push or rapidly changing customer preference, it is firms' common wisdom to introduce high-end product first, and follow by low-end product-line extensions. A key decision in this “down-market stretch” strategy is the introduction time. High inventory cost is pervasive in such industries, but its impact has long been ignored during the presale planning stage. This study takes a first step toward filling this gap. We propose an integrated inventory (supply) and diffusion (demand) framework and analyze how inventory cost influences the introduction timing of product-line extensions, considering substitution effect among successive generations. We show that under low inventory cost or frequent replenishment ordering policy, the optimal introduction time indeed follows the well-known “now or never” rule. However, sequential introduction becomes optimal as the inventory holding gets more substantial or the product life cycle gets shorter. The optimal introduction timing can increase or decrease with the inventory cost depending on the marketplace setting, requiring a careful analysis.", "e:volume": "22", "@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01425.x", "e:issue": "5", "e:keyword": ["New‐product introduction", "Inventory management", "Marketing and operations coordination", "Innovation diffusion"]}, {"e:abstract": "This note discusses the impact of collection cost structure on the optimal reverse channel choice of manufacturers who remanufacture their own products. Using collection cost functions that capture collection rate and collection volume dependency, we show that the optimal reverse channel choice (retailer- vs. manufacturer-managed collection) is driven by how the cost structure moderates the manufacturer's ability to shape the retailer's sales and collection quantity decisions.", "e:volume": "22", "@id": "http://dx.doi.org/10.1111/j.1937-5956.2012.01426.x", "e:issue": "5", "e:keyword": ["Closed‐loop supply chain", "Reverse logistics", "Remanufacturing", "Channel choice"]}, {"@id": "http://dx.doi.org/10.1111/poms.12000", "e:abstract": "We study the linkages between firm-level quality initiatives such as quality management systems (QMS) and total quality management (TQM) and output productivity in the Indian auto component industry. We use externally validated quality certification and quality awards as proxies for QMS and TQM, respectively, as it is difficult to directly measure the QMS and TQM efforts of firms. We use an unbalanced panel of 220 firms and a balanced panel of 73 firms from the Indian auto component industry over the period 1993–2006 to study these links. Both parametric as well as non-parametric approaches are used, as appropriate, to measure the rate of change in productivity and the impact of quality initiatives on productivity change during this period. We determine the proportion of productivity resulting from technical change and relative efficiency change, thus providing insights into the structure of productivity improvements. We find that TQM efforts resulted in a high rate of productivity change (11%) in the award-winning firms after the award. On the other hand, pre-certification productivity change due to QMS was 5% and post-certification change was 3.6%. In the periods prior to certification, productivity change was driven mainly by technical change; whereas the source of productivity change after certification is mixed. However, prior to awards, productivity change was driven mainly by relative efficiency change, whereas post-award productivity change was due to technical change. The results suggest that management focus on attaining certification did generate conceptual learning (linked to technical change) during the period leading to certification, but these effects were not significant after certification. The results also suggest that the TQM programs generated significant productivity gains in the long run, although setting the associated systems in place did not result in significant productivity change prior to winning awards. Thus, the study provides direct but nuanced evidence linking quality certification as well as the adoption of TQM programs to the associated conceptual and operational learning processes and their impact on the change in productivity.", "e:keyword": ["Productivity", "Technical change", "Relative efficiency", "QMS", "TQM", "Indian auto component industry", "Data envelopment analysis", "Quality certification", "Quality awards", "Panel data"]}, {"e:abstract": "In this study, we use a game-theory-based framework to model power in a supply chain with random and price-dependent demand and examine how power structure and demand models (expected demand and demand shock) affect supply chain members' performance. We demonstrate that whether a firm benefits from its power depends on the expected demand model but not on demand shock model. A firm benefits from its power only for linear but not for constant elasticity expected demand. The impact of power structure on supply chain efficiency depends on the models of both expected demand and demand shock. With additive shock, supply chain efficiency is highest (lowest) when neither firm dominates for linear (constant elasticity) expected demand. With multiplicative shock, the supply chain efficiency is highest with a power retailer (manufacturer) for linear (constant elasticity) expected demand. The manufacturer always benefits from a reduction in demand uncertainty. However, the retailer loses (benefits) from demand uncertainty reduction for linear (constant elasticity) expected demand. With a power retailer, the retail price is always on the higher end for linear expected demand, and the customer service level is the lowest for constant elasticity expected demand. Consequently, consumers do not necessarily benefit from a power retailer.", "e:volume": "22", "@id": "http://dx.doi.org/10.1111/poms.12002", "e:issue": "5", "e:keyword": ["Supply chain", "Power structure", "Demand uncertainty", "Pricing", "Game theory"]}, {"e:abstract": "I consider pricing and ordering decisions faced by a retailer selling a perishable product with a two-period shelf life over an infinite horizon. In the first period, the product is “new”; in the next, it becomes “old.” The new product is perceived by customers to have a higher quality than the old product. Every period, the retailer makes three decisions: prices for the new and old products and how much new product to order. I first show, with some simple cases, that demand uncertainty can make the sale of the old product profitable. I then consider a more realistic case with dynamic demand substitution among customers. I recognize that the retailer's decisions may be constant or may vary across different periods, under different contexts. For instance, varying the price of the new product can sometimes be difficult due to the negative impact it generates among customers. I find that (i) the benefit obtained from selling the old product with constant decisions is much higher than the benefit from allowing all the decisions to vary; (ii) the former benefit increases with a higher procurement cost, a higher quality of the new product, and higher demand volatility; however, the latter benefit is non-monotone in these parameters; (iii) most of the latter benefit can be obtained by just changing the order quantity; and (iv) as the inventory of the old product increases, when all the decisions vary, the optimal price of the new product may increase or decrease.", "e:volume": "22", "@id": "http://dx.doi.org/10.1111/poms.12004", "e:issue": "5", "e:keyword": ["Joint pricing and inventory decisions", "Perishable", "Vertical differentiation", "Lost sales", "Dynamic demand substitution"]}, {"@id": "http://dx.doi.org/10.1111/poms.12005", "e:abstract": "Design rework is a core phenomenon in new product development (NPD). Yet carrying out design rework presupposes recognizing the need for it. I characterize the types of interpersonal knowledge transfer that help developers realize the need for design rework in NPD. As predicted by the NPD literature, I find that individuals who interact frequently with colleagues to address their task interdependences are more likely to realize the need for rework. I also learn that interacting with colleagues who have different expertise in process-related knowledge (as opposed to product-related knowledge) facilitates realizing the need for rework. However, to develop a deeper understanding of how individuals recognize the need for rework when interacting with others, we must expand our views beyond task interdependence and expertise-related factors. In particular, organizational variables—both formal and informal—play a significant role. With respect to formal hierarchical structures, actors of superior rank are less likely to realize the need for rework regardless of whether or not their interacting partner is of superior rank; however, actors of superior rank are more likely to trigger realizing the need for rework when interacting with partners of subordinate rank. By examining an organization's informal structure, I discover that the social “embeddedness” of developers (i.e., the energy and attention invested in a dyadic relationship) significantly influences their propensity to realize the need for rework. Several hypotheses are tested in a sociometric study conducted within the development department of a software company, and I discuss the implications for behavioral operations in NPD.", "e:keyword": ["New product development", "Rework", "Social networks", "Hierarchies", "Expertise"]}, {"e:abstract": "Recent years have seen a drastic transformation in the organization of wholesale and retail markets. Where once clear distinctions between wholesale suppliers and retail competitors existed, now an era of blurring boundaries has emerged. This transformation has been marked by the introduction of online channels for suppliers to provide products directly to consumers while, at the same time, traditional retailers too persist. Thus, retailers are both wholesale customers and retail competitors of many manufacturers. The consequences of the rapid emergence of instances of such partial forward integration by suppliers are not yet fully known. To this end, we study how partial forward integration can affect competing firms' strategic investments. We find that integration shifts the environment from being one in which firms invest to undercut retail rivals to one in which firms invest more in boosting demand, even that of their competitors. A case in point is the tendency for a manufacturer to invest broadly in brand promotion (benefiting both itself and its retail competitor), rather than heavy promotion of its own sales channel. The shift in the nature of strategic investments arising from partial forward integration implies that such integration can benefit firms and consumers alike, even the firm which finds itself reliant on a competitor for supplies.", "e:volume": "22", "@id": "http://dx.doi.org/10.1111/poms.12006", "e:issue": "5", "e:keyword": ["Dual distribution", "Forward integration", "Investments", "Supply chains"]}, {"e:abstract": "The changing climate and concerns over food security are prompting a new look at the supply chain reliability of products derived from agriculture, and the potential role of contract farming as a mechanism to address climate and price risk while contributing toward crop diversification and water use efficiency is also emerging. In this study, the decision problem of a farmer associated with allocating his land among different crops with varying water requirements is considered, given that a subset of the crops may be associated with a forward contract that is being offered by a buyer. The problem includes a decision to acquire a certain amount of irrigation water capacity prior to the season and to allocate this capacity as irrigation water to be applied during the season to each of the crops selected. Rainfall in the growing season and the market price of each crop at the end of the season are considered to be random variables. Two stochastic programming models are developed to consider facets of this problem and to understand how contracts that reduce market price uncertainty from the problem may change the farmer's decision. The structural properties of these models are discussed, and selected implications are illustrated through an application to data from the Ganganagar district in Rajasthan, India.", "e:volume": "22", "@id": "http://dx.doi.org/10.1111/poms.12007", "e:issue": "5", "e:keyword": ["Crop planning", "Contract farming", "Irrigation", "Agriculture", "India"]}, {"e:abstract": "I consider a channel with one manufacturer selling the same product to two retailers engaged in imperfect competition. The retailers are asymmetric because one has a lower marginal selling cost (or a higher demand potential) than the other. I design the manufacturer's optimal selling mechanism, whereby the manufacturer must offer the same contract options to both retailers. I fully characterize the manufacturer's optimal selling mechanism for varying degrees of retailer asymmetry and competition intensity. I find that under certain conditions, the manufacturer is better off selling a larger quantity through the high-cost (or low-demand potential) retailer. I also show how the optimal mechanism can be implemented using a menu of two-part tariffs with quantity controls.", "e:volume": "22", "@id": "http://dx.doi.org/10.1111/poms.12008", "e:issue": "5", "e:keyword": ["Optimal contracts", "Competition", "Retail channels", "Asymmetric retailers"]}, {"e:abstract": "A fundamental aspect of designing systems with dedicated servers is identifying and improving the system bottlenecks. We extend the concept of a bottleneck to networks with heterogeneous, flexible servers. In contrast with a network with dedicated servers, the bottlenecks are not a priori obvious, but can be determined by solving a number of linear programming problems. Unlike the dedicated server case, we find that a bottleneck may span several nodes in the network. We then identify some characteristics of desirable flexibility structures. In particular, the chosen flexibility structure should not only achieve the maximal possible capacity (corresponding to full server flexibility), but should also have the feature that the entire network is the (unique) system bottleneck. The reason is that it is then possible to shift capacity between arbitrary nodes in the network, allowing the network to cope with demand fluctuations. Finally, we specify when certain flexibility structures (in particular chaining, targeted flexibility, and the “N” and “W” structures from the call center literature) possess these desirable characteristics.", "e:volume": "22", "@id": "http://dx.doi.org/10.1111/poms.12009", "e:issue": "5", "e:keyword": ["Cross‐trained servers", "System bottleneck", "Chaining", "Desirable flexibility structures"]}, {"@id": "http://dx.doi.org/10.1111/poms.12012", "e:abstract": "The field of Production and Operations Management (POM) is increasingly perceived as a rigorous but narrow field, antiquated and not very relevant to the current challenges and concerns of managers in job-creating growth companies vital to our economies. I argue that a narrower positioning of POM in the past is responsible for its perceived limited utility to growth firms and global economies. POM at its core is about “doing more with less,” which is very well aligned with the context and needs of resource-constrained entrepreneurial companies. My discussion is focused on how the research paradigm of POM is and can be relevant to meeting the emerging challenges of growth companies of tomorrow. Specifically, I examine how POM can help meet the needs of these organizations to become scalable and sustainable. The objective is to stimulate thought and discussion and encourage early-stage POM scholars to seriously consider the contexts of technology commercialization, entrepreneurship, and growth companies as avenues for future research.", "e:keyword": ["Technology commercialization", "Innovation", "Entrepreneurship"]}, {"@id": "http://dx.doi.org/10.1111/poms.12014", "e:abstract": "This article draws on my field research in the retailing industry to identify the operational challenges faced by retailers and the relevance of those challenges to senior retail managers and researchers in operations management. It summarizes areas of research in retail operations that have evolved recently and are likely to be important in the future.", "e:keyword": ["Retail operations", "Inventory management", "Inventory data accuracy", "Online retailing", "Store execution"]}, {"@id": "http://dx.doi.org/10.1111/poms.12017", "e:abstract": "Two laboratory experiments on a single-echelon inventory task show that inventory durability interacts with transit lags to create order volatility that exceeds demand volatility. Thus, inventory durability and transit lags cause managers to deviate from inventory decision optimality. Durability creates a large increase in order volatility because players adjust orders insufficiently to reflect current inventory and backlogs, much as they adjust orders insufficiently to reflect holding and backlog costs in newsvendor studies (e.g., Schweitzer and Cachon 2000). Transit lags exacerbate non-optimal ordering by interfering with players' ability to correct prior errors. Our results suggest that non-optimal inventory decisions can be driven by inventory and supply chain characteristics, even in the absence of the coordination and information sharing problems studied by Croson et al. (2005) and Sterman (1989a,b). We also examine the influence of features related to personality. We find little evidence that the interactive effects of durability and transit lags are altered by need for cognition, impulsiveness, or locus of control, suggesting that these features make supply chain management extremely difficult. These results imply that retailers and their upstream partners must consider the characteristics of their product and supply chains when interpreting demand signals received from downstream partners.", "e:keyword": ["Behavioral operations", "Newsvendor problem", "Single‐echelon inventory problem", "Decision biases", "Ordering decisions", "Inventory management", "Supply chain management"]}, {"e:abstract": "Customers are averse to disappointment that arises when economic outcomes fall short of expectations. In this study, we study a two-period model in which the firm may create rationing in either period. In the anticipation of possible disappointment due to stock-outs, strategic customers decide when to purchase and the firm determines the prices and rationing levels in each period. We explore the impact of disappointment aversion on customers' strategic purchasing behavior and the firm's pricing and rationing decisions. Without disappointment aversion, it is optimal for the firm to adopt a uniform pricing policy without rationing. However, when strategic customers are averse to disappointment, a firm may be able to increase profits with an appropriate level of rationing. We analyze both the mark-up and mark-down policies. We show that, in a mark-down scenario, the firm always benefits from disappointment aversion behavior by using an appropriate level of rationing in a low-price period. However, in a mark-up scenario, whether it is beneficial for the firm to induce disappointment aversion behavior depends on how customers frame payoffs in different periods when forming utilities. Particularly, when customers compartmentalize payoffs in different periods to form utilities, the firm should not induce disappointment aversion behavior.", "e:volume": "22", "@id": "http://dx.doi.org/10.1111/poms.12018", "e:issue": "5", "e:keyword": ["Strategic customer behavior", "Disappointment aversion", "Pricing", "Capacity rationing"]}, {"e:abstract": "We develop and evaluate a modeling approach for making periodic review production and distribution decisions for a supply chain in the processed food industry. The supply chain faces several factors, including multiple products, multiple warehouses, production constraints, high transportation costs, and limited storage at the production facility. This problem is motivated by the supply chain structure at Amy's Kitchen, one of the leading producers of natural and organic foods in the United States. We develop an enhanced myopic two-stage approach for this problem. The first stage determines the production plan and uses a heuristic, and the second stage determines the warehouse allocation plan and uses a non-linear optimization model. This two-stage approach is repeated every period and incorporates look-ahead features to improve its performance in future periods. We validate our model using actual data from one factory at Amy's Kitchen and compare the performance of our model to that of the actual operation. We find that our model significantly reduces both inventory levels and stockouts relative to those of the actual operation. In addition, we identify a lower bound on the total costs for all feasible solutions to the problem and measure the effectiveness of our model against this lower bound. We perform sensitivity analysis on some key parameters and assumptions of our modeling approach.", "e:volume": "22", "@id": "http://dx.doi.org/10.1111/poms.12019", "e:issue": "5", "e:keyword": ["Inventory", "Production", "Distribution"]}, {"e:abstract": "The debate of net neutrality and the potential regulation of net neutrality may fundamentally change the dynamics of data consumption and transmission through the Internet. The existing literature on economics of net neutrality focuses only on the supply side of the market, that is, a broadband service provider (BSP) may charge content providers for priority delivery of their content to consumers. In this article, we explore a complete spectrum of broadband network management options based on both the supply and demand sides of the market. We find that although the BSP always prefers the non-neutral network management options, it does not always discriminate both sides of the market. From the social planner's perspective, we find that some network management options maximize the social welfare under certain market conditions while other options reduce the social welfare. Using the terminology from a recent Federal Communications Commission report and order, we categorize the social welfare maximizing options as “reasonable network management” and the social welfare reducing options as “unreasonable discrimination.” We also identify conditions under which the BSP's network management choices deviate from the social optimum. These conditions help establish the criteria under which the social planner might wish to regulate the BSP's actions.", "e:volume": "22", "@id": "http://dx.doi.org/10.1111/poms.12020", "e:issue": "5", "e:keyword": ["Net neutrality", "Broadband network management", "Traffic prioritization", "Public policy"]}, {"@id": "http://dx.doi.org/10.1111/poms.12021", "e:abstract": "As public awareness of environmental hazards increases, a growing concern for corporations is the potential negative environmental impact of their products and the chemicals these products contain. In this study, we analyze the optimal decisions of a firm when a substance within its product is identified as potentially hazardous. Although the substance is not currently regulated, regulation may occur in the future. Therefore, the firm must devise a strategy for the development and implementation of a replacement substance. In an environment where replacement costs can be millions of dollars, regulation is uncertain, and both consumer and non-governmental organization pressures exist, a carefully developed plan that balances costs and risks is critical for a firm. Our results demonstrate that as long as a threat of regulation exists, a firm should always dedicate resources toward developing a replacement substance. However, it is not always optimal for a firm to implement a developed replacement. Regarding competitive dynamics, we find that competition between firms can offset a low chance of a shift in consumer perception about a substance and compel firms to replace; however, competition can lead to inefficient outcomes in which firms incur avoidable costs to implement ahead of potential regulation.", "e:keyword": ["Environmental investments and regulation", "Hazardous substance uncertainty", "Product strategy", "Two‐stage dynamic programming"]}, {"e:abstract": "We present a method for forecasting sales using financial market information and test this method on annual data for US public retailers. Our method is motivated by the permanent income hypothesis in economics, which states that the amount of consumer spending and the mix of spending between discretionary and necessity items depend on the returns achieved on equity portfolios held by consumers. Taking as input forecasts from other sources, such as equity analysts or time-series models, we construct a market-based forecast by augmenting the input forecast with one additional variable, lagged return on an aggregate financial market index. For this, we develop and estimate a martingale model of joint evolution of sales forecasts and the market index. We show that the market-based forecast achieves an average 15% reduction in mean absolute percentage error compared with forecasts given by equity analysts at the same time instant on out-of-sample data. We extensively analyze the performance improvement using alternative model specifications and statistics. We also show that equity analysts do not incorporate lagged financial market returns in their forecasts. Our model yields correlation coefficients between retail sales and market returns for all firms in the data set. Besides forecasting, these results can be applied in risk management and hedging.", "e:volume": "22", "@id": "http://dx.doi.org/10.1111/poms.12022", "e:issue": "5", "e:keyword": ["Retail operations", "Sales forecasting", "Operational hedging", "Martingale modulated forecast evolution", "Operations", "Finance interface"]}, {"e:abstract": "We study several important aspects of using environmental taxes to motivate the choice of innovative and “green\" emissions-reducing technologies as well as the role of fixed cost subsidies and consumer rebates in this process. In our model, a profit-maximizing monopolistic firm facing price-dependent demand selects emissions control technology, production quantity, and price in response to the tax, subsidy, and rebate levels set by the regulator. The available technologies vary in environmental efficiency as well as in the fixed and variable costs. Both the optimal policy for the firm and the social-welfare maximizing policy for the regulator are analyzed. We find that the firm's reaction to an increase in taxes may be non-monotone: while an initial increase in taxes may motivate a switch to a greener technology, further tax increases may motivate a reverse switch. For the regulator, we compare the social welfare achievable in the centralized system (which serves as an upper bound) to the highest level achievable under different classes of environmental policies. If the regulator is limited to a tax-only policy, then when the regulator is moderately concerned with environmental impacts, the tax level that maximizes social welfare simultaneously motivates the choice of clean technology and closes the gap to the upper bound; however, both low and high levels of societal environmental concerns may lead to the choice of dirty technology and significant welfare losses as compared to the centralized case. Supplementing the environmental taxation with fixed cost subsidies and consumer rebates can eliminate this effect, expanding the range of parameters over which the green technology is chosen and often closing the welfare gap to the centralized solution.", "e:volume": "22", "@id": "http://dx.doi.org/10.1111/poms.12023", "e:issue": "5", "e:keyword": ["Green technologies", "Sustainability", "Environmental policy", "Environmental taxes", "Subsidies and rebates"]}, {"@id": "http://dx.doi.org/10.1111/poms.12024", "e:abstract": "Systems thinking has proven useful in project management planning activities and has been suggested as a critical driver of a range of beneficial organizational behaviors. Yet, empirical evidence on the myriad of ways in which systems thinking can impact internal project dynamics and performance remains limited. This study focuses on one aspect of systems thinking in particular: the ability to recognize and understand the dynamics of systems and their features (e.g., feedback and delay). It makes use of a unique, large-scale interview data set along with objective and structured survey data drawn from multiple sources associated with supply chain system implementation projects. Analysis suggests that an individual's understanding of system dynamics as well as the similarity of such understanding to that typical of their team is, in fact, a strong predictor of both perceptions of psychological safety and information sharing quality in project work. These outcomes appear to mediate the relationship between system dynamics understanding and performance.", "e:keyword": ["Project management", "Systems thinking"]}, {"@id": "http://dx.doi.org/10.1111/poms.12025", "e:abstract": "In a three-tier supply chain comprising an original equipment manufacturer (OEM), a contract manufacturer (CM), and a supplier, there exist two typical outsourcing structures: control and delegation. Under the control structure, the OEM contracts with the CM and the supplier respectively. Under the delegation structure, the OEM contracts with the CM only and the CM subcontracts with the supplier. We compare the two outsourcing structures under a push contract (whereby orders are placed before demand is realized) and a pull contract (whereby orders are placed after demand is realized). For all combinations of outsourcing structures and contracts, we derive the corresponding equilibrium wholesale prices, order quantities, and capacities. We find that the equilibrium production quantity is higher under control than under delegation for the push contract whereas the reverse holds for the pull contract. Both the OEM and the CM prefer control over delegation under the push contract. However, under the pull contract, the OEM prefers control over delegation whereas the CM and the supplier prefer delegation over control. We also show that for a given outsourcing structure, the OEM prefers the pull contract over the push contract. In extending our settings to a general two-wholesale-price (TWP) contract, we find that when wholesale prices are endogenized decision variables, the TWP contract under our setting degenerates to either a push or a pull contract.", "e:keyword": ["Pull", "Push", "Control", "Delegation", "Three‐tier supply chain"]}, {"e:abstract": "Despite the spread of cost-driven outsourcing practices, academic research cautions that suppliers' cost advantage may weaken manufacturers' bargaining positions in negotiating outsourcing agreements, thereby hurting their profitability. In this study, we attempt to further understand the strategic impact of low-cost outsourcing on manufacturers' profitability by investigating the contractual form of outsourcing agreements and the industry structure of the upstream supply market. We consider a two-tier supply chain system, consisting of two competing manufacturers, who have the option to produce in-house or to outsource to an upstream supplier with lower cost. To reach an outsourcing agreement, each manufacturer engages in bilateral negotiation with her supplier, who may be an exclusive supplier or a common supplier serving both manufacturers. Our analysis shows that wholesale-price contracts always mitigate the competition between manufacturers regardless of whether they compete with price or quantity. In contrast, two-part tariffs intensify the competition when the manufacturers compete with quantity, but soften it when they compete with price. As a result, when outsourcing with two-part tariffs, the manufacturers may earn lower profits than they would from in-house production, although the suppliers are more cost efficient. This suggests that managers have to be wary about the downside of using coordinating contracts such as two-part tariffs when pursuing low-cost outsourcing strategies. Our analysis also sheds some light on the profitability of using an exclusive supplier for outsourcing. When outsourcing with wholesale-price contracts, the competing manufacturers are better off outsourcing to an exclusive supplier. However, when outsourcing with two-part tariffs, the manufacturers may earn higher profits by outsourcing to a common supplier than to an exclusive one when the manufacturers' bargaining power is sufficiently strong (weak) under quantity (price) competition.", "e:volume": "22", "@id": "http://dx.doi.org/10.1111/poms.12026", "e:issue": "5", "e:keyword": ["Outsourcing", "Wholesale‐price contract", "Common vs. exclusive supplier", "Two‐part tariff", "Multiunit bilateral bargaining"]}, {"@id": "http://dx.doi.org/10.1111/poms.12027", "e:abstract": "Recent years have witnessed the pervasive supply disruptions and their impacts on supply chain performance. In this study, we investigate the optimal procurement design with supply disruptions and heterogeneous beliefs between the buyer and the supplier. We examine the impact of information asymmetry on the supplier's belief, the control right of the backup production, and the verifiability of supply disruption. The belief heterogeneity creates speculative gains and losses because the buyer and the supplier hold different estimates of the disruption probability. We demonstrate that the buyer's incentive to exploit this belief heterogeneity leads to real production inefficiencies in different scenarios. The production efficiency is not necessarily improved with more transparent information. Moreover, a very pessimistic supplier may have no incentive to invest in improving the reliability even if this is costless, and the supplier may produce more when the expected production cost becomes higher. When the buyer sees some value in using the supplier's estimate to update his own belief, we find that the main results hold unless the buyer completely abandons his belief.", "e:keyword": ["Supply disruptions", "Heterogeneous beliefs", "Information asymmetry", "Backup production"]}, {"@id": "http://dx.doi.org/10.1111/poms.12028", "e:abstract": "This study characterizes the class of Pareto optimal returns policies between a manufacturer and a retailer who receives consumer returns. The manufacturer may take a costly hidden action that reduces the expected number of products returned by consumers, which when realized is hidden information known only to the retailer. When faced with consumer returns, the retailer must decide whether to send the product back to the manufacturer, who harvests a low salvage value, or to engage in costly refurbishment that permits the returned product to be resold to consumers. We find that the optimal returns policies may be implemented through the payment by the manufacturer of a full refund to the retailer of the wholesale price for any returns as well as a bonus paid to the retailer that is decreasing in the number of returns to the manufacturer.", "e:keyword": ["Consumer returns", "Returns policy", "Preponement", "Hidden action", "Hidden information"]}, {"@id": "http://dx.doi.org/10.1111/poms.12029", "e:abstract": "A dedicated subnetwork (DSN) refers to a subset of lanes, with associated loads, in a shipper's transportation network, for which resources—trucks, drivers, and other equipment—are exclusively assigned to accomplish shipping requirements. The resources assigned to a DSN are not shared with the rest of the shipper's network. Thus, a DSN is an autonomously operated subnetwork and, hence, can be subcontracted. We address a novel problem of extracting a DSN for outsourcing to one or more subcontractors, with the objective of maximizing the shipper's savings. In their pure form, the defining conditions of a DSN are often too restrictive to enable the extraction of a sizable subnetwork. We consider two notions—deadheading and lane-sharing—that aid in improving the size of the DSN. We show that all the optimization problems involved are both strongly NP-hard and APX-hard, and demonstrate several polynomially solvable special cases arising from topological properties of the network and parametric relationships. Next, we develop a network-flow-based heuristic that provides near-optimal solutions to practical instances in reasonable time. Finally, using a test bed based on data obtained from a national 3PL company, we demonstrate the substantial monetary impact of subcontracting a DSN and offer useful managerial insights.", "e:keyword": ["Transportation network", "Dedicated subnetwork", "Deadheading", "Lane‐sharing", "Heuristics"]}, {"@id": "http://dx.doi.org/10.1111/poms.12030", "e:abstract": "We consider two competing supply chains, each consisting of supplier, a manufacturer, and a retailer. The suppliers exert effort to improve product quality, and the retailers sell products competitively. Each manufacturer chooses one of the three strategies: forward integration, backward integration, or no vertical integration. We seek for a subgame perfect Nash equilibrium and study the resulting market structure. Moreover, we characterize the effect of vertical integration on profitability, product price, and quality in a competitive setting. Existing literature has shown that, when manufacturers consider only forward integration, they may choose not to vertically integrate in equilibrium. In contrast, we find that, when both forward and backward integration options are considered, disintegration cannot be an equilibrium outcome. In this case, both manufacturers either forward or backward integrate, and the degree of product perishability, cost of quality, and how much consumers value quality are critical for the chosen direction of integration. Furthermore, competition increases attractiveness of backward integration relative to forward integration. We show that, while integrating backward unilaterally is always beneficial, unilateral forward integration can harm a manufacturer's profitability. Finally, vertical integration can result in a better quality product sold at a lower price.", "e:keyword": ["Vertical integration", "Competition", "Supply chain", "Quality", "Pricing"]}, {"@id": "http://dx.doi.org/10.1111/poms.12031", "e:abstract": "We consider a continuous review inventory system where delivery lead times can be managed by expediting in-transit orders shipped from the supplier. First, we propose an ordering/expediting policy and derive expressions for evaluating the operating characteristics of such systems. Second, using extensive numerical experiments, we quantify the benefits of such an expediting policy. Third, we investigate a number of managerial issues. Specifically, we analyze the impact of the number of expediting hubs and their locations along the shipment network on the performance of such systems and offer insights into the design of the shipment network. We show (i) a single expediting hub that is optimally located in a shipment network can capture the majority of cost savings achieved by a multi-hub system, especially when expediting cost is not low or demand variability is not high; (ii) when expediting time is proportional to the time to destination, for small-enough or large-enough demand variations, a single expediting hub located in the middle of the shipment network can capture the majority of cost savings of an optimally located hub; and (iii) in general, hubs close to the retailer significantly drive down costs, whereas hubs close to the supplier may not offer much cost savings.", "e:keyword": ["Expediting", "Inventory management", "Continuous‐review inventory systems", "Shipment network design"]}, {"@id": "http://dx.doi.org/10.1111/poms.12032", "e:abstract": "We consider a pricing and short-term capacity allocation problem in the presence of buyers with orders for bundles of products. The supplier's objective is to maximize her net profit, computed as the difference between the revenue generated through sales of products and the production and inventory holding costs. The objective of each buyer is similarly profit maximization, where a buyer's profit is computed as the difference between the time-dependent utility of the product bundle he plans to buy, expressed in monetary terms, and the price of the bundle. We assume that bundles' utilities are buyers' private information and address the problem of allocating the facility's output. We directly consider the products that constitute the supplier's output as market goods. We study the case where the supplier follows an anonymous and linear pricing strategy, with extensions that include quantity discounts and time-dependent product and delivery prices. In this setting, the winner determination problem integrates the capacity allocation and scheduling decisions. We propose an iterative auction mechanism with non-decreasing prices to solve this complex problem, and present a computational analysis to investigate the efficiency of the proposed method under supplier's different pricing strategies. Our analysis shows that the problem with private information can be effectively solved with the proposed auction mechanism. Furthermore, the results indicate that the auction mechanism achieves more than 80% of the system's profit, and the supplier receives a higher percentage of profit especially when the ratio of demand to available capacity is high.", "e:keyword": ["Auctions", "Pricing", "Scheduling", "Capacity allocation"]}, {"e:abstract": "Service level agreements (SLAs) are widely employed forms of performance-based contracts in operations management. They compare performance during a period against a contracted service level and penalize outcomes exceeding some allowed deviation. SLAs have a number of design characteristics that need careful tuning to ensure that incentives are properly aligned. However, there is little theoretical research in this area. Using an example of an SLA for outsourcing inventory management, we make a number of recommendations. First it is preferable, if possible, that penalties be proportional to the underperformance rather than lump-sum ones. This goes a long way towards mitigating strategic (“gaming”) behavior by the supplier. Second, it might be thought that giving “bonuses for good performance” rather than “penalties for bad performance” are essentially identical apart from the former being a more positive approach to management. This turns out to be incorrect in the case of large percentage service rate targets and that penalties will normally be preferred by the buying firm. Third, in order not to incorrectly penalize underperformance resulting purely from “noise” rather than supplier efforts, management might think it best to make allowed deviations from the target generous. Again intuition is not a helpful guide here: for proportional penalties, acceptable performance deviations should be close to the target. Although these results come from a particular inventory application, it is likely that the lessons are applicable to SLAs in general.", "e:volume": "22", "@id": "http://dx.doi.org/10.1111/poms.12033", "e:issue": "5", "e:keyword": ["Service level agreement", "Performance‐based contract", "Inventory management", "Strategic behavior", "Moral hazard"]}, {"@id": "http://dx.doi.org/10.1111/poms.12034", "e:abstract": "In this study, we investigate the bullwhip effect in China using data on over 1200 companies listed on the Shanghai and Shenzhen stock exchanges from 2002 to 2009. Specifically, we estimate the ratio of the volatility of production to the volatility of demand as a proxy for the bullwhip effect. Our results show that more than two-thirds of the companies we studied exhibit the bullwhip effect. We also find that several hypotheses proposed in the existing literature are supported by firm-level data from China, and that the intensity of the bullwhip effect in China declined during the period from 2002 to 2009.", "e:keyword": ["Bullwhip effect", "Empirical study", "China", "Supply chain management"]}, {"@id": "http://dx.doi.org/10.1111/poms.12035", "e:abstract": "This study investigates the roles of bank and trade credits in a supply chain with a capital-constrained retailer facing demand uncertainty. We evaluate the retailer's optimal order quantity and the creditors' optimal credit limits and interest rates in two scenarios. In the single-credit scenario, we find the retailer prefers trade credit, if the trade credit market is more competitive than the bank credit market; otherwise, the retailer's preference of a specific credit type depends on the risk levels that the retailer would divert trade credit and bank credit to other risky investments. In the dual-credit scenario, if the bank credit market is more competitive than the trade credit market, the retailer first borrows bank credit prior to trade credit, but then switches to borrowing trade credit prior to bank credit as the retailer's internal capital declines. In contrast, if the trade credit market is more competitive, the retailer borrows only trade credit. We further analytically prove that the two credits are complementary if the retailer's internal capital is substantially low but become substitutable as the internal capital grows, and then empirically validate this prediction based on a panel of 674 firms in China over the period 2001–2007.", "e:keyword": ["Trade credit", "Bank credit", "Capital constrained", "Newsvendor", "Moral hazard"]}, {"@id": "http://dx.doi.org/10.1111/poms.12036", "e:abstract": "For infectious diseases like tuberculosis and HIV, treatment adherence plays an important role in treatment effectiveness and epidemic control. Studies of some infectious diseases indicate that patients who live closer to their health facilities maintain higher adherence; however, most models ignore the heterogeneity of patients' adherence. Clinics must balance knowledge about adherence with epidemic growth when creating successful treatment programs. We develop an optimization model that integrates a clinic's capacity decisions with population health outcomes. We find that incorporating adherence into clinic planning models can lead to decisions that significantly improve outcomes. For example, in a realistic case study of the HIV epidemic in Zambia, we find that decision makers who ignore decreasing adherence make suboptimal decisions and overestimate the effectiveness of their treatment programs by as much as 94%. Our model is a first step toward understanding the relationship between adherence and health delivery.", "e:keyword": ["Health care management", "Public policy", "Humanitarian operations", "Clinic capacity planning and investment", "Math programming"]}, {"@id": "http://dx.doi.org/10.1111/poms.12037", "e:abstract": "This study investigates firms' R&D cooperation behavior in a supply chain where two firms first cooperate in R&D investments and then decide the production quantity according to a wholesale price contract. By using a concept named contribution level that measures a firm's technological contribution to the R&D cooperation in the supply chain, we show that both firms can achieve win–win via cartelization only if their contribution levels are Pareto matched, i.e., when each firm's contribution level is comparable to its partner's. When spillovers are endogenized, we further establish that an increasing spillover always benefits both firms without any R&D cooperation, but only benefits the firm whose contribution level is relatively low when under R&D cartels. Finally, we show that the path of first increasing spillovers to be perfect and then forming a cartel has a higher chance of achieving the best mode in terms of profitability.", "e:keyword": ["Supply chain", "R&D cooperation behavior", "Cartelization", "Spillover", "Cooperation path"]}, {"@id": "http://dx.doi.org/10.1111/poms.12038", "e:abstract": "We investigate relationships between operational capabilities and new venture survival. On the basis of operations management and entrepreneurship literature, we develop a contingency framework of operational capabilities especially appropriate at different life phases of a new venture's evolution. We expect that in the first years of a new venture's life, entrepreneurs should emphasize high inventory turnover to preserve working capital, support customer responsiveness, and aid firm adaptability. As new ventures grow, entrepreneurs should emphasize internal working capital generation via larger gross margins to support production ramp-up. Later, new venture entrepreneurs should emphasize employee productivity to buttress sustainable volume production. We analyze a 6-year longitudinal sample of 812 Swedish manufacturing new ventures using a gamma frailty-based Cox regression. The findings show that specific operational capabilities, while always supporting new venture survival, have exceptional influence in specific new venture life phases. The three hypotheses are confirmed, suggesting that higher inventory turnover, gross margin, and employee productivity further increase new venture survival likelihoods, respectively, in the venture's start-up, growth, and stability phases. This suggests a phased-capabilities approach to new venture survival. This study contributes to operations management and entrepreneurship theory and practice, and sets a foundation for future research on operations strategy for new ventures.", "e:keyword": ["Firm survival", "Working capital", "Labor productivity", "Start‐ups", "Longitudinal methods", "Performance measurement"]}, {"@id": "http://dx.doi.org/10.1111/poms.12040", "e:abstract": "We consider an original equipment manufacturer (OEM) who faces competition from an independent remanufacturer (IR). The OEM decides the quality of the new product, which also determines the quality of the competing remanufactured product. The OEM and the IR then competitively determine their production quantities. We explicitly characterize how the OEM competes with the IR in equilibrium. Specifically, we show that the OEM relies more on quality as a strategic lever when it has a stronger competitive position (determined by the relative cost and value of new and remanufactured products), and in contrast it relies more heavily on limiting quantity of cores when it has a weaker competitive position. The IR's entry threat as well as its successful entry can decrease the consumer surplus. Furthermore, our results illustrate that ignoring the competition or the OEM's quality choice leads to overestimating benefits of remanufacturing for consumer and social welfare. In addition, we show an IR with either a sufficiently weak competitive position (so the OEM deters entry) or a sufficiently strong one (so the OEM is forced to limit quantity of cores) is desirable for reducing the environmental impact. Comparing our results with the benchmark in which the OEM remanufactures suggests that encouraging IRs to remanufacture in lieu of the OEMs may not benefit the environment. Furthermore, the benchmark illustrates that making remanufacturing more attractive improves the environmental impact when the remanufacturer is the OEM, while worsening it when remanufacturing is done by the IR.", "e:keyword": ["Product quality", "Remanufacturing", "Competition", "Environmental impact", "Social welfare"]}, {"@id": "http://dx.doi.org/10.1111/poms.12041", "e:abstract": "In this study, we consider the integrated inventory replenishment and transportation operations in a supply chain where the orders placed by the downstream retailer are dispatched by the upstream warehouse via an in-house fleet of limited size. We first consider the single-item single-echelon case where the retailer operates with a quantity based replenishment policy, (r,Q), and the warehouse is an ample supplier. We model the transportation operations as a queueing system and derive the operating characteristics of the system in exact terms. We extend this basic model to a two-echelon supply chain where the warehouse employs a base-stock policy. The departure process of the warehouse is characterized in distribution, which is then approximated by an Erlang arrival process by matching the first two moments for the analysis of the transportation queueing system. The operating characteristics and the expected cost rate are derived. An extension of this system to multiple retailers is also discussed. Numerical results are presented to illustrate the performance and the sensitivity of the models and the value of coordinating inventory and transportation operations.", "e:keyword": ["Joint replenishment", "Transportation", "Inventory", "Logistics"]}, {"@id": "http://dx.doi.org/10.1111/poms.12042", "e:abstract": "We introduce a two-period Stackelberg game of a supplier and buyer. We recognize that learning from manufacturing experience has many advantages. Consistent with the literature, we assume both the buyer and supplier realize reductions in their respective production costs in period 2 due to volume-based learning from period 1 production. In addition, we introduce another learning concept, the future value, to capture the buyer's benefits of transferring current manufacturing experience for the design and development of future products and technologies. In contrast to the literature, we allow the supplier two mechanisms to impact the buyer's outsourcing decision: price and the investment in integration process improvement (IPI) that reduces the buyer's unit cost of integration. IPI may include the investment in new materials, specialized technology, or the re-design of the integration process. Conditions are given whereby the buyer partially outsources component demand as opposed to fully outsourcing or fully producing in-house. Furthermore, conditions are given characterizing when the supplier's price and investment in IPI are substitute strategies versus complements. Both analytic and numerical results are presented.", "e:keyword": ["Buyer–supplier problem", "Integration process improvement", "Partial outsourcing", "Stackelberg game", "Volume‐based learning"]}, {"@id": "http://dx.doi.org/10.1111/poms.12043", "e:abstract": "With the growing influence of online social media, firms increasingly take an active role in interacting with consumers in social media. For many firms, their first step in online social media is management responses, where the management responds to customers' comments about the firm or its products and services. In this article, we measure the impact of management responses on customer satisfaction using data retrieved from a major online travel agency in China. Applying a panel data model that controls for regression toward the mean and heterogeneity in individual preference for hotels, we find that online management responses are highly effective among low satisfaction customers but have limited influence on other customers. Moreover, we show that the public nature of online management responses introduces a new dynamic among customers. Although online management responses increase future satisfaction of the complaining customers who receive the responses, they decrease future satisfaction of complaining customers who observe but do not receive management responses. The result is consistent with the peer-induced fairness theory.", "e:keyword": ["Online social media", "Management response", "Service recovery", "Customer satisfaction", "Peer‐induced fairness"]}, {"@id": "http://dx.doi.org/10.1111/poms.12044", "e:abstract": "Information sharing in supply chains has become an important topic over the past decade. This study uses data from 617 Chinese manufacturing firms to investigate the relationships among competitive environments, supply chain information sharing (SCIS), and supply chain performance. The results of structural equation modeling analysis show that (i) international competition is positively related to all three types of SCIS whereas local competition is not significantly related to any of the three types, (ii) internal information sharing is positively related to external information sharing with suppliers and customers, and (iii) internal information sharing and information sharing with customers are positively related to superior supply chain performance, whereas supplier information sharing is not significantly related to performance. The findings enhance our understanding of the relationships among competitive environment, SCIS, and supply chain performance in Chinese manufacturing settings.", "e:keyword": ["Competitive environment", "Information sharing", "Supply chain performance", "China"]}, {"@id": "http://dx.doi.org/10.1111/poms.12045", "e:abstract": "This study describes (through an application) a novel approach toward organizing work distribution across globally distributed design and development centers of a product development (PD) organization. While there exist several studies (and modeling applications) for work distribution and allocation for manufacturing and supply chain networks, those related to product development organizations are limited to qualitative suggestions such as offshoring of modular tasks. However, most PD efforts are characterized by significant complexity in information sharing and information dependency among PD tasks (represented by coupling in the system architecture of the firm), thus preventing the identification of modular tasks. Also, redesigning the architecture to introduce modularity has associated risks of costs and product integrity. We demonstrate a methodology to organize work distribution globally in an industrial setting, utilizing the design structure matrix to quantify the system architecture of the firm. Our optimization results show significant cost savings through a restructured PD organization. On analysis of the results, we make two significant observations: (a) while offshoring based on modularity is generally appropriate, it is not the whole answer, as there exists a trade-off between the efficiency of performing specific PD tasks at the offshore location and the modularity of the task; and (b) firms should successively increase work allocation to the offshore location, benefiting from capability improvements through learning effects.", "e:keyword": ["Distributed product development", "Complex engineered systems", "System architecture", "Design structure matrix"]}, {"@id": "http://dx.doi.org/10.1111/poms.12046", "e:abstract": "We consider firms that feature their products on the Internet but take orders offline. Click and order data are disjoint on such non-transactional websites, and their matching is error-prone. Yet, their time separation may allow the firm to react and improve its tactical planning. We introduce a dynamic decision support model that augments the classic inventory planning model with additional clickstream state variables. Using a novel data set of matched online clickstream and offline purchasing data, we identify statistically significant clickstream variables and empirically investigate the value of clickstream tracking on non-transactional websites to improve inventory management. We show that the noisy clickstream data is statistically significant to predict the propensity, amount, and timing of offline orders. A counterfactual analysis shows that using the demand information extracted from the clickstream data can reduce the inventory holding and backordering cost by 3% to 5% in our data set.", "e:keyword": ["Click tracking", "Advance demand information", "Inventory theory and control", "Empirical research", "Dynamic programming", "Econometric analysis", "Big data"]}, {"@id": "http://dx.doi.org/10.1111/poms.12047", "e:abstract": "We consider a periodic-review inventory system with regular and expedited supply modes. The expedited supply is faster than the regular supply but incurs a higher cost. Demand for the product in each period is random and sensitive to its selling price. The firm determines its order quantity from each supply in each period as well as its selling price to maximize the expected total discounted profit over a finite or an infinite planning horizon. We show that, in each period if it is optimal to order from both supplies, the optimal inventory policy is determined by two state-independent thresholds, one for each supply mode, and a list price is set for the product; if only the regular supply is used, the optimal policy is a state-dependent base-stock policy, that is, the optimal base-stock level depends on the starting inventory level, and the optimal selling price is a markdown price that decreases with the starting inventory level. We further study the operational impact of such supply diversification and show that it increases the firm's expected profit, reduces the optimal safety-stock levels, and lowers the optimal selling price. Thus that diversification is beneficial to both the firm and its customers. Building upon these results, we conduct a numerical study to assess and compare the respective benefit of dynamic pricing and supply diversification.", "e:keyword": ["Optimal policy", "Pricing", "Inventory control", "Supply diversification", "Lead time"]}, {"@id": "http://dx.doi.org/10.1111/poms.12048", "e:abstract": "In this article, we analyze how retailers change their inventory investment behavior in response to macroeconomic shocks. We examine if service level, as measured by the ratio of stockout to inventory holding costs, can explain the differences in observed behavior across retailers. We use data on macroeconomic indicators and quarterly filings of US public retailers from 1985 to 2009 to estimate a dynamic model of short- and long-term impact of macroeconomic shocks on inventory investment. Our results show that retailers with a high service level increase their inventory investment significantly more than those with a low service level during expansion shocks. Conversely, retailers with a low service level curtail their inventory investment significantly more than those with a high service level during periods of economic contractions. Thus, we show that the aggregate change in inventory investment documented in prior macroeconomics research is driven by different sets of retailers, as predicted by newsvendor logic. We draw implications of our findings to retailers as well as their suppliers.", "e:keyword": ["Inventory investment", "Macroeconomic shocks", "Expansion", "Contraction", "Inventory holding cost", "Stockout cost", "Service level"]}, {"@id": "http://dx.doi.org/10.1111/poms.12051", "e:abstract": "Rapid advances of information technology in recent years have enabled both the manufacturers and the retailers to operate their own Internet channels. In this study, we investigate the interaction between the capabilities of introducing the Internet channels, the pricing strategies, and the channel structure. We classify consumers into two segments: grocery shoppers attach a higher utility from purchasing through the physical channel, whereas a priori Internet shoppers prefer purchasing online. We find that when the Internet shoppers are either highly profitable or fairly unimportant, the manufacturer prefers to facilitate the channel separation either through his own Internet channel or the retailer's. In the intermediate region, however, the manufacturer encroaches the grocery shoppers and steals the demand from the retailer's physical channel. With horizontal competition between retailers, a priori symmetric retailers may adopt different channel strategies as a stable market equilibrium. The manufacturer may willingly give up his Internet channel and leverage on the retailer competition. When the manufacturer sells through an online e-tailer, Internet shoppers may be induced to purchase through the physical channel. This reverse encroachment strategy emerges because selling through the e-tailer leads to a more severe double marginalization problem.", "e:keyword": ["Multi‐channel management", "Retail operations", "Electronic commerce", "Game theory"]}, {"@id": "http://dx.doi.org/10.1111/poms.12052", "e:abstract": "Supply chain integration is increasingly seen as a method to obtain flexibility and, consequently, to provide competitive advantage for firms within a supply chain. Product modularity, either in concert with or independent of such integration, can also produce flexibility for firms within a supply chain. In this proof-of-concept research, we explore whether the supply chain network affects each constituent firm's market valuation and how decisions regarding the level of supply chain integration and the usage of product modularity are associated with the value of the supply chain. We develop a method to identify and measure the supply chain's effect on each constituent firm's market valuation. Results indicate that greater integration is associated with a higher supply chain valuation, whereas increasing aggregated product modularity across the supply chain relates to a lower supply chain value. However, when combined, the interaction of aggregated product modularity and supply chain integration is positively associated with the supply chain's valuation.", "e:keyword": ["Product modularity", "Supply chain integration", "Network", "Market valuation"]}, {"@id": "http://dx.doi.org/10.1111/poms.12054", "e:abstract": "We show simple yet optimal results to update the inventory/capacity levels, expected profit, fill rates, and service levels of substitutable resources in response to an updating of the mean demand forecasts for the resources. We find that a change in the mean demand of one resource does not affect the optimal inventory level of any other resource. The results are obtained for demands with location-scale distribution, and for a revenue structure satisfying a triangle property such that the manager will always use the inventory of a resource to meet her own demand first before using it for substitution. The results for updating the performance measures also extend to managers who maintain non-optimal inventory/capacity levels. Implications for procurement, sales and operational planning, and multi-store operations are discussed.", "e:keyword": ["Substitutable resources", "Forecast updates", "Inventory updates", "Structural properties of multi‐product newsvendor problems"]}, {"@id": "http://dx.doi.org/10.1111/poms.12055", "e:abstract": "This special issue presents production and operations management research papers from emerging markets worldwide, focusing on their unique contexts, institutions and markets. Collectively, they offer insights into the unique operations management strategies and practices that firms face in emerging markets. The magnitude and pace of change is staggering. As a result, execution and managing growth in these emerging markets represents both huge operational and supply chain risks, and simultaneously vast opportunities. We are confident that these papers stimulate new operations management research while highlighting the effective use of different research methodologies. We welcome you to enjoy this special issue of POMS. We express our deep gratitude to editorial team for their support. We especially wish to thank the authors for their contributions to this special issue.", "e:keyword": ["Global", "Emerging markets", "Operations", "Supply chain management", "Growth", "Risk"]}, {"@id": "http://dx.doi.org/10.1111/poms.12057", "e:abstract": "In this article, we model various forms of non-optimizing behavior in a newsvendor setting, including biases such as recency, reinforcement, demand chasing, and anchoring, as well as unsystematic decision errors. We assume that a newsvendor may evaluate decisions by examining both past outcomes and future expected payoffs. Our model is motivated by laboratory observations under several types of supply chain contracts. Ordering decisions are found to follow multi-modal distributions that are dependent on contract structures and incentives. We differ from previous research by using statistics to determine which behavioral factors are applicable to each decision maker. A great deal of heterogeneity was discovered, indicating the importance of calibrating a contract to the individual. Our analysis also shows that the profit performance and the effectiveness of co-ordinating contracts can be affected by non-optimizing behaviors significantly. We conclude that, in addition to the aggregate order quantities, the decision distributions should be considered in designing contracts.", "e:keyword": ["Behavioral operations management", "Newsvendor decisions", "Supply chain contracts", "Bounded rationality", "Individual heterogeneity"]}, {"@id": "http://dx.doi.org/10.1111/poms.12061", "e:abstract": "Decentralized decision making is a fact in the modern business world accompanied by extensive research that looks into its consequences for overall firm profits. We study the interactions of decentralized marketing and operations divisions in a corporation and explore their impact on overall firm profits in the case with and without coordination of the two decentralized units. We assume that the marketing department is responsible for the price that influences the demand (sales), and the operations department is responsible for the production rate. We allow for backlogging over time. We model the interdependence involving marketing and operations decisions as a non-cooperative differential game, with the two divisions as strategically interacting players. We find that, without coordination, strategic interactions of marketing and production result in inefficiencies that can quantitatively be substantial. Next, we introduce a dynamic transfer pricing scheme as a coordination device and evaluate if it establishes efficient (first best and fully coordinated) outcomes. We show that if production and marketing play a game with pre-commitment strategies, there exists a dynamic transfer price that efficiently (fully) coordinates decentralized decision making and hence results in Pareto-efficient company profits. If the two decentralized divisions play a game without pre-commitment, dynamic transfer prices can partially coordinate decentralized decision making but fail to fully eliminate overall inefficiencies arising from strategic interactions among decentralized divisions.", "e:keyword": ["Coordinating decentralized divisions", "Dynamic transfer price", "Production and marketing interface", "Price production differential game"]}, {"@id": "http://dx.doi.org/10.1111/poms.12062", "e:abstract": "This research investigates the value of category captainship (a management practice in which a retailer relies on a manufacturer for recommendations regarding strategic category management decisions) in retail supply chains. We consider a setting where the scope of category management is limited to assortment decisions and demand enhancing activities. We assume that the retailer selects a category captain among multiple competing manufacturers with privately known capabilities for driving category traffic. First, we consider a benchmark scenario where the retailer is responsible for category management. Then, we consider the category captainship scenario where the retailer selects one of the manufacturers as a captain to manage the category. We find that captainship is more likely to emerge in categories where the cost of managing variety, the retail margins, and the competition for captainship are moderate and the captain is more capable of driving traffic compared to the retailer. In such categories the collaboration between the retailer and the captain ensures sufficient surplus for both parties. Finally, we show that captainship can also benefit the non-captain manufacturers.", "e:keyword": ["Retail supply chain management", "Supply chain collaboration", "Category management", "Category captainship", "Auctions with externalities"]}, {"@id": "http://dx.doi.org/10.1111/poms.12063", "e:abstract": "We consider a two-stage principal–agent screening environment in a decentralized supply chain with retailers, distributors, and a supplier. The retailers possess private information regarding their local market profitabilities. The distributors can partially observe the retailers' profitabilities and are heterogeneous with regard to the precision of that information. The supplier determines the level of production, but knows neither the local market profitabilities nor the precision of the distributors' information. The supplier first allocates finished products to distributors, and the distributors then contract with local retailers with a capacity constraint. We find that due to the distributors' superior information, the quantity distortion on the retailers' side is mitigated, and the upstream information asymmetry subsequently affects the quantity allocation among the downstream retailers. The supplier may not benefit from contracting with the distributors. In addition, no distributor is excluded based on the heterogeneity of the information precision, even though some distributors do not have better information than the supplier. In the numerical examples, we further analyze how the local market heterogeneity and inventory costs affect the capacity allocation, the retailers' payoffs, and the supply chain profits. We document some counter-intuitive quantity allocation rules that arise from the distributors' information advantage.", "e:keyword": ["Capacity allocation", "Supply chains", "Hierarchy", "Mechanism design"]}, {"@id": "http://dx.doi.org/10.1111/poms.12066", "e:abstract": "Conventional wisdom holds that adding layers to a distribution channel is detrimental to the interests of consumers and the channel that serves them. In contrast, our study indicates that a disintegrated channel structure can be desirable in some instances. When consumers have valuation uncertainty prior to consuming a product, having an independent retailer may boost both channel profits and consumer surplus relative to direct selling by an integrated firm. The quandary in selling such products is that after early adopters make their purchase decisions, the seller may alter prices in such a way that makes early adopters' decisions appear suboptimal in hindsight. Since the seller cannot credibly commit to future prices, customers are reluctant to adopt early, choosing instead to delay their purchase decisions. This delay is certainly detrimental to the interest of the distribution channel, but the rejection of the early adoption discount can equally reduce consumer surplus. This problem can be mitigated by introducing an independent retailer. The familiar double marginalization “problem” from channel disintegration can credibly assure customers of unfavorable future prices for late adoption. This assurance attracts more customers to seek early adoption, leading to lower overall retail prices, increased supply, and higher consumer and producer surpluses.", "e:keyword": ["Supply chains", "Channel disintegration", "Double marginalization"]}, {"@id": "http://dx.doi.org/10.1111/poms.12068", "e:abstract": "Operations management methods have been applied profitably to a wide range of technology portfolio management problems, but have been slow to be adopted by governments and policy makers. We develop a framework that allows us to apply such techniques to a large and important public policy problem: energy technology R&D portfolio management under climate change. We apply a multi-model approach, implementing probabilistic data derived from expert elicitations into a novel stochastic programming version of a dynamic integrated assessment model. We note that while the unifying framework we present can be applied to a range of models and data sets, the specific results depend on the data and assumptions used and therefore may not be generalizable. Nevertheless, the results are suggestive, and we find that the optimal technology portfolio for the set of projects considered is fairly robust to different specifications of climate uncertainty, to different policy environments, and to assumptions about the opportunity cost of investing. We also conclude that policy makers would do better to over-invest in R&D rather than under-invest. Finally, we show that R&D can play different roles in different types of policy environments, sometimes leading primarily to cost reduction, other times leading to better environmental outcomes.", "e:keyword": ["Energy technology", "R&D portfolio", "Climate change", "Public policy", "Stochastic progamming"]}, {"@id": "http://dx.doi.org/10.1111/poms.12070", "e:abstract": "This article provides a data-driven assessment of economic and environmental aspects of remanufacturing for product + service firms. A critical component of such an assessment is the issue of demand cannibalization. We therefore present an analytical model and a behavioral study which together incorporate demand cannibalization from multiple customer segments across the firm's product line. We then perform a series of numerical simulations with realistic problem parameters obtained from both the literature and discussions with industry executives. Our findings show that remanufacturing frequently aligns firms' economic and environmental goals by increasing profits and decreasing the total environmental impact. We show that in some cases, an introduction of a remanufactured product leads to no changes in the new products' prices (positioning within the product line), implying a positive demand cannibalization and a decrease in the environmental impact; this provides support for a heuristic approach commonly used in practice. Yet in other cases, the firm can increase profits by decreasing the new product's prices and increasing sales—a negative effective cannibalization. With negative cannibalization the firm's total environmental impact often increases due to the growth in new production. However, we illustrate that this growth is nearly always sustainable, as the relative environmental impacts per unit and per dollar rarely increase.", "e:keyword": ["Remanufacturing", "Demand cannibalization", "Product + service firms", "Environmental impact"]}, {"@id": "http://dx.doi.org/10.1111/poms.12071", "e:abstract": "The value of demand information underlies many supply chain strategies that aim at better matching supply and demand. This study reports on the results of a laboratory experiment designed to estimate the behavioral value of demand information. Relative to the commonly assumed benchmark of a rational risk-neutral decision maker, we find that decision makers are consistently willing to pay too much for the option to eliminate the risk of supply not matching demand. Contrary to intuition, we show that risk aversion does not explain this result. We posit that demand information provides behavioral value because it mitigates regret from ex post inventory errors.", "e:keyword": ["Newsvendor decisions", "Value of demand information", "Inventory error regret", "Risk aversion"]}, {"@id": "http://dx.doi.org/10.1111/poms.12074", "e:abstract": "This article examines the effect of product development restructuring (PDR) on shareholder value. The results are based on a sample of 165 announcements made during 2002–2011. PDR announcements are associated with an economically and statistically significant positive stock market reaction. Over a two-day period (the day of the announcement and the day preceding the announcement), the mean (median) market reaction is 1.63% (0.87%). The market reaction is generally positive regardless of the PDR purpose or action. Although the market reaction is more positive for higher R&D intensity firms, it is not directly affected by the firm's prior financial performance or whether the firm's primary PDR objective is to increase revenues or cut costs. However, the interaction between the firm's prior financial performance and its primary PDR objective is significant. For firms that are financial outperformers, the market reaction is more positive if the firm's primary PDR objective is to increase revenues. For financial underperformers, the market reaction is more positive if the firm's primary PDR objective is to cut costs.", "e:keyword": ["Product development", "Empirical research", "Stock market reaction", "Restructuring"]}, {"@id": "http://dx.doi.org/10.1111/poms.12077", "e:abstract": "Online customers expect to wait, sometimes for a delay of many days. At the fulfillment center, there might be an opportunity to fill customer orders earlier than the due date through a cross-docking transaction: rather than picking the item from inventory, the item moves directly from the receiving to the shipping dock, saving shelving and picking transactions. While cross docking reduces shelving and picking costs, it risks changing customer expectations for how soon a product will be delivered. Given customer order arrivals random in quantity and due dates, random replenishment arrivals, and costs (or benefits) for shipping a product early, we characterize the optimal decision as to whether to cross dock a replenishment item to fulfill demand that is not immediately due or to wait to (hopefully) cross dock in later periods. With multiple demands and due dates, the cross-docking decision depends on the number of unfulfilled demands in each period across the horizon, the number of units that have just arrived (available for cross docking), picking and shelving costs, and the delay cost (or benefit). We formulate the problem as a Markov decision process, determine the structure of the optimal policy, and propose a well-performing heuristic.", "e:keyword": ["Cross docking", "Online retailing", "Inventory", "Markov decision processes"]}, {"@id": "http://dx.doi.org/10.1111/poms.12078", "e:abstract": "This study develops an analytical model to evaluate competing retail firms' sourcing strategies in the presence of supply uncertainty. We consider a common supplier that sells its uncertain supply to two downstream retail firms engaging in price competition in a horizontally differentiated product market. The focal firm has a dual-sourcing option, while the rival firm can only source from the common supplier. We assess the system-wide effects of supply uncertainty on the focal firm's incentive to pursue the dual-sourcing strategy. We find that the focal firm's dual-sourcing strategy can create a win–win situation that leads to increased retail prices and expected profits for both firms. Furthermore, under certain conditions, we show that it is beneficial for the focal firm to strategically source from the common supplier, even if its alternative supplier offers a lower wholesale price. Overall, we identify two types of incentives for adopting the dual-sourcing strategy: the incentive of mitigating supply risk through supplier diversification and the incentive of strategic sourcing for more effective retail competition.", "e:keyword": ["Dual sourcing", "Supply uncertainty", "Uniform allocation", "Price competition", "Supply chain"]}, {"@id": "http://dx.doi.org/10.1111/poms.12080", "e:abstract": "We consider a problem where a firm produces a variety of fresh products to supply two markets: an export market and a local market. A public transportation service is utilized to deliver the products to the export market, which is cheap, but its schedule is often disrupted severely. Each time this happens, the firm faces the following questions. (i) For a product that has been finished and is waiting for delivery to the export market, should it continue to wait, at an increasing risk of decay, and when should the waiting be terminated and the product be put to the local market? (ii) For a product that has not been finished, should its processing be postponed, so as to reduce the loss from decay after its completion? (iii) What is the best sequence to process the remaining products, according to the information available? We develop, in this study, a model to address these and other related questions. We find optimal policies that minimize the total expected loss in both the make-to-order and make-to-stock production systems, respectively. For each finished product, we reveal relationships among the desirable waiting time, the price at the local market, and the decaying cost. For unfinished products, we find the optimal start times and processing sequence. Numerical experiments are also conducted to evaluate the optimal policies.", "e:keyword": ["Food and agricultural industries", "Production and delivery of perishable products", "Random demands", "Transportation disruptions", "Disruption management"]}, {"@id": "http://dx.doi.org/10.1111/poms.12081", "e:abstract": "To understand whether retailers should consider consumer returns when merchandising, we study how the optimal assortment of a retailer is influenced by its return policy. The retailer selects its assortment from an exogenous set of horizontally differentiated products. Consumers make purchase and keep/return decisions in nested multinomial logit fashion. Our main finding is that the optimal assortment has a distinct structure for relatively strict return policies: it is optimal to offer a mix of the most popular and most eccentric products when the refund amount is sufficiently low, which can be viewed as a form of risk sharing between the retailer and consumers. In contrast, if the refund is sufficiently high or when returns are disallowed, the optimal assortment is composed of only the most popular products (a common finding in the literature). We provide preliminary empirical evidence for one of the key drivers of our results: more eccentric products have higher probability of return—conditional on purchase. In light of our analytical findings and managerial insights, we conclude that retailers should take returns into account when merchandising.", "e:keyword": ["Assortment planning", "Product variety", "Consumer returns", "Retail operations", "Nested logit"]}, {"@id": "http://dx.doi.org/10.1111/poms.12082", "e:abstract": "In this article, we study a firm's interdependent decisions in investing in flexible capacity, capacity allocation to individual products, and eventual production quantities and pricing in meeting uncertain demand. We propose a three-stage sequential decision model to analyze the firm's decisions, with the firm being a value maximizer owned by risk-averse investors. At the beginning of the time horizon, the firm sets the flexible capacity level using an aggregate demand forecast on the envelope of products its flexible resources can accommodate. The aggregate demand forecast evolves as a Geometric Brownian Motion process. The potential market share of each product is determined by the Multinomial Logit model. At a later time and before the end of the time horizon, the firm makes a capacity commitment decision on the allocation of the flexible capacity to each product. Finally, at the end of the time horizon, the firm observes the demand and makes the production quantity and pricing decisions for end products. We obtain the optimal solutions at each decision stage and investigate their optimal properties. Our numerical study investigates the value of the postponed capacity commitment option in supplying uncertain operation environments.", "e:keyword": ["Flexible capacity", "Capacity investment", "Product mix", "Real options", "Postponement"]}, {"@id": "http://dx.doi.org/10.1111/poms.12083", "e:abstract": "Project switching occurs when a multi-project worker shifts his/her attention from one project to another before completing the first project. In this study, we study the effects of two areas of management policy on project switching behavior, project prioritization, and work monitoring. We conduct a controlled experiment to evaluate direct and combined effects of prioritization, scheduled progress checks, and managerial progress checks on project switching behavior in a distributed, multi-project work environment. We use computerized tasks constituting multiple projects as a means of efficiently simulating a project work setting. Working professionals served as subjects for the experiment, thereby enabling us to control for experience and other individual differences that may vary across workers in real-world projects. We find that clarifying priorities has little overall effect on the prevalence of switching in our multi-project setting, while the presence of managerial progress checks has significant and distinct impacts, driving up switch tendencies. Interestingly, various attributes of the timing of these monitoring events also significantly impact the likelihood that workers will switch in response to these event triggers. We discuss the implications of these findings for managerial practice and for future research.", "e:keyword": ["Project management", "Switching", "Priorities", "Monitoring", "Experiment"]}, {"@id": "http://dx.doi.org/10.1111/poms.12086", "e:abstract": "Quality issues in milk—arising primarily from deliberate adulteration by producers—have been reported in several developing countries. In the milk supply chain, a station buys raw milk from a number of producers, mixes the milk and sells it to a firm (that then sells the processed milk to end consumers). We study a non-cooperative game between a station and a population of producers. Apart from penalties on proven low-quality producers, two types of incentives are analyzed: confessor rewards for low-quality producers who confess and quality rewards for producers of high-quality milk. Contrary to our expectations, whereas (small) confessor rewards can help increase both the quality of milk and the station's profit, quality rewards can be detrimental. We examine two structures based on the ordering of individual and mixed testing of milk: pre-mixed individual testing (first test a fraction of producers individually and then [possibly] perform a mixed test on the remaining producers) and post-mixed individual testing (first test the mixed milk from all producers and then test a fraction of producers individually). Whereas pre-mixed individual testing can be socially harmful, a combination of post-mixed individual testing and other incentives achieves a desirable outcome: all producers supply high-quality milk with only one mixed test and no further testing by the station.", "e:keyword": ["Milk supply chain", "Non‐cooperative games", "Quality testing", "Free riding"]}, {"@id": "http://dx.doi.org/10.1111/poms.12087", "e:abstract": "In contrast to the Pollution Haven Hypothesis, the Trade-Up Hypothesis holds that international integration helps improve firms' environmental performance in developing countries. Using firm-level data from Shanghai, this article examines how international linkages, in the form of foreign direct investment or international trade, affect firms' environmental compliance and performance. We find that firms with international linkage via ownership exhibit better compliance with environmental regulation and emit less pollution than firms with no international linkage. We also find that firms with international linkage via market exposure are more likely to exhibit better compliance with environmental regulation than firms with no international linkage, but find no evidence that the former emit less pollution than the latter. This provides a piece of empirical evidence for the Trade-Up Hypothesis.", "e:keyword": ["Trade‐Up Hypothesis", "Pollution Haven Hypothesis", "International integration", "Environment", "China"]}, {"@id": "http://dx.doi.org/10.1111/poms.12090", "e:abstract": "Advertising is a crucial tool for demand creation and market expansion. When a manufacturer uses a retailer as a channel for reaching end customers, the advertising strategy takes on an additional dimension: which party will perform the advertising to end customers. Cost sharing (“co-operative advertising”) arrangements proliferate the option by decoupling the execution of the advertising from its funding. We examine the efficacy of cost sharing in a model of two competing manufacturer–retailer supply chains who sell partially substitutable products that may differ in market size. Some counterintuitive findings suggest that the firms performing the advertising would rather bear the costs entirely if this protects their unit profit margin. We also evaluate the implications of advertising strategy for overall supply chain efficiency and consumer welfare.", "e:keyword": ["Manufacturer advertising", "Retailer advertising", "Cost sharing", "Supply chain competition", "Game theory", "Co‐op advertising"]}, {"@id": "http://dx.doi.org/10.1111/poms.12092", "e:abstract": "Most organizations employ collaborative teams to manage innovation projects. Although the use of collaborative innovation teams is a good starting point, an organization's ability to innovate can be enhanced by managing risk-taking behavior through monetary incentive schemes and through an organizational culture that tolerates failure. This article reports the results of two controlled experiments aimed at understanding how tolerance for failure and incentives impact the decisions of individuals engaged in a collaborative innovation initiative. A key element of our experiments is the notion of endogenous project risk, which we define as the explicit link between resources allocated to a project and the likelihood of project success. We observe that when penalties are low, the amount of risk an individual assumes is fairly insensitive to the rewards that are offered. In an analogous result, when individuals make decisions alone (rather than collaboratively), higher tolerance for failure does little to increase the amount of risk an individual is willing to take. Taken together, these results highlight the importance of implicit incentives that are created as a result of project and organizational characteristics.", "e:keyword": ["Innovation", "New product development", "Organization control", "Rewards and penalties", "Project management", "Project risk", "Behavioral operations"]}, {"@id": "http://dx.doi.org/10.1111/poms.12095", "e:abstract": "The rising trend of projects with high-skilled and autonomous contributors increasingly exposes managers to the risk of idiosyncratic individual behaviors. In this article, we examine the effects of an important behavioral factor, an individual's cost salience. Cost salience leads individuals to perceive the cost of immediate effort to be larger than the cost of future effort. This leads to procrastination in early stages and back-loaded effort over the course of the project. We model the problem confronting the manager of a project whose quality is adversely impacted by such distortion of individual effort over time. Complementary to prior works focused on the planning and scheduling tasks of project management in the absence of human behavior, we find that managers should reward contributions made in earlier stages of a project. Our analysis also yields interesting insights on the project team performance: teams with diverse levels of cost salience will perform better than homogeneous teams. We also address another important facet of team composition, namely, the choice between stable and fluid teams, and find that the practice of creating fluid teams might have previously unrecognized benefits when behavioral aspects of projects are considered. We conclude with insights and organizational implications for project managers.", "e:keyword": ["Project management", "Procrastination", "Cost salience", "Behavioral operations management"]}, {"@id": "http://dx.doi.org/10.1111/poms.12097", "e:abstract": "This paper studies an outsourcing problem where two service providers (suppliers) compete for the service contract from a client. The suppliers face uncertain cost for providing the service because they do not have perfect information about the client's type. The suppliers receive differential private signals about the client type and thus compete under asymmetric information. We first characterize the equilibrium of the supplier competition. Then we investigate two of the client's information sharing decisions. It is shown that less information asymmetry between the suppliers may dampen their competition. Therefore, the client does not necessarily have the incentive to reduce information asymmetry between the suppliers. We characterize the conditions under which leveling the informational ground is beneficial to the client. We also find that under the presence of information asymmetry (e.g., when the suppliers have different learning abilities), sharing more information with both suppliers may enhance the advantage of one supplier over the other and at the same time increase the upper bound of the suppliers' quotes in equilibrium. Consequently, the suppliers compete less aggressively and the client's payoff decreases in the amount of shared information. The findings from this study provide useful managerial implications on information management for outsourcing firms.", "e:keyword": ["Service outsourcing", "Asymmetric information", "Information sharing", "Common value auction"]}, {"@id": "http://dx.doi.org/10.1111/poms.12098", "e:abstract": "In this study, we consider the supplier selection problem of a relief organization that wants to establish framework agreements (FAs) with a number of suppliers to ensure quick and cost-effective procurement of relief supplies in responding to sudden-onset disasters. Motivated by the FAs in relief practice, we focus on a quantity flexibility contract in which the relief organization commits to purchase a minimum total quantity from each framework supplier over a fixed agreement horizon, and, in return, the suppliers reserve capacity for the organization and promise to deliver items according to pre-specified agreement terms. Due to the uncertainties in demand locations and amounts, it may be challenging for relief organizations to assess candidate suppliers and the offered agreement terms. We use a scenario-based approach to represent demand uncertainty and develop a stochastic programming model that selects framework suppliers to minimize expected procurement and agreement costs while meeting service requirements. We perform numerical experiments to understand the implications of agreement terms in different settings. The results show that supplier selection decisions and costs are generally more sensitive to the changes in agreement terms in settings with high-impact disasters. Finally, we illustrate the applicability of our model on a case study.", "e:keyword": ["Supplier selection", "Framework agreements", "Humanitarian relief", "Procurement", "Stochastic programming"]}, {"@id": "http://dx.doi.org/10.1111/poms.12100", "e:abstract": "This research examines how organizations simultaneously manage their operations and occupational health and safety. Although both safety and operations scholars conduct research in the same operational settings, they have reached different, yet untested, conclusions about the relationship between creating a safe workplace and creating a productive workplace. The results from a series of 10 case studies show that it is possible to create safe and productive workplaces, but that many facilities fail at this task because of problems associated with the culture management creates and the practices management adopts.", "e:keyword": ["Operational safety", "Human resources", "Practices", "Qualitative research"]}, {"@id": "http://dx.doi.org/10.1111/poms.12101", "e:abstract": "Inefficiency and inequity are two challenges that plague humanitarian operations and health delivery in resource-limited regions. Increasing capacity in humanitarian and health delivery supply chains is one option that has the potential to improve equity while maintaining efficiency. For example, the nonprofit organization Riders for Health has worked to increase capacity by providing reliable transportation to health workers in rural parts of sub-Saharan Africa; with more motorcycle hours at their disposal, health workers can perform more outreach to outlying communities. We develop a model using a family of fairness function to quantify the efficiency and equity of health delivery as capacity is increased via development programs. We present optimal resource allocations under utilitarian, proportionally fair, and egalitarian objectives and extend the model to include dual modes of transport and diminishing returns of subsequent outreach visits. Finally, we demonstrate how to apply our model at a regional level to provide support for humanitarian decision makers such as Riders for Health. We use data from the baseline phase of our evaluation trial of Riders for Health in Zambia to quantify efficiency and equity for one real-world scenario.", "e:keyword": ["Health care", "Public policy", "Humanitarian operations", "Capacity planning"]}, {"@id": "http://dx.doi.org/10.1111/poms.12102", "e:abstract": "The basis for this article is an information-processing view of the UN's cluster approach. We use agent-based modeling and simulations to show that clusters, if properly utilized, encourage better information flow and thus facilitate effective response to disasters. The article intends to turn the attention of the humanitarian community to the importance of sharing information and the role of cluster leads in facilitating humanitarian aid. Our results indicate that if cluster leads act as information hubs, information reaches its target faster, enabling a prompt humanitarian response. In addition, we show that information quality is critical for effective resource utilization—if cluster leads filter information, it moves faster. We also found evidence that the willingness to exchange information plays a larger role in transmitting information than that of an information hub, particularly during later stages of response operations.", "e:keyword": ["Humanitarian logistics", "Cluster approach", "Disaster response", "Coordination", "Information flows"]}, {"@id": "http://dx.doi.org/10.1111/poms.12103", "e:abstract": "In many services, for example, website or landscape design, the value or quality derived by a customer depends upon the service time, and this valuation differs across customers. Customers procure the service based on the expected value to be delivered, prices charged, and the timeliness of service. We investigate the performance of the optimal pricing scheme as well as two commonly used pricing schemes (fixed fee and time-based pricing) for such services on important dimensions such as revenue, demand served, and utilization. We propose a novel model that captures the above features and wherein both service rate and demand are endogenous and functions of the pricing scheme. In particular, service time is an outcome of the pricing scheme adopted and the heterogeneous valuations of customers, unlike in the queueing-based pricing literature. We find that the service system may benefit from a greater variance in consumer valuations, and the performance of pricing schemes is impacted by the shape of the distribution of customers' valuation of service time and the responsiveness desired by customers. Both the fixed fee and time-based schemes do well relative to the optimal pricing scheme in terms of revenue in many plausible scenarios, but there are substantial differences between the pricing schemes in some important operational metrics. For instance, the fixed fee scheme serves more customers and has higher utilization than the time-based scheme. We also explore variants of the fixed and time-based schemes that have better revenue performance and show that the two-part tariff which is a combination of fixed and time-based pricing can do as well as the optimal scheme in terms of revenue.", "e:keyword": ["Discretionary service", "Pricing scheme", "Service performance", "Queuing"]}, {"@id": "http://dx.doi.org/10.1111/poms.12104", "e:abstract": "We study several finite-horizon, discrete-time, dynamic, stochastic inventory control models with integer demands: the newsvendor model, its multi-period extension, and a single-product, multi-echelon assembly model. Equivalent linear programs are formulated for the corresponding stochastic dynamic programs, and integrality results are derived based on the total unimodularity of the constraint matrices. Specifically, for all these models, starting with integer inventory levels, we show that there exist optimal policies that are integral. For the most general single-product, multi-echelon assembly system model, integrality results are also derived for a practical alternative to stochastic dynamic programming, namely, rolling-horizon optimization by a similar argument. We also present a different approach to prove integrality results for stochastic inventory models. This new approach is based on a generalization we propose for the one-dimensional notion of piecewise linearity with integer breakpoints to higher dimensions. The usefulness of this new approach is illustrated by establishing the integrality of both the dynamic programming and rolling-horizon optimization models of a two-product capacitated stochastic inventory control system.", "e:keyword": ["Integrality", "Stochastic inventory control", "Total unimodularity", "Multi‐dimensional piecewise linearity"]}, {"@id": "http://dx.doi.org/10.1111/poms.12105", "e:abstract": "This research analyzes how individual differences affect performance in judgmental time-series forecasting. Decision makers with the ability to balance intuitive judgment with cognitive deliberation, as measured by the cognitive reflection test, tend to have lower forecast errors. This relationship holds when controlling for intelligence. Furthermore, forecast errors increase for very fast or very slow decisions. We provide evidence that forecast performance can be improved by manipulating decision speed.", "e:keyword": ["Forecasting", "Behavioral operations", "Decision speed", "Cognitive reflection"]}, {"@id": "http://dx.doi.org/10.1111/poms.12108", "e:abstract": "This article aims to identify optimal vehicle procurement policies for organizations engaged in humanitarian development programs and to derive general insights on the characteristics of these policies. Toward that end, we follow an inductive approach. First, we study the operations of the International Committee of the Red Cross (ICRC) in three representative countries: Sudan, Afghanistan, and Ethiopia. Using a linear programming (LP) model primed with field data provided by the ICRC, we calculate the optimal vehicle fleet size and compare it with the policies actually implemented. Second, drawing from results of the LP model, we develop a stylized quadratic control model and use it to characterize the general structure of the optimal policy under different demand scenarios and operational constraints. After demonstrating that the results of the control model are consistent with those of the LP model in the specific context analyzed, we discuss the optimal policies and the applicability of the former as a practical tool for strategic asset planning.", "e:keyword": ["Fleet management", "Humanitarian logistics", "Development programs", "Procurement"]}, {"@id": "http://dx.doi.org/10.1111/poms.12109", "e:abstract": "School feeding is an established development aid intervention with multiple objectives including education, nutrition, and value transfer. Traditionally run by international organizations in low-income settings, school feeding programs have had a substantial impact in many less-developed countries. However, recent rethinking by the World Bank and the World Food Programme has prompted a shift toward long-term, sustainable solutions that rely more upon local resources, local capacity, and community participation. Supply chain management, which is critical to program delivery, is vital to developing a sustainable approach to school feeding. We propose a theoretical framework that identifies the internal and external factors that shape the supply chain and connects them to the objectives and performance measures of sustainable programs. Drawing upon supply chain management theory, current school feeding practices, and expert feedback, this article contributes to development aid logistics and program transitioning with a focus on sustainable program design. It aims to provide a comprehensive introduction to school feeding and relevant supply chain issues, a framework to identify sustainability problems in school feeding supply chains, and a starting point for further research on program design.", "e:keyword": ["Humanitarian supply chain", "School feeding", "Sustainability", "Framework"]}, {"@id": "http://dx.doi.org/10.1111/poms.12111", "e:abstract": "Floods are the most frequent category of disasters worldwide. Among all geographic regions, Asia has suffered the most. While there are several ongoing humanitarian efforts and initiatives, we believe there is a new opportunity to coordinate “last mile” humanitarian efforts in the event of a flood using micro-retailers. Because micro-retailers are the “last mile” nodes in traditional retail supply chains in many Asian countries, we propose the use of social enterprise to buttress these supply chains for distribution of essential goods by coordinating with micro-retailers before and after floods. We also present a stylized model to quantify the benefits of doing so.", "e:keyword": ["Supply chain design", "Floods", "Natural disasters", "Humanitarian relief", "Social enterprise", "Buttressed supply chains", "Disaster relief"]}, {"@id": "http://dx.doi.org/10.1111/poms.12160", "e:abstract": "Supply disruptions are all too common in supply chains. To mitigate delivery risk, buyers may either source from multiple suppliers or offer incentives to their preferred supplier to improve its process reliability. These incentives can be either direct (investment subsidy) or indirect (inflated order quantity). In this study, we present a series of models to highlight buyers’ and suppliers’ optimal parameter choices. Our base-case model has deterministic buyer demand and two possibilities for the supplier yield outcomes: all-or-nothing supply or partial disruption. For the all-or-nothing model, we show that the buyer prefers to only use the subsidy option, which obviates the need to inflate order quantity. However, in the partial disruption model, both incentives—subsidy and order inflation—may be used at the same time. Although single sourcing provides greater indirect incentive to the selected supplier because that avoids order splitting, we show that the buyer may prefer the diversification strategy under certain circumstances. We also quantify the amount by which the wholesale price needs to be discounted (if at all) to ensure that dual sourcing strategy dominates sole sourcing. Finally, we extend the model to the case of stochastic demand. Structural properties of ordering/subsidy decisions are derived for the all-or-nothing model, and in contrast to the deterministic demand case, we establish that the buyer may increase use of subsidy and order quantity at the same time.", "e:keyword": ["Supply disruption", "Process improvement", "Incentive mechanism", "Dual sourcing"]}, {"@id": "http://dx.doi.org/10.1111/poms.12162", "e:abstract": "We propose a model where customers are classified into two groups: short lead-time customers who require the product immediately and long lead-time customers to whom the supplier may deliver either immediately or in the next cycle. Unmet orders are backlogged with associated costs. Specifically, the supplier faces two problems: how the on-hand inventories should be allocated between the two classes of customers and how the backlogged orders should be cleared when replenishments arrive. We treat the former as an inventory commitment problem and handle the latter with priority rules. We characterize and compare the inventory commitment policies with three priority rules in clearing backlogs. We also explore the optimal inventory replenishment decision and evaluate the performance of each priority rule.", "e:keyword": ["Flexible delivery", "Backlog models", "Priority rules", "Inventory management"]}, {"@id": "http://dx.doi.org/10.1111/poms.12163", "e:abstract": "We consider a supply chain with a supplier that sells to a retailer under a revenue-sharing arrangement. Demand is uncertain and unobservable to the supplier. We assume that the retailer is rational, that is, the retailer behaves opportunistically and underreports sales revenues to the supplier whenever such underreporting is profitable. Assuming the supplier has the ability to audit the retailer and learn about the actual sales revenues, we show that the supplier will never find it optimal to audit to the point that ensures truthful reporting for all demand realizations. By committing to an auditing policy, the supplier can exploit retailer opportunism and derive profits that at times even exceed those that could be obtained when dealing with a retailer that always strictly adheres to the agreed-upon contract terms. We also show that the retailer's opportunistic behavior can increase total supply chain profits.", "e:keyword": ["Supply chain management", "Revenue‐sharing contracts", "Noncooperative game theory"]}, {"@id": "http://dx.doi.org/10.1111/poms.12164", "e:abstract": "In this study, we present new approximation methods for the network revenue management problem with customer choice behavior. Our methods are sampling-based and so can handle fairly general customer choice models. The starting point for our methods is a dynamic program that allows randomization. An attractive feature of this dynamic program is that the size of its action space is linear in the number of itineraries, as opposed to exponential. It turns out that this dynamic program has a structure that is similar to the dynamic program for the network revenue management problem under the so called independent demand setting. Our approximation methods exploit this similarity and build on ideas developed for the independent demand setting. We present two approximation methods. The first one is based on relaxing the flight leg capacity constraints using Lagrange multipliers, whereas the second method involves solving a perfect hindsight relaxation problem. We show that both methods yield upper bounds on the optimal expected total revenue. Computational experiments demonstrate the tractability of our methods and indicate that they can generate tighter upper bounds and higher expected revenues when compared with the standard deterministic linear program that appears in the literature.", "e:keyword": ["Network revenue management", "Customer choice", "Dynamic programming", "Simulation"]}, {"@id": "http://dx.doi.org/10.1111/poms.12167", "e:abstract": "This article presents a model of the design and introduction of a product line when the firm is uncertain about consumer valuations for the products. We find that product line introduction strategy depends on this uncertainty. Specifically, under low levels of uncertainty the firm introduces both models during the first period; under higher levels of uncertainty, the firm prefers sequential introduction and delays design of the second product until the second period. Under intermediate levels of uncertainty the firm's first product should be of lower quality than one produced by a myopic firm that does not take product line effects into consideration. We find that when the firm introduces a product sequentially, the strategy might depend on realized demand. For example, if realized demand is high, the firm's second product should be a higher-end model; if demand turns out to be low, the firm's second product should be a lower-end model or replace the first product with a lower-end model.", "e:keyword": ["Product line", "Product introduction", "Introduction strategy", "Demand uncertainty"]}, {"@id": "http://dx.doi.org/10.1111/poms.12169", "e:abstract": "This paper studies the impact of supply chain power structure on firms' profitability in an assembly system with one assembler and two suppliers. Two power regimes are investigated—in a Single Power Regime, a more powerful firm acts as the Stackelberg leader to decide the wholesale price but not the quantity whereas in a Dual Power Regime, both the price and quantity decisions are granted to the more powerful firm. Tallying the power positions of the three firms, for each power regime we study three power structures and investigate the system's as well as the firms' preference of power. We find that when the assembler is the most powerful firm among the three, the system-wide profit is the highest and so is the assembler's profit. The more interesting finding is that, if the assembler is not the most powerful player in the system, more power does not necessarily guarantee her a higher profit. Similarly, a supplier's profit can also decrease with the power he has. These results contrast with the conclusion for serial systems, where a firm always prefers more power. We also find that when both suppliers are more (less) powerful than the assembler, it can be beneficial (indifferent) for everyone if the two suppliers merge into a mega supplier to make decisions jointly. When the assembler is more powerful than one supplier and less so than the other, it is always better for the system to have the two suppliers merge, and for each individual firm, merging is preferred if the firm becomes the more powerful party after merging.", "e:keyword": ["Assembly system", "Supply chain power structure", "Profitability"]}, {"@id": "http://dx.doi.org/10.1111/poms.12171", "e:abstract": "When facing heterogeneous customers, how should a service firm make its pricing decision to maximize revenue? If discrimination is allowed, then priority schemes and differentiated pricing are often used to achieve that. In many applications, however, the firm cannot or is not allowed to set discriminatory prices, for example, list price in retail stores, online shopping, and gas stations; thus a uniform price must be applied to all customers. This study addresses the optimal uniform pricing problem of a service firm using a queueing system with two classes of customers. Our result shows that the potential pool of customers plays a central role in the firm's optimal decision. Depending on the range of system parameters, which are determined explicitly by the primitive data, the firm's optimal strategy may choose to serve only one class of customers, a subset of a class of customers, or a combination of different classes of customers. In addition, the optimal price is in general not monotonic with respect to the potential market sizes because their changes may lead to a major shift in the firm's decision on which customer class to serve. However, unless such a shift occurs, the optimal price is weakly decreasing in the potential market sizes.", "e:keyword": ["Service system", "Queueing delays", "Delay‐sensitive customers", "Optimal pricing"]}, {"@id": "http://dx.doi.org/10.1111/poms.12175", "e:abstract": "Taking advantage of low tax rates using transfer pricing and taking advantage of low production costs using offshoring are two strategies multinational firms (MNFs) use to increase profits. We identify an important trade-off that MNFs face in setting their transfer prices: the conflict between (i) the incentive role and (ii) the tax role of the transfer price. For MNFs, we find the profit-maximizing transfer-pricing strategies that motivate divisional management to (i) make good sourcing decisions and (ii) take advantage of favorable tax rates. We quantify the absolute and relative maximum inefficiency in terms of the after-tax MNF's profit change from using a single transfer-pricing system as compared to the dual transfer-pricing system. We show that the highest relative loss is attained when the average sourcing cost and the tax differential are high. We demonstrate that the highest absolute loss is attained when the average outsourcing cost is approximately equal to the offshoring cost. We extend our results to two practical variations in MNF structures: an MNF that faces operational constraints on its offshoring capacity and an MNF that uses compensation contracts linked to after-tax firm-wide profits. Our insights help MNFs' managers identify when to use single and dual transfer-pricing systems.", "e:keyword": ["Transfer pricing", "International tax", "Multinational firms", "Global sourcing"]}, {"@id": "http://dx.doi.org/10.1111/poms.12177", "e:abstract": "We analyze the efficacy of different asset transfer mechanisms and provide policy recommendations for the design of humanitarian supply chains. As a part of their preparedness effort, humanitarian organizations often make decisions on resource investments ex ante because doing so allows for rapid response if an adverse event occurs. However, programs typically operate under funding constraints and donor earmarks with autonomous decision-making authority resting with the local entities, which makes the design of efficient humanitarian supply chains a challenging problem. We formulate this problem in an agency setting with two independent aid programs, where different asset transfer mechanisms are considered and where investments in resources are of two types: primary resources that are needed for providing the aid and infrastructural investments that improve the operation of the aid program in using the primary resources. The primary resources are acquired from earmarked donations. We show that allowing aid programs the flexibility of transferring primary resources improves the efficiency of the system by yielding greater social welfare than when this flexibility does not exist. More importantly, we show that a central entity that can acquire primary resources from one program and sell them to the other program can further improve system efficiency by providing a mechanism that facilitates the transfer of primary resources and eliminates losses from gaming. This outcome is achieved without depriving the individual aid programs of their decision-making autonomy while maintaining the constraints under which they operate. We find that outcomes with centralized resource transfer but decentralized infrastructural investments by the aid programs are the same as with a completely centralized system (where both resource transfer and infrastructural investments are centralized).", "e:keyword": ["Asset transfer", "Humanitarian logistics", "Supply chain design"]}, {"@id": "http://dx.doi.org/10.1111/poms.12179", "e:abstract": "In order to reduce their inventory risk, firms can attempt to contract with their suppliers for shorter supply lead-times, with their buyers for longer demand lead-times, or both. We designed a controlled laboratory experiment to study contracts that shift a focal firm's inventory risk to its supply chain partners and address two questions. First, is it more effective if the cost of shifting inventory risk is framed as a fixed fee or in per-unit cost terms? We find that, generally, our participants are willing to pay more to avoid supply–demand mismatches than the expected costs from such mismatches. This tendency to overpay is mitigated under fixed fee schemes. Second, does it matter whether the option to reduce inventory risk is the outcome of either increased responsiveness from the upstream supplier or advanced demand information from the downstream buyer? Our results suggest that this difference, when only a matter of framing, has no significant effect on willingness-to-pay.", "e:keyword": ["Newsvendor decisions", "Value of demand information", "Fixed fee and per‐unit contracts"]}, {"@id": "http://dx.doi.org/10.1111/poms.12180", "e:abstract": "Large sunk costs of development, negligible costs of reproduction, and distribution resulting in economies of scale distinguish information goods from physical goods. Versioning is a way firms may take advantage of these properties. However, in a baseline model where consumers differ in their tastes for quality, an information goods monopolist only offers one version, and this differs from what we observe in practice. We explore formulations that add features to the baseline model that result in a monopolist offering multiple versions. We examine versioning where consumers differ in individual tastes for quality, and groups of consumers that share the same group taste are delineated by segments of individual tastes. We find that if groups have mutually exclusive characteristics—a horizontal dimension—that they value relative to the shared characteristics, then versioning is optimal. Consequently, any horizontal differentiation in product line design favors versioning. In addition, when group tastes are hierarchical such that higher taste groups value characteristics that lower taste groups value but not vice versa—a vertical dimension—as long as the valuations of the higher and adjacent lower taste group are sufficiently close, then versioning is also optimal. Our conditions, which also help determine how many versions are optimal, are based on exogenously defined parameters so that it is feasible to check them in practice.", "e:keyword": ["Information goods", "Market segmentation", "Product differentiation", "Versioning strategies", "Pricing strategies"]}, {"@id": "http://dx.doi.org/10.1111/poms.12181", "e:abstract": "This article surveys the literature and develops a framework for research into the integration of distributed knowledge work (DKW). Knowledge work is considered to be “distributed” whenever key decisions for execution of the project cut across organizational boundaries, as occurs under outsourcing, offshoring, or open-source arrangements. The growth of such arrangements in recent years is well documented. Nonetheless, research into maintaining the coherence of a DKW project from initiation to customer delivery, often referred to as supply chain integration, project or systems integration, or simply “integration,” is relatively new. We first review the relevant literature from operations, service, and information management, organizational theory, and engineering design, focusing on the key decisions identified by this literature in relation to the contracting, organization, work, and information infrastructure design of a knowledge work project. We then attempt to open the “black box” of integration by inductively organizing these key decisions. Finally, we contrast this approach with prior research frameworks and identify key topics for future study.", "e:keyword": ["Supply chain integration", "Outsourcing", "Project management", "Product development", "Software development"]}, {"@id": "http://dx.doi.org/10.1111/poms.12182", "e:abstract": "This article studies the impact of modular assembly on supply chain efficiency. In the modular assembly approach, a manufacturer acquires pre-assembled modules from its suppliers, rather than the individual components, as in the traditional assembly approach. We analyze the competitive behavior of a two-stage modular assembly system consisting of a manufacturer, and a supplier who pre-assembles two components into a module. The firms can choose their own inventory policies and we show the existence of Nash equilibrium in the inventory game. Moving from the traditional to the modular approach has a twofold effect on the supply chain. First, we investigate the effect of centralizing the component suppliers. It can be shown that when there is no production time shift, the module supplier always holds more component inventories than suppliers do in the traditional approach, which yields a lower cost for the manufacturer. However, the suppliers, and therefore the supply chain may incur a higher cost in the modular approach. Second, we study the effect of a shift in production time from the manufacturing stage to the supplier stage. From numerical studies, it has been found that such a lead time shift always benefits a centralized supply chain, but not necessarily so for a decentralized system. Combining the two effects, we find that the modular approach generally reduces the cost to the manufacturer and the supply chain, which explains the prevalence of modular assembly from the perspective of inventory management. These results also provide some insight into how firms can improve supply chain efficiency by choosing the right decision structure and lead time configuration.", "e:keyword": ["Modular assembly", "Supply chains", "Inventory management", "Game theory"]}, {"@id": "http://dx.doi.org/10.1111/poms.12183", "e:abstract": "We study network games in which users choose routes in computerized networks susceptible to congestion. In the “unsplittable” condition, route choices are completely unregulated, players are symmetric, each player controls a single unit of flow and chooses a single origin–destination (O–D) path. In the “splittable” condition, which is the main focus of this study, route choices are partly regulated, players are asymmetric, each player controls multiple units of flow and chooses multiple O–D paths to distribute her fleet. In each condition, users choose routes in two types of network: a basic network with three parallel routes and an augmented network with five routes sharing joint links. We construct and subsequently test equilibrium solutions for each combination of condition and network type, and then propose a Markov revision protocol to account for the dynamics of play. In both conditions, route choice behavior approaches equilibrium and the Braess Paradox is clearly manifested.", "e:keyword": ["Splittable and unsplittable flow", "Braess Paradox", "Equilibrium analysis", "Experiment"]}, {"@id": "http://dx.doi.org/10.1111/poms.12185", "e:abstract": "Distributed product development is becoming increasingly prevalent in a number of industries. We study how the global distribution of product development impacts the profit-maximizing product line that a firm offers. Specifically, we formulate a model to understand the linkage between cost arbitrage as a driver of distributed development and consequent market implications such as customer perceived quality loss to remotely developed products. Analysis of the model reveals that a firm should expand the product line for a development-intensive good only at intermediate values of cost advantage and quality loss. We modify the base model to include development capacity constraints as a driver of distributed development and find that the results are robust to this change. Our analysis affirms the need for product managers to incorporate the implications of distributed development in making their product line design decision.", "e:keyword": ["Distributed development", "Product line design", "Global operations management", "Operations‐marketing interface"]}, {"@id": "http://dx.doi.org/10.1111/poms.12186", "e:abstract": "Quality testing by suppliers has significant ramifications for downstream supply chain participants and retail consumers. This article focuses on such implications accounting for the fact that suppliers often enjoy discretion in quality testing and reporting. Under a discretionary testing and reporting environment, we show that a supplier can improve the market's perception of product quality by engaging in self-imposed production cuts. Production cuts dampen supplier incentives to engage in excessive quality testing, putting the supplier and the market on a more equal information footing. This reduces the market's need to skeptically discount product quality to protect itself. The improved market perception, then, reduces quality testing demand, introducing cost savings. The result that costly production cuts can improve quality perceptions indicates that the groundwork for influencing market perceptions may have to be laid upfront, even prior to acquiring private information, providing a contrast to routine signaling models.", "e:keyword": ["Voluntary disclosure", "Quality testing", "Perceived quality", "Product rationing"]}, {"@id": "http://dx.doi.org/10.1111/poms.12188", "e:abstract": "The “Principle of Least Action\" is the foundational principle of fundamental physics. Application of this principle to the supply chain naturally results in an “uncertainty principle” linking variation in production to variation in net-inventory. The model also provides an easy means of determining the stationary distribution of net-inventory for a variety of control strategies. The formalism results in a control strategy that outperforms commonly used control methods.", "e:keyword": ["Production‐inventory models", "Brownian motion", "Uncertainty"]}, {"@id": "http://dx.doi.org/10.1111/poms.12191", "e:abstract": "We consider assortment optimization problems under the multinomial logit model, where the parameters of the choice model are random. The randomness in the choice model parameters is motivated by the fact that there are multiple customer segments, each with different preferences for the products, and the segment of each customer is unknown to the firm when the customer makes a purchase. This choice model is also called the mixture-of-logits model. The goal of the firm is to choose an assortment of products to offer that maximizes the expected revenue per customer, across all customer segments. We establish that the problem is NP complete even when there are just two customer segments. Motivated by this complexity result, we focus on assortments consisting of products with the highest revenues, which we refer to as revenue-ordered assortments. We identify specially structured cases of the problem where revenue-ordered assortments are optimal. When the randomness in the choice model parameters does not follow a special structure, we derive tight approximation guarantees for revenue-ordered assortments. We extend our model to the multi-period capacity allocation problem, and prove that, when restricted to the revenue-ordered assortments, the mixture-of-logits model possesses the nesting-by-fare-order property. This result implies that revenue-ordered assortments can be incorporated into existing revenue management systems through nested protection levels. Numerical experiments show that revenue-ordered assortments perform remarkably well, generally yielding profits that are within a fraction of a percent of the optimal.", "e:keyword": ["Logit", "Assortment optimization", "Revenue management", "Capacity control"]}, {"@id": "http://dx.doi.org/10.1111/poms.12192", "e:abstract": "Forecast sharing among trading partners lies at the heart of many collaborative and contractual supply chain management efforts. Even though it has been praised in both academic and practitioner circles for its critical role in increasing demand visibility, some concerns remain: The first one is related to the credibility of forecast sharing, and the second is the fear that it may turn into a competitive disadvantage and induce suppliers to increase their price offerings. In this study, we explore the validity of these concerns under a supply chain with a competitive upstream structure, focusing specifically on (i) when and how a credible forecast sharing can be sustainable, and (ii) how it impacts on the intensity of price competition. To address these issues, we develop a supply chain model with a buyer facing a demand risk and two heterogeneous suppliers competing for order allocation from the buyer. The extent of demand is known only to the buyer. The buyer submits a buying request to the suppliers via a commonly used procurement mechanism called request for quotation (RFQ). We consider two variants of RFQ. In the first type, the buyer simply shares the estimated order quantity with no further specifications. In the second one, in addition to this, the buyer also specifies minimum and/or maximum order quantities. We fully characterize equilibrium decisions and profits associated with them under symmetric and asymmetric information scenarios. Our main findings are that the buyer can use a RFQ with quantity restrictions as a credible signal for forecast sharing as long as the degree of demand information asymmetry is not too high, and that, contrary to above concerns, the equilibrium prices that emerge between competing suppliers under asymmetric information may indeed increase if the buyer cannot share forecast information credibly with its upstream partners.", "e:keyword": ["Forecast sharing", "Competition", "Credibility", "Asymmetric information", "Signalling"]}, {"@id": "http://dx.doi.org/10.1111/poms.12193", "e:abstract": "Coordinating knowledge transfer within multi-plant manufacturing networks is a challenging task. Using a computational model, we examine when it is beneficial to create production knowledge within a central unit, the “lead factory,” and transfer it to geographically dispersed plants. We demonstrate that the knowledge transfer generates a trade-off between a positive cost-saving effect due to fewer adaptations in each plant, and a negative transfer cost effect due to the costly knowledge transfer itself. The complexity of the production process moderates the performance implications of the knowledge transfer because it determines the relative strength of these two effects. For production processes with low complexity, knowledge transfer can engender superior network performance. Here, an optimal extent of knowledge transfer exists, and thus, a complete knowledge transfer is not performance maximizing. For production processes with medium and high levels of complexity, performance is reduced rather than enhanced through knowledge transfer so that it is optimal not to transfer any knowledge from the lead factory to the plants. While we analyze knowledge transfer within a manufacturing network, our results are transferable to other settings that consist of a knowledge sending and receiving unit.", "e:keyword": ["Manufacturing network", "Knowledge transfer", "Lead factory", "Complexity", "NK model"]}, {"@id": "http://dx.doi.org/10.1111/poms.12194", "e:abstract": "This paper studies the optimal policy for a periodic-review inventory system in which the production costs consist of a fixed cost and a piecewise linear convex variable cost. Such a cost function can arise from alternate sources of supply or from the use of overtime production. We fully characterize the structure of the optimal policy for the single-period problem. For the multi-period problem, the optimal policy can have disconnected production regions and complicated optimal produce-up-to levels, which implies that implementation of the optimal policy may not be practical. Fortunately, careful investigation shows that the optimal policy has some interesting properties. The structure of the optimal policy outlined by these properties leads to a practical and close-to-optimal heuristic policy. In an extensive numerical study, the average gap is only 0.02% and the worst gap is 1.37%.", "e:keyword": ["Inventory control", "Fixed cost", "Convex cost", "Heuristic policy"]}, {"@id": "http://dx.doi.org/10.1111/poms.12195", "e:abstract": "We investigate strategic information sharing in two competing channels. The retailer in a channel can ex post decide whether to share private demand information with his upstream manufacturer after the content of information becomes known. We find that a retailer discloses low demand and withholds high demand to induce lower wholesale prices from his manufacturer. We show that a retailer should share less information when the retail market becomes more competitive, but should disclose more information when his capability to acquire information improves. When a decentralized supply chain competes with an integrated channel, we show that firms in the supply chain benefit from the rival channel's effort to improve information capability, that the incentive for the retailer in the supply chain to improve his information capability increases with the intensity of competition and with the rival channel's information capability, and that the retailer may not want to pursue perfect information acquisition even when doing so is costless. Extensive numerical studies demonstrate that similar results also hold for two decentralized supply chains competing with each other.", "e:keyword": ["Competition", "Disclosure", "Supply chain", "Strategic information sharing", "Channel"]}, {"@id": "http://dx.doi.org/10.1111/poms.12196", "e:abstract": "When facing supply uncertainty caused by exogenous factors such as adverse weather conditions, firms diversify their supply sources following the wisdom of “not holding all eggs in one basket.” We study a firm that decides on investment and production levels of two unreliable but substitutable resources. Applying real options thinking, production decisions account for actual supply capabilities, whereas investment decisions are made in advance. To model triangular supply and demand correlations, we adapt the concepts of random capacity and stochastic proportional yield while using concordant ordered random variables. Optimal profit decreases monotonically in supply correlation and increases monotonically in supply–demand correlation. Optimal resource selection, however, depends on the trivariate interplay of supply and demand and responds non-monotonically to changing correlations. Moreover, supply hedges (i.e., excess capacity at alternative sources) can be optimal even if supply resources are perfectly positively correlated. To accommodate changing degrees of correlation, the firm adjusts the lower margin capacities under random capacity; but under stochastic proportional production capability, it uses either low- or high-margin capacities to create tailored “scale hedges” (i.e., excess capacity at one source which can partially substitute for diversification).", "e:keyword": ["Supply and demand risk", "Operational hedging", "Diversification", "Concordance order", "Trivariate correlation"]}, {"@id": "http://dx.doi.org/10.1111/poms.12197", "e:abstract": "We study a firm's optimal transshipment problem considering the impacts of setup costs for transshipment and demand distribution shapes. We assume that the demand follows a three-point distribution, which changes from a degenerate distribution, to a unimodal distribution, and to a bimodal distribution as the demand shape parameter increases. We find that as the demand shape parameter increases, the optimal transshipment strategy changes from no transshipment to transshipment, and finally to no transshipment. The firm would use two-way transshipment when the shape parameter is relatively small, while it would use one-way transshipment when the shape parameter is relatively large. When the optimal strategy is one-way transshipment, the transshipment direction depends on the contribution margin as well as the demand shape, when the difference between the two demand uncertainties is small. Our study of a dual-channel retail system shows that the additional benefit of two-way transshipment is negligible when there are many retail stores.", "e:keyword": ["Transshipment", "Inventory sharing", "Demand shapes", "Three‐point distribution"]}, {"@id": "http://dx.doi.org/10.1111/poms.12199", "e:abstract": "We study a decentralized assembly supply chain in which an assembler (she) assembles a set of n components, each produced by a different supplier (he), into a final product to satisfy an uncertain market demand. Each supplier holds private cost information to himself, for which the assembler only has a subjective estimate. Furthermore, the assembler believes that the suppliers' costs follow a joint discrete probability distribution. The assembler aims to design an optimal menu of contracts to maximize her own expected profit. The assembler's problem is a complex multi-dimensional constrained optimization problem. We prove that there exists a unique optimal menu of contracts for the assembler, and we further develop an efficient algorithm with a complexity of O(n) to compute the optimal contract. In addition, we conduct a comprehensive sensitivity analysis to analyze how environmental parameters affect individual firm's performance and the value of information to the assembler, to each supplier, and to the supply chain. Our results suggest that each supplier's private cost information becomes more valuable to the assembler and each supplier when the average market demand increases or when the final product unit revenue increases. Surprisingly, when a supplier's cost volatility increases and its mean remains the same, the value of information to the assembler or to each supplier does not necessarily increase. Furthermore, we show that when the suppliers' cost distributions become more positively correlated, the suppliers are always worse off, but the assembler is better off. However, the value of information for the assembler might increase or decrease.", "e:keyword": ["Mechanism design", "Private cost information", "Decentralized assembly systems", "Demand uncertainty"]}, {"@id": "http://dx.doi.org/10.1111/poms.12201", "e:abstract": "The relationship between emissions reduction and firm financial performance has been studied with mixed results. We consider potential sources of this ambiguity by examining announcements of voluntary emissions reduction (VER) from 1990 to 2009. We measure the stock market reaction associated with VER announcements to estimate the effects of time, emissions type, and whether the reduction was announced ex ante or ex post. We find that the market reaction to VER significantly decreased over time. The changing nature of the market reaction to VER over time highlights the importance of evaluating the financial impact of any VER in the current context rather than relying on past findings. We also find that the market reaction is more positive if the reduction is for greenhouse gas (GHG) rather than other emissions types. In light of the increasing concern with GHGs, this finding should be welcome news for managers. Last, we find a more positive market reaction for VER announcements that are pledges or statements of intent rather than realized achievements of VER. Managers contemplating VER might find benefit (and at least no harm) in announcing their intent to reduce emissions rather than waiting until they have achieved the reduction.", "e:keyword": ["Environmental performance", "Emissions reduction", "Stock market reaction"]}, {"@id": "http://dx.doi.org/10.1111/poms.12202", "e:abstract": "Should capacitated firms set prices responsively to uncertain market conditions in a competitive environment? We study a duopoly selling differentiated substitutable products with fixed capacities under demand uncertainty, where firms can either commit to a fixed price ex ante, or elect to price contingently ex post, e.g., to charge high prices in booming markets, and low prices in slack markets. Interestingly, we analytically show that even for completely symmetric model primitives, asymmetric equilibria of strategic pricing decisions may arise, in which one firm commits statically and the other firm prices contingently; in this case, there also exists a unique mixed strategy equilibrium. Such equilibrium behavior tends to emerge, when capacity is ampler, and products are less differentiated or demand uncertainty is lower. With asymmetric fixed capacities, if demand uncertainty is low, a unique asymmetric equilibrium emerges, in which the firm with more capacity chooses committed pricing and the firm with less capacity chooses contingent pricing. We identify two countervailing profit effects of contingent pricing under competition: gains from responsively charging high price under high demand, and losses from intensified price competition under low demand. It is the latter detrimental effect that may prevent both firms from choosing a contingent pricing strategy in equilibrium. We show that the insights remain valid when capacity decisions are endogenized. We caution that responsive price changes under aggressive competition of less differentiated products can result in profit-killing discounting.", "e:keyword": ["Competition", "Contingent pricing", "Committed pricing", "Revenue management", "Demand uncertainty"]}, {"@id": "http://dx.doi.org/10.1111/poms.12204", "e:abstract": "We study competitive capacity investment for the emergence of a new market. Firms may invest either in capacity leading demand or in capacity lagging demand at different costs. We show how the lead time and other operational factors including volume flexibility, existing capacity, and demand uncertainty impact equilibrium outcomes. Our results indicate that a type of bandwagon behavior is the most likely equilibrium outcome: if both firms are going to invest, then they are most likely to act in unison. Contrary to much received wisdom, we show that leader–follower behavior is very uncommon in equilibrium where firms do not have volume flexibility, and will not occur at all if lead times are sufficiently short. On the other hand, if there is volume flexibility in production, then the likelihood of this sequential investment behavior increases. Our findings underscore the importance of operational characteristics in determining the competitive dynamics of capacity investment timing.", "e:keyword": ["Capacity investment timing", "Lead time", "Volume flexibility", "Existing capacity", "Operations strategy"]}, {"@id": "http://dx.doi.org/10.1111/poms.12206", "e:abstract": "This paper explores how the capacity of colonoscopy services should be allocated for screening and diagnosis of colorectal cancer to improve health outcomes. Both of these services are important since screening prevents cancer by removing polyps, while diagnosis is required to start treatment for cancer. This paper first presents a basic compartmental model to illustrate the trade-off between these two analytically. Further, a more realistic population dynamics model with resource constraints is introduced for colorectal cancer screening and analyzed numerically. The best resource allocation decisions are investigated with the objectives of minimizing mortality or incidence rates. We provide a sensitivity analysis with respect to policy and disease-related parameters. We conclude that to minimize mortality, the capacity should be rationed to ensure that the wait for diagnosis is at reasonable levels. When the relevant performance measure is the incidence rate, screening is allocated more capacity compared to the case with mortality rate measure. We also show that benefits from increasing compliance to screening programs can only be realized if there is sufficient service capacity.", "e:keyword": ["Colorectal cancer", "Screening", "Colonoscopy", "Resource allocation", "Compartmental model"]}, {"@id": "http://dx.doi.org/10.1111/poms.12208", "e:abstract": "We study a newsvendor who can acquire the services of a forecaster, or, more generally, an information gatherer (IG) to improve his information about demand. When the IG's effort increases, does the average ex ante order quantity rise or fall? Do average ex post sales rise or fall? Improvements in information technology and in the services offered by forecasters provide motivation for the study of these questions. Much depends on our model of the IG and his efforts. We study an IG who sends a signal to a classic single-period newsvendor. The signal defines the newsvendor's posterior probability distribution on the possible demands and the newsvendor uses that posterior to calculate the optimal order. Each of the possible posteriors is a scale/location transform of the same base distribution. When the IG works harder, the average scale parameter drops. Higher IG effort is always useful to the newsvendor. We show that there is a critical value of order cost. For costs on one side of this value more IG effort leads to a higher average ex ante order and for costs on the other side to a lower average order. But for all costs, more IG effort leads to higher average ex post sales. We obtain analogous results for a “regret-averse” newsvendor who suffers a penalty that is a nonlinear function of the discrepancy between quantity ordered and true demand.", "e:keyword": ["Newsvendor", "Inventory management", "Information gathering", "Demand forecasting"]}, {"@id": "http://dx.doi.org/10.1111/poms.12209", "e:abstract": "We address the use and value of time and temperature information to manage perishables in the context of a retailer that sells a random lifetime product subject to stochastic demand and lost sales. The product's lifetime is largely determined by the temperature history and the flow time through the supply chain. We compare the case in which information on flow time and temperature history is available and used for inventory management to a base case in which such information is not available. We formulate the two cases as Markov Decision Processes and evaluate the value of information through an extensive simulation using representative, real world supply chain parameters.", "e:keyword": ["Perishable inventory", "Value of information", "RFID", "Simulation"]}, {"@id": "http://dx.doi.org/10.1111/poms.12210", "e:abstract": "The objective of this study was to extend existing understanding of supplier encroachment to contexts in which there is information asymmetry and the supplier can use nonlinear pricing. Prior research has shown that supplier encroachment can mitigate double marginalization and thus benefit both the supplier and the reseller. However, under symmetric information, this benefit disappears if the supplier can use nonlinear pricing. In our model, the reseller observes the true market size while the supplier knows only the prior distribution, that is, a seemingly ideal setting for implementing mechanism design through nonlinear pricing. We first show that, because encroachment capability enables the supplier to make an ex post output decision, it fundamentally alters the structure of the optimal nonlinear pricing policy. In addition to the usual downward distortion effect, where the reseller may purchase less than the efficient quantity, we also have the possibility for upward distortion. Thus, under asymmetric information and nonlinear pricing, supplier encroachment has two opposing effects. On one hand, the ability to shift sales to the direct channel allows the supplier to reduce information rents with less sacrifice of efficiency; but on the other hand, by introducing the possibility of her own opportunistic behavior, it can result in upward distortion of the quantities sold through the reselling channel, which is a new source of inefficiency. Depending upon the relative efficiency of the reselling channel and the demand distribution, either of these two effects may dominate and the supplier's ability to encroach may either benefit or hurt both the supplier and the reseller.", "e:keyword": ["Supplier encroachment", "Information asymmetry", "Nonlinear pricing"]}, {"@id": "http://dx.doi.org/10.1111/poms.12211", "e:abstract": "We empirically examine the association between downstream firms’, i.e., customers’ capital market information quality, and the operating performance of upstream firms, i.e., suppliers. Customers’ capital market information quality is measured by the customers’ provision of earnings forecasts, the customers’ reported earnings quality, and the customers’ coverage by financial analysts and credit rating agencies. We hypothesize and find a positive association between customers’ capital market information quality and suppliers’ operating performance measured by the DuPont profitability ratios. The association is stronger for suppliers with higher sales volatility, no order backlogs, customers who are less dependent on their input, and shorter business relation with customers. Collectively, the results suggest that the quality of information provided by the customers to the capital market has a spillover effect in the input market, i.e., helps the suppliers improve their performance.", "e:keyword": ["Information sharing", "Earnings guidance and quality", "Analysts", "Credit rating", "DuPont profitability ratios"]}, {"@id": "http://dx.doi.org/10.1111/poms.12212", "e:abstract": "With increasing frequency, firms are locating their operations in disparate countries with distinct national cultures and languages. This study develops and empirically tests hypotheses relating an operation's process compliance performance to (1) the presence of a language difference between the location of the operation and that of headquarters and (2) the national culture of the location of the operation and that of headquarters. Employing an international sample of pharmaceutical manufacturing plants located primarily in Western nations, the analysis reveals that a language difference between the location of a plant and the firm's headquarters is consistently related to decreased process compliance at the plant level. Regarding national culture, only limited evidence of a direct relationship between national cultural dimensions (at either the plant or headquarters location) and process compliance exists. However, the analysis does suggest that cultural congruence between the location of the plant and that of headquarters can relate to improved compliance performance. Such a relationship depends on the specific national cultural dimension studied. While these results are obtained in a specific manufacturing setting, they potentially have implications for process compliance in any global operation.", "e:keyword": ["Routines", "Knowledge transfer", "Offshoring", "International", "Manufacturing"]}, {"@id": "http://dx.doi.org/10.1111/poms.12214", "e:abstract": "We consider the problem faced by a company selling a product with warranty and under partial information about the product reliability. The product can fail from multiple failure types, each of which is associated with an inherently different repair cost. If the product fails within the warranty duration, then the company is required to pay the repair cost. The company does not know the probabilities associated with different failure types, but it learns the failure probabilities as sales occur and failure information is accumulated. If the failure probabilities turn out to be too high and it becomes costly to fulfill the warranty coverage, then the company may decide to stop selling the product, possibly replacing it with a more reliable alternative. The objective is to decide if and when to stop. By formulating the problem as a dynamic program with Bayesian learning, we establish structural properties of the optimal policy. Since computing the optimal policy is intractable due to the high dimensional state space, we propose two approximation methods. The first method is based on decomposing the problem by failure types and it provides upper bounds on the value functions. The second method provides lower bounds on the value functions and it is based on a deterministic approximation. Computational experiments indicate that the policy from the first method provides noticeable benefits, especially when it is difficult to form good estimates of the failure probabilities quickly.", "e:keyword": ["Revenue management", "Reliability", "Marketing", "Optimal stopping", "Bayesian learning"]}, {"@id": "http://dx.doi.org/10.1111/poms.12215", "e:abstract": "The work of international humanitarian organizations (IHOs) frequently involves operating in remote locations, decentralized decision-making, and the simultaneous implementation of development and disaster response programs. A large proportion of this work is funded by “earmarked” donations, since donors often exhibit a preference for the programs they are willing to fund. From extensive research involving qualitative descriptions and quantitative data, and applying system dynamics methodology, we model vehicle supply chains (VSCs) in support of humanitarian field operations. Our efforts encompass the often-overlooked decentralized environment by incorporating the three different VSC structures that IHOs operate, as well as examining the entire mix of development and disaster response programs, and the specific (and virtually unexplored) effects of earmarked funding. Our results suggest that earmarked funding causes a real—and negative—operational impact on humanitarian disaster response programs in a decentralized setting.", "e:keyword": ["Disaster management", "Humanitarian operations", "Humanitarian logistics", "Supply chain management", "System dynamics"]}, {"@id": "http://dx.doi.org/10.1111/poms.12217", "e:abstract": "The focus of this study is on the A+B transportation procurement mechanism, which uses the proposed cost (A component) and the proposed time (B component) to score contractors’ bids. Empirical studies have shown that this mechanism shortens project durations. We use normative models to study the effect of certain discretionary parameters set by state transportation agencies on contractors’ equilibrium bidding strategies, winner selection, and actual completion times. We model the bidding environment in detail including multi-dimensional bids, contractors’ uncertainty about completion times, and reputation cost. The latter refers to a private penalty that accrues to tardy contractors from increased cost of posting bonds and reduced prospects of winning future projects. Our model explains why contractors may skew line-item bids and why winners frequently finish earlier than bid. It has several policy implications as well. For example, we recommend that agencies set the daily incentive, disincentive, and road user cost to be equal and not cap incentives. This is a departure from current practice, where incentives are often capped and weaker than penalties. Furthermore, we show that agencies may be justified in setting daily road user cost strictly smaller than the true cost of traffic disruption during construction.", "e:keyword": ["Auctions", "Time‐based incentives", "A+B bidding", "Procurement policy"]}, {"@id": "http://dx.doi.org/10.1111/poms.12218", "e:abstract": "We consider a supply chain with an upstream supplier who invests in innovation and a downstream manufacturer who sells to consumers. We study the impact of supply chain contracts with endogenous upstream innovation, focusing on three different contract scenarios: (i) a wholesale price contract, (ii) a quality-dependent wholesale price contract, and (iii) a revenue-sharing contract. We confirm that the revenue-sharing contract can coordinate supply chain decisions including the innovation investment, whereas the other two contracts may result in underinvestment in innovation. However, the downstream manufacturer does not always prefer the revenue-sharing contract; the manufacturer's profit can be higher with a quality-dependent wholesale price contract than with a revenue-sharing contract, specifically when the upstream supplier's innovation cost is low. We then extend our model to incorporate upstream competition between suppliers. By inviting upstream competition, with the wholesale price contract, the manufacturer can increase his profit substantially. Furthermore, under upstream competition, the revenue-sharing contract coordinates the supply chain, and results in an optimal contract form for the manufacturer when suppliers are symmetric. We also analyze the case of complementary components suppliers, and show that most of our results are robust.", "e:keyword": ["Supply chain management", "Innovation", "Quality", "Contracts", "Competition"]}, {"@id": "http://dx.doi.org/10.1111/poms.12220", "e:abstract": "It is generally believed that store brands hurt the manufacturers of competing national brands while benefiting retailers. In this study, we challenge this notion by studying the impacts of a store brand when it is introduced by a power retailer. We show that a store brand may benefit the manufacturer when the interaction between the manufacturer and retailer is modeled as a retailer-led Stackelberg game. This phenomenon occurs because the store brand changes the nature of the strategic interaction between the manufacturer and retailer in our model. In particular, while the interaction is always vertical strategic substitutability without a store brand, it may become vertical strategic independence with one. With the store brand, the demand for the national brand becomes larger, and the wholesale price for the national brand may increase, both of which benefit the manufacturer. Finally, the store brand may lessen the double marginalization problem of the supply chain for the national brand in the retailer-led Stackelberg game, but does so in an unconventional way: The reduction in the double marginalization effect may come from a lowered retail markup instead of a lowered wholesale price. Our results reconcile some discrepancies between theoretical predictions and empirical findings regarding the impacts of store brands on manufacturers.", "e:keyword": ["Store brand", "Supply chain", "Power retailer", "Vertical strategic interaction"]}, {"@id": "http://dx.doi.org/10.1111/poms.12221", "e:abstract": "It is common for a firm to make use of multiple suppliers of different delivery lead times, reliabilities, and costs. In this study, we are concerned with the joint pricing and inventory control problem for such a firm that has a quick-response supplier and a regular supplier that both suffer random disruptions, and faces price-sensitive random demands. We aim at characterizing the optimal ordering and pricing policies in each period over a planning horizon, and analyzing the impacts of supply source diversification. We show that, when both suppliers are unreliable, the optimal inventory policy in each period is a reorder point policy and the optimal price is decreasing in the starting inventory level in that period. In addition, we show that having supply source diversification or higher supplier reliability increases the firm's optimal profit and lowers the optimal selling price. We also demonstrate that, with the selling price as a decision, a supplier may receive even more orders from the firm after an additional supplier is introduced. For the special case where the quick-response supplier is perfectly reliable, we further show that the optimal inventory policy is of a base-stock type and the optimal pricing policy is a list-price policy with markdowns.", "e:keyword": ["Inventory control", "Source diversification", "Optimal pricing", "Supplier disruption", "List‐price with markdown policy"]}, {"@id": "http://dx.doi.org/10.1111/poms.12222", "e:abstract": "This paper studies the impact of fairness concerns on supply chain performance (SCP) in the two-party newsvendor setting. We extend prior fairness analysis to a wide range of demand distributions, and also allow the degree and definition of fairness to assume a broader range of preferences than those in prior literature. Contrary to prior literature, we find that if the retailer's ideal allocation to the supplier is not sufficiently large, regardless of demand variability, a fair-minded retailer makes no difference to system efficiency when facing a traditional profit-maximizing supplier. Only when the retailer's ideal allocation to the supplier is above a threshold can the retailer's fairness concern improve the system efficiency for sufficiently high demand uncertainty. In order for the retailer's fairness concern to improve expected profits of both parties compared to the traditional supply chain case (win–win), the demand uncertainty cannot be too low, the retailer is not very averse to disadvantageous inequity, and his ideal allocation to the supplier is within a specific range. If only the supplier is concerned for fairness, the results range from worsening to improving (but not coordinating) the system and a win–win situation is impossible. Finally, when both the supplier and retailer are fair-minded, SCP is improved unless both parties prefer to allocate small portions of system profit to the other. Again, win–win will be achieved only when the demand uncertainty is sufficiently high, the retailer's ideal allocation is within a certain range, and he is not very averse to disadvantageous inequity.", "e:keyword": ["Supply chain management", "Modeling behavioral preferences", "Incentives and contracts", "Fairness", "Supply chain efficiency"]}, {"@id": "http://dx.doi.org/10.1111/poms.12224", "e:abstract": "In this study, I investigate supply chain contracts in a setting where a supplier uses its inventory to directly satisfy a retailer's demand. These “pull” contracts have increased in popularity in practice but have not been studied experimentally. In a controlled laboratory setting, I evaluate a wholesale price contract and two coordinating contracts. The data suggest that the benefit of the two coordinating contracts over the wholesale price contract is less than the standard theory predicts, and that retailers, in the two coordinating contracts, exhibit a systematic bias of setting the coordinating parameter too low, and the wholesale price too high, relative to the normative benchmarks. In an effort to explain this deviation, I explore three behavioral models and find that loss aversion and reference dependence fit the data well. I empirically test this result in a follow-up experiment, which directly controls for loss aversion and reference dependence, and observe that retailers make significantly better decisions. Lastly, I administer a number of experiments which reduce the complexity of the problem, curtail the amount of risk, and increase the level of decision support, and find that none improve decisions relative to the treatment that controls for loss aversion and reference dependence.", "e:keyword": ["Behavioral operations management", "Pull contracts", "Supply chain management", "Loss aversion and reference dependence"]}, {"@id": "http://dx.doi.org/10.1111/poms.12225", "e:abstract": "How should a firm with limited capacity introduce a new product? Should it introduce the product as soon as possible or delay introduction to build up inventory? How do the product and market characteristics affect the firm's decisions? To answer such questions, we analyze new product introductions under capacity restrictions using a two-period model with diffusion-type demand. Combining marketing and operations management decisions in a stylized model, we optimize the production and sales plans of the firm for a single product. We identify four different introduction policies and show that when the holding cost is low and the capacity is low to moderate, a (partial) build-up policy is indeed optimal if consumers are sensitive to delay. Under such a policy, the firm (partially) delays the introduction of its product and incurs short-term backlog costs to manage its future demand and total costs more effectively. However, as either the holding cost or the capacity increases, or consumer sensitivity to delay decreases, the build-up policy starts to lose its appeal, and instead, the firm prefers an immediate product introduction. We extend our analysis by studying the optimal capacity decision of the firm and show that capacity shortages may be intentional.", "e:keyword": ["Product introductions", "Bass diffusion model", "Capacity", "Myopic policy", "Build‐up policy"]}, {"@id": "http://dx.doi.org/10.1111/poms.12227", "e:abstract": "The Genesis of this Special Issue came from the Board of the POMS College on Humanitarian Operations and Crisis Management (HO&CM). It was seen as a necessary initiative to define the field and examine research opportunities. This Special Issue shows that humanitarian operations pose challenges for P/OM researchers and practitioners that differ markedly from those of conventional supply chains associated with profitable enterprises. On the basis of the eight articles in this Special Issue, we have described and demonstrated the unique characteristics of the POM/HO&CM interaction. We have also identified those attributes that tend to overlap with conventional aspects of POM. In addition to wanting to be cost effective, the issue of equity fairness is pervasive in humanitarian operations, and so is the need to always base considerations on “last-mile logistics,” that is, getting aid to those in most need. Research is essential to determine how to train researchers to scout out and map the territory of the real problems. One of the most vexing problems is the lack of robust data in the humanitarian domain which is as richly varied as the types of disasters that can occur.", "e:keyword": ["Humanitarian operations", "Crisis management", "Disasters of nature", "Logistics", "Efficiency‐equity tension", "Supply chains", "Last‐mile"]}, {"@id": "http://dx.doi.org/10.1111/poms.12228", "e:abstract": "This paper studies contract renegotiation in a stylized supply chain model. Two original equipment manufacturers (OEMs) sign fixed-quantity contracts with a contract manufacturer (CM) prior to demand realization. Contract renegotiation after demand realization allows the OEMs to use capacity that is more or less than what they contracted for. We assume that the extra profit due to efficient allocation of capacity is allocated to the supply chain parties according to the egalitarian rule and investigate when an OEM's expected post-renegotiation profit is maximized. We aim to understand how an OEM's expected post-renegotiation profit is affected by her ability to negotiate a low wholesale price in the initial contract as well as the ability of the other OEM to do the same. Regardless of whether renegotiation is anticipated or not at the time of the initial contract, we find that an OEM, who had weak buyer power vis-a-vis the CM and was unable to negotiate a low wholesale price in the initial contract, may benefit more from renegotiation than a stronger OEM. In addition, we show that how the expected post-renegotiation profit of an OEM changes with demand variance or anticipating renegotiation depends on the strength of the OEM's buyer power. Finally, we numerically test the robustness of our results in a supply chain with three OEMs and also identify when the OEMs prefer to leave the CM out of the renegotiation.", "e:keyword": ["Supply chain management", "Fixed‐quantity contract", "Contract renegotiation", "Cooperative game theory", "Egalitarian rule"]}, {"@id": "http://dx.doi.org/10.1111/poms.12230", "e:abstract": "This study names a pantheon of entrepreneurs and managers who have introduced a range of far-reaching productivity innovations throughout modern history. The thread tying together all of the innovations, in whatever sector of the economy one examines, is the theory of swift, even flow. The study argues why swift, even flow explains the power and long-lasting nature of these innovations and why other factors thought by some to affect productivity fall short.", "e:keyword": ["Productivity", "Business history", "Theory of swift", "Even flow", "Automation", "Economies of scale"]}, {"@id": "http://dx.doi.org/10.1111/poms.12235", "e:abstract": "We consider a setting in which a manufacturer sequentially sources two components and uses reverse auction to select a supplier with the lowest bidding price for each component. The manufacturer chooses a quantity to order from each supplier and a price for selling the final product. We show that the interplay between the direct competition faced by suppliers in providing their respective components and the sequence whereby the manufacturer sources components influence system performance in a subtle, and sometimes dramatic, way. As the direct competition for the early sourced component intensifies, the profit of its supplier will deteriorate while the profits of the other firms will improve. As the direct competition for the late sourced component intensifies, however, the profit of its supplier may improve, and the profits of the other supplier, the manufacturer, and the system can all decrease. Compared with when the manufacturer simultaneously sources the components, sequentially sourcing the components can benefit the manufacturer and every supplier. Furthermore, all the channel parties can unanimously agree on a specific sourcing sequence. All of these signify the importance for manufacturers to take appropriate measures to manage their sourcing procedures and the competition environments faced by their suppliers.", "e:keyword": ["Supplier competition", "Sequential decision", "Sourcing", "Reverse auction"]}, {"@id": "http://dx.doi.org/10.1111/poms.12236", "e:abstract": "In health care, most quality transparency and improvement programs focus on the quality variation across hospitals, while we know much less about within-hospital quality variation. This study examines one important factor that is associated with the fluctuation of quality of care in the same hospital—the timing of patient arrival. We analyze data from the National Trauma Data Bank and find that patients arriving at the hospital during off-hours (6 PM–6 AM) receive significantly lower quality care than those who arrive during the daytime, as reflected in higher mortality rates, among other measures. More importantly, we try to uncover the mechanism for the quality variation. Interestingly, we find consistent evidence that the inferior care received during off-hours is not likely due to unobserved heterogeneity, disruptions in circadian rhythms, or delays in receiving treatment. Instead, it is more likely due to the limited availability of high-quality resources. This leads to a higher surgical complication rate, a higher likelihood of multiple surgeries, and longer patient length of stay in the intensive care unit. These findings have important implications for optimal resource allocation in hospitals to improve the quality-of-care delivery.", "e:keyword": ["Health care", "Service quality", "Time of day", "Trauma center"]}, {"@id": "http://dx.doi.org/10.1111/poms.12237", "e:abstract": "In this study, we use hourly data on store traffic, sales, and labor from 41 stores of a large retail chain to identify the extent of understaffing in retail stores and quantify its impact on sales and profitability. Using an empirical model motivated from queueing theory, we calculate the benchmark staffing level for each store, and establish the presence of systematic understaffing during peak hours. We find that all 41 stores in our sample are systematically understaffed during a 3-hour peak period. Eliminating understaffing in these stores can result in a significant increase in sales and profitability in these stores. Also, we examine the extent to which forecasting errors and scheduling constraints drive understaffing in retail stores and quantify their relative impacts on store profits for the retailer in our study.", "e:keyword": ["Data analytics", "Retail staffing", "Store performance"]}, {"@id": "http://dx.doi.org/10.1111/poms.12239", "e:abstract": "The linear programming approach to approximate dynamic programming has received considerable attention in the recent network revenue management (RM) literature. A major challenge of the approach lies in solving the resulting approximate linear programs (ALPs), which often have a huge number of constraints and/or variables. Starting from a recently developed compact affine ALP for network RM, we develop a novel dynamic disaggregation algorithm to solve the problem, which combines column and constraint generation and exploits the structure of the underlying problem. We show that the formulation can be further tightened by considering structural properties satisfied by an optimal solution. We prove that the sum of dynamic bid-prices across resources is concave over time. We also give a counterexample to demonstrate that the dynamic bid-prices of individual resources are not concave in general. Numerical experiments demonstrate that dynamic disaggregation is often orders of magnitude faster than existing algorithms in the literature for problem instances with and without choice. In addition, adding the concavity constraints can further speed up the algorithm, often by an order of magnitude, for problem instances with choice.", "e:keyword": ["Network revenue management", "Choice behavior", "Dynamic programming", "Linear programming"]}, {"@id": "http://dx.doi.org/10.1111/poms.12241", "e:abstract": "This study uses a service operations management (SOM) strategy lens to investigate chain store retailers' strategic design responsiveness (SDR)—a term that captures the degree to which retailers dynamically coordinate investments in human and structural capital with the complexity of their service and product offerings. Labor force and physical capital are respectively used as proxies for investments in human capital and structural capital, whereas gross margins are proxies for product/service offering complexity. Consequently, SDR broadly reflects three salient complementary choices of SOM design strategy. We test the effects of “brick and mortar” chain store retailers' SDR on current and future firm performance using publically available panel data collected from Compustat and the University of Michigan American Customer Satisfaction Index databases for the period 1996–2011. We find that retailers that fail to keep pace with investments in both structural and human capital exhibit short-term financial benefits, but have worse ongoing operational performance. These findings corroborate the importance of managers strategically maintaining the complementarity of design-related choices for improving and maintaining business performance.", "e:keyword": ["Retail operations", "Design strategy", "Responsiveness", "Customer contact"]}, {"@id": "http://dx.doi.org/10.1111/poms.12243", "e:abstract": "We propose a tractable, data-driven demand estimation procedure based on the use of maximum entropy (ME) distributions, and apply it to a stochastic capacity control problem motivated from airline revenue management. Specifically, we study the two fare class “Littlewood” problem in a setting where the firm has access to only potentially censored sales observations; this is also known as the repeated newsvendor problem. We propose a heuristic that iteratively fits an ME distribution to all observed sales data, and in each iteration selects a protection level based on the estimated distribution. When the underlying demand distribution is discrete, we show that the sequence of protection levels converges to the optimal one almost surely, and that the ME demand forecast converges to the true demand distribution for all values below the optimal protection level. That is, the proposed heuristic avoids the “spiral down” effect, making it attractive for problems of joint forecasting and revenue optimization problems in the presence of censored observations.", "e:keyword": ["Revenue management", "Censored demand", "Uncensoring", "Maximum entropy distributions"]}, {"@id": "http://dx.doi.org/10.1111/poms.12244", "e:abstract": "Optimized profile descent (OPD) is an operating procedure being used by airlines to improve fuel and environmental efficiency during arrival operations at airports. In this study, we develop a stochastic dynamic programming framework to manage the sequencing and separation of flights during OPD operations. We find that simple calculation based measures can be used as optimal decision rules, and that the expected annual savings can be around $29 million if such implementations are adapted by major airports in the United States. Of these savings, $24 million are direct savings for airlines due to reduced fuel usage, corresponding to a potential savings of 10%–15% in fuel consumption over current practice. We also find that most of these savings will be due to the optimal spacing of OPD flights, as opposed to the optimal sequencing policies which contribute only 14% to the total savings. Hence, optimal spacing of OPD flights is much more important than optimal sequencing of these flights. We also conclude that there is not much difference between the environmental costs of fuel-optimal and sustainably-optimal spacing policies. Hence, an airline-centric approach in improving OPD operations is likely to be not in conflict with objectives that might be prioritized by other stakeholders.", "e:keyword": ["Airline industry", "Aviation", "Runway operations", "Sustainable operations", "Air traffic management"]}, {"@id": "http://dx.doi.org/10.1111/poms.12245", "e:abstract": "We analyze a signaling game between the manager of a firm and an investor in the firm. The manager has private information about the firm's demand and cares about the short-term stock price assigned by the investor. Previous research has shown that under continuous decision choices and the Intuitive Criterion refinement, the least-cost separating equilibrium will result, in which a low-quality firm chooses its optimal capacity and a high-quality firm over-invests in order to signal its quality to investors. We build on this research by showing the existence of pooling outcomes in which low-quality firms over-invest and high-quality firms under-invest so as to provide identical signals to investors. The pooling equilibrium is practically appealing because it yields a Pareto improvement compared to the least-cost separating equilibrium. Distinguishing features of our analysis are that: (i) we allow the capacity decision to have either discrete or continuous support, and (ii) we allow beliefs to be refined based on either the Undefeated refinement or the Intuitive Criterion refinement. We find that the newsvendor model parameters impact the likelihood of a pooling outcome, and this impact changes in both sign and magnitude depending on which refinement is used.", "e:keyword": ["Capacity investment", "Newsvendor model", "Game theory", "Information asymmetry"]}, {"@id": "http://dx.doi.org/10.1111/poms.12246", "e:abstract": "This study is motivated by examples of outsourcing that are not readily explained by widely established economic theories. We extend recent literature that develops the idea that outsourcing can help firms avoid overinvestment by specifying more precisely the conditions under which this thesis is likely to apply. Our extension is realized through a two-period game theoretic model in which the outsourcing and in-house investments are driven by (1) the cost required to develop a product or process module, (2) competitive relevance, defined as the module's share in the production cost or the module's importance to the customer, and (3) modularity, defined as the extent to which generic investments in the module can approach firm-specific investments in terms of the overall product/process performance. The analysis generates predictions about what types of insourcing, outsourcing, and non-sourcing behaviors are likely to emerge in different parts of the parameter space. Outsourcing to a more concentrated industry upstream emerges at equilibrium when modularity is high, relevance low to medium, and development cost high enough that none or only a subset of focal firms wants to invest. While firms are forced to insource and overinvest due to a prisoner's dilemma when the development cost is sufficiently high relative to the module's relevance, we do not find outsourcing equilibria that solve this problem in a two-period game with no commitment. This result implies that some form of tacit coordination in a multi-period game may be necessary. We conclude the study with a discussion of empirical implications.", "e:keyword": ["Outsourcing", "Vertical integration", "Modularity", "Supply chain design"]}, {"@id": "http://dx.doi.org/10.1111/poms.12247", "e:abstract": "Prior research documents the value of network relationships to firm behavior but is relatively silent on how networks influence opportunism in distribution channels. Focusing on a common type of distribution networks in which multiple distributors serve a single, dominant supplier, this study moves beyond a dyadic view to examine how a focal distributor's relational and structural embeddedness in such a distribution network influences its opportunism toward the dominant supplier. In particular, we postulate that a distributor's relational embeddedness in the network curbs its opportunism, whereas its network centrality, as a form of structural embeddedness in the network, promotes its opportunism. Moreover, we propose that relational embeddedness magnifies the role of a focal distributor's dependence on the supplier in suppressing the distributor's opportunism, whereas network centrality buffers such a role. We first empirically test these hypotheses using data collected from car dealers in China; the results provide support for the hypotheses. We then develop an analytical model to validate and further explain the underlying mechanisms of the network effects. Our analytical results not only validate the empirical results but also provide guidance for managers on controlling opportunism in distribution networks.", "e:keyword": ["Opportunism", "Network effect", "Embeddedness", "Dependence", "Multi‐methodological research"]}, {"@id": "http://dx.doi.org/10.1111/poms.12249", "e:abstract": "Motivated by an increasing adoption of evidence-based medical guidelines in the delivery of medical care, we examine whether increased adherence to such guidelines (typically referred to as higher process quality) is associated with reduced resource usage in the course of patient treatment. In this study, we develop a sample of US hospitals and use cardiac care as our context to empirically examine our questions. To measure a patient's resource usage, we use the total length of stay, which includes any additional inpatient stay necessitated by unplanned readmissions within thirty days after initial hospitalization. We find evidence that higher process quality, and more specifically its clinical (as opposed to its administrative) dimensions, are associated with a reduction in resource usage. Moreover, the standardization of care that is achieved via the implementation of medical guidelines, makes this effect more pronounced in less focused environments: higher process quality is more beneficial when the cardiac department's patient population is distributed across a wider range of medical conditions. We explore the implications of these findings for process-oriented pay-for-performance programs, which tie the reimbursement of hospitals to their adherence to evidence-based medical guidelines.", "e:keyword": ["Healthcare operations", "Healthcare policy", "Pay‐for‐performance"]}, {"@id": "http://dx.doi.org/10.1111/poms.12251", "e:abstract": "Extended enterprises face many challenges in managing the product quality of their suppliers. Consequently characterizing the quality risk posed by value-chain partners has become increasingly important. There have been several recent efforts to develop frameworks for rating the quality risk posed by suppliers. We develop an analytical model to examine the impact of such quality ratings on suppliers, manufacturers, and social welfare. While it might seem that quality ratings would benefit high-quality suppliers and hurt low-quality suppliers, we show that this is not always the case. We find that such quality ratings can hurt both types of suppliers or benefit both, depending on the market conditions. We also find that quality ratings do not always benefit the most demanding manufacturers who desire high-quality suppliers. Finally, we find that social welfare is not always improved by risk ratings. These results suggest that public policy initiatives addressing risk ratings must be carefully considered.", "e:keyword": ["Quality risk", "Vendor rating", "Supplier rating and evaluation", "Global supply chain", "Analytical modeling"]}, {"@id": "http://dx.doi.org/10.1111/poms.12252", "e:abstract": "This article examines the influence of ISO 9000 certification on plant-level process compliance, which arguably is its first-order, targeted performance dimension. The empirical setting is the medical device manufacturing industry. Process compliance is measured through Food and Drug Administration inspections of manufacturing plants. We control for several observable factors that possibly affect process compliance by matching certified plants with non-certified plants. Using longitudinal data, we find plants that obtained certification in the earlier diffusion period (early-certified plants) tend to have significantly better process compliance than a matched, non-certified control group of plants. The compliance difference between early-certified plants and their matched control group is greater than the compliance difference between late-certified plants and their matched control group. We also find deterioration in process compliance over time after certification. Because we capture longitudinally the first-order effects of ISO 9000 on process compliance, this study provides a useful baseline for assessing causality in ISO 9000-performance linkages. Also, we explain, in part, the inconsistencies observed in related ISO 9000 literature examining the performance effects of certification. Further, this research offers managerial insights on the dynamics of certification and process compliance with time, and highlights the need for continued vigilance post certification.", "e:keyword": ["Certifications", "Decay", "Diffusion", "Management standards", "Quality control"]}, {"@id": "http://dx.doi.org/10.1111/poms.12257", "e:abstract": "Existing studies on capacity allocation games have demonstrated that the standard Nash theory exaggerates retailers' tendency of ordering more than they need in the situation of supply shortage. Adding to the results in the literature, our experimental study with consideration of demand uncertainty demonstrates that the standard Nash theory also exaggerates retailers' tendency of telling the truth in their ordering strategy. To account for these systematic biases, based on the quantal response equilibrium framework, we develop a behavioral model with different mental weights on the underage and overage costs to characterize a retailer's perception bias regarding a critical fractile. Based on the parameter estimates, we show that retailers perceive the critical fractile as being closer to 0.5 than it is, and the perceived critical fractile increases over time. Such empirical evidence of retailers' behavior in capacity allocation games can be valuable, for example, in the mechanism design of coordination and in improving supply chain performance.", "e:keyword": ["Behavioral operations", "Capacity allocation", "Experiments", "Mental accounts", "Quantal response equilibrium"]}, {"@id": "http://dx.doi.org/10.1111/poms.12258_1", "e:abstract": "", "e:keyword": []}, {"@id": "http://dx.doi.org/10.1111/poms.12258_4", "e:abstract": "", "e:keyword": []}, {"@id": "http://dx.doi.org/10.1111/poms.12260", "e:abstract": "This study develops a theoretical model and then, using Canadian joint replacement surgery data, empirically tests the relationship between government policies that promote privately funded health care and patients’ waiting time in the public health care system. Two policies are tested: one policy allows opt-out physicians to extra-bill private patients, and the other provides public subsidies to private patients. We find that both policies are associated with shorter public waiting time, and that the subsidy policy appears to be more effective in waiting time reduction than the extra-billing policy. Our findings are consistent with a dominant demand-side effect in that these policies would provide patients an option, and some incentive, to opt out of the public health system, shifting the demand from the public health system to the private care market.", "e:keyword": ["Health care waiting time", "Elective surgery", "Health policy", "Privately funded health service"]}, {"@id": "http://dx.doi.org/10.1111/poms.12289", "e:abstract": "We develop stochastic models to help manage the pace of play on a conventional 18-hole golf course. These models are for group play on each of the standard hole types: par-3, par-4, and par-5. These models include the realistic feature that k−2 groups can be playing at the same time on a par-k hole, but with precedence constraints. We also consider par-3 holes with a “wave-up” rule, which allows two groups to be playing simultaneously. We mathematically determine the maximum possible throughput on each hole under natural conditions. To do so, we analyze the associated fully loaded holes, in which new groups are always available to start when the opportunity arises. We characterize the stationary interval between the times successive groups clear the green on a fully loaded hole, showing how it depends on the stage playing times. The structure of that stationary interval evidently can be exploited to help manage the pace of play. The mean of that stationary interval is the reciprocal of the capacity. The bottleneck holes are the holes with the least capacity. The bottleneck capacity is then the capacity of the golf course as a whole.", "e:keyword": ["Pace of play in golf", "The capacity of a golf course", "Queueing models of golf", "Throughput", "Production lines", "Queues in series"]}, {"@id": "http://dx.doi.org/10.1111/poms.12293", "e:abstract": "We study a manufacturer's optimal multiple-sourcing strategies when some but not all suppliers face risks of complete supply disruptions. Using an approximate model, we show that the optimal unreliable orders are ranked by a simple and intuitive criterion, and are invariant of minor market size changes. Furthermore, when ordering from one reliable and one unreliable supplier, we show that the total order quantity and its allocation between the two suppliers are independent decisions. We then test and confirm the robustness of the insights without the approximation, as well as when we relax various assumptions.", "e:keyword": ["Multiple sourcing", "Guaranteed delivery", "Supplier ranking"]}, {"@id": "http://dx.doi.org/10.1111/poms.12294", "e:abstract": "This study considers a supply chain with two heterogeneous suppliers and a common retailer whose type is either low-volume or high-volume. The retailer's type is unknown to the suppliers. The flexible supplier has a high variable cost and a low fixed cost, while the efficient supplier has a low variable cost and a high fixed cost. Each supplier offers the retailer a menu of contracts. The retailer chooses the contract that maximizes its expected profit. For this setting, we characterize the equilibrium contract menus offered by the suppliers to the retailer. We find that the equilibrium contract menus depend on which supplier–retailer match can generate the highest supply chain profit and on how much information rent the supplier may need to pay. An important feature of the equilibrium contract menus is that the contract assigned to the more profitable retailer will coordinate the supply chain, while the contract assigned to the less profitable retailer may not. In addition, in some circumstances, the flexible supplier may choose not to serve the high-volume retailer, in order to avoid excessive information rent.", "e:keyword": ["Supply chain management", "Supply contracts", "Competition", "Asymmetric information", "Stochastic inventory model"]}, {"@id": "http://dx.doi.org/10.1111/poms.12295", "e:abstract": "Dynamic pricing enables a firm to increase revenue by better matching supply with demand, responding to shifting demand patterns, and achieving customer segmentation. In the last 20 years, numerous success stories of dynamic pricing applications have motivated a rapidly growing research interest in a variety of dynamic pricing problems in the academic literature. A large class of problems that arise in various revenue management applications involve selling a given amount of inventory over a finite time horizon without inventory replenishment. In this study, we identify most recent trends in dynamic pricing research involving such problems. We review existing research on three new classes of problems that have attracted a rapidly growing interest in the last several years, namely, problems with multiple products, problems with competition, and problems with limited demand information. We also identify a number of possible directions for future research.", "e:keyword": ["Survey", "Dynamic pricing", "Multiple products", "Competition", "Limited demand information"]}, {"@id": "http://dx.doi.org/10.1111/poms.12296", "e:abstract": "Online discount voucher market In the discount voucher market, customers usually face two types of valuation uncertainty, namely, preference uncertainty and consumption state uncertainty. Preference uncertainty is related to the customer's lack of relevant experience with the merchant, whereas consumption state uncertainty is related to the advance selling nature of the discount voucher mechanism. By taking a comprehensive perspective (i.e., considering revenue management and promotion effect at the same time), we find (i) no show of voucher buyers may not be a good thing for the merchant, especially for those large or start-up ones; (ii) offering refund may always hurt the merchant's profit and the PayPal model may not be optimal in terms of maximizing social welfare; and (iii) market segmentation is not necessary for the profitability of promotion.", "e:keyword": ["Customer valuation uncertainty", "Discount vouchers", "Revenue management", "Marketing‐operations interface"]}, {"@id": "http://dx.doi.org/10.1111/poms.12297", "e:abstract": "We study and compare decision-making behavior under the newsvendor and the two-class revenue management models, in an experimental setting. We observe that, under both problems, decision makers deviate significantly from normative benchmarks. Furthermore, revenue management decisions are consistently higher compared to the newsvendor order quantities. In the face of increasing demand variability, revenue managers increase allocations; this behavior is consistent with normative patterns when the ratio of the selling prices of the two customer segments is less than 1/2, but is its exact opposite when this ratio is greater than 1/2. Newsvendors' behavior with respect to changing demand variability, on the other hand, is consistent with normative trends. We also observe that losses due to leftovers weigh more in newsvendor decisions compared to the revenue management model; we argue that overage cost is more salient in the newsvendor problem because it is perceived as a direct loss, and propose this as the driver of the differences in behavior observed under the two problems.", "e:keyword": ["Behavioral operations management", "Revenue management", "Newsvendor problem"]}, {"@id": "http://dx.doi.org/10.1111/poms.12302", "e:abstract": "As a result of slow patient recruitment and high patient costs in the United States, clinical trials are increasingly going global. While recruitment efforts benefit from a larger global footprint, the supply chain has to work harder at getting the right drug supply to the right place at the right time. Certain clinical trial supply chains, especially those supplying biologics, have a combination of unique attributes that have yet to be addressed by existing supply chain models. These attributes include a fixed patient horizon, an inflexible supply process, a unique set of service-level requirements, and an inability to transfer drug supplies among testing sites. We provide a new class of multi-echelon inventory models to address these unique aspects. The resulting mathematical program is a nonlinear integer programming problem with chance constraints. Despite this complexity, we develop a solution method that transforms the original formulation into a linear integer equivalent. By analyzing special cases and through numerical study of both real-life and simulated examples, we demonstrate the effectiveness of the solution and develop insights into inventory positioning and the cost drivers in clinical trial supply chains.", "e:keyword": ["Clinical trial supply chains", "Multi‐echelon inventory models", "Finite patient horizon", "Pharmaceutical supply chains"]}, {"@id": "http://dx.doi.org/10.1111/poms.12303", "e:abstract": "The recent surge in the usage of social media has created an enormous amount of user-generated content (UGC). While there are streams of research that seek to mine UGC, these research studies seldom tackle analysis of this textual content from a quality management perspective. In this study, we synthesize existing research studies on text mining and propose an integrated text analytic framework for product defect discovery. The framework effectively leverages rich social media content and quantifies the text using various automatically extracted signal cues. These extracted signal cues can then be used as modeling inputs for product defect discovery. We showcase the usefulness of the framework by performing product defect discovery using UGC in both the automotive and the consumer electronics domains. We use principal component analysis and logistic regression to produce a multivariate explanatory analysis relating defects to quantitative measures derived from text. For our samples, we find that a selection of distinctive terms, product features, and semantic factors are strong indicators of defects, whereas stylistic, social, and sentiment features are not. For high sales volume products, we demonstrate that significant corporate value is derivable from a reduction in defect discovery time and consequently defective product units in circulation.", "e:keyword": ["Social media analytics", "Quality management"]}, {"@id": "http://dx.doi.org/10.1111/poms.12305", "e:abstract": "We look at a simple service system with two servers serving arriving jobs (single class). Our interest is in examining the effect of routing policies on servers when they care about fairness among themselves, and when they can endogenously choose capacities in response to the routing policy. Therefore, we study the two-server game where the servers’ objective functions have a term explicitly modeling fairness. Moreover, we focus on four commonly seen policies that are from one general class. Theoretical results concerning the existence and uniqueness of the Nash equilibrium are proved for some policies. Further managerial insights are given based on simulation studies on servers’ equilibrium/off-equilibrium behaviors and the resulting system efficiency performance under different policies.", "e:keyword": ["Service system", "Heterogeneous servers", "Fairness", "Endogenous capacity"]}, {"@id": "http://dx.doi.org/10.1111/poms.12313", "e:abstract": "We study the deferred payment and inspection mechanisms for mitigating supplier product adulteration, with endogenous procurement decision and general defect discovery process. We first derive the optimal deferred payment contract, which reveals that either entire or partial deferral can arise, depending on the moral hazard severity and the information accumulation rate. Because of the supplier's incentive to adulterate, the optimal procurement quantity under deferred payment generally is smaller than the first-best quantity. We then investigate the inspection mechanism and characterize the equilibrium. We find that under the inspection mechanism, the optimal procurement quantity is no less than the first best. A comparison between these two mechanisms shows that the deferred payment mechanism generally can outperform the inspection mechanism when either the market size is small or the profit margin is low. However, we find that these two mechanisms can also be complementary, for which we characterize a necessary condition.", "e:keyword": ["Quality control", "Deferred payment", "Inspection", "Moral hazard"]}, {"@id": "http://dx.doi.org/10.1111/poms.12314", "e:abstract": "A paper manufacturing plant minimizes its production cost by using long production runs that combine the demands from its various customers. As jobs are completed, they are released to distribution for delivery. Deliveries are made by railcars, each of which is dedicated to one customer. Long production runs imply that maximizing railcar utilization requires holding the cars over several days or holding completed jobs within the loading facility. Each of these methods imposes a cost onto the distribution function. We find how distribution can minimize its cost, given production's schedule. We then consider the problem of minimizing the company's overall cost of both production and distribution. A computational study using general data illustrates that the distribution cost is reduced by 25.80% through our proposed scheme, and that the overall cost is reduced an additional 4.40% through our coordination mechanism. An optimal algorithm is derived for a specific plant's operations.", "e:keyword": ["Coordination", "Distribution", "Bin‐packing", "Non‐bipartite matching", "Paper industry"]}, {"@id": "http://dx.doi.org/10.1111/poms.12317", "e:abstract": "We analyze the dynamic price discrimination strategies of a monopolist who offers new services on a subscription basis. Access to customers' subscription histories permits the monopolist to design pricing policies that can be based on customers' past purchase behavior, and on the time period in which they made their purchases. Uncertainty regarding the value of new features, and heterogeneity in consumers' valuation for existing features, creates inter-temporal incentives that influence both profits and the rate of adoption of new technology. We find that the comparison of pricing regimes critically depends on whether the monopolist finds it optimal to encourage all consumers to adopt the new technology early. The pricing regimes differ only when the prior heterogeneity in consumer valuation for the existing features is relatively large, in which case the monopolist finds it optimal to serve only the part of the population of consumers that has a relatively high valuation. The monopolist can improve his profits by committing to ignore consumer past behavior, and to vary prices based only on the time period. If a stronger commitment to never utilize any price discrimination is feasible, the profits of the monopolist are even higher. However, the “First Best” outcome cannot be achieved, because it requires the monopolist to discriminate in favor of returning customers, by offering them lower prices than it offers to new customers. We also investigate the effect of positive correlation between the consumer valuations for the existing and the new features of the technology. We find that, as the correlation increases, the gap in profits among the various regimes narrows, while the ranking of the regimes remains the same. In particular, with perfect correlation, time inconsistency issues that arise due to lack of commitment disappear completely for all regimes, and the “First Best” outcome is attainable.", "e:keyword": ["Commitment power in pricing", "Dynamic pricing", "Experience‐based learning", "Game theory", "Price discrimination", "Strategic customers"]}, {"@id": "http://dx.doi.org/10.1111/poms.12319", "e:abstract": "Gray markets, also known as parallel imports, have created fierce competition for manufacturers in many industries. We analyze the impact of parallel importation on a price-setting manufacturer that serves two markets with uncertain demand, and characterize her policy against parallel importation. We show that ignoring demand uncertainty can take a significant toll on the manufacturer's profit, highlighting the value of making price and quantity decisions jointly. We find that adjusting prices is more effective in controlling gray market activity than reducing product availability, and that parallel importation forces the manufacturer to reduce her price gap while demand uncertainty forces her to lower prices. Furthermore, we explore the impact of market conditions (such as market base, price sensitivity, and demand uncertainty) and product characteristics (“fashion” vs. “commodity”) on the manufacturer's policy towards parallel importation. We also provide managerial insights about the value of strategic decision-making by comparing the optimal policy to the uniform pricing policy that has been adopted by some companies to eliminate gray markets entirely. The comparison indicates that the value of making price and quantity decisions strategically is highest for moderately different market conditions and non-commodity products.", "e:keyword": ["Gray markets", "Parallel importation", "Parallel markets", "Strategic pricing", "Demand uncertainty", "Uniform pricing"]}, {"@id": "http://dx.doi.org/10.1111/poms.12320", "e:abstract": "We consider a decentralized two-period supply chain in which a manufacturer produces a product with benefits of cost learning, and sells it through a retailer facing a price-dependent demand. The manufacturer's second-period production cost declines linearly in the first-period production, but with a random learning rate. The manufacturer may or may not have the inventory carryover option. We formulate the resulting problems as two-period Stackelberg games and obtain their feedback equilibrium solutions explicitly. We then examine the impact of mean learning rate and learning rate variability on the pricing strategies of the channel members, on the manufacturer's production decisions, and on the retailer's procurement decisions. We show that as the mean learning rate or the learning rate variability increases, the traditional double marginalization problem becomes more severe, leading to greater efficiency loss in the channel. We obtain revenue sharing contracts that can coordinate the dynamic supply chain. In particular, when the manufacturer may hold inventory, we identify two major drivers for inventory carryover: market growth and learning rate variability. Finally, we demonstrate the robustness of our results by examining a model in which cost learning takes place continuously.", "e:keyword": ["Learning curve", "Pricing", "Inventory management", "Channel coordination", "Revenue sharing contracts"]}, {"@id": "http://dx.doi.org/10.1111/poms.12322", "e:abstract": "We analyze the benefit of production/service capacity sharing for a set of independent firms. Firms have the choice of either operating their own production/service facilities or investing in a facility that is shared. Facilities are modeled as queueing systems with finite service rates. Firms decide on capacity levels (the service rate) to minimize delay costs and capacity investment costs possibly subject to service-level constraints on delay. If firms decide to operate a shared facility they must also decide on a scheme for sharing the capacity cost. We formulate the problem as a cooperative game and identify settings under which capacity sharing is beneficial and there is a cost allocation that is in the core under either the first-come, first-served policy or an optimal priority policy. We show that capacity sharing may not be beneficial in settings where firms have heterogeneous work contents and service variabilities. In such cases, we specify conditions under which capacity sharing may still be beneficial for a subset of the firms.", "e:keyword": ["Capacity sharing", "Queueing systems", "Joint ventures", "Cost allocation", "Cooperative game theory"]}, {"@id": "http://dx.doi.org/10.1111/poms.12325", "e:abstract": "Based on a serial supply chain model with two periods and price-sensitive demand, we present the first experimental test of the effect of strategic inventories on supply chain performance. In theory, if holding costs are sufficiently low, the buyer builds up a strategic inventory (even if no operational reasons for stock-holding exist) to limit the supplier's market power, and to increase the own profit share. As it turns out, this enhances the overall supply chain performance. The supplier anticipates the effect of the strategic inventory and differentiates prices to capture a part of the increased supply chain profits. Our results show that the positive effects of strategic inventories are even more pronounced than theoretically predicted, because strategic inventories empower buyers by shifting the perception of the fair split. Overall, strategic inventories have a double positive effect, a strategic and a behavioral, both reducing the average wholesale prices and dampening the double marginalization effect. The latter effect leads to more equitable payoffs.", "e:keyword": ["Supply chain coordination", "Vertical contracts", "Fair behavior", "Intertemporal supplier pricing"]}, {"@id": "http://dx.doi.org/10.1111/poms.12326", "e:abstract": "The use of government incentives tied to market prices as means of boosting corporate social responsibility (CSR) has expanded notably in recent decades. Enhanced business tax deductions for charitable donations and credits for conservation easements are notable cases. While providing incentives for socially desirable behavior to achieve legislative goals has intuitive appeal, the broader economic consequences are not always fully understood. In this study, we examine such wider consequences for supply chains when subsidies for CSR are offered. One effect we identify is that since incentives are typically tied to market value, firms have not only an added incentive to achieve societal objectives (say by donating inventory) but also an incentive to raise output (retail) market prices. A second consequence is that since firms forgo potential revenues by engaging in socially desired behavior, they become increasingly sensitive to supplier pricing; in an uncoordinated supply chain this leads to input (wholesale) price concessions. Among other things, the results underscore that incentives put in place to meet broader societal objectives also have notable ramifications for suppliers, retailers, and consumers in primary markets.", "e:keyword": ["Corporate social responsibility", "Philanthropy", "Pricing", "Supply chains"]}, {"@id": "http://dx.doi.org/10.1111/poms.12331", "e:abstract": "This study considers a typical scheduling environment that is influenced by the behavioral phenomenon of multitasking. Under multitasking, the processing of a selected job suffers from interruption by other jobs that are available but unfinished. This situation arises in a wide variety of applications; for example, administration, manufacturing, and process and project management. Several classical solution methods for scheduling problems no longer apply in the presence of multitasking. The solvability of any scheduling problem under multitasking is no easier than that of the corresponding classical problem. We develop optimal algorithms for some fundamental and practical single machine scheduling problems with multitasking. For other problems, we show that they are computationally intractable, even though in some cases the corresponding problem in classical scheduling is efficiently solvable. We also study the cost increase and value gained due to multitasking. This analysis informs companies about how much it would be worthwhile to invest in measures to reduce or encourage multitasking.", "e:keyword": ["Scheduling", "Multitasking", "Polynomial time algorithm", "Cost and value of multitasking"]}, {"@id": "http://dx.doi.org/10.1111/poms.12333", "e:abstract": "Most service systems consist of multidepartmental structures with multiskill agents that can deal with several types of service requests. The design of flexibility in terms of agents' skill sets and assignments of requests is a critical issue for such systems. The objective of this study was to identify preferred flexibility structures when demand is random and capacity is finite. We compare structures recommended by the flexibility literature to structures we observe in practice within call centers. To enable a comparison of flexibility structures under optimal capacity, the capacity optimization problem for this setting is formulated as a two-stage stochastic optimization problem. A simulation-based optimization procedure for this problem using sample-path gradient estimation is proposed and tested, and used in the subsequent comparison of the flexibility structures being studied. The analysis illustrates under what conditions on demand, cost, and human resource considerations, the structures found in practice are preferred.", "e:keyword": ["Flexibility", "Call centers", "Multidimensional newsvendor", "Gradient estimation via perturbation analysis"]}, {"@id": "http://dx.doi.org/10.1111/poms.12335", "e:abstract": "Motivated by the observation that durability ratings of automobile manufacturers are not necessarily linked to the proportion of leasing but tend to decrease with the density of their dealer networks, we explore the interactions between channel structure (direct interaction with consumers vs. through an intermediary(ies)) and mode of operations (leasing vs. selling) and their implications for a manufacturer's willingness to invest in making her product more durable. Using a manufacturer who leases her product directly to consumers as a point of reference, we find that an isolated change in either the channel structure (selling through an intermediary), or the operational mode (leasing to selling) can decrease the manufacturer's willingness to provide durability. However, if combined, these two changes together may strengthen the manufacturer's willingness to invest in durability. Specifically, the traditional result that a manufacturer who leases provides more durability than one who sells, can be reversed in a decentralized channel.", "e:keyword": ["Durable goods", "Channel structure", "Competition", "Product life cycle"]}, {"@id": "http://dx.doi.org/10.1111/poms.12336", "e:abstract": "To alleviate poverty in developing countries, governments and non-governmental organizations disseminate two types of information: (i) agricultural advice to enable farmers to improve their operations (cost reduction, quality improvement, and process yield increase); and (ii) market information about future price/demand to enable farmers to make better production planning decisions. This information is usually disseminated free of charge. While farmers can use the market information to improve their production plans without incurring any (significant) cost, adopting agricultural advice to improve operations requires upfront investment, for example, equipment, fertilizers, pesticides, and higher quality seeds. In this study, we examine whether farmers should use market information to improve their production plans (or adopt agricultural advice to improve their operations) when they engage in Cournot competition under both uncertain market demand and uncertain process yield. Our analysis indicates that both farmers will use the market information to improve their profits in equilibrium. Hence, relative to the base case in which market information is not available, the provision of market information can improve the farmers' total welfare (i.e., total profit for both farmers). Moreover, when the underlying process yield is highly uncertain or when the products are highly heterogeneous, the provision of market information is welfare-maximizing in the sense that the maximum total welfare of farmers is attained when both farmers utilize market information in equilibrium. Furthermore, in equilibrium, whether a farmer adopts the agricultural advice depends on the size of the requisite upfront investment. More importantly, we show that agricultural advice is not always welfare improving unless the upfront investment is sufficiently low. This result implies that to improve farmers' welfare, governments should consider offering farmer subsidies.", "e:keyword": ["Emerging markets", "Social responsibility", "Operational improvements", "Competitive production strategies"]}, {"@id": "http://dx.doi.org/10.1111/poms.12337", "e:abstract": "We consider a situation in which shippers (customers) can purchase ocean freight services either directly from a carrier (service provider)in advance or from the spot market just before the departure of an ocean liner. The price is known in the former case, while the spot price is uncertain ex-ante in the latter case. Consequently, some shippers are reluctant to book directly from the carrier in advance unless the carrier is willing to “partially match” the realized spot price when it is lower than the regular price. This study is an initial attempt to examine if the carrier should bear some of the “price risk” by offering a “fractional” price matching contract that can be described as follows. The shipper pays the regular freight price in advance; however, the shipper will get a refund if the realized spot price is below the regular price, where the refund is a “fraction” of the difference between the regular price and the realized spot price. By modeling the dynamics between the carrier and the shippers as a sequential game, we show that the carrier can use the fractional price matching contract to generate a higher demand from the shippers compared to no price matching contract by increasing the “fraction” in equilibrium. However, as the carrier increases the “fraction,” the carrier should increase the regular price to compensate for bearing additional risk. By selecting the fractional price matching contract optimally, we show that the carrier can afford to offer this price matching mechanism without incurring revenue loss: the optimal fractional price matching contract is “revenue neutral.”", "e:keyword": ["Ocean freight", "Fractional price matching", "Pricing contracts"]}, {"@id": "http://dx.doi.org/10.1111/poms.12344", "e:abstract": "In recent supply chains, often operating multiple delivery modes such as standard freight shipping and air is an effective way of addressing both delivery lead time uncertainties and service rates. We propose a model on how to optimally operate multiple delivery modes. We consider a serial supply chain and an expediting option from intermediate installations to the downstream of the chain. The goods move stochastically among the installations and the system faces a stochastic demand. We identify systems that yield simple optimal policies, in which both regular ordering and expediting follow a variant of the base stock policy. Expediting allows the system to be leaner due to the reduced regular order amount. In addition, we provide managerial insights linking expediting, base stock levels, and expediting costs based on analytical and numerical results.", "e:keyword": ["Multi‐echelon supply chain", "Inventory management", "Dynamic ordering", "Expediting", "Stochastic lead time"]}, {"e:abstract": "Online material and waste exchanges (OMWEs) provide online channels to repurpose by-products, unused materials and waste from industrial and commercial facilities. Unfortunately, OMWE's also have challenges. First, sellers may have access to other disposal options and, as a result, may not fully commit to the exchange. Second, buyers can face high uncertainty about the product exchanged and the transaction being undertaken. Overcoming these challenges is the “last hurdle” to making OMWEs successful. This study investigates the factors that reduce the buyers' uncertainty and increase the sellers' commitment to the OMWE. We analyze novel transaction-level data from an online exchange (MNExchange.org) combined with other archival public records on county-level repurposing and disposal statistics. First, we find that regional repurposing policies and alternatives have a complementary effect on sellers' commitment toward OMWEs, resulting in increased OMWE exchanges. However, regional disposal policies and alternatives have a substitution effect on sellers' commitment, resulting in reduced exchange success. Further, greater product and transaction information reduce the buyer's uncertainty and increase exchange success. Finally, the analysis shows that users' (buyers and sellers) heavily rely on their prior experience with OMWEs. Specifically, higher familiarity between the buyer–seller pair and familiarity with the OMWE system leads to higher likelihood of exchange success. This study lays the foundation for understanding OMWEs and has important implications for developing policies and operations to increase online transactions of by-products, materials and wastes.", "e:volume": "24", "@id": "http://dx.doi.org/10.1111/poms.12345", "e:issue": "9", "e:keyword": ["Socially responsible operations", "Materials and waste exchange", "Sustainability", "Online markets", "Closed loop supply chains"]}, {"@id": "http://dx.doi.org/10.1111/poms.12346", "e:abstract": "This study is based on the analysis of field data on the revenues and patient flows that we collected on all adult emergency department (ED) visits to a level-1 trauma, tertiary referral center. Our objective was to provide researchers in operations a rich overview of the processes, resources, and metrics of financial and operations performance in the ED. We analyze how patients, physicians, hospitals/physician employer groups, and payers are party to the value created and financial workflow of the ED. A waterfall model for professional services revenue is developed that highlights the impacts of changes in processes, resources, scale, complexity, and mix of patients treated in the ED. We also discuss future implications of new compensation models and potential scenarios that will focus upon controlling costs while maximizing population health and patient satisfaction. These models will necessitate re-engineering of operations in the ED from a strategic perspective. Four major thrusts for selecting the capacity portfolio in the ED operations to align the interests of all the stakeholders are recommended. New avenues for research are also identified.", "e:keyword": ["Strategic management", "Health care operations", "Waterfall revenue model", "Capacity portfolio", "Prevention and risk assessment capacity"]}, {"@id": "http://dx.doi.org/10.1111/poms.12348", "e:abstract": "When firms invest in a shared supplier, one key concern is whether the invested capacity will be used for a competitor. In practice, this concern is addressed by restricting the use of the capacity. We consider what happens when two competing firms invest in a shared supplier. We consider two scenarios that differ in how capacity is used: exclusive capacity and first-priority capacity. We model firms' investment and production decisions, and analyze the equilibrium outcomes in terms of the number of investing firms and capacity levels for each scenario; realized capacity is a stochastic function of investment levels. We also identify conditions under which the spillover effect occurs, where one firm taps into the other firm's invested capacity. Although the spillover supposedly intensifies competition, it actually discourages firms' investment. We also characterize the firms' and supplier's preference about the capacity type. While the non-investing firm always prefers spillovers from the first-priority capacity, the investing firm does not always want to shut off the other firm's access to its leftover capacity, especially when allowing spillover induces the other firm not to invest. The supplier's preference depends on the trade-off between over-investment and flexibility.", "e:keyword": ["Capacity investment", "Supplier development", "Cournot competition", "Non‐cooperative game"]}, {"@id": "http://dx.doi.org/10.1111/poms.12354", "e:abstract": "This note complements the study of Burke, Carillo, and Vakharia (2009 hereafter “BCV”) which analyzes a class of single-product multisourcing problems under stochastic demand and random yields. The purpose is twofold. First, we prove that the objective function used by these authors is only a lower bound for the expected profit for which we provide the correct expression. Second, we show on some of the numerical instances provided in BCV's study that the structure and the performance of the BCV ordering policy may be substantially different from the optimal ordering policy. We conclude by giving general qualitative insights characterizing suboptimality of the BCV solution.", "e:keyword": ["Sourcing", "Supplier selection", "Random yield"]}, {"@id": "http://dx.doi.org/10.1111/poms.12355", "e:abstract": "In this study, we consider a supplier's contract offerings to a buyer who may obtain improved forecasts for her demand over time. We investigate how the supplier can take advantage of the buyer's better forecasts and what kind of contracts he should offer to the buyer in order to maximize his profits. We model a natural forecast evolution where the buyer can obtain a more accurate forecast closer to the selling season. We assume there is information asymmetry between the buyer and the supplier at all times in that the buyer understands her demand better than the supplier. Three types of contracts that the supplier can offer are considered: (1) one where a contract is offered before the buyer has a chance to obtain improved forecasts, (2) one where a contract is offered after the buyer has obtained improved forecasts, and (3) a contingent (dynamic) contract which offers an initial contract to the buyer before she obtains improved forecasts, followed by a later contract (contingent on the initial contract) offered after improved forecasts have been obtained. We consider two scenarios: (1) where the supplier is certain that the buyer can obtain more accurate forecasts over time, and (2) where the supplier is uncertain about the buyer's forecasting capability (or forecasting cost). In the first scenario, we show that among the three types of contracts, the contingent contract is always the most profitable for the supplier. Furthermore, using the contingent contract, the supplier always benefits from higher accuracy of the buyer's demand forecasts. In the second scenario, we explicitly model the supplier's level of certainty about the buyer's capability of obtaining better forecasts, and explore how the supplier can design contracts to induce the buyer to obtain better forecasts when she is capable.", "e:keyword": ["Supply chain contracting", "Information sharing", "Demand forecasting"]}, {"@id": "http://dx.doi.org/10.1111/poms.12356", "e:abstract": "This study develops an approximate optimal control problem to produce time-dependent bid prices for the airline network revenue management problem. The main contributions of our study are the analysis of time-dependent bid prices in continuous time and the use of splines to modify the problem into an approximate second-order cone program (ASOCP). The spline representation of bid prices permits the number of variables to depend solely on the number of resources and not on the size of the booking horizon. The advantage of this framework is the ASOCP's scalability, which we demonstrate by solving for bid prices on an industrial-sized network. The numerical experiments highlight the ASOCP's ability to solve industrial sized problems in seconds.", "e:keyword": ["Network revenue management", "Dynamic bid prices", "Second‐order cone programming"]}, {"@id": "http://dx.doi.org/10.1111/poms.12357", "e:abstract": "Eroglu et al. (2013) study a retailer with limited shelf capacity and a backroom. They study a continuous review (r, q) ordering policy with a known order quantity, q. Assuming that backorders can be satisfied from the backroom inventory (if available), they find the expression for the optimal reorder level, r. Our work builds on Eroglu et al. (2013). We correct an erroneous derivation of the expected overflow term, as well as derive an exact expression for the expected cost function, and hence optimal reorder level, instead of the approximate one used by Eroglu et al. (2013).", "e:keyword": ["Retail operations", "Backroom", "(r", "q) policy"]}, {"@id": "http://dx.doi.org/10.1111/poms.12358", "e:abstract": "The majority of after-sales service providers manage their service parts inventory by focusing on the availability of service parts. This approach, combined with automatic replenishment systems, leads to reactive inventory control policies where base stock levels are adjusted only after a service contract expires. Consequently, service providers often face excess stock of critical service parts that are difficult to dispose due to their specificity. In this study, we address this problem by developing inventory control policies taking into account contract expirations. Our key idea is to reduce the base stock level of the one-for-one policy before obsolescence (a full or partial drop in demand rate) occurs and let demand take away excess stock. We refer to this policy as the single-adjustment policy. We benchmark the single-adjustment policy with the multiple-adjustment policy (allowing multiple base stock adjustments) formulated as a dynamic program and verify that for a wide range of instances the single-adjustment policy is an effective heuristic for the multiple-adjustment policy. We also compare the single-adjustment policy with the world-dependent base stock policy offered by Song and Zipkin (1993) and identify the parameter combinations where both policies yield similar costs. We consider two special cases of the single-adjustment policy where the base stock level is kept fixed or the base stock adjustment is postponed to the contract expiration time. We find that the initial demand rate, contract expiration time, and size of the drop in demand rate are the three key parameters driving the choice between the single-adjustment policy and its special cases.", "e:keyword": ["Service parts", "Contract expirations", "Inventory", "Obsolescence", "After sales"]}, {"@id": "http://dx.doi.org/10.1111/poms.12360", "e:abstract": "We study a compensation mechanism design problem with customer-choice behavior in a continuous review setting where the production and demand processes are stochastic. When a stockout occurs, the firm controls backorders on the basis of certain compensation policies. Customers make decisions to maximize their utility, which is decreasing in the price, the waiting time, and the customer's impatience factor. We assume that the impatience factor is private information held by the customer only. Two compensation mechanisms are designed to control backorders, namely uniform compensation and priority auction with an admission price. Under uniform compensation, the firm offers the same discount to all customers, whereas under auction compensation, priority is granted according to the customers' bid prices. We obtain the optimal stockout price and base stock level under each mechanism, and analyze the properties of the respective optimal policies. Assuming linear waiting costs with uniformly distributed impatience factor, we find that the auction mechanism (1) maintains a lower base stock level and results in greater profit and (2) benefits customers with relatively lower or higher impatience factors, but customers with a medium impatience factor may be rendered worse off. We further show that both compensation mechanisms are suitable for products with a high unit profit, a high lost sales penalty cost, and a high holding cost.", "e:keyword": ["Strategic customers", "Compensation mechanism", "Pricing", "Auction", "Make‐to‐stock", "Queuing", "Nash equilibrium"]}, {"@id": "http://dx.doi.org/10.1111/poms.12361", "e:abstract": "We investigate newsvendor ordering behavior under competition. We present a laboratory experiment that documents the behavioral ordering regularities in competitive newsvendor environments, and an analytical model extending the standard theory of newsvendor competition by including an optimal best-response policy for competing with a behaviorally biased newsvendor. We test the effectiveness of this policy using an out-of-sample experiment and find that it results in improved market share, service level and profitability.", "e:keyword": ["Newsvendor", "Behavioral operations management", "Experimental economics", "Competition"]}, {"@id": "http://dx.doi.org/10.1111/poms.12363", "e:abstract": "Since the development of the Internet, thousands of manufacturers have been referring consumers visiting their websites to some or all of their retailers. Through a model with one manufacturer and two heterogeneous retailers, we investigate whether it is an equilibrium for the manufacturer to refer consumers exclusively to a retailer or nonexclusively to both retailers. Our analysis indicates that nonexclusive referral is the manufacturer's equilibrium choice if the referral segment market size is sufficiently large; otherwise, exclusive referral is the equilibrium choice. In exclusive referral, the manufacturer would refer consumers to the more cost-efficient and smaller retailer. In the presence of infomediary referral, it is less likely for both exclusive and nonexclusive referrals to be an equilibrium, as the infomediary referral segment grows. We also show our qualitative results are robust even if there were price discrimination among consumers, referral position disparity, local consumers, and asymmetric referral market sizes.", "e:keyword": ["Manufacturer referral", "Heterogeneous retailers", "Channel competition", "Game theory"]}, {"@id": "http://dx.doi.org/10.1111/poms.12364", "e:abstract": "We study a minimum total commitment (MTC) contract embedded in a finite-horizon periodic-review inventory system. Under this contract, the buyer commits to purchase a minimum quantity of a single product from the supplier over the entire planning horizon. We consider nonstationary demand and per-unit cost, discount factor, and nonzero setup cost. Because the formulations used in existing literature are unable to handle our setting, we develop a new formulation based on a state transformation technique using unsold commitment instead of unbought commitment as state variable. We first revisit the zero setup cost case and show that the optimal ordering policy is an unsold-commitment-dependent base-stock policy. We also provide a simpler proof of the optimality of the dual base-stock policy. We then study the nonzero setup cost case and prove a new result, that the optimal solution is an unsold-commitment-dependent (s, S) policy. We further propose two heuristic policies, which numerical tests show to perform very well. We also discuss two extensions to show the generality of our method's effectiveness. Finally, we use our results to examine the effect of different contract terms such as duration, lead time, and commitment on buyer's cost. We also compare total supply chain profits under periodic commitment, MTC, and no commitment.", "e:keyword": ["Supply contracts", "Inventory management", "Quantity commitment", "Dynamic programming", "(s", "S) policy"]}, {"@id": "http://dx.doi.org/10.1111/poms.12365", "e:abstract": "We consider assortment problems under a mixture of multinomial logit models. There is a fixed revenue associated with each product. There are multiple customer types. Customers of different types choose according to different multinomial logit models whose parameters depend on the type of the customer. The goal is to find a set of products to offer so as to maximize the expected revenue obtained over all customer types. This assortment problem under the multinomial logit model with multiple customer types is NP-complete. Although there are heuristics to find good assortments, it is difficult to verify the optimality gap of the heuristics. In this study, motivated by the difficulty of finding optimal solutions and verifying the optimality gap of heuristics, we develop an approach to construct an upper bound on the optimal expected revenue. Our approach can quickly provide upper bounds and these upper bounds can be quite tight. In our computational experiments, over a large set of randomly generated problem instances, the upper bounds provided by our approach deviate from the optimal expected revenues by 0.15% on average and by less than one percent in the worst case. By using our upper bounds, we are able to verify the optimality gaps of a greedy heuristic accurately, even when optimal solutions are not available.", "e:keyword": ["Multinomial logit model", "Assortment optimization", "Lagrangian relaxation", "Retail operations", "Choice modeling"]}, {"@id": "http://dx.doi.org/10.1111/poms.12370", "e:abstract": "This paper is motivated by observing that an increasing number of firms are offering modular products assembled with multiple option choices for the consumer. Starting with the PC offerings by Dell which allowed (and still allows) users to configure their product by choosing among multiple choices for each option, the current market place seems to have evolved to a make-to-stock scenario where Apple offers its IPAD series with multiple models each with a unique storage size, color, and wireless chip technology. The focus of our work is on determining the optimal stocking level of modular end-products. Our analysis is based on a benchmark model with the aim of maximizing expected profit subject to an aggregate fill rate constraint as well as variant-specific individual fill rates under a make-to-stock setting. To further assess the robustness of our finding, we consider the extensions of correlated market preferences over options, price-dependent demand, and alternative probability distributions for characterizing uncertainty in market preferences or aggregate demand. Finally we also show how to extend the single period model into a multiple-period setting. Through extensive computational analysis, we find that more precise estimates of market preferences for various modular options constitute extremely valuable information that goes beyond the usefulness of forecasts of aggregate market demand. From a practical perspective, this might be indicative of another classic marketing-operations trade-off. Offering more options for consumers would be preferred by marketing managers since this would reach more consumers and hence, enhance product sales. On the other hand, the ability to obtaining greater forecast accuracy would decline when the number of options increase. Hence, from an operational perspective, it would be preferred to limit option choices (so that better forecasts can be obtained) since this would lead to lower stocking costs and hence, higher profits.", "e:keyword": ["Modular products", "Inventory planning", "Fill rates"]}, {"e:abstract": "In developing countries, farmers lack information for making informed production, manufacturing/selling decisions to improve their earnings. To alleviate poverty, various non-governmental organizations (NGOs) and for-profit companies have developed different ways to distribute information about market price, crop advisory and farming technique to farmers. We investigate a fundamental question: will information create economic value for farmers? We construct a stylized model in which farmers face an uncertain market price (demand) and must make production decisions before the market price is realized. Each farmer has an imprecise private signal and an imprecise public signal to estimate the actual market price. By examining the equilibrium outcomes associated with a Cournot competition game, we show that private signals do create value by improving farmers' welfare. However, this value deteriorates as the public signal becomes available (or more precise). In contrast, in the presence of private signals, the public signal does not always create value for the farmers. Nevertheless, both private and public signals will reduce price variation. We also consider two separate extensions that involve non-identical private signal precisions and farmers' risk-aversion, and we find that the same results continue to hold. More importantly, we find that the public signal can reduce welfare inequality when farmers have non-identical private signal precisions. Also, risk-aversion can dampen the value created by private or public information.", "e:volume": "24", "@id": "http://dx.doi.org/10.1111/poms.12371", "e:issue": "9", "e:keyword": ["Social responsibility", "Information provision", "Value creation", "Game theory"]}, {"e:abstract": "The agricultural sector plays an important role in emerging economies even though most farmers are trapped in the poverty cycle owing to their smallholdings. Aggregating farmers through formal or informal cooperatives (coops) can enable them to: (i) reduce production cost; (ii) increase/stabilize process yield; (iii) increase brand awareness; (iv) eliminate unnecessary intermediaries; and (v) eliminate price uncertainty. To examine whether these effects will benefit the members of such aggregation when they compete with other individual farmers, we present separate models to capture the essence of these five effects. For each effect, we find that it is beneficial for a farmer to be part of the aggregation only when the size of the aggregation is below a certain threshold. Also, while certain effects are beneficial to the market as a whole, other effects are hurtful due to higher market price and/or lower production quantity.", "e:volume": "24", "@id": "http://dx.doi.org/10.1111/poms.12372", "e:issue": "9", "e:keyword": ["Cooperatives", "Socially responsible operations", "Cournot competition"]}, {"e:abstract": "This paper studies whether imposing carbon costs changes the supply chain structure and social welfare. We explore the problem from a central policymaker's perspective who wants to maximize social welfare. We consider two stakeholders, retailers, and consumers, who optimize their own objectives (i.e., profits and net utility) and three competitive settings (i.e., monopoly, monopolistic competition with symmetric market share, and monopolistic competition with asymmetric market share). For the monopoly case, we find that when the retailer's profit is high, imposing some carbon emission charges on the retailer and the consumers does not substantially change the supply chain structure or the social welfare. However, when the retailer's profit is low, imposing carbon costs optimally can lead to a significant increase in social welfare. Moreover, the impact of imposing carbon emission charges becomes more significant when the degree of competition increases. Additionally, the quantum of benefit may depend only on factors common across industries, such as fuel and carbon costs.", "e:volume": "24", "@id": "http://dx.doi.org/10.1111/poms.12373", "e:issue": "9", "e:keyword": ["Sustainability", "Supply chain design", "Policy making", "Carbon tax", "Monopolistic competition"]}, {"e:abstract": "Firms are increasingly looking to eradicate social and environmental non-compliances at their suppliers in response to increasing regulations, consumer demand, potential for supply chain disruptions, and to improve their social, environmental, and economic supply chain performance. This study develops a model of the relationship between the buyer's supplier incentives and penalties for the supplier's social and environmental compliance, and the outcomes in terms of reduction in supplier social and environmental violations as well as the buyer's own operating costs. This model is tested empirically through analysis of a dataset of opinion-based survey responses from practitioners at 334 companies across 17 industries. The analysis finds specific penalties and incentives that are positively associated with reduced supplier violations and reduced buyer operating costs. In particular, offering suppliers incentives of increased business and training for improving social and environmental performance is strongly associated with a reduction in both violations and operating costs.", "e:volume": "24", "@id": "http://dx.doi.org/10.1111/poms.12376", "e:issue": "9", "e:keyword": ["Social and environmental responsibility", "Supplier non‐compliances and violations", "Responsible supplier management", "Supplier incentives and penalties"]}, {"@id": "http://dx.doi.org/10.1111/poms.12377", "e:abstract": "Hospital readmissions present an increasingly important challenge for health-care organizations. Readmissions are expensive and often unnecessary, putting patients at risk and costing $15 billion annually in the United States alone. Currently, 17% of Medicare patients are readmitted to a hospital within 30 days of initial discharge with readmissions typically being more expensive than the original visit to the hospital. Recent legislation penalizes organizations with a high readmission rate. The medical literature conjectures that many readmissions can be avoided or mitigated by post-discharge monitoring. To develop a good monitoring plan it is critical to anticipate the timing of a potential readmission and to effectively monitor the patient for readmission causing conditions based on that knowledge. This research develops new methods to empirically generate an individualized estimate of the time to readmission density function and then uses this density to optimize a post-discharge monitoring schedule and staffing plan to support monitoring needs. Our approach integrates classical prediction models with machine learning and transfer learning to develop an empirical density that is personalized to each patient. We then transform an intractable monitoring plan optimization with stochastic discharges and health state evolution based on delay-time models into a weakly coupled network flow model with tractable subproblems after applying a new pruning method that leverages the problem structure. Using this multi-methodologic approach on two large inpatient datasets, we show that optimal readmission prediction and monitoring plans can identify and mitigate 40–70% of readmissions before they generate an emergency readmission.", "e:keyword": ["Hospital readmissions", "Post‐discharge patient monitoring", "Readmission risk profiling", "Bayesian survival analysis", "Delay‐time models of readmissions"]}, {"@id": "http://dx.doi.org/10.1111/poms.12378", "e:abstract": "We study the logistics problem faced by Regional Branches (RBs) of a central bank in managing the currency supply under security concerns. While making banknote supply decisions to Sub-Branches (SBs), the management of RB must achieve two goals simultaneously: (i) guarantee that each SB has sufficient inventories of all denominations of banknotes to satisfy the demands from all commercial banks within its service area, and (ii) control the annual spending on this banknote supply operation. Due to security concerns, the following methods are implemented in the process of transporting banknotes: (i) the capacity of a cash truck is limited by the total face value (instead of the physical space) of banknotes, and (ii) empty decoy trucks are deployed along with the trucks filled with banknotes. After deriving a polynomial-time strategy to guarantee an optimal solution for the special Bin-Packing Problem faced in this study, we provide an exact formulation for the RB's supply planning problem. We also propose several polynomial-time algorithms for deriving either optimal or near-optimal solutions for the problem under different settings. Using the weekly demand data obtained from the central bank, we verify the performance of our algorithms, and analyze the impacts of changes in these features and in the fleet capacity on the total cost incurred by an RB under various scenarios.", "e:keyword": ["Supply chain", "Logistics", "Cash", "Scheduling", "Security concern"]}, {"@id": "http://dx.doi.org/10.1111/poms.12379", "e:abstract": "All major world economies are exhibiting a shift from products to services in terms of relative share of GNP and employment. A well accepted explanation for this shift to services has been the lower productivity growth in services relative to manufacturing. A second trend visible in the United States and other advanced economies is that from material-intensive to information-intensive sectors with the latter growing relative to the former. There does not seem to be a generally accepted explanation for this shift; in fact, here it would appear that productivity in information-intensive sectors is increasing. We construct a model of an economy with endogenous production and consumption decisions by utility maximizing individuals. We show that differential productivity changes can result in either relative growth or decline of a sector. A second factor affecting the direction of change is the degree to which consumption of sector outputs approaches satiation. When marginal utility of additional consumption drops sufficiently low, productivity increases can lead to declines in the relative size and share of, and employment in the sector. Concurrently, increases in productivity increase average wealth as expected, but income inequality can either increase or decrease.", "e:keyword": ["Industrialization", "Manufacturing", "Productivity", "Service"]}, {"@id": "http://dx.doi.org/10.1111/poms.12385", "e:abstract": "Descending mechanisms for procurement (or, ascending mechanisms for selling) have been well-recognized for their simplicity from the viewpoint of bidders—they require less bidder sophistication as compared to sealed-bid mechanisms. In this study, we consider procurement under each of two types of constraints: (1) Individual/Group Capacities: limitations on the amounts that can be sourced from individual and/or subsets of suppliers, and (2) Business Rules: lower and upper bounds on the number of suppliers to source from, and on the amount that can be sourced from any single supplier. We analyze two procurement problems, one that incorporates individual/group capacities and another that incorporates business rules. In each problem, we consider a buyer who wants to procure a fixed quantity of a product from a set of suppliers, where each supplier is endowed with a privately known constant marginal cost. The buyer's objective is to minimize her total expected procurement cost. For both problems, we present descending auction mechanisms that are optimal mechanisms. We then show that these two problems belong to a larger class of mechanism design problems with constraints specified by polymatroids, for which we prove that optimal mechanisms can be implemented as descending mechanisms.", "e:keyword": ["Procurement", "Capacity constraints", "Business rules", "Optimal mechanism", "Descending auctions"]}, {"@id": "http://dx.doi.org/10.1111/poms.12386", "e:abstract": "We consider a stochastically failing component that will be needed at a random future time when an emergency occurs. If the component is not operational at that time, the system incurs a large penalty, which we want to avoid through inspections and replacements. We propose a model and solution algorithm for finding an inspection policy that minimizes the infinite horizon discounted expected penalty, replacement, and inspection costs. We also discuss structural properties of the solution, as well as insights based on numerical results.", "e:keyword": ["Inspection policies", "Preventive maintenance", "Stand‐by system"]}, {"@id": "http://dx.doi.org/10.1111/poms.12387", "e:abstract": "We examine two time-related incentive project management contracts (C1 and C2 contracts) when the manager conducts a reverse auction. Under the C1 contract, the contractor with the lowest bid price wins; however, the manager imposes a linear and symmetric incentive/disincentive for early/late completion according to a pre-specified due date. Under the C2 contract, the winning contractor has the lowest composite score that is based on the quoted price and the quoted due date; however, in addition to the linear and symmetric penalty/incentive, the contractor is subject to an additional penalty for late completion. While the C2 contract is more sophisticated than the C1 contract (in terms of the number of decisions that each party has to make), our analysis reveals that, unless the project is truly urgent, the more complicated C2 contract adds no value to the manager— the simple C1 contract will suffice.", "e:keyword": ["Project management", "Uncertain completion time", "Incentive contracts"]}, {"@id": "http://dx.doi.org/10.1111/poms.12388", "e:abstract": "A firm's two-product bundling decision is examined when the supply of one product is limited and consumer valuations are normally distSteckeributed. The firm can choose to sell products separately and/or through a bundle. We find that the impact of limited supply on a firm's bundling decision depends on the correlation between the consumer valuations of the two products as well as the symmetry level of the two products in terms of their attractiveness (how much they are valued by consumers). When the valuation correlation is high and the symmetry level of the two products is low, limited supply can drive bundling. When the valuation correlation is low or the symmetry level is high, limited supply can drive no bundling. When the attractiveness of both products are low or the valuation correlation is very high, limited supply has no impact on a firm's bundling decision: The firm should not bundle for all supply levels.", "e:keyword": ["Limited supply", "Pure bundling", "Mixed bundling", "Supply‐driven bundling"]}, {"e:abstract": "We study a municipal groundwater management problem to determine optimal allocation and control policies in the presence of water transfer opportunities. We establish and characterize threshold polices governing export or import decisions of a given municipality. In the spirit of the Triple Bottom Line (3BL), we ascertain that exporting (importing) water through a water market defined by an exogenous export/import price is detrimental (beneficial) to both society and the environment within the municipality. In contrast, fixed quantity trading between two municipalities defined by an endogenously negotiated export/import price can have positive as well as negative impacts from a global 3BL perspective. In particular, typical trading scenarios that occur between municipalities can be detrimental to the environment. We also study the implications of privatization, and find that a privatized municipality would be more (less) likely to export (import) water as compared to its non-privatized counterpart, resulting in negative implications for society within the municipality. However, if exports are banned, privatization can benefit the environment by mitigating the damage caused by the extraction differential, a phenomenon analogous to the green paradox. Moreover, careful and restricted privatization of municipalities can lead to positive global 3BL impacts from fixed quantity trading.", "e:volume": "24", "@id": "http://dx.doi.org/10.1111/poms.12389", "e:issue": "9", "e:keyword": ["Groundwater management", "Triple Bottom Line", "Water transfers", "Privatization"]}, {"@id": "http://dx.doi.org/10.1111/poms.12392", "e:abstract": "In recent years, increasing interests have arisen in adding product value through the provision of service. This study considers the problem in which a demand-enhancing service can be provided by different supply chain parties, resulting in four alternative service channels: (a) manufacturer undertaking service, namely M-channel, (b) retailer undertaking service, namely R-channel, (c) manufacturer outsourcing service to third-party (3P), namely M-3P-channel, and (d) retailer outsourcing service to 3P, namely R-3P-channel. We quantitatively model these service channels and derive the optimal decisions with the following observations: When the service costs are equal for the different parties, there is a conflict in service channel choice since both the manufacturer and the retailer prefer to undertake the service or hire the 3P by themselves, although M-channel generates the highest market demand and system profit; When the service costs are different among these parties, R-channel and 3P-channels are more preferable if the service cost is less sensitive to the service level and if the market demand is more sensitive to the service level. We also conduct an empirical study to test some of the insights developed from the analytical models; our empirical findings support the analytical results.", "e:keyword": ["Channel choice", "Service", "Supply chain management", "Game theory"]}, {"@id": "http://dx.doi.org/10.1111/poms.12394", "e:abstract": "Buying frenzies caused by a firm's intentional undersupplying of a new product are frequently evident in several industries including electronics (cell phones, video games), luxury automobiles, and fashion goods. We develop a dynamic model of buying frenzies that incorporates the firm's manufacturing and sale of a product over time and characterizes the conditions under which inducing such frenzies is an optimal strategy. We find that buying frenzies occur when customers are sufficiently uncertain about their valuations of the product and when they discount the future sufficiently but not excessively. We propose measures of “customer desperation” and of the extent of scarcity to measure the depth and breadth of buying frenzies, respectively. We also demonstrate that such frenzies can have a significantly positive effect on firm profits and partially recover the loss due to non-commitment to future prices. This study provides managerial insights on how firms can influence market response to a new product through production, pricing, and inventory decisions to induce profitable frenzies.", "e:keyword": ["Advance selling", "Buying frenzy", "Customer desperation", "Strategic customer behavior"]}, {"@id": "http://dx.doi.org/10.1111/poms.12395", "e:abstract": "We consider a patient admission problem to a hospital with multiple resource constraints (e.g., OR and beds) and a stochastic evolution of patient care requirements across multiple resources. There is a small but significant proportion of emergency patients who arrive randomly and have to be accepted at the hospital. However, the hospital needs to decide whether to accept, postpone, or even reject the admission from a random stream of non-emergency elective patients. We formulate the control process as a Markov decision process to maximize expected contribution net of overbooking costs, develop bounds using approximate dynamic programming, and use them to construct heuristics. We test our methods on data from the Ronald Reagan UCLA Medical Center and find that our intuitive newsvendor-based heuristic performs well across all scenarios.", "e:keyword": ["Patient admission", "Patient scheduling", "Multiple resources", "Markov decision process", "Approximate dynamic programming"]}, {"@id": "http://dx.doi.org/10.1111/poms.12402", "e:abstract": "The role of assortment planning and pricing in shaping sales and profits of retailers is well documented and studied in monopolistic settings. However, such a role remains relatively unexplored in competitive environments. In this study, we study equilibrium behavior of competing retailers in two settings: (i) when prices are exogenously fixed, and retailers compete in assortments only; and (ii) when retailers compete jointly in assortment and prices. For this, we model consumer choice using a multinomial Logit, and assume that each retailer selects products from a predefined set, and faces a display constraint. We show that when the sets of products available to retailers do not overlap, there always exists one equilibrium that Pareto-dominates all others, and that such an outcome can be reached through an iterative process of best responses. A direct corollary of our results is that competition leads a firm to offer a broader set of products compared to when it is operating as a monopolist, and to broader offerings in the market compared to a centralized planner. When some products are available to all retailers, that is, assortments might overlap, we show that display constraints drive equilibrium existence properties.", "e:keyword": ["Assortment planning", "Competition", "Choice models", "Multinomial Logit", "Pricing"]}, {"@id": "http://dx.doi.org/10.1111/poms.12407", "e:abstract": "Facing the growing concern of environmental impact, green service (GS) has emerged as an important research topic in production and operations management. However, empirical research on GS is hindered by the lack of theoretically developed and empirically validated measurement scales covering various practices in service operations of a supply chain. GS indicates the strategic orientation of firms in developing a combination of practices and routines to reduce environmental impact in service operations that span from product development to servicing customers. Grounded in the natural resource-based view (NRBV), this study conceptualizes GS from the supply chain perspective and in the consumer-product context to develop a GS measurement model. Collecting secondary and primary data in both qualitative and quantitative forms, this study reports the development of GS multi-item measurement scales using a multi-method research design that combines interviews, content analysis, and mass survey. GS is operationalized as a multi-dimensional construct reflecting three complementary dimensions, namely pollution prevention-, product-, and long-term development-oriented GS practices, where each of them comprises three sub-dimensions, resulting in a total of 34 measurement items. The empirically validated scales can be used to advance theory and practices of GS, while providing a useful reference for firms to evaluate their GS efforts, and identify areas for improvement.", "e:keyword": ["Green service practices", "Environmental management", "Empirical", "Research methodology", "Multi‐method research design"]}, {"@id": "http://dx.doi.org/10.1111/poms.12408", "e:abstract": "The construction of a software system requires not only individual coding effort from team members to realize the various functionalities, but also adequate team coordination to integrate the developed code into a consistent, efficient, and bug-free system. On the one hand, continuous coding without adequate coordination can cause serious system inconsistencies and faults that may subsequently require significant corrective effort. On the other hand, frequent integrations can be disruptive to the team and delay development progress. This tradeoff motivates the need for a good coordination policy. Both the complexity and the importance of coordination is accentuated in distributed software development (DSD), where a software project is developed by multiple, geographically-distributed sub-teams. The need for coordination in DSD exists both within one sub-team and across different sub-teams. The latter type of coordination involves communication across spatial boundaries (different locations) and possibly temporal boundaries (different time zones), and is a major challenge that DSD faces. In this study, we model both inter- and intra-sub-team coordination in DSD based on the characteristics of the systems being developed by the sub-teams, the deadline for completion, and the nature of division adopted by the sub-teams with respect to development and integration activities. Our analysis of optimal coordination policies in DSD shows that integration activities by one sub-team not only benefit that sub-team (as is the case in co-located development) but can also help the other sub-teams by providing greater visibility, thereby resulting in a higher integration frequency relative to co-located development. Analytical results are presented to demonstrate how the characteristics of the projects and the sub-teams, and the efficiency of communication across the sub-teams, affect coordination and productivity. We also investigate the pros and cons of using specialized integration sub-teams and find that their advantage decreases as the project schedule becomes tighter. Decentralized decisions and asymmetric subsystems are also discussed.", "e:keyword": ["Distributed software development", "Coordination in teams", "Project management", "Optimal policies"]}, {"@id": "http://dx.doi.org/10.1111/poms.12409", "e:abstract": "Past researchers have found evidence that customers consider the sequence of event utility when evaluating past and future service experiences. Specifically, the evidence confirms that the placement of a peak event, the utility of the last event, and the slope of event utility over time all affect customer behavior and perception. We formulate an optimization problem with a focus on optimizing schedule sequence characteristics in order to maximize customer experiences. We discuss possible contexts in which this type of scheduling might be considered and, as an example, present a particularly complex model of a world-renowned performing arts venue. We solve the problem with a simulated annealing algorithm and further discuss the complexity and opportunities associated with this type of scheduling effort.", "e:keyword": ["Service scheduling", "Sequence effects", "Behavioral operations", "Service design", "Social pyschology"]}, {"@id": "http://dx.doi.org/10.1111/poms.12411", "e:abstract": "Several contradictions are noted among the Economic Order Quantity (EOQ), Just-In-Time (JIT), and Optimized Production Technology (OPT) approaches and the economic framework for profit maximization. A fundamental model referred to as the Economic Manufacturing Quantity (EMO) is developed and examined for its integrating implications for the three approaches. An implication for the classic EOQ approach is that the balance between setup and inventory carrying costs is valid when a production facility is operating at or below a certain critical level but not when operating above that level. An implication for the JIT approach is that one must reduce setup cost at non-bottlenecks and setup time at bottlenecks to reduce inventory. An implication for the OPT approach is that trade-offs between setup and inventory carrying costs may indeed be ignored while determining process batch sizes, provided each facility in a production system is operating at or above Its critical level. Economic theoretic analysis of the EMO model provides a basis for unification of JIT which advocates stability in operating level as a key to improved productivity and quality, and OPT that advocates maximizing operating level with resultant emphasis on bottlenecks as a key to increased profits. This unifying basis states that a profit-maximizing production facility or system will operate at the full and stable level as long as market demand remains relatively sensitive to price and operating at the full (maximum) level provides positive unit contribution.", "e:keyword": ["Economic Manufacturing Quantity", "Economic Order Quantity", "Just‐In‐Time production", "Optimized Production Technology", "Profit maximization", "Full and stable operating level principle"]}, {"@id": "http://dx.doi.org/10.1111/poms.12416", "e:abstract": "We examine the effect of a hospital's objective (i.e., non-profit vs. for-profit) in hospital markets for elective care. Using game-theoretic analysis and queueing models to capture the operational performance of hospitals, we compare the equilibrium behavior of three market settings in terms of such criteria as waiting times and patient costs from waiting and hospital payments. In the first setting, a monopoly, patients are served exclusively by a single non-profit hospital; in the second, a homogeneous duopoly, patients are served by two competing non-profit hospitals. In our third setting, a heterogeneous duopoly, the market is served by one non-profit hospital and one for-profit hospital. A non-profit hospital provides free care to patients, although they may have to wait; for-profit hospitals charge a fee to provide care with minimal waiting. A comparison between the monopolistic and each of the duopolistic settings reveals that the introduction of competition can hamper a hospital's ability to attain economies of scale and can also increase waiting times. Moreover, the presence of a for-profit sector may be desirable only when the hospital market is sufficiently competitive. A comparison across the duopolistic settings indicates that the choice between homogeneous and heterogeneous competition depends on the patients' willingness to wait before receiving care and the reimbursement level of the non-profit sector. When the public funder is not financially constrained, the presence of a for-profit sector may allow the funder to lower both the financial costs of providing coverage and the total costs to patients. Finally, our analysis suggests that the public funder should exercise caution when using policy tools that support the for-profit sector—for example, patient subsidies—because such tools may increase patient costs in the long run; it might be preferable to raise the non-profit sector's level of reimbursement.", "e:keyword": ["Hospitals", "For‐profit health care", "Non‐profit health care", "Queueing models", "Service provider competition"]}, {"@id": "http://dx.doi.org/10.1111/poms.12418", "e:abstract": "Inventory decisions made at a centralized level often rely on demand forecast information passed from regional managers within a supply chain. Such managers often have unique insights into the demand patterns at their local sites that can help inform how much inventory to order for the system as a whole. Problems can arise with this setup, however, if these managers have incentives to misreport their forecasts and the central planner (CP), in turn, mistrusts this information. The goal of our research is to shed light on the existence, magnitude, and causes of such coordination problems using a combination of analytical models and behavioral experiments. The analytical analysis reveals that incentives are misaligned in this setting and no truth-telling equilibrium exists in general, unless inventory competition or demand uncertainty is removed. With this theoretical grounding, we conduct a series of controlled laboratory experiments to test the magnitude of these problems and how they are impacted by inventory competition, strategic concerns regarding the other parties, and the demand environment. We find that inventory competition and market uncertainty harm the efficacy of forecast sharing and channel efficiency, while the possibility that untrustworthy reports are detected (identical local demand information) does not deter regional managers from misreporting their forecasts. Removing strategic concerns regarding the CP (automating the central ordering decision) does not improve profit but reduces order variability. Information sharing appears to be a dominant policy as it significantly improves profit in all treatments compared with no information sharing.", "e:keyword": ["Inventory pooling", "Information sharing", "Trust and trustworthiness", "Behavioral operations", "Experimental economics"]}, {"@id": "http://dx.doi.org/10.1111/poms.12420", "e:abstract": "In retailing industries, such as apparel, sporting goods, customer electronics, and appliances, many firms deploy sophisticated modeling and optimization software to conduct dynamic pricing in response to uncertain and fluctuating market conditions. However, the possibility of markdown pricing creates an incentive for customers to strategize over the timing of their purchases. How should a retailing firm optimally account for customer behavior when making its pricing and stocking/capacity decisions? For example, is it optimal for a firm to create rationing risk by deliberately under stocking products? In this study, we develop a stylized modeling framework to answer these questions. In our model, customers strategize over the timing of their purchases. However, customers have boundedly rational expectations in the sense of anecdotal reasoning about the firm's fill rate, i.e., they have to rely on anecdotes, past experiences, or word-of-mouth to infer the firm's fill rate. In our modeling framework, we distinguish two settings: (i) capacity commitment, where the firm commits to its capacity level in the long run, or (ii) the firm dynamically changes it in each season. For both settings, within the simplest form of anecdotal reasoning, we prove that strategic capacity rationing is not optimal independent of customer risk preferences. Then, using a general form of anecdotal reasoning, we provide sufficient conditions for capacity rationing to be optimal for both settings, respectively. We show that the result of strategic capacity rationing being suboptimal is fairly robust to different valuation distributions and utility functions, heterogeneous sample size, and price optimization.", "e:keyword": ["Strategic capacity management", "Bounded rationality", "Capacity rationing", "Anecdotal reasoning", "Revenue management"]}, {"@id": "http://dx.doi.org/10.1111/poms.12425", "e:abstract": "In a technology project, project integration represents the pooling together of complete, interdependent task modules to form a physical product or software delivering a desired functionality. This study develops and tests a conceptual framework that examines the interrelationships between the elements of work design, project integration challenges, and project performance. We identify two distinct elements of work design in technology projects: (i) the type of project organization based on whether a technology project spans a firm boundary (Domestic-Outsourcing) or a country boundary (Offshore-Insourcing) or both boundaries (Offshore-Outsourcing) or no boundaries (Domestic-Insourcing), and (ii) the joint coordination practices among key stakeholders in a technology project—namely, Onsite Ratio and Joint-Task Ownership. Next, we measure the effectiveness of project integration using integration glitches that capture the incompatibility among interdependent task modules during project integration. Based on analysis of data from 830 technology projects, the results highlight the differential effects of distributed project organizations on integration glitches. Specifically, we find that project organizations that span both firm and country boundaries (Offshore-Outsourcing) experience significantly higher levels of integration glitches compared to domestic project organizations (Domestic-Outsourcing and Domestic-Insourcing). The results further indicate that the relationship between project organization type and integration glitches is moderated by the extent of joint coordination practices in a project. That is, managers can actively lower integration glitches by increasing the levels of onsite ratio and by promoting higher levels of joint-task ownership, particularly in project organization types that span both firm and country boundaries (Offshore-Outsourcing). Finally, the results demonstrate the practical significance of studying integration glitches by highlighting its significant negative effect on project performance.", "e:keyword": ["Global sourcing", "Work design", "Integration glitches", "Project management", "Offshoring", "Outsourcing"]}, {"@id": "http://dx.doi.org/10.1111/poms.12427", "e:abstract": "We model the global vehicle supply chain of an International Humanitarian Organization (IHO) with a dynamic hub location model across monthly periods. We use actual vehicle data from the International Federation of the Red Cross to feed our model and provide insights into IHO secondary support demand. We find that secondary support demand for items such as vehicles is different from primary beneficiary demand for items such as water and food. When considering disaster response and development program demand simultaneously (disaster cycle management), our results illustrate that keeping a lean centralized hub configuration with an option for temporary hubs in mega disaster locations can reduce overall supply chain costs over a long time horizon. We also show that it is possible to structure a supply chain to take operational advantage of earmarked funding. This research lays the groundwork for using optimization models to analyze disaster cycle management.", "e:keyword": ["Humanitarian logistics", "Disaster cycle management", "Dynamic hub location", "Earmarked funding"]}, {"@id": "http://dx.doi.org/10.1111/poms.12429", "e:abstract": "We identify market conditions under which intermediaries can thrive in retailer-driven supply chains. Our main finding is that, as a consequence of the retailers’ leadership position, intermediaries prefer products for which the supply base (existing production capacity) is neither too narrow nor too broad; that is, less existing capacity can result in more intermediary profit. We also show that our main finding is robust to (i) the presence of horizontal competition among retailers and intermediaries, (ii) the existence of exclusive suppliers, and (iii) the ability of the retailers to source directly from the suppliers. Nevertheless, we find that horizontal competition between intermediaries encourages them to carry products with relatively smaller production capacity, whereas exclusive suppliers and direct sourcing encourage intermediaries to carry products with relatively larger installed capacity.", "e:keyword": ["Intermediation", "Supply chain", "Vertical and horizontal competition", "Stackelberg leader"]}, {"@id": "http://dx.doi.org/10.1111/poms.12430", "e:abstract": "Recent research on decision framing has shown that (i) there are multiple types of framing effects and (ii) the context of the decision can influence framing effects. This research examines decision framing effects in inventory control contexts by questioning the assumption of procedure invariance, that preference should not be impacted by how options are presented to a supply chain manager making an inventory control decision. Study 1 uses three single-shot decision experiments to establish that all three types of framing effects identified by Levin et al. (1998) apply in basic inventory control contexts. Results were consistent with theory in all three cases. Given this evidence that framing effects have potential to impact inventory control decisions, two laboratory experiments in Study 2 utilize multi-period decision tasks to demonstrate that framing effects can impact performance in a dynamic inventory decision setting similar to practice. One of the experiments in Study 2 was conducted with student subjects, while the other with inventory managers from a large retail firm. Results from both experiments provide evidence that even when initial framing effects on order quantities fade, there can be longer term effects on inventory levels and performance. Furthermore, these effects are robust to education and professional experience. The findings suggest that although a manager might select appropriate inventory control metrics, prudence must be exercised in the presentation of these metrics, and that mere presentation can be used to alleviate known human biases in inventory control decisions.", "e:keyword": ["Behavioral operations management", "Decision biases", "Inventory control", "Supply chain management", "Laboratory experiment"]}, {"@id": "http://dx.doi.org/10.1111/poms.12431", "e:abstract": "This study explores whether the negative impact of “groupthink concurrence-seeking behavior” (GTB) on business process reengineering (BPR) projects is affected by group members personal traits and interpersonal ties within the group. To this purpose we conduct and present the results of a longitudinal controlled field experiment over 18 BPR projects lasting 3 months and involving 18 teams comprising 71 first-year MBA students. The main contribution of this study is twofold. First, we explicitly consider and measure the core construct of groupthink phenomenon: that is, GTB. Existing organizational behavior literature has, contrarily, considered only its causes, symptoms, and outcomes. Second, we show evidence that GTB does have a negative impact on group performance in BPR project settings. In this regards, results also indicate that while perceived control, conscientiousness and interpersonal evaluation mitigate the negative impact of GTB on group project performance, confidence, and previous relationships amplify this negative impact, even if they have a direct positive effect on performance. Thanks to the findings of this study, we are able to provide valuable suggestions to managers in charge of BPR projects for ensuring effective performance of project teams and controlling for potential obstacles due to GTB.", "e:keyword": ["Behavioral operations management", "Groupthink", "Business process reengineering", "Concurrence‐seeking behavior"]}, {"@id": "http://dx.doi.org/10.1111/poms.12495", "e:abstract": "Modularity has the potential to impact various facets of new product introduction performance including product development lead time, frequency of new product introduction, on time introduction and product innovation. The impact of modularity on new product introduction performance, however, may vary for different levels of product and process complexity. This study empirically investigates relationships between perceptual measures of product modularity, process modularity, and new product introduction performance and explores whether an objective product/process complexity measure moderates these relationships. Using survey-based methodology we probe both manufacturers of technically simple products and technically complex products. Hierarchical regression models are used to test hypotheses concerning the main effects of product and process modularity and the effects of their interactions with complexity on new product introduction performance. The results show that the main effect of product modularity was positive and its interaction with complexity was disordinal and negative, suggesting that the positive effect of product modularity on new product introduction performance is dampened when complexity is high. For process modularity, only the interaction effect (positive) was statistically significant and it was also disordinal in nature. Thus, the effect of process modularity on new product introduction performance is heightened when complexity is high. The implications of these findings are discussed and more specific theoretical and managerial implications are delineated by examining the impacts of these main and interaction effects on individual measures of new product introduction performance (frequency of new product introduction, product development lead times, product innovation, and on-time product launch).", "e:keyword": ["Product modularity", "Process modularity", "Complexity", "New product introduction", "Empirical"]}, {"@id": "http://dx.doi.org/10.1111/poms.12496", "e:abstract": "When dealing with urgent, ill-defined problems, such as rapidly evolving emergency situations, operations managers have little time for problem formulation or solution. While the mechanisms by which humans formulate and solve problems have been described, mechanisms for rapid, concurrent formulating and solving are not well understood. This study investigates these mechanisms through a field study of transportation planning in a humanitarian response setting. The findings show that the problem is solved through greedy search and formulated through sensemaking, in which search enables updates to an evolving problem formulation, and the formulation directs and limits the search process. This study explores the implications of these findings for the development of better problem formulation processes and problem-solving strategies for urgent and ill-defined operations management problems.", "e:keyword": ["Problem formulation", "Problem solving", "Behavioral operations", "Humanitarian logistics"]}, {"@id": "http://dx.doi.org/10.1111/poms.12497", "e:abstract": "We solve a sequential-moves game that involves three players: the franchisor, the entrepreneur, and the banks. The franchisor chooses the contract terms (a one-time franchise fee and a royalty rate for on-going payments). The entrepreneur dynamically decides when to sign this contract, open a store, and apply for debt financing to cover the initial investment. In response to the entrepreneur's application, banks competitively determine loan rates. We find that the franchisor should use royalty cash flows and not the franchise fee to extract value from the entrepreneur. This is a new explanation of empirical evidence that franchise contracts favor royalties over franchise fees. To account for the possibility of the entrepreneur's bankruptcy and bankruptcy costs, the franchisor should decrease the royalty rate. However, despite a lower rate, the threshold for the entrepreneur to open the store is higher in the model with financing than in the model without financing. This threshold is much higher than it would have been for the integrated system, which in turn is higher than the static break-even-NPV threshold. If a franchisor ignores financing considerations, she will suffer from having to wait longer for the store opening and from a higher bankruptcy probability. We predict that the franchisor is the main beneficiary of the entrepreneur's greater initial wealth and that the franchisor will benefit more if she assumes a greater share of the store's operating costs.", "e:keyword": ["Optimal stopping time", "Royalty rate", "Franchise fee", "Strategic entrepreneurs", "Bankruptcy"]}, {"@id": "http://dx.doi.org/10.1111/poms.12501", "e:abstract": "We investigate a manufacturer–retailer channel to explore the role of a retailer in assuring the quality of a manufacturer's product as a quality gatekeeper. Such a gatekeeping activity can entail a reduction in the defective rate for consumers, if the retailer charges the manufacturer a penalty for each identified defect that is no smaller than the market penalty for an unidentified defect. As a result of the retailer's gatekeeping, the change in the negotiated wholesale price only depends on the manufacturer's individual benefit, whereas the change in the retailer's optimal retail price is associated with the channel-wide benefit. When the impact of quality relative to retail price on demand is higher, the retailer benefits more from her gatekeeping activity, thus having a greater incentive to take on the quality gatekeeping responsibility. Moreover, the retailer's gatekeeping generates a larger increase in the demand as well as each firm's profit, when the retailer has a stronger relative bargaining power.", "e:keyword": ["Quality gatekeeping", "Pricing", "Game theory", "Bargaining"]}, {"@id": "http://dx.doi.org/10.1111/poms.12502", "e:abstract": "We empirically investigate how time reductions in particular product development stages impact market value. Using longitudinal project data from 107 firms, we compare stage times prior to and following investments in new product development process changes. Our analysis reveals a predominance of focus on time reduction in the late stages of product development. We also find support for the existence of an inverted-U relationship between market performance and time reductions for some of these stages: beta testing and technical implementation. Therefore, while time reductions can improve time to market, we observe a clear limit to the benefits associated with stage time reductions at particular stages. We also investigate the role of strategic contextual factors such as the extent to which a firm's patented innovations rely upon a variety, as opposed to a limited range, of diverse technology classes. The extent of this technology-span impacts optimal stage time reductions. We perform an in-depth post hoc analysis with a small set of firms to uncover how they should invest in stage time reduction given our empirical results. The post hoc analysis highlights that some firms are likely overinvesting in stage time reductions and destroying market value.", "e:keyword": ["New product development", "Stage‐gate", "Abnormal market returns", "Time to market"]}, {"@id": "http://dx.doi.org/10.1111/poms.12503", "e:abstract": "We investigate the optimal strategies for firms to invest in their suppliers when the benefits of such investments can spillover to other firms who also source from the same suppliers. We consider two Bayesian firms that can invest in improving the quality of their shared supplier; the firms do not have complete information on the true quality of the supplier, but they update their beliefs based on the supplier's performance. We formulate the problem as an investment game and obtain Markov perfect equilibria characterized by the investment thresholds of both firms. The equilibrium investment strategies of the two firms are characterized by a region of preemption and a region of war of attrition. We also examine how the interplay between spillover, competition, and returns from the investment at shared suppliers affect the investment threshold and the time to the leader's investment, and identify the conditions under which competition delays or hastens the first investment in a shared supplier.", "e:keyword": ["Spillover", "Supplier investment", "Shared suppliers", "Quality management"]}, {"@id": "http://dx.doi.org/10.1111/poms.12504", "e:abstract": "In retailing operations, retailers face the challenge of incomplete demand information. We develop a new concept named K-approximate convexity, which is shown to be a generalization of K-convexity, to address this challenge. This idea is applied to obtain a base-stock list-price policy for the joint inventory and pricing control problem with incomplete demand information and even non-concave revenue function. A worst-case performance bound of the policy is established. In a numerical study where demand is driven from real sales data, we find that the average gap between the profits of our proposed policy and the optimal policy is 0.27%, and the maximum gap is 4.6%.", "e:keyword": ["Inventory and pricing coordination", "Incomplete demand information", "K‐approximate convexity"]}, {"@id": "http://dx.doi.org/10.1111/poms.12510", "e:abstract": "Indoor cell phone users often suffer poor connectivity. One promising solution to this issue, femtocell technology, has been rapidly developed and deployed over the past few years. One of the biggest challenges facing femtocell deployment is the lack of a clear business model. This study investigates the economic incentive for cellular operators (also called macrocell operators) to enable femtocell service by leasing spectrum resources to independent femtocell operators. We model the interactions between a macrocell operator, a femtocell operator, and end-users as a three-stage dynamic game, and derive the equilibrium pricing and capacity allocation decisions. We show that when spectrum resources are very limited, the macrocell operator has more incentive to lease spectrum to the femtocell operator, as femtocell services can help cover more users and improve the utilization efficiency of the limited spectrum resource. However, when the total spectrum resource is large, femtocell service offers significant competition to macrocell service and, as a result, the macrocell operator has less incentive to enable femtocell service. We also show the impact of the additional operational costs and limited coverage of femtocell service on equilibrium decisions, consumer surplus, and social welfare.", "e:keyword": ["Wireless service", "Capacity allocation", "Pricing", "Game theory"]}, {"@id": "http://dx.doi.org/10.1111/poms.12511", "e:abstract": "Inventory inaccuracy is common in many businesses. While retailers employ cash registers to enter incoming orders and outgoing sales, inaccuracy arises because they do not record invisible demand such as spoilage, damage, pilferage, or returns. This setting results in incomplete inventory and demand information. An important inventory control problem therefore is to maximize the total expected discounted profit under this setting. Allowing for dependence between demand and invisible demand, we obtain the associated dynamic programming equation with an infinite-dimensional state space, and reduce it to a simpler form by employing the concept of unnormalized probability. We develop an analytical upper bound on the optimal profit as well as an iterative algorithm for an approximate solution of the problem. We compare profits of the iterative solution and the myopic solution, and then to the upper bound. We see that the iterative solution performs better than the myopic solution, and significantly so in many cases. Furthermore, it gives a profit not far from the upper bound, and is therefore close to optimal. Using our results, we also discuss meeting inventory service levels.", "e:keyword": ["Inventory uncertainty", "Markov dynamic programming", "Invisible demand", "Censored demand"]}, {"@id": "http://dx.doi.org/10.1111/poms.12512", "e:abstract": "This study examines a firm's quality and price decisions when consumers differ not only in their willingness-to-pay for quality but also in their reservation utility for the basic product. We find that while the firm offers lower-quality products when consumers' valuations for quality deteriorate, the optimal quality may increase with a negative shift in consumers' reservation utilities. We also investigate the optimal price and quality of the products within a vertically differentiated product line when the number of products is exogenously given. The existing literature shows that when consumers differ only in their willingness-to-pay for quality, the firm sets the efficient quality for consumers with the highest valuation for quality, whereas the concern for cannibalization pushes down the quality of inferior products. We find that when consumers are heterogeneous in both their reservation utility and valuation for quality, the concern for cannibalization may distort the quality upwards, even for consumers with the highest willingness-to-pay for quality. In addition, a low-quality product may enjoy a higher profit margin than a high-quality product within the product line.", "e:keyword": ["Quality decision", "Utility modeling", "Reservation utility", "Willingness‐to‐pay"]}, {"@id": "http://dx.doi.org/10.1111/poms.12513", "e:abstract": "In recent years, there has been increasing pressure on the US federal government to reduce spending and improve the management of its technology projects. Mitigating the adverse impact of risks on the performance of these projects presents a significant challenge for its stakeholders. Our research examines this challenge in two steps. First, we identify and define a set of salient risks in federal technology projects—specifically, complexity risk and contracting risk in the planning process, and execution risk in the execution process. Next, we investigate whether higher levels of process maturity, assessed by the Capability Maturity Model Integration (CMMI) framework, mitigate the negative effect of project risks on project performance. The analysis of time-series data collected from 82 federal technology projects across 519 quarterly time periods indicates that each of the three types of risks has a significant negative effect on project performance. This finding highlights the practical significance of managing these risks in the federal technology project context. Further, we find that increasing levels of process maturity attenuate the negative effect of project risks on the performance of federal technology projects. However, the attenuation effects are consequential only at high levels of project risks; at low levels of project risk, increasing levels of process maturity can adversely affect project performance. To demonstrate the financial implications of increasing process maturity levels in federal technology projects, we examine the magnitude of project cost savings (and overruns) across different levels of CMMI and project risks. In summary, our study contributes to the sparse literature on public sector operations by addressing the understudied context of federal technology projects, and provides a nuanced examination of the implications of process maturity in managing the risk to performance relationship in such projects.", "e:keyword": ["Project Management", "Process Maturity", "Project Risk", "Federal Technology Projects", "Public Sector"]}, {"@id": "http://dx.doi.org/10.1111/poms.12514", "e:abstract": "In this study, we develop an analytical framework for personalizing the anticoagulation therapy of patients who are taking warfarin. Consistent with medical practice, our treatment design consists of two stages: (i) the initiation stage, modeled using a partially-observable Markov decision process, during which the physician learns through systematic belief updates about the unobservable patient sensitivity to warfarin, and (ii) the maintenance stage, modeled using a Markov decision process, during which the physician relies on his formed belief about patient sensitivity to determine the stable, patient-specific, warfarin dose to prescribe. We develop an expression for belief updates in the POMDP, establish the optimality of the myopic policy for the MDP, and derive conditions for the existence and uniqueness of a myopically optimal dose. We validate our models using a real-life patient data set gathered at the Hematology Clinic of the Jewish General Hospital in Montreal. The proposed analytical framework and case study enable us to develop useful clinical insights, for example, concerning the length of the initiation period and the importance of correctly assessing patient sensitivity.", "e:keyword": ["Personalized treatment", "Stroke prevention", "Treatment design", "Warfarin"]}, {"@id": "http://dx.doi.org/10.1111/poms.12515", "e:abstract": "To date, it has not been elucidated whether the strategy method and the direct-response method lead to different behaviors in experiments of economic games. In this study, we investigate this issue under a multi-round setting of the capacity allocation game with both of the elicitation methods. In the first experiment (regular behavioral experiment), subjects are paired to make decisions in a laboratory through a computer network platform. In the second experiment (neuroimaging experiment), the functional magnetic resonance imaging (fMRI) technique is applied to observe similarities and differences in brain activities between the two elicitation methods. The results show that no significant difference is observed in the ordering behaviors between the two methods. Meanwhile, the neuroimaging data reveal that the strategy method induces comparable activations in similar brain regions, as does the direct-response method. Additionally, it is more likely that subjects adjust their decisions during the feedback phase, rather than during the decision phase. Our results indicate that, in multi-round game experiments without features such as emotion, the effect of the elicitation method is not likely to be exhibited.", "e:keyword": ["Strategy method", "Capacity allocation game", "Behavioral operations", "fMRI"]}, {"@id": "http://dx.doi.org/10.1111/poms.12521", "e:abstract": "This study presents the formal problem definition and computational analysis of the network design improvements for idea and message propagation in both enterprise and consumer social networks (ESN and CSN, respectively). Message propagation in social networks is impacted by how messages are seeded in the network, and by propagation characteristics of the network topology itself. It has been recognized that the propagation properties of these networks can be actively influenced by network design interventions, such as the deliberate creation of new connections. We address the problem of finding cost-effective message seeding, and identifying potential new network connections that allow improved propagation in social networks with cascade propagation. We use the hop-constrained minimum spanning tree (HMST) model to find the seeds and possible new connections that result in networks with improved propagation properties. Moreover, we present new heuristic algorithms that substantially improve the solution quality for the HMST problem. Computational results posit that the design improvements proposed by the HMST approach can greatly improve cascade propagation performance of the networks at low cost.", "e:keyword": ["Propagation", "Social networks", "Network intervention", "Network alteration", "Hop‐constrained minimum spanning tree"]}, {"@id": "http://dx.doi.org/10.1111/poms.12523", "e:abstract": "We study the impact of emissions tax and emissions cap-and-trade regulation on a firm's technology choice and capacity decisions. We show that emissions price uncertainty under cap-and-trade results in greater expected profit than a constant emissions price under an emissions tax, which contradicts popular arguments that the greater uncertainty under cap-and-trade will erode value. We further show that two operational drivers underlie this result: (i) the firm's option not to operate, which effectively right-censors the uncertain emissions price; and (ii) dispatch flexibility, which is the firm's ability to first deploy its most profitable capacity given the realized emissions price. In addition to these managerial insights, we also explore policy implications: the effect of emissions price level, and the effect of investment and production subsidies. Through an illustrative example, we show that production subsidies of higher investment and production cost technologies (such as carbon capture and storage technologies) have no effect on the firm's optimal total capacity when firms own a portfolio of both clean and dirty technologies, but that investment subsidies of these technologies increase the firm's total capacity, conditionally increasing expected emissions. A subsidy of a lower production cost technology, on the other hand, has no effect on the firm's optimal total capacity in multi-technology portfolios, regardless of whether the subsidy is a production or investment subsidy.", "e:keyword": ["Sustainable operations", "Technology choice", "Emissions regulation", "Clean technology subsidy"]}, {"@id": "http://dx.doi.org/10.1111/poms.12524", "e:abstract": "Online sales platforms have grown substantially in recent years. These platforms assist sellers to conduct sales, and in return, collect service fees from sellers. We study the fee policies by considering a fee-setting platform, on which a seller may conduct a sale with a reserve price to a group of potential buyers: the seller retains the object for sale if the final trading price is below the reserve price. The platform may charge two types of fees as in current practice: a reserve fee as a function of the seller's reserve price and a final value fee as a function of the sale's final trading price. We derive the optimality condition for fee policies, and show that the platform can use either just a final value fee or just a reserve fee to achieve optimality. In the former case, the optimal final value fee charged by the platform is independent of the number of buyers. In the latter case, the optimal reserve fee is often a decreasing, instead of increasing, function of the seller's reserve price. An increasing reserve fee may make the seller reluctant to use a positive reserve price and hurt the platform's revenue. In general, the optimal fees are nonlinear functions, but in reality, linear fees are commonly used because of their simplicity for implementation. We show that a linear fee policy is indeed optimal in the case that the seller's valuation follows a power distribution. In other cases, our numerical analysis suggests close-to-optimal performance of the linear policy.", "e:keyword": ["Sales platforms", "Service fees", "Revenue maximization", "Principal‐agent problems", "Auctions"]}, {"@id": "http://dx.doi.org/10.1111/poms.12525", "e:abstract": "Product design has increasingly been recognized as an important source of competitive advantage. This study empirically estimates the impact of effective design on the market value of the firm. We use a firm's receipt of a product design award as a proxy for its design effectiveness. Based on data from 264 announcements of design awards given to commercialized products between 1998 and 2011, we find that award announcements are associated with statistically significant positive stock market reactions. Depending on the benchmark model used to estimate the stock market reaction, the market reaction over a two-day period (the day of announcement and the preceding day) ranges from 0.95% to 1.02%. The market reaction is more positive for smaller firms and for firms whose award winning products are consumer goods. However, a firm's growth potential, industry competitiveness, and whether a firm is a first time or repeated award winner do not significantly affect the market reaction.", "e:keyword": ["Product design", "Design award", "Shareholder value", "Abnormal returns"]}, {"@id": "http://dx.doi.org/10.1111/poms.12528", "e:abstract": "Scheduling patients involves a trade-off between the productivity of the service provider and customer service. This study considers how outpatient medical facilities can improve their appointment scheduling by incorporating individual patient information in the scheduling process. Specifically, we obtain data on patient characteristics and examination durations from a health clinic, describe how that data can be used to predict patient examination durations in the clinic's appointment scheduling system, and evaluate the benefit of using individual patient characteristics over a conventional classification method. Computational results illustrate this method of patient scheduling reduces an overall cost function comprised of patient wait time, physician idle time, and over time by up to 24.2%, particularly when patients are sequenced with short duration patients being scheduled first. Several environmental characteristics are found to play critical roles in determining the magnitude of the benefit, including patient punctuality, no-show probability, the clinic duration, the appointment rule used for scheduling, and the ratio of the physician's idle time cost to the patient wait cost. We also detail and evaluate a practical procedure for using heterogeneous scheduling under a fixed schedule.", "e:keyword": ["Appointment scheduling", "Heterogeneous scheduling", "Health care", "Simulation"]}, {"@id": "http://dx.doi.org/10.1111/poms.12529", "e:abstract": "A criticism of behavioral health care delivery is that it has largely missed the social determinants of behavioral health disorders and their diagnosis. Toward addressing this criticism, this study evaluates the delivery of behavioral health care as a part of primary care operations. Focusing on the treatment of depression, the study results show that: (i) primary care clinics operating in communities with superior social environment characteristics are associated with improved depression outcomes in the short term, and (ii) psychosocial resources (social and emotional support) and the built environment (man-made resources and infrastructure to support human activity) of primary care clinics are associated with sustaining the improvement in depression outcome in the long term. Centering our attention on IT-enabled, evidence-based, and affordable primary care as mechanisms that can enable the integration of behavioral and medical care delivery, the results suggest that IT-enabled and evidence-based primary care are associated with improvements in depression outcomes. We also find that the effect of improving the affordability of behavioral health care delivery depends on the community's socioeconomic status. Primary care clinics in socioeconomically disadvantaged communities practicing cost-containment are associated with improvements in depression outcomes, and, therefore, can contribute toward reducing disparities in behavioral health care delivery. Counter to our original expectations, we find that the effect of evidence-based care on improvements on depression outcomes increases as the availability of medically trained behavioral health care specialists practicing in a community increases lending support to concerns that primary care clinics in resource-rich communities obtain greater benefit from quality improvement interventions.", "e:keyword": ["Health care operations management", "Socially responsible operations", "Behavioral health care", "Primary care operations"]}, {"@id": "http://dx.doi.org/10.1111/poms.12533", "e:abstract": "In the aftermath of a disaster, the relief items are transported from temporary warehouses (Staging Areas, SAs) to the Points of Distribution (PODs). Reducing the response time to provide relief items to disaster victims and cost minimization are two important objectives of this study. We propose an integrated optimization model for simultaneously determining (1) locations of staging areas, (2) inventory assignments to these SAs, (3) selecting sizes and numbers of trucks, and (4) routing of trucks from SAs to PODs. We also introduce another variable, a value function, which forces the model to reduce the logistics response time. We study the interactions among these variables through extensive sensitivity analysis. The time horizon for supply of relief items to disaster areas is usually limited to six days after the disaster occurs. Therefore, we use the proposed optimization model in a rolling-horizon manner, one day at a time. This reduces daily demand uncertainty. We analyze three disaster scenarios: (1) a low impact disaster, (2) a medium impact disaster, and (3) a high impact disaster. We conduct 720 experiments with different parameter values, and provide answers to the following questions that are useful for the logistic managers: (i) What are the right sizes (in terms of storage capacities) of SAs closer to the PODs? (ii) How should the budget be allocated in a disaster scenario? (iii) What mix of different types (in terms of sizes) of trucks should be selected in a given scenario? The most important managerial insights include: (i) operational budget beyond a limit does not improve the operational efficiency, (ii) when the budget is very low, it is essential to select smaller SAs close to the PODs in order to carry out operations in a feasible manner, (iii) when the impact of disaster is high, it is always beneficial to select larger SAs close to the PODs (as long as the budget is not very low), (iv) when the budget is high and the impact of disaster is not very high, the emergency management administrators need to select SAs prudently based on the tradeoff between the operational cost and the humanitarian value, and (v) the cost of operations is higher when all the trucks are of the same type compared to the case when there is a mix of different types of trucks. Also, we find that the optimal selection of SAs is not impacted by different combinations of the types of trucks. The focus of this study is on disasters that can be forecasted in advance and provide some lead time for preparations, for example, hurricanes. In order to understand the disaster management process of such disasters and develop our model, we (i) interviewed several emergency management administrators, and (ii) studied the disaster management processes available in documents released by various government agencies.", "e:keyword": ["Disaster", "Logistic operations", "Integer programming", "Last mile distribution", "Value function"]}, {"@id": "http://dx.doi.org/10.1111/poms.12535", "e:abstract": "Advance selling (AS) from a retailer to consumers is commonly observed in practice. With an AS capability, a retailer has the option to sell in advance or not. Having the AS option seems to increase flexibility and thus profit for a retailer. However, we show that the AS option can hurt the retailer's profit as well as supply chain performance. We identify two thresholds for a product's marginal production cost. A retailer's AS option benefits both the manufacturer and retailer when the marginal production cost is high, that is, above both thresholds. It benefits the manufacturer but hurts the retailer when the marginal production cost is moderate, that is, between the two thresholds. The result is ambiguous when the marginal production cost is low, that is, below both thresholds. We find that consumer valuation uncertainty under AS is the key driving force for the surprising result that having the retailer's AS option can hurt the retailer. When compared to the scenario where the retailer does not have the AS option, we find that the manufacturer's optimal wholesale price weakly decreases under the retailer's AS option if the marginal production cost is high. The statement is reversed if the marginal production cost is moderate or low.", "e:keyword": ["Advance selling", "Decentralized supply chain"]}, {"@id": "http://dx.doi.org/10.1111/poms.12537", "e:abstract": "We study the implementation of operations strategy at six German manufacturers in mature businesses. Search theory argues that vertical coordination (i.e., unilateral top-down adjustment of lower-level search actions) balances stability against the improvement potential enabled by frontline search and also that horizontal coordination (i.e., bilateral adjustment among lower-level search actions) is required to ensure compatibility among the initiatives generated in various organizational subunits. Much less is known about how vertical and horizontal coordination interact in operations strategy implementation—that is the focus of this study. We first study how horizontal and vertical coordination affect the compatibility and creativity of distributed search, triangulating our cross-level interviews with data on the manufacturers' productivity gains and their strategic projects. We then examine whether and how vertical and horizontal coordination interact. Our case comparisons suggest that leaving either one of them “loose” and keeping the other one “tight” results in a useful balance between compatibility and creativity; in contrast, tightening both types of coordination suppresses creativity and loosening both types risks incompatibility of initiatives across units. These results lead to a theoretical framework that identifies vertical and horizontal coordination as partial substitutes for operations strategy implementation.", "e:keyword": ["Search", "Coordination", "Operations strategy", "Frontline innovation"]}, {"@id": "http://dx.doi.org/10.1111/poms.12538", "e:abstract": "We consider the stochastic, single-machine earliness/tardiness problem (SET), with the sequence of processing of the jobs and their due-dates as decisions and the objective of minimizing the sum of the expected earliness and tardiness costs over all the jobs. In a recent paper, Baker (2014) shows the optimality of the Shortest-Variance-First (SVF) rule under the following two assumptions: (a) The processing duration of each job follows a normal distribution. (b) The earliness and tardiness cost parameters are the same for all the jobs. In this study, we consider problem SET under assumption (b). We generalize Baker's result by establishing the optimality of the SVF rule for more general distributions of the processing durations and a more general objective function. Specifically, we show that the SVF rule is optimal under the assumption of dilation ordering of the processing durations. Since convex ordering implies dilation ordering (under finite means), the SVF sequence is also optimal under convex ordering of the processing durations. We also study the effect of variability of the processing durations of the jobs on the optimal cost. An application of problem SET in surgical scheduling is discussed.", "e:keyword": ["Stochastic scheduling", "Appointment scheduling", "Smallest‐variance‐first rule", "Convex order"]}, {"@id": "http://dx.doi.org/10.1111/poms.12540", "e:abstract": "We consider subscription-based rental organizations, such as Netflix, where the satisfaction of customers depends on the availability of requested products. Recommender systems, in a DVD-rental context, are typically used to help customers in finding the right movies for them. Accordingly, the focus in recommender system research is generally on making better predictions of users' ratings. In contrast, we focus on better utilizing these rating estimates in the operations of DVD-rental firms. We show that a more explicit consideration of inventory level and future demand can help the firms better manage demand, and can increase the number of satisfied customers substantially. However, if the uncertainty regarding inventory levels is high, the performance of one of our proposed approaches may be worse than the prevalent industry practice under certain conditions. We discuss these conditions and propose a quick recipe for dealing with high levels of variation in inventory estimation. We show that when it is not possible to estimate inventory levels reliably, it is better to underestimate rather than overestimate. Other findings include the trade-off between the short-term profitability of the firms and long-term customer trust; and the effect of variation in rating estimates on the quality of our solution approaches.", "e:keyword": ["Recommendations", "DVD rentals", "Inventory"]}, {"@id": "http://dx.doi.org/10.1111/poms.12541", "e:abstract": "In many industries, original equipment manufacturers (OEMs) must obtain critical components from a few powerful suppliers. To the extent that the OEMs are also concentrated, the interactions between the suppliers of critical components and the OEMs are strategic, and have implications for how an incumbent OEM chooses its product line and interacts with potential rivals. We demonstrate that, by adding a low-end product line extension, an OEM can induce a strategic supplier to offer more favorable pricing. Moreover, depending upon the cost structure and relative performance of the product line extension, the OEM may benefit even more from the low-end line extension if it is produced by a rival instead of by itself, even if it cannot obtain any licensing income from it. Among other things, we show that this can result in a decentralized OEM accommodating competition from rivals producing product line extensions that would not be developed in a vertically integrated supply chain. In an extension, we re-examine the common assumption that the supplier unilaterally dictates a single wholesale price that is available to all downstream buyers. We demonstrate that, by committing to offer a “lowest available” wholesale price to all downstream buyers, a supplier can encourage an incumbent OEM to share its technology (or otherwise accommodate the entry of a rival) so that the supplier, the incumbent OEM, and the rival are all better off.", "e:keyword": ["Game theory", "Marketing strategy", "Competition", "Vertical differentiation", "Strategic effect"]}, {"@id": "http://dx.doi.org/10.1111/poms.12544", "e:abstract": "We consider how a firm should ration inventory to multiple classes in a stochastic demand environment with partial, class-dependent backlogging where the firm incurs a fixed setup cost when ordering from its supplier. We present an infinite-horizon, average cost criterion Markov decision problem formulation for the case with zero lead times. We provide an algorithm that determines the optimal rationing policy, and show how to find the optimal base-stock reorder policy. Numerical studies indicate that the optimal policy is similar to that given by the equivalent deterministic problem and relies on tracking both the current inventory and the rate that backorder costs are accumulating. Our study of the case of non-zero lead time shows that a heuristic combining the optimal, zero lead time policy with an allocation policy based on a single-period profit management problem is effective.", "e:keyword": ["Stochastic inventory", "Multiple class", "Rationing", "Backlogging"]}, {"@id": "http://dx.doi.org/10.1111/poms.12546", "e:abstract": "On a daily basis, thousands of employees suffer from severe occupational accidents worldwide. These accidents not only lead to negative consequences for the physical and mental health of employees, but also to high costs for companies and the society as a whole. A large share of these accidents take place in warehouses. Prior research has demonstrated the critical role of leadership, and especially safety-specific transformational leadership (SSTL), in reducing warehouse accidents. Yet several important questions concerning SSTL remain: What effects does SSTL have on outcomes other than safety, and what determines whether leaders display SSTL behaviors? To answer these questions, this research studies the relationship between SSTL of warehouse managers and not only occupational accidents, but also quality and productivity. Moreover, it investigates the managers who are most likely to display SSTL. Data from 87 warehouse managers and 1233 employees were used to test the conceptual model. The results suggest that the dispositional prevention focus of the manager (one of two possible motivational strategies that people deploy) positively relates to SSTL, and that SSTL negatively relates to occupational accidents. Furthermore, SSTL and its identified negative relationship with occupational accidents does not appear to have detrimental impact on productivity or quality. These results extend existing models of SSTL and safety, and can help companies to reduce the number of accidents and the associated costs by selecting and developing safety-specific transformational leaders.", "e:keyword": ["Warehouse accidents", "Occupational safety", "Transformational leadership", "Prevention focus", "Behavioral operations"]}, {"@id": "http://dx.doi.org/10.1111/poms.12547", "e:abstract": "A controlled field experiment investigates order picking performance in terms of productivity. We examined three manual picker-to-parts order picking methods (parallel, zone, and dynamic zone picking) under two different incentive systems (competition-based vs. cooperation-based) for pickers with different regulatory foci (prevention-focus vs. promotion-focus). The study was carried out in a warehouse erected especially for the purposes of order picking research. Our results show that when using a parallel picking method, a competition-based incentive system increases productivity compared to a cooperation-based incentive system, and that when using a zone picking method it is more productive to use a cooperation-based incentive system. This pattern of results was especially pronounced for pickers with a dominant promotion focus. Dominantly, prevention-focused pickers were more productive in zone picking with a cooperation-based incentive system than a competition-based incentive system, but in the other two picking methods the incentive systems delivered a similar productivity performance. No effects on order picking quality were identified. The analyses demonstrate that by aligning order picking methods, incentive systems, and regulatory focus, warehouses can substantially improve productivity.", "e:keyword": ["Behavioral operations", "Warehousing", "Order picking", "Incentives", "Regulatory focus"]}, {"@id": "http://dx.doi.org/10.1111/poms.12548", "e:abstract": "Sourcing from multiple suppliers with different characteristics is common in practice for various reasons. This paper studies a dynamic procurement planning problem in which the firm can replenish inventory from a fast and a slow supplier, both with uncertain capacities. The optimal policy is characterized by two reorder points, one for each supplier. Whenever the pre-order inventory level is below the reorder point, a replenishment order is issued to the corresponding supplier. Interestingly, the reorder point for the slow supplier can be higher than that of the fast even if the former has a higher cost, lower reliability, and smaller capacity than the latter, suggesting the possibility of ordering exclusively from an inferior slow supplier in the short term. Moreover, the firm may allocate a larger portion of the long-term total order quantity to the slow supplier than to the fast, even if the former does not possess any cost or reliability advantage over the latter. Such phenomena, different from the observations made in previous studies, happen when the demand is uncertain and the supply is limited or unreliable. Our observations highlight the importance of incorporating both demand uncertainty and supplier characteristics (i.e., cost, lead time, capacity and uncertainty) in a unified framework when formulating supplier selection and order allocation strategies.", "e:keyword": ["Inventory model", "Random supply capacity", "Dual supply modes", "Convexity"]}, {"@id": "http://dx.doi.org/10.1111/poms.12549", "e:abstract": "This study examines the effects of a relatively new channel structure on prices and sales in a large department store, which in recent years has switched the management of many of its product categories from a traditional retailer-managed system to a manufacturer-managed system. We find that the change caused overall retail prices to decrease. However, there was significant heterogeneity in the response across brands. In the cell phone category, brands with high market shares and inelastic demand did not change prices. In the watch category, the retail prices of relatively low-end brands decreased while the prices of premium brands increased substantially after the switch. In addition to sales increases due to lower prices, we find that the channel structure change further caused sales to increase by 9–10% in the cell phone category and by 11–17% in the watch category. These results are consistent with previous theoretical predictions. We believe that our results provide important academic and managerial implications due to the increasing prevalence of manufacturer-managed systems in the retail industry.", "e:keyword": ["Retailing", "Channel management", "Decision delegation", "Empirical study", "Marketing"]}, {"@id": "http://dx.doi.org/10.1111/poms.12550", "e:abstract": "The organization of charitable distribution channels to ensure donor contributions reach beneficiaries in an efficient manner and the use of accounting metrics of such efficiency (whether provided directly or by charity rating groups) are oft-discussed issues in the nonprofit sector. The two issues are inextricably linked since reported efficiency measures influence subsequent donor giving. This study develops a parsimonious model of a charity that must decide how best to employ its resources, either by acting as a direct service provider or as a grant provider to organizations that provide services to beneficiaries. We show that the desire to boost perceptions of efficiency vis-à-vis accounting reports leads an organization to rely more on others to provide services rather than being a direct service provider. This temptation to expand either the scope or length of the charity supply line is muted by a desire to avoid redundant costs and improve service delivery. The model's results have implications both for the role of nonprofit accounting and observed distribution strategies of nonprofits.", "e:keyword": ["Accounting", "Nonprofits", "Philanthropy", "Supply chains"]}, {"@id": "http://dx.doi.org/10.1111/poms.12551", "e:abstract": "This study investigates the value of inventory sharing in the presence of spot and forward markets. We consider a multi-period setting where two firms process a common commodity to meet stochastic demands. They can buy and sell the commodity through both the spot and forward markets. They can also share the commodity if one has leftover inventory while the other has excess demand. We first characterize the equilibrium strategies of the two firms. Our analysis reveals that in such a context, the value of inventory sharing is low when the forward price is directly used to value the sharing transactions. We then develop a structured trans-shipment price scheme that uses a linear combination of the spot and forward prices. We show that this method can substantially increase the value of inventory sharing. Our analysis also reveals that in the presence of liquid spot and forward markets, the value of inventory sharing mainly results from the difference of the transaction costs, and it increases if the market in which firms operate becomes more competitive.", "e:keyword": ["Inventory sharing", "Commodity procurement", "Transshipment price", "Competition"]}, {"@id": "http://dx.doi.org/10.1111/poms.12552", "e:abstract": "Innovation contests are increasingly adopting a format where submissions are viewable by all contestants and the information structure changes during the contest. In such an “unblind” format, contestants must weigh the costs of revealing their submissions against the benefits of improving their submissions through emerging information. We take a closer look at how contestants solve problems in innovation contests with public submission of solutions—that is, unblind contests, by examining the implications of their submission behavior for contest outcomes. We analyze the submission behavior in terms of three dimensions: the position of first submission by the contestant, the number of submissions the contestant makes, and the length of active participation by the contestant. The econometric analysis of a large dataset of unblind innovation contests and participating contestants indicates that, despite the potential for free riding and intellectual property loss from disclosure of submissions, contestants who have a lower position of first submission are more likely to succeed in the contest. Further, we find some evidence of a curvilinear relationship between a contestant's number of submissions and her likelihood of success, indicating a potential “quality–quantity” trade-off in unblind innovation contests. Finally, our findings indicate that increasing the length of participation in a contest has a positive effect on a contestant's likelihood of success. Departing from prior studies on innovation contests, where a contestant's success is assumed to be a function of her prior experience and problem-solving skills, our study provides new empirical evidence that, in innovation contests with public submissions, the submission behavior of a contestant also plays an explanatory role in a contestant's success.", "e:keyword": ["Innovation contests", "Unblind contests", "Public submissions", "Tournaments", "Crowdsourcing"]}, {"@id": "http://dx.doi.org/10.1111/poms.12553", "e:abstract": "We study a joint capacity leasing and demand acceptance problem in intermodal transportation. The model features multiple sources of evolving supply and demand, and endogenizes the interplay of three levers—forecasting, leasing, and demand acceptance. We characterize the optimal policy, and show how dynamic forecasting coordinates leasing and acceptance. We find (i) the value of dynamic forecasting depends critically on scarcity, stochasticity, and volatility; (ii) traditional mean-value equivalence approach performs poorly in volatile intermodal context; (iii) mean-value-based forecast may outperform stationary distribution-based forecast. Our work enriches revenue management models and applications. It advances our understanding on when and how to use dynamic forecasting in intermodal revenue management.", "e:keyword": ["Revenue management", "Forecasting", "Leasing", "Stochastic comparison", "Dynamic programming"]}, {"@id": "http://dx.doi.org/10.1111/poms.12554", "e:abstract": "We discuss the optimal raw material acquisition strategy for a third party remanufacturer (3PR). We specifically investigate whether a 3PR should acquire used products or cores in bulk with uncertain quality levels, or in sorted grades with known quality levels; and whether to acquire and remanufacture cores before the demand is realized (planned acquisition), or after the demand is realized (reactive acquisition), or on both occasions (sequential acquisition). When only sorted cores are acquired, we find that, (i) it is optimal to acquire cores in multiple grades to balance acquisition and remanufacturing costs; (ii) if reactive acquisition is possible, it reduces the assortment size (number of grades in which cores are acquired) and the total inventory acquired in the planned acquisition; and (iii) the optimal portfolio of grades to acquire and the optimal acquisition and remanufacturing quantities of these grades can be determined analytically. When bulk cores are acquired in addition to sorted cores, the property of reduction in assortment size of the planned acquisition is preserved. We also show that the 3PR should acquire only a fraction of the demand in planned acquisition, and leave the rest for reactive acquisition. This fraction changes during the lifecycle of a remanufactured product. Using a combination of empirical and realistic data from a smartphone remanufacturer we show that sequential acquisition increases expected profit by up to 8% and 27% over only planned and only reactive acquisitions respectively, and reduces the inventory acquired by up to 21% over only planned acquisition.", "e:keyword": ["Third party remanufacturing", "Closed‐loop supply chains", "Product acquisition management", "Product lifecycle"]}, {"@id": "http://dx.doi.org/10.1111/poms.12556", "e:abstract": "We consider multitier push assembly systems with sequential supplier decisions and a wholesale price contract. We show that both an Original Equipment Manufacturer (OEM)–Contract Manufacturer (CM) assembly and a modular assembly with sequential supplier decisions are mathematically equivalent to the corresponding traditional assembly. We determine that, in most cases, the first mover supplier realizes a higher profit than the second mover supplier but we also identify the sufficient conditions for the reverse to occur. We provide conditions under which the order quantity, the second mover profit, total supplier profits, and the assembler profit are either higher or lower for a multitier system with sequential suppliers compared to simultaneous suppliers. We conclude that the first mover is always better off in a three-tier sequential system while she can be either better off or worse off in a four-tier sequential system compared to the corresponding simultaneous systems. We also analyze the impact of information asymmetry on the supplier and assembler profits in a three-tier sequential system. Finally, we determine the profit threshold for an independent manufacturer in a three-tier system to become a CM in a four-tier system and vice versa.", "e:keyword": ["Push assembly systems", "Sequential supplier decisions", "Asymmetric information"]}, {"@id": "http://dx.doi.org/10.1111/poms.12558", "e:abstract": "This article seeks to encourage scholars to conduct research that is more relevant to the decisions faced by managers and policymakers, and addresses why research relevance matters, what relevance means in terms of a journal article, and how scholars can increase the relevance of their research. I define relevant research papers as those whose research questions address problems found (or potentially found) in practice and whose hypotheses connect independent variables within the control of practitioners to outcomes they care about using logic they view as feasible. I provide several suggestions for how scholars can enhance research relevance, including engaging practitioners in on-campus encounters, at managerial conferences, and at crossover workshops; conducting site visits and practitioner interviews; working as a practitioner; and developing a practitioner advisory team. I describe several ways that scholars can convey relevant research insights into practitioners, including presenting at practitioner conferences, writing for practitioners in traditional crossover journals and in shorter pieces like op-eds and blogs, and attracting the interest of those who write columns, blogs, and articles about research for practitioners. I conclude by describing a few ways that academic institutions can encourage more relevant research, focusing on journals, professional societies, and doctoral programs.", "e:keyword": ["Research questions", "Relevance", "Rigor", "Communication", "Practice‐based research"]}, {"@id": "http://dx.doi.org/10.1111/poms.12559", "e:abstract": "In consulting, finance, and other service industries, customers represent a revenue stream, and must be acquired and retained over time. In this paper, we study the resource allocation problem of a profit maximizing service firm that dynamically allocates its resources toward acquiring new clients and retaining unsatisfied existing ones. The interaction between acquisition and retention in our model is reflected in the cash constraint on total expected spending on acquisition and retention in each period. We formulate this problem as a dynamic program in which the firm makes decisions in both acquisition and retention after observing the current size of its customer base and receiving information about customers in danger of attrition, and we characterize the structure of the optimal acquisition and retention strategy. We show that when the firm's customer base size is relatively low, the firm should spend heavily on acquisition and try to retain every unhappy customer. However, as its customer base grows, the firm should gradually shift its emphasis from acquisition to retention, and it should also aim to strike a balance between acquisition and retention while spending its available resources. Finally, when the customer base is large enough, it may be optimal for the firm to begin spending less in both acquisition and retention. We also extend our analysis to situations where acquisition or retention success rate, as a function of resources allocation, is uncertain and show that the optimal acquisition and retention policy can be surprisingly complex. However, we develop an effective heuristic for that case. This paper aims to provide service managers some analytical principles and effective guidelines on resource allocation between these two significant activities based on their firm's customer base size.", "e:keyword": ["Dynamic Programming", "Service Operations", "OM‐Marketing Interface"]}, {"@id": "http://dx.doi.org/10.1111/poms.12560", "e:abstract": "We examine the link between network neutrality (NN) and content innovation on the Internet by comparing the impact of NN and packet discrimination (PD) regimes on content innovation. We do this in the context of a two-sided market model that simultaneously considers content provider (CP) and consumer decisions concerning market entry and participation while taking into account consumers’ response to network congestion. We find that content innovation flourishes under NN to a greater degree than under PD due to two effects we uncover: the generation of what we call a pro bono innovation zone in which CPs are able to enter the market without contributing to network provider profits; and the cross-side congestion effect, a negative network externality wherein higher broadband market coverage levels result in greater congestion for CPs, and increased content results in greater congestion for consumers, taking into account consumers’ strategic response to network congestion. These results have important implications for current public policy debates regarding the Federal Communications Commission's Open Internet Rules.", "e:keyword": ["Network neutrality", "Paid prioritization", "Content innovation", "Broadband coverage", "Social welfare"]}, {"@id": "http://dx.doi.org/10.1111/poms.12561", "e:abstract": "Managers at all stages of a supply chain are concerned about meeting profit targets. We study contract design for a buyer–supplier supply chain, with each party maximizing expected profit subject to a chance constraint on meeting his respective profit target. We derive the optimal contract form (across all contract types) with randomized and deterministic payments. The best contract has the property that, if the chance constraints are binding, at most one party fails to satisfy his profit target for any given demand realization. This implies that “least risk sharing,”that is, minimizing the probability of outcomes for which both parties fail to achieve their profit targets, is optimal, contrary to the usual expectations of “risk sharing.” We show that an optimal contract can possess only two of the following three properties simultaneously: (i) supply chain coordination, (ii) truth-telling, and (iii) non-randomized payments. We discuss methods to mitigate the consequent implementation challenges. We also derive the optimal contract form when chance constraints are incorporated into several simpler and easier-to-implement contracts. From a numerical study, we find that an incremental returns contract (in which the marginal rebate rate depends on the return quantity) performs quite well across a relatively broad range of conditions.", "e:keyword": ["Supply contract", "Earnings target", "Risk‐sharing", "Chance constraints"]}, {"@id": "http://dx.doi.org/10.1111/poms.12562", "e:abstract": "Operations Management (OM) research on organizational culture has to change to be able to inform practice. Currently, organizational culture research in OM is largely confined to narrow topical and methodological niches and culture is most frequently used as an explanatory variable in quantitative, survey-based research. We argue that the relegation of culture to this niche is due to self-imposed methodological blinders that hobble the OM field. We then present four research imperatives to reinvigorate organizational culture research within our field. We urge OM scholars to view culture as a dynamic concept that can be influenced, to adopt alternative methods, to use non-traditional data sources, and to rethink assumptions about dependent variables. We also identify gaps in the current knowledge and new research questions for the OM domain. We conclude that the field of OM could greatly expand its understanding of organizational culture and in so doing greatly improve business practice, but that to do so will require a change in the culture of the operations management research community.", "e:keyword": ["Organizational culture", "Research methods", "Ethnography"]}, {"@id": "http://dx.doi.org/10.1111/poms.12566", "e:abstract": "This paper studies the optimal component procurement strategies of two competing OEMs selling substitutable products. The OEMs outsource their production to a common contract manufacturer, who in turn needs an input from a component supplier. Each OEM may either directly procure the input from the component supplier, or delegate the procurement task to the contract manufacturer. We first analyze the OEMs' procurement game under a non-strategic supplier whose component price is exogenously given. It is found that symmetric equilibria arise for most situations, that is, both OEMs either control or delegate their component procurement in equilibrium. Interestingly, despite the commonly-held belief that the contract manufacturer would be worse off as OEMs gain component procurement control, we show that the contract manufacturer may enjoy a higher profit. Then we study the OEMs' procurement game under a strategic supplier who can set its component price. We find that the supplier's strategic pricing behavior plays a critical role in the equilibrium procurement structure. In particular, in the equilibrium under strategic supplier, the larger OEM always uses delegation while the smaller OEM may use either delegation or control. By identifying the driving forces behind the OEMs' procurement choices, this research helps explain observed industry practices and offer useful guidelines for firms' component sourcing decisions.", "e:keyword": ["Procurement", "Delegation", "Contract manufacturing", "Supply chain"]}, {"@id": "http://dx.doi.org/10.1111/poms.12567", "e:abstract": "In Online Movie Rental Systems, customer desire to rent can often be observed before the actual consumption occurs. Desire represents uncensored (or true) demand information. Hence, the impact of inventory decisions (numbers of physical copies of different movies) can be accurately traced to the creation of desire (via Word-of-mouth), and then to rental. Word-of-Mouth (WOM) has been recognized as one of the most influential sources of information transmission, especially for experience goods. Poor inventory decisions may result in lost rentals in two ways: One is the loss of rentals because of low inventory (direct effect), and the other is the loss of the possible demand (rentals) that could have been created through WOM (indirect effect). We use data from an online DVD-by-mail firm to estimate the direct and indirect effects of inventory decisions, considering the circular relationship: Rental generates WOM, WOM creates Desire, and Desire turns into Rental. We find that the magnitude of indirect effects is significant, comparable to and sometimes even exceeding direct effects. The value of the empirical findings to facilitate better inventory allocation decisions is examined.", "e:keyword": ["Online DVD rental", "Inventory allocation", "Word‐of‐mouth"]}, {"@id": "http://dx.doi.org/10.1111/poms.12573", "e:abstract": "Stockpiling inventory is an essential strategy for building supply chain resilience. It enables firms to continue operating while finding a solution to an unexpected event that causes a supply disruption or demand surge. While extremely valuable when actually deployed, stockpiles incur large holding costs and usually provide no benefits until such a time. To help to reduce this cost, this study presents a new approach for managing stockpiles. We show that if leveraged intelligently, stockpiles can also help an organization better meet its own regular demand by enabling a type of virtual pooling we call virtual stockpile pooling (VSP). The idea of VSP is to first integrate the stockpile into several locations’ regular inventory buffers and then dynamically reallocate the stockpile among these locations in reaction to the demand realizations to achieve a kind of virtual transshipment. To study how to execute VSP and determine when it can provide the most value, we formulate a stylized multi-location stochastic inventory model and solve for the optimal stockpile allocation and inventory order policies. We show that VSP can provide significant cost savings: in some cases nearly the full holding cost of the stockpile (i.e., VSP effectively maintains the stockpile for free), in other cases nearly the savings of traditional physical inventory pooling. Last, our results prescribe implementing VSP with many locations for large stockpiles, but only a few locations for small stockpiles.", "e:keyword": ["Supply chain disruption risk management", "Demand surge", "Mutli‐location inventory model", "Inventory pooling", "Transshipment"]}, {"@id": "http://dx.doi.org/10.1111/poms.12575", "e:abstract": "The flow of jobs within a system is an important operating characteristic that influences system performance. While the majority of previous studies on manufacturing performance consider product flows only as an implicit parameter of the design, we introduce an explicit measure of flow dominance based on entropy and test its efficacy in predicting the performance of manufacturing systems. In computing entropy flow dominance (EFD), we aggregate information embedded in the routings of all products within a system into a single measure. EFD is designed to indicate on a 0–1 scale the level of flow dominance, where 1 represents a pure flow shop and 0 represents a pure job shop. The result is a simple measure that provides managers a way to explain and predict complex phenomena. Our experimental results indicate that EFD is a statistically significant determinant of manufacturing system performance. Furthermore, the model including EFD as an independent variable accurately predicts manufacturing system performance as measured by job flow time, flow time standard deviation, and work in process. We note that the same results can also apply to service systems, such as the “back-room” low-contact type systems, that have similar characteristics as manufacturing systems.", "e:keyword": ["Manufacturing performance", "Entropy", "Flow dominance", "Simulation", "Predictive model"]}, {"@id": "http://dx.doi.org/10.1111/poms.12576", "e:abstract": "Electronic reverse auctions are a commonly used procurement mechanism. Research to date has focused on suppliers who are ex ante symmetric in that their costs are drawn from a common distribution. However, in many cases, a seller's range of potential costs depends on their own operations, location, or economies of scale and scope. Thus, understanding how different bidder types impact auction outcomes is key when designing an auction. This study reports the results of the first controlled laboratory experiment designed to compare prices between first-price and second-price procurement auctions for homogeneous goods when seller cost types are asymmetric and the number of bidders varies. The results indicate that first-price auctions generate lower prices regardless of market composition. The results also reveal that first-price auctions are at least weakly more efficient than second-price auctions despite the theoretical prediction that the reverse should hold in asymmetric auctions. Post hoc analysis of individual bidders' behavior in first-price auctions revealed evidence that bidders systematically underbid when their cost realizations were close to the lower bound. Furthermore, bidders adjust their behavior based on the type of the other bidders in the market in a manner inconsistent with theory. Consequently, adding a third bidder to a two-bidder market is not advantageous to the buyer unless that third bidder is a low-cost type.", "e:keyword": ["Procurement", "Reverse auction", "Asymmetric auctions", "Laboratory experiment"]}, {"@id": "http://dx.doi.org/10.1111/poms.12578", "e:abstract": "“Gray markets” are unauthorized channels that distribute a branded product without the manufacturer's permission. Since gray markets are not officially sanctioned by the manufacturer, their existence is assumed to hurt the manufacturer. Yet manufacturers sometimes tolerate or even encourage gray market activities. We investigate the incentives of a manufacturer and its authorized retailer to engage in (or tolerate) gray markets. The firms need to consider the trade-off between the positive effects of a gray market (price discrimination and cost savings) and the negative effects (cannibalization of sales and a loss in consumer valuation). Generally, gray markets can be categorized into two types: (i) a “local gray market,” where a retailer diverts products to unauthorized sellers operating in the same region as the retailer; and, (ii) “bootlegging,” where the retailer diverts products to unauthorized sellers in another market where the manufacturer sells through a direct channel. We characterize the equilibrium in each type of gray market and identify conditions under which the retailer will divert products to the gray market. Incentive problems are more complicated when the retailer bootlegs and, in this case, we show that conflicting incentives may lead to the emergence of a gray market where both the manufacturer's and retailer's profits decrease.", "e:keyword": ["Gray market", "Bootlegging", "Decentralized supply chain", "Retailer incentives"]}, {"@id": "http://dx.doi.org/10.1111/poms.12579", "e:abstract": "This paper studies a stochastic model of optimal stopping processes, which arise frequently in operational problems (e.g., when a manager needs to determine an optimal epoch to stop a process). For such problems, we propose an effective method of characterizing the structure of the optimal stopping policy for the class of discrete-time optimal stopping problems. Using this method, we also derive a set of metatheorems that can help identify when a threshold or control-band type stopping policy is optimal. We show that our proposed method can determine the structure of the optimal policy for some stopping problems that conventional methods fail to do so. In some cases, our method also simplifies the analysis of some existing results. Moreover, the metatheorems we propose help identify sufficient conditions that yield simple optimal policies when such policies are not generally optimal. We demonstrate these benefits by applying our method to several optimal stopping problems frequently encountered in, for example, the operations, marketing, finance, and economics literatures. We note that with structural results, optimal-stopping policies are easier to follow, describe, and compute and hence implement. They also help determine how a stopping policy should be adjusted in response to changes in the operational environment. In addition, as structural results are critical for the development of efficient algorithms to solve optimal stopping problems numerically, we hope that the method and results provided in the study will contribute to that effort.", "e:keyword": ["Optimal stopping", "Process design", "Benefit function", "Structure of optimal policy", "Threshold policy", "Control‐band policy"]}, {"@id": "http://dx.doi.org/10.1111/poms.12580", "e:abstract": "It is conventional wisdom that a manufacturer's encroachment into retail space will likely hurt an existing retailer. In contrast to this conventional belief, current research indicates that a retailer may welcome a manufacturer's encroachment despite the new competition in the final market. The encroachment may help the manufacturer have some “skin in the game” at the retail level, which will cause the manufacturer to make a selfish cost-reducing investment that spills over to the retailer as a lower wholesale price. Such a spillover effect enhances the retailer's profit as long as the encroachment does not result in extreme retail competition by a certain degree of product differentiation, and ultimately generates Pareto gains in the supply chain. The spillover effect is so robust that the retailer's benefit from the encroachment remains even after considering potential mitigating factors such as selling costs, a nonlinear form of cost reduction, decentralized encroachment, additional retail competition, price competition, and a negotiation between the manufacturer and the retailer.", "e:keyword": ["Encroachment", "Investments", "Spillover effects", "Dual channels"]}, {"@id": "http://dx.doi.org/10.1111/poms.12581", "e:abstract": "We consider a revenue management problem involving a two compartment aircraft flying a single leg, with no cancellations or over-booking. We apply the practice of transforming a choice revenue management model into an independent demand model. Within this assumed independent model, there are two sets of demands, business and economy, each with multiple fare class products. A business passenger can only be accepted into business. An economy passenger can be accepted into economy or upgraded into business. We define a two-dimensional dynamic program (DP) and show that the value function is sub-modular and concave in seat availability in the two compartments. Thus the bid prices are non-decreasing with respect to these state variables. We use this result to propose an exact algorithm to solve the DP. Our numerical investigation suggests that in contrast to standard backward induction, our method could be included in production revenue management systems. Further, when the economy compartment is capacity constrained, we observe a substantial monetary benefit from optimal dynamic upgrading compared to the static upgrading procedures currently used in practice.", "e:keyword": ["Capacity sharing", "Dynamic upgrade", "Revenue management", "Dynamic programming", "Exact methods"]}, {"@id": "http://dx.doi.org/10.1111/poms.12584", "e:abstract": "We consider scheduling issues at Beyçelik, a Turkish automotive stamping company that uses presses to give shape to metal sheets in order to produce auto parts. The problem concerns the minimization of the total completion time of job orders (i.e., makespan) during a planning horizon. This problem may be classified as a combined generalized flowshop and flexible flowshop problem with special characteristics. We show that the Stamping Scheduling Problem is NP-Hard. We develop an integer programming-based method to build realistic and usable schedules. Our results show that the proposed method is able to find higher quality schedules (i.e., shorter makespan values) than both the company's current process and a model from the literature. However, the proposed method has a relatively long run time, which is not practical for the company in situations when a (new) schedule is needed quickly (e.g., when there is a machine breakdown or a rush order). To improve the solution time, we develop a second method that is inspired by decomposition. We show that the second method provides higher-quality solutions—and in most cases optimal solutions—in a shorter time. We compare the performance of all three methods with the company's schedules. The second method finds a solution in minutes compared to Beyçelik's current process, which takes 28 hours. Further, the makespan values of the second method are about 6.1% shorter than the company's schedules. We estimate that the company can save over €187,000 annually by using the second method. We believe that the models and methods developed in this study can be used in similar companies and industries.", "e:keyword": ["Stamping scheduling", "Machine scheduling", "Flowshop scheduling", "Integer programming", "Decomposition"]}, {"@id": "http://dx.doi.org/10.1111/poms.12585", "e:abstract": "Downstream firms increasingly recognize the importance of integrating social and environmental concerns with their businesses. As a consequence, they urge to create incentives for their suppliers to invest in corporate social responsibility (CSR) activities. Contracts to provide these incentives are rarely observed in practice. If not totally absent, contracts may be incomplete, in that unforeseen contingencies or some CSR attributes that are difficult to measure may not be included in the contract. We show that incentives for CSR investments can also be provided through the supply chain structure, which consists of the distribution of ownership rights over the firms' assets of production, and involves horizontal and/or vertical alliances among supply chain members. Motivated by examples in agricultural contexts, this study adopts the property rights approach to study the impact of supply chain structures on the adoption of CSR activities. We show that the structure that best incentivizes CSR investments depends on the interaction between CSR vertical synergy, free-riding, and countervailing power. One of the main findings is that the alliance between suppliers is beneficial only if the revenues generated by a downstream investment are sufficiently high. In fact, only in this case, the suppliers can appropriate a sufficiently large stake of the revenues generated downstream, thanks to their countervailing power. When the upstream investment costs become high, however, the suppliers will invest in CSR only if the downstream distributor is vertically integrated. The resulting structure of a cooperative will best incentivize CSR investments only if the CSR vertical synergy between the two tiers of the supply chain is sufficiently high.", "e:keyword": ["Corporate social responsibility", "Supply chain structure", "Incomplete contracting", "Property rights", "Shapley value"]}, {"@id": "http://dx.doi.org/10.1111/poms.12586", "e:abstract": "Firms producing complementary goods often strategically form groups and jointly sell their products to better coordinate their decisions. For consumer durables, decisions about such collaboration might be complicated due to two factors. Because of their durability and presence of used goods markets, such products engender “future” price competition between new and used goods. On the other hand, consumers of such products might be forward-looking and patient, both of which affect their purchasing behavior. In this study, we study how the above product and consumer characteristics interact to affect the group selling decisions of complementary firms. We do so through a two-period model consisting of a value chain with two upstream manufacturers and a downstream retailer. When consumers are relatively impatient and reluctant to wait to buy later, group selling by manufacturers will take place only when the end product is relatively perishable, that is, product durability is low. However, if consumers are patient, that is, willing to wait, collaboration happens only when the end product is quite durable; for relatively perishable products the manufacturers sell their products separately. We also comment on how our results are affected by factors like manufacturers directly selling to end consumers or there being multiple opportunities to decide whether or not to use group selling strategy.", "e:keyword": ["Group selling", "Complementary firms", "Durable products", "Customer patience"]}, {"@id": "http://dx.doi.org/10.1111/poms.12588", "e:abstract": "Delivery time differentiation is a supply chain concept that has been implemented in various industries, but not yet in the automotive industry. One reason is that the effects of delivery time differentiation on the supply chain are not well understood. The BMW Group, for instance, has considered offering an express order option, where express orders bypass standard orders in the supply chain processes to achieve short delivery times. Express orders distort planning processes, increase operations cost, and increase the delivery times of standard orders, however the effects have not been quantified yet. This study analyzes the impact of express orders on the supply chain, when express orders are built-to-order. To understand the supply chain consequences of express orders better, we analyzed the relevant supply chain processes at BMW Group. We determine the effect that built-to-order express orders have on delivery times and on component demand. To analyze the effect of introducing express orders on expected delivery times and expected cost, we use queuing theory and derive expressions for the transient behavior of a discrete time batch queue. Our analyses indicate that many supply chain processes are only marginally affected. However, the orders to the suppliers become considerably more uncertain, which must be compensated by additional safety stock. Our results indicate that express orders can be an attractive option for BMW and other automotive companies. If the fraction of express orders stays at a reasonable level, express orders can be delivered within about two weeks.", "e:keyword": ["Delivery time differentiation", "Discrete time batch queue", "Automotive industry", "Built‐to‐order"]}, {"@id": "http://dx.doi.org/10.1111/poms.12590", "e:abstract": "During the last 25 years, the ecosystem of knowledge creation and dissemination in operations and supply chain management has improved remarkably. We now see OM as a vibrant community and an ecosystem in steady state. Yet, there are many opportunities ahead to revitalize our field and to expand our influence. In the spirit of continuous improvement, we propose that we focus our major efforts on accelerating the following four developments: First, having greatly expanded the domain of operations management, we should continue to expand its boundaries. Second, after a visible increase in exploratory studies, our community should accelerate our pursuit of such research. Third, we encourage OM faculty to develop programs that enable Ph.D. students to carry out part of their work in actual organizational settings. Fourth, we should further strengthen our interactions with the business community and create mechanisms to systematically disseminate our research to its members.", "e:keyword": ["Operations management", "OM ecosystem", "Change management", "Research", "Research in business"]}, {"@id": "http://dx.doi.org/10.1111/poms.12591", "e:abstract": "We have reviewed disaster management research papers published in major operations management, management science, operations research, supply chain management and transportation/logistics journals. In reviewing these studies, our objective is to assess and present the macro level “architectural blue print” of disaster management research with the hope that it will attract new researchers and motivate established researchers to contribute to this important field. The secondary objective is to bring this disaster research to the attention of disaster administrators so that disasters are managed more efficiently and more effectively. We have mapped the disaster management research on the following five attributes of a disaster: (1) Disaster Management Function (decision-making process, prevention and mitigation, evacuation, humanitarian logistics, casualty management, and recovery and restoration), (2) Time of Disaster (before, during and after), (3) Type of Disaster (accidents, earthquakes, floods, hurricanes, landslides, terrorism and wildfires etc.), (4) Data Type (Field and Archival data, Real data and Hypothetical data), and (5) Data Analysis Technique (bidding models, decision analysis, expert systems, fuzzy system analysis, game theory, heuristics, mathematical programming, network flow models, queueing theory, simulation and statistical analysis). We have done cross tabulations of data among these five parameters to gain greater insights into disaster research. Recommendations for future research are provided.", "e:keyword": ["Disaster management", "Humanitarian logistics", "Supply chains", "Prevention and mitigation", "Evacuation", "Casualties", "Recovery", "Restoration", "Federal Emergency Management Agency"]}, {"@id": "http://dx.doi.org/10.1111/poms.12594", "e:abstract": "In this study, we consider the issue of preannouncing or not preannouncing the development of a new product. Our research is motivated by contrasting views in the literature and varying actions observed in practice. We develop and analyze a game theoretic model that examines the effect of a firm's preannouncement of its product development. Our model is based on a durable goods duopoly market with profit-maximizing firms. The first firm is an innovator who initially begins developing the product; the second firm is an imitator that begins developing a competing product as soon as it becomes aware of the innovator's product. We assume that consumers are rationally expectant and purchase at most one unit of the product when they have maximum positive utility surplus that is determined by the characteristics of the product, the consumer's marginal utility, and the consumer's discounted utility for future expected products. The innovator firm can release information about its product when it begins developing the product or can guard information about its product until it introduces the product into the market. Our analysis and numerical tests show that, under some conditions, the innovator firm can benefit by preannouncing its product and giving the imitator firm additional time to differentiate its product. We discuss these conditions and their implications for new product development efforts.", "e:keyword": ["New product development", "Product design", "New product introduction"]}, {"@id": "http://dx.doi.org/10.1111/poms.12596", "e:abstract": "We examine the relationship between Operational Productivity (OP), Corporate Social Performance (CSP), Financial Performance (FP), and risk. Our sample frame comprises 476 firms in nine US manufacturing industries during the period 1999–2009. We employ DEA-based measures for OP and CSP, two operationalizations for FP to reflect current profitability and market value, and two operationalizations for risk to reflect bankruptcy risk and stock price volatility. We confirm that OP is essential for good financial performance and reduced risk (as expected), but the main effects of CSP are mixed. Importantly, we find that OP moderates the CSP–FP and CSP–risk relationships. Specifically, if OP is poor, CSP is of limited benefit to FP or risk. However, at or above a threshold level of OP, firms can use CSP to build upon it to yield further improvements in FP and reductions in risk. We discuss the implications of our findings for theory and practice.", "e:keyword": ["Productivity", "Corporate social performance", "Operations strategy", "Financial performance", "Financial risk"]}, {"@id": "http://dx.doi.org/10.1111/poms.12597", "e:abstract": "In industries where firms perform dangerous (but necessary) operations, liability costs—due to potential harm to third parties—can be significant. Firms may therefore find it optimal to exit the market, and this may lead to an inefficiently low number of incumbents. A social planner can discourage exit by offering appropriately designed subsidies. Ex ante subsidies defray the costs associated with making operations safer (e.g., funds to subsidize the purchase of safety equipment). Ex post subsidies mitigate the financial damages caused by an accident (e.g., funds to defray the cost of cleaning up a toxic spill). We consider a model where (i) firms have private information about their ability to improve reliability and (ii) reliability investments are unobservable. We demonstrate that when the social value of reliability outweighs the benefit of increased competition, it is optimal to offer ex ante subsidies alone (i.e., to subsidize the cost of making operations safer). Conversely, when the benefits of competition outweigh the benefits of reliability, a combination of ex ante and ex post subsidies is optimal (i.e., not only to subsidize safer operations, but also to share the costs of a potential accident).", "e:keyword": ["Public policy", "Risk management", "Subsidies", "Tort liability", "Firm exit"]}, {"@id": "http://dx.doi.org/10.1111/poms.12607", "e:abstract": "We investigate retailers’ dynamic pricing decisions in a stylized two-period setting with possible supply constraints and demand from both myopic and strategic consumers. We present an analytical model and then test its predictions in a behavioral experiment in which human subjects played the role of pricing managers. We find that the fraction of strategic consumers in the market systematically moderates the optimal pricing structure. When this fraction exceeds a certain threshold, the retailer offers relatively small late season markdowns to discourage strategic consumers from waiting and to incentivize them to buy during the early season; otherwise, the retailer offers relatively large markdowns to divert all strategic consumers to the late season, where the majority of revenue is made. Our model analyses suggest that the latter policy is optimal under fairly broad conditions. Our experiment shows that after some significant learning, aggregate behavior is able to approximate the key qualitative predictions from our model analysis, with one notable deviation: in the presence of a mixture of myopic and strategic consumers, subjects act somewhat myopically – they underprice and oversell in the main selling season, which significantly limits their ability to generate revenue in the markdown season.", "e:keyword": ["Dynamic pricing", "Inventory scarcity", "Myopic consumers", "Strategic consumers"]}, {"@id": "http://dx.doi.org/10.1111/poms.12608", "e:abstract": "We consider a dynamic pricing problem that involves selling a given inventory of a single product over a short, two-period selling season. There is insufficient time to replenish inventory during this season, hence sales are made entirely from inventory. The demand for the product is a stochastic, nonincreasing function of price. We assume interval uncertainty for demand, that is, knowledge of upper and lower bounds but not a probability distribution, with no correlation between the two periods. We minimize the maximum total regret over the two periods that results from the pricing decisions. We consider a dynamic model where the decision maker chooses the price for each period contingent on the remaining inventory at the beginning of the period, and a static model where the decision maker chooses the prices for both periods at the beginning of the first period. Both models can be solved by a polynomial time algorithm that solves systems of linear inequalities. Our computational study demonstrates that the prices generated by both our models are insensitive to errors in estimating the demand intervals. Our dynamic model outperforms our static model and two classical approaches that do not use demand probability distributions, when evaluated by maximum regret, average relative regret, variability, and risk measures. Further, our dynamic model generates a total expected revenue which closely approximates that of a maximum expected revenue approach which requires demand probability distributions.", "e:keyword": ["Dynamic pricing", "Interval uncertainty", "Minimax regret", "Linear programming"]}, {"@id": "http://dx.doi.org/10.1111/poms.12609", "e:abstract": "Notwithstanding the popularity of outsourcing as a business strategy, the performance benefits realized through outsourcing efforts are observed to be mixed in practice. This leads to important unresolved questions regarding why some firms are able to derive substantial value from their outsourcing initiatives while other firms are left disappointed. This study joins an emerging literature integrating transaction cost economics and capabilities-based perspectives to develop a deeper understanding of the drivers of outsourcing performance. I develop a theoretical model that examines the independent and joint influence of governance misalignment (i.e., deviation from transaction cost's predicted mode of governance) and a firm's outsourcing capability on the performance of outsourced processes. I test the theoretical model using a dataset of 172 outsourced and 156 in-house processes. The finding that governance misalignment corresponds to inferior process performance supports transaction cost's discriminating alignment hypothesis. Interestingly, I also find that a retained technical expertise (TE) and outsourcing knowledge management routines (OKMR; both contributors to a firm's outsourcing capability) positively influence outsourcing performance both directly and via their relationship with governance misalignment. While a retained technical expertise and outsourcing knowledge management routines each positively influence outsourcing performance, they do so in distinctive ways. These findings have important managerial implications and make a significant theoretical contribution. Specifically, this study demonstrates that the notion of a governance misalignment is firm-specific, conditional on the governance capabilities of the organization. This insight underscores the value of integrating transaction cost logic with capabilities-based perspectives.", "e:keyword": ["Outsourcing", "Transaction cost economics", "Capabilities‐based view"]}, {"@id": "http://dx.doi.org/10.1111/poms.12613", "e:abstract": "In many innovation settings, ideas are generated over time and managers face a decision about if and how to provide in-process feedback to the idea generators about the quality of submissions. In this article, we use design contests allowing repeated entry to examine the effect of in-process feedback on idea generation. We report on a set of field experiments using two online contest websites to compare the performance of three different feedback treatments—no feedback, random feedback, and directed feedback (i.e., in-process feedback highly correlated with the final quality rating of the entry). We posted six logo design contests for consumer products and accepted submissions for 1 week. We provided daily feedback during the contest period using one of the three treatments. We then used a panel of target consumers to rate the quality of each idea. We find that directed feedback is associated positively with agent participation. For outcome, while directed feedback benefits the average quality of entries submitted, we don't find that relationship for the best entries—indeed, no feedback or random feedback may produce better top-end entry quality. We also find that, under directed feedback, the variance in quality declines as the contest progresses.", "e:keyword": ["Innovation", "Contest", "Crowdsourcing", "Creativity", "Feedback"]}, {"@id": "http://dx.doi.org/10.1111/poms.12627", "e:abstract": "In recent years, instances of organizations failing to maintain digital confidentiality performance have greatly increased in frequency and monetary damage. While the global sourcing of activities in the development of digital assets is widespread, very little is known about how location-related factors may affect confidentiality outcomes. Addressing this, we empirically investigate two factors with rich theoretical bases and logical linkages to confidentiality: industrial agglomeration and national property rights protections. We conduct a large-scale, empirical study at the product level of analysis, and treat the confidentiality of a digital product as a performance outcome that is affected by the locations of the two key organizational entities involved in the product's development. We leverage modern, web-crawling methods to harvest secondary data from a major, illicit distribution channel for these products and combine these data with other secondary data involving legitimate commerce to derive a secondary measure of confidentiality performance. We find robust results, and demonstrate practical significance of our findings through scenario analyses based on actual data from our sample.", "e:keyword": ["Clusters", "Video game industry", "Digital economy", "New product development", "Global sourcing", "Intellectual property"]}, {"@id": "http://dx.doi.org/10.1111/poms.12628", "e:abstract": "Recent research indicates that consumers hold significant concerns about the quality of remanufactured products. To better understand this phenomenon, this manuscript combines surveys and experimental studies to identify the antecedents of perceived quality—in the form of perceived risk of functionality and cosmetic defects—and their significant impact on consumers' willingness to pay (wtp) for remanufactured electronics products. The study also controls for alternative explanations for wtp suggested in the literature, such as consumers' wtp for new products, environmental beliefs, disgust aversion toward used products, brand perceptions, risk aversion, and various demographic traits. Importantly, the study empirically estimates the magnitude and distribution of discount factors for remanufactured electronics products—the ratio between wtp for a remanufactured product and wtp for a corresponding new product—among consumers. Finally, the manuscript analytically compares a monopolist's decision to include remanufactured products in its portfolio under both the empirically derived discount factor distributions and the classical linear demand model, which assumes constant discount factors. Interestingly, the classical linear demand model remains reasonably robust for high-level insights, such as the presence of cannibalization and market expansion effects. However, the analytical model that uses the empirically-derived distributions of discount factors demonstrates significantly higher profitability than predicted by the classical linear model. This fundamental link between risk perceptions, wtp for remanufactured products, and profitability provides new insights on how to manage demand and product pricing in closed-loop supply chains.", "e:keyword": ["Closed‐loop supply chains", "Remanufacturing", "Behavioral operations", "Risky choice"]}, {"@id": "http://dx.doi.org/10.1111/poms.12629", "e:abstract": "What motivates the geographic footprint of the supply chains that multinational firms (MNFs) deploy? Traditional research in the operations and supply chain management literature tends to recommend locations primarily based on differentials in production costs and the ramifications of physical distance ignoring the role of taxation. MNFs that strategically position parts of their supply chains in low-tax locations can allocate the profits across the divisions to improve post-tax profits. For the profit allocation to be defensible to tax authorities, the divisional operations must possess real decision authority and bear meaningful risks. Generally speaking, the greater the transfer of risk and control, the larger the allowable allocation of profit. These transfers may also create inefficiencies due to misalignment of business goals and attitudes toward risk. We model these trade-offs in the context of placing in a low-tax region a subsidiary that oversees product distribution (as a limited risk distributor commissionnaire, limited risk distributor, or fully fledged distributor). Our analysis demonstrates that the MNF's preferences regarding the operating structures are not necessarily an obvious ordering based on the amount of risk and decision authority transferred to the division in the low-tax jurisdiction. We derive and analyze threshold values of the performance parameters that describe the main trade-offs involved in selecting an operating structure. We find some of the optimal decisions to exhibit interesting non-monotone behavior. For instance, profits can increase when the tax rate in the low-tax jurisdiction increases. Numerical analysis shows that the Limited-Risk Distributor structure is rarely optimal and quantifies when each alternative dominates it.", "e:keyword": ["Tax efficient supply chain management", "Principal‐agent model", "Supply chain contracts", "Multinational firms", "Distribution structure"]}, {"@id": "http://dx.doi.org/10.1111/poms.12631", "e:abstract": "We demonstrate the need to view in a dynamic context any decision based on limited information. We focus on the use of product costs in selecting the product portfolio. We show how ex post data regarding the actual costs from implementing the decision leads to updating of product cost estimates and potentially trigger a revision of the initial decision. We model this updating process as a discrete dynamical system (DDS). We define a decision as informationally consistent if it is a fixed-point solution to the DDS. We employ numerical analysis to characterize the existence and properties of such solutions. We find that fixed points are rare, but that simple heuristics find them often and quickly. We demonstrate the usefulness and robustness of our methodology by examining the interaction of limited information with multiple decision rules (heuristics) and problem features (size of product portfolio, profitability of product markets). We discuss implications for research on cost systems.", "e:keyword": ["Costing systems", "Numerical experiment", "Cost accounting", "Heuristics", "Dynamical systems"]}, {"@id": "http://dx.doi.org/10.1111/poms.12635", "e:abstract": "The practice of diverting genuine products to unauthorized gray markets continues to challenge companies in various industries and creates intense competition for authorized channels. Recent industry surveys report that the abuse of channel incentives is a primary reason for the growth of gray market activities. Therefore, it is crucial that companies take the presence of gray markets into consideration when they design contracts to distribute products through authorized retailers. This issue has received little attention in the extensive literature on contracting and supply chain coordination. In this study, we analyze the impacts of gray markets on two classic contracts, wholesale price and quantity discount, in a supply chain with one manufacturer and one retailer when the retailer has the opportunity to sell to a domestic gray market. Our analysis provides interesting and counterintuitive results. First, a classic quantity-discount contract that normally coordinates the supply chain can perform so poorly in the presence of a gray market that the supply chain would be better off using a wholesale price contract instead. Second, the presence of gray market can also degrade the performance of the wholesale price contract; therefore, a more sophisticated contract is needed for coordinating the supply chain. We show that contracts that solely depend on retailer's order quantity cannot coordinate the supply chain, and provide the conditions for coordinating the supply chain with price-dependent quantity discount contracts. We also provide comparative statics and show that when there is a gray market, coordinating the supply chain enhances total consumer welfare.", "e:keyword": ["Gray markets", "Supply chain coordination", "Strategic customers", "Quantity discount", "Price of anarchy"]}, {"@id": "http://dx.doi.org/10.1111/poms.12636", "e:abstract": "We study dual sourcing inventory systems with backordering and with stationary, stochastic demands. The two supply sources differ in their unit prices and lead times. We focus on the option of making costless returns to the cheaper, longer leadtime supplier. We show that the value of this option is zero. Our analysis leading to this result includes the derivation of several structural properties of the optimal policies for dual sourcing systems with and without the return option.", "e:keyword": ["Inventory/production systems", "Sample‐path analysis", "Dual sourcing", "Multiple suppliers", "Optimal policies"]}, {"@id": "http://dx.doi.org/10.1111/poms.12637", "e:abstract": "", "e:keyword": []}, {"@id": "http://dx.doi.org/10.1111/poms.12640", "e:abstract": "The research domain Industry Studies and Public Policy (IS&PP) seeks to further our understanding of industrial practices and managerial challenges by explicitly considering contextual details in the design and interpretation of research studies. These details can be vital considerations when shaping public policies. This article reviews a sample of IS&PP publications and analyzes the content of 180 selected papers—85 papers published in the Production and Operations Management (POM) journal and 95 papers published in related journals between 1992 and 2014. Our analysis of the sample dataset and examination of exemplar papers provide four findings. First, studies in different industries emphasize different themes of operational decisions. This difference in emphasis reveals potential research opportunities, especially for conducting inter-industry studies. Second, our analysis reveals a shift in focus over time. Earlier studies contain a mix of benchmarks and inter-industry comparisons, while later studies tend to be context-specific, intra-industry studies. Third, we report on empirics → analytics → empirics cycles that reveal gaps for building novel theories. Finally, we observe that the relationship between POM decisions and public policy is bi-directional. This highlights the need to jointly examine operational decisions with policy considerations, especially in information goods, healthcare, sustainable operations and high-tech manufacturing industries.", "e:keyword": ["Context‐based research", "Industry studies", "Public policy", "Production and Operations Management"]}, {"@id": "http://dx.doi.org/10.1111/poms.12642", "e:abstract": "Many manufacturers ensure supply capacity by using more than one supplier and sharing their capacity investment costs via supplier development programs. Their suppliers face competitive pressure from peers despite the reduced capacity investment cost. Although standard game theory makes clear prediction that cost sharing increases the suppliers' capacity choice and supply chain profit, the complex decision environment of capacity competition makes it interesting to test whether the theory predictions are robust and, if not, whether systematic deviations occur. We present a laboratory experiment study. The experiment data show that supplier subjects invested in higher capacities than what our theoretical analysis predicted, resulting in profit loss for the supply chain. Our econometric analysis indicates that the subjects are bounded rational and their concern for relative standing may be the potential driver of capacity over-investment. Based on the experimental findings, we study a modified cost-sharing mechanism that adapts to the behavioral biases. Its performance is validated in a second experiment.", "e:keyword": ["Capacity procurement", "Supplier competition", "Supplier development", "Behavioral operations"]}, {"@id": "http://dx.doi.org/10.1111/poms.12645", "e:abstract": "Gray markets are created by unauthorized retailers selling manufacturer's branded products. Similar to international gray markets, domestic gray markets are a growing phenomenon whose impact on supply chains is not clear. We consider a supply chain with one manufacturer and several authorized retailers who face a newsvendor problem and a domestic gray market. While a gray market provides an opportunity for retailers to clear their excess inventory (inventory-correction effect), it also can be a threat to their demand (demand-cannibalization effect). We first characterize the emerging equilibrium by assuming an MSRP environment. Comparing a decentralized and centralized system, we show that a wholesale pricing contract is quite efficient in a gray market environment; we explain the underlying mechanism and note some of the operational decisions that could hurt that efficiency. We show that the gray market price determines the degree of both the negative effects of demand-cannibalization and the positive effects of inventory correction, which in turn determines the net impact of gray markets on the retailer's stocking choice and, ultimately, the manufacturer's profit. We then study the authorized retailers' problem as a price-setting newsvendor. We observe that the gray market creates price competition between the authorized and unauthorized retailers, causing a drop in the primary market price. However, this price competition can be counteracted by the authorized retailers' stocking decision. Finally, we extend our model to consider the cases where the demand can be correlated across retailers.", "e:keyword": ["Domestic gray markets", "Supply chain coordination", "Contracting", "Wholesale pricing"]}, {"@id": "http://dx.doi.org/10.1111/poms.12649", "e:abstract": "When network effects are important and technology is rapidly improved, this study explores the relative optimality of five product introduction strategies of a durable goods manufacturer: (1) replacement, (2) skipping, (3) a delayed line, (4) shelving, and (5) line-extension. Using a two-period analytical model, we show how the type of compatibility—either full or backward compatibility—and the magnitude of the network effect influence the manufacturer's preference for the above strategies. Our analysis reveals that only the strategies (1)–(3) above can be optimal; and the optimal strategy varies with network strength. Further, the type of compatibility can dramatically change the profitability under each optimal strategy; for instance, while backward compatibility can increase the profitability of replacement under certain conditions, it always reduces the profitability of a delayed line. We also illustrate that if compatibility were a choice, although backward compatibility may be observed widely in practice, the parametric region for its optimality is relatively more restricted than that of full compatibility.", "e:keyword": ["Durability", "Sequential innovation", "Compatibility", "Network effects"]}, {"@id": "http://dx.doi.org/10.1111/poms.12651", "e:abstract": "This study investigates the interactions between a manufacturer's information acquisition and quality disclosure strategies in a supply chain setting in which the manufacturer privately knows his product quality but is uncertain about consumer preferences. We argue that the manufacturer should treat his information acquisition and quality disclosure decisions as an integrated process because these decisions can significantly influence a retailer's rational inferences about product quality and can have conflicting effects on his own profitability. Although information acquisition helps a manufacturer subsequently craft better pricing and quality disclosure strategies, it also leaks certain product information to the retailer, thus helping the retailer better estimate product quality. Therefore, in equilibrium, a manufacturer may choose not to acquire any consumer information, even when such acquisition is costless. Moreover, we find that this adverse effect of acquisition is highly dependent on the cost of disclosure and consumers’ preference differentiation. Increased consumer preference differentiation may have a non-monotonic relationship with the manufacturer's profit, and information acquisition can become detrimental to the manufacturer once the disclosure cost is sufficiently high.", "e:keyword": ["Information acquisition", "Quality disclosure", "Two‐sided information asymmetry", "Game theory"]}, {"@id": "http://dx.doi.org/10.1111/poms.12652", "e:abstract": "We present a framework to describe and analyze operational risk in financial services from an operations management perspective, focusing in particular on process design, process management, and human behavior aspects. The financial services industry differs from other service industries in ways that affect the nature of the operational risks it is subject to. In recent decades, many books and papers have focused on operational risk in financial services; however, this literature has focused mainly on the conceptual and statistical aspects of operational risk management and not on its operational aspects. Operational risk in financial services has not received much attention from the operations management community. The framework presented here is based on the premise that operational risk in financial services can reap significant benefits from research done in the theory and practice of operations management in manufacturing industries as well as in other services industries. The objective of this study is to propose particular challenges and questions raised in the practice of operational risk management that may stimulate future research in this particular area of operations management.", "e:keyword": ["Operational risk", "Reliability", "Capacity allocation", "Total quality management", "Human errors"]}, {"@id": "http://dx.doi.org/10.1111/poms.12653", "e:abstract": "Can peer-to-peer (P2P) marketplaces benefit traditional supply chains when consumers may experience valuation risk? P2P marketplaces can mitigate consumers' risk by allowing them to trade mismatched goods; yet, they also impose a threat to retailers and their suppliers as they compete over consumers. Further, do profit-maximizing marketplaces always extract the entire consumer surplus from the online trades? Our two-period model highlights the effects introduced by P2P marketplaces while accounting for the platform's pricing decisions. We prove that with low product unit cost, the P2P marketplace sets its transaction fee to the market clearing price, thereby extracting all of the seller surplus. In this range of product unit cost, the supply chain partners are worse off due to the emergence of a P2P marketplace. However, when the unit cost is high, the platform sets its transaction fee to be less than the market clearing price, intentionally leaving money on the table, as a mechanism to stimulate first period demand for new goods in expectation for some of them to be traded later, in the second period, via the marketplace. It is not until the surplus left with the sellers is sufficiently high that the supply chain partners manage to extract some of this surplus, ultimately making them better off due to a P2P marketplace. We further analyze the impact of a P2P marketplace on consumer surplus and social welfare. In addition, we consider model variants accounting for a frictionless platform and consumer strategic waiting.", "e:keyword": ["Consumers' valuation risk", "P2P marketplace", "Retailing strategy", "Backward induction"]}, {"@id": "http://dx.doi.org/10.1111/poms.12654", "e:abstract": "We model a supply chain consisting of a supplier and multiple retailers facing deterministic demand. We denote some retailers as strategic in the sense that given the supplier inventory information, they will implement the optimal stocking policy by incorporating such information. On the other hand, some retailers are denoted as naïve in the sense that they ignore supply information and resort to a simplistic ordering policy. Naïve retailers learn the optimal policy over time and adjust their orders accordingly. We study the dynamics of this game and investigate the impact of such strategic and naïve retailers on the cost, ordering pattern and stocking policies of all parties. We analyze the supply chain under two scenarios: the centralized supply chain where the objective is to minimize the total supply chain cost, and the decentralized supply chain where each self-interested player minimizes its own cost in a Stackelberg game setting. We fully characterize the optimal policies under both centralized and decentralized scenarios and show that, surprisingly, the supply chain might be better off by virtue of naïve retailers. The result is driven by the fact that strategic and naïve players’ decisions shift the positioning of inventory in the supply chain with its final impact being determined by the relative costs of different retailer-types. Our results also offer managerial insights into how access to supply information can improve supply chain performance.", "e:keyword": ["Inventory management", "Supply information", "Reverse information"]}, {"@id": "http://dx.doi.org/10.1111/poms.12656", "e:abstract": "We consider a firm's sourcing problem from one reliable supplier and one unreliable supplier in two price-setting scenarios. In the committed pricing scenario, the firm makes the pricing decision before the supply uncertainty is resolved. In the responsive pricing scenario, the firm's pricing decision is made after the supply uncertainty is resolved. For the committed pricing scenario, we develop a condition on supply uncertainty that guarantees the unimodality of the firm's objective function. By comparing the firm's optimal diversification decisions in the two pricing scenarios, we examine the interplay of supply diversification strategy and responsive pricing strategy in mitigating supply uncertainty. While both strategies are effective in mitigating supply uncertainty, we show that they are not necessarily substitutes. The relationship between these two strategies depends on two adverse effects caused by supply uncertainty: the lost-revenue effect and the lost-goodwill effect. More specifically, when the lost-revenue effect dominates the lost-goodwill effect, these two strategies are complements; otherwise, they are substitutes. Furthermore, we examine the impact of market size, price sensitivity, supplier reliability, and failure rebate on the interplay between these two strategies, and discuss the implications of our results. Finally, we extend our analysis to the case of two unreliable suppliers and show that the insights regarding the interplay between diversification and pricing continue to hold.", "e:keyword": ["Supply uncertainty", "Supply diversification", "Supply reliability", "Pricing"]}, {"@id": "http://dx.doi.org/10.1111/poms.12659", "e:abstract": "The current state of outpatient healthcare delivery is characterized by capacity shortages and long waits for appointments, yet a substantial fraction of valuable doctors’ capacity is wasted due to no-shows. In this study, we examine the effect of wait to appointment on patient flow, specifically on a patient's decision to schedule an appointment and to subsequently arrive to it. These two decisions may be dependent, as appointments are more likely to be scheduled by patients who are more patient and are thereby more likely to show up. To estimate the effect of wait on these two decisions, we introduce the willingness to wait (WTW), an unobservable variable that affects both bookings and arrivals for appointments. Using data from a large healthcare system, we estimate WTW with a state-of-the-art non-parametric method. The WTW, in turn, allows us to estimate the effect of wait on no-shows. We observe that the effect of increased wait on the likelihood of no-shows is disproportionately greater among patients with low WTW. Thus, although reducing the wait to an appointment will enable a provider to capture more patient bookings, the effects of wait time on capacity utilization can be non-monotone. Our counterfactual analysis suggests that increasing wait times can sometimes be beneficial for reducing no-shows.", "e:keyword": ["Queuing behavior", "Empirical study", "Healthcare operations"]}, {"@id": "http://dx.doi.org/10.1111/poms.2_12637", "e:abstract": "", "e:keyword": []}, {"@id": "http://dx.doi.org/10.1111/poms.3_12637", "e:abstract": "", "e:keyword": []}, {"@id": "http://dx.doi.org/10.3401/poms.1070.0001", "e:abstract": "Greater interdependence among workers and activities not only increases the need for internal communication, but it also imposes complications and barriers to effective information exchange. Intraorganizational communication capabilities of certain information systems can help overcome these barriers. However, the extent to which certain systems are promoted as communication tools depends largely on management's interpretation of their usefulness, which in turn may be largely dependent on operational context and managerial experience. We use a controlled experimental approach to study how these issues interact to impact managerial assessments of resource planning systems. Results show that managers value the communication capabilities of resource planning systems more so in highly task-interdependent contexts and that these assessments are still more positive among managers with greater supervisory experience. As a result, these findings pose direct implications regarding the management support of technology use.", "e:keyword": ["Enterprise resource planning", "Interdependence", "Supervisors", "Experience"]}, {"@id": "http://dx.doi.org/10.3401/poms.1070.0002", "e:abstract": "We identify and analyze a scenario where a firm first opens up what we call a “detached” market, by offering a new product that meets a customer need that is very different from (i.e., detached from) the need met by the old established product. Our analysis builds on the previous studies that describe alternate ways in which a new product might open a new market and ultimately encroach on an existing market. Consider the example of cell phones: They opened up a new detached market by meeting the customer need for mobility, a need very different from the traditional attribute of reception quality. By meeting an important detached need, a new product can sell at a high price, even though it might be woefully deficient with regard to the traditional performance dimension (the reception/coverage of early cell phones was sorely lacking). A person who is a high-end customer for the old product initially despises the new product as a replacement for the old one but might simultaneously be one of the first customers for the new product because it fills the detached-market need. Over time, the new product improves along the traditional dimension (e.g., cell phone reception/coverage has dramatically improved), and eventually it becomes a replacement for the old product, encroaching from the lower end upward (the first customers to drop their landlines have been lower-end customers such as students and apartment dwellers, whereas higher-end business customers still have landlines in their offices). We call this the detached-market form of low-end encroachment and show how it helps explain the conundrum of an expensive “disruptive” innovation. We go on to relate our results to the finding that “willingness to cannibalize” is a key factor in an incumbent firm's growth and survival, and to the “blue ocean strategy.”", "e:keyword": ["Diffusion", "Disruptive innovation", "Low‐end encroachment", "Willingness to cannibalize", "Blue ocean strategy"]}, {"@id": "http://dx.doi.org/10.3401/poms.1070.0004", "e:abstract": "We examine optimal control decisions regarding pricing, network size, and hiring strategy in the context of open source software development. Opening the source code to a software product often implies that consumers would not pay for the software product itself. However, revenues may be generated from complementary products. A software firm may be willing to open the source code to its software if it stands to build a network for its complementary products. The rapid network growth is doubly crucial in open source development, in which the users of the firm's products are also contributors of code that translates to future quality improvements. To determine whether or not to open the source, a software firm must jointly optimize prices for its various products while simultaneously managing its product quality, network size, and employment strategy. Whether or not potential gains in product quality, network size, and labor savings are sufficient to justify opening the source code depends on product and demand characteristics of both the software and the complementary product, as well as on the cost and productivity of in-house developers relative to open source contributors. This paper investigates these crucial elements to allow firms to reach the optimal decision in choosing between the open and closed source models.", "e:keyword": ["Pricing research", "Optimal control", "Open source", "Network externalities"]}, {"@id": "http://dx.doi.org/10.3401/poms.1070.0005", "e:abstract": "We study how a commercial firm competes with a free open source product. The market consists of two customer segments with different preferences and is characterized by positive network effects. The commercial firm makes product and pricing decisions to maximize its profit. The open source developers make product decisions to maximize the weighted sum of the segments' consumer surplus, in addition to their intrinsic motivation. The more importance open source developers attach to consumer surplus, the more effort they put into developing software features. Even if consumers do not end up adopting the open source product, it can act as a credible threat to the commercial firm, forcing the firm to lower its prices. If the open source developers' intrinsic motivation is high enough, they will develop software regardless of eventual market dynamics. If the open source product is available first, all participants are better off when the commercial and open source products are compatible. However, if the commercial firm can enter the market first, it can increase its profits and gain market share by being incompatible with its open source competitor, even if customers can later switch at zero cost. This first-mover advantage does not arise because users are “locked in,” but because the commercial firm deploys a “divide and conquer” strategy to attract early adopters and exploit late adopters. To capitalize on its first-mover advantage, the commercial firm must increase its development investment to improve its product features.", "e:keyword": ["Open source", "Network effects", "Free technology", "Market segmentation", "First‐mover advantage"]}, {"@id": "http://dx.doi.org/10.3401/poms.1070.0007", "e:abstract": "We highlight many of the traditional research themes in the management of technology as well as research themes on emerging topics such as those that appear in this focused issue. The discussion demonstrates the breadth and multidisciplinary nature of management of technology as well as the variety of methods employed in management of technology research. We conclude by offering a list of research themes that are of particular interest to the Management of Technology Department of Production and Operations Management.", "e:keyword": ["Innovation", "Diffusion", "And technology adoption", "Learning and knowledge management", "Technology implementation", "Open source software development", "Technology as automation versus labor enhancing", "e‐services"]}, {"@id": "http://dx.doi.org/10.3401/poms.1070.0008", "e:abstract": "We use a real-options approach to analyze investments in process improvement. We develop a simple, stochastic model of a firm making investment decisions in process improvement. Our analysis offers several interesting insights into investments in process improvement. First, early investment in process improvement results in valuable knowledge, which helps increase the value of the option to invest in process improvement in future periods. This may motivate a firm to invest in process improvements as early as possible. Second, it may be optimal for a firm to stop investing when such investments do not create enough value in the later stages of the investment horizon. Third, although one would expect the state of a firm's process relative to that of other firms to impact a firm's decision to invest in process improvement, this study finds that the impetus is conditional and identifies these conditions. Finally, in such an environment, the delay of investment in process improvement incurs an opportunity cost for a firm, and we show that the traditional net present value rule must incorporate this opportunity cost and the knowledge-induced change in future option values to lead to a correct investment decision.", "e:keyword": ["Process improvement", "Learning", "Knowledge", "Investment", "Real options"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0011", "e:abstract": "Vendor managed inventory systems are becoming increasingly popular. An important issue in implementing a vendor managed inventory scheme is the contracting terms that dictate the ownership of the inventory and the responsibility of inventory replenishment decisions. Thus the performance of a vendor managed system crucially depends on these terms and on how inventory-related costs are shared in a supply chain. We consider a system where a manufacturer supplies a single product to a retailer who faces random demand in a competitive market. The retailer incurs a fixed cost per order, inventory holding cost, and a penalty cost for a stockout (unsatisfied demand is back-ordered). Further, the manufacturer incurs a penalty cost when there is a stockout at the retailer and a fixed replenishment cost. We assume that the players are rational and act noncooperatively. We compare the performance of retailer managed inventory systems, where the retailer places orders and makes replenishment decisions, with vendor managed inventory systems, wherein the vendor or manufacturer makes inventory and replenishment decisions. Specifically, in the vendor managed inventory system, we propose and evaluate holding cost subsidy-type contracts on inventories offered by the retailer to improve system performance. We evaluate this contract in the context of three widely used inventory systems—deterministic economic order quantity, continuous review (Q, r) policies, and periodic review policies—and show when such contracts may improve channel performance.", "e:keyword": ["Vendor managed inventory", "Coordination", "Contracting", "Multiperiod model", "Holding cost subsidy"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0012", "e:abstract": "Due to the proliferation of electronic commerce and the development of Internet technologies, many firms have considered new pricing-inventory models. In this paper, we study the role of stockless (i.e., zero-inventory) operations in online retailing by a considering duopoly competition in which two retailers compete to maximize profit by jointly optimizing their pricing and inventory decisions. In our model, the retailers are allowed to choose either an in-stock policy or stockless operations with a discounted price. We first present the characteristics and properties of the equilibrium. We then demonstrate that the traditional outcome of asymmetric Bertrand competition is observed under head-to-head competition. However, when the two firms choose different operational policies, with corresponding optimal pricing, they can share the market under certain conditions. Finally, we report interesting observations on the interaction between pricing and inventory decisions obtained from an extensive computational study.", "e:keyword": ["Online retailing", "Stockless operation", "Duopoly competition", "Pricing", "Inventory management"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0013", "e:abstract": "We report on a cross-sectional and longitudinal comparison of European distribution centers in the Netherlands. European distribution centers are responsible for the distribution of a manufacturer's (mostly Asian or American) products over customers in a large part of Europe, the Middle East, and Africa, often with strict service-level agreements. In total, 65 physical warehouses, containing 140 European, Asian, and American European distribution center operations, in combination with different outsourcing relations (own-account, dedicated outsourced, and public outsourced), were benchmarked in 2000 and monitored over the period 2000–2004. We conclude that both in 2000 and 2004, European warehouses are more efficient than Asian and American warehouses, and outsourced operations (particularly public warehouses) are more efficient than own-account operations. Over the period 2000–2004, efficiency appears to have declined substantially; the most distinct differences are to be found among public outsourced warehouses and, because many European distribution center warehouse operations of European origin are run by public service providers, among European warehouses. This decline in efficiency also led to a decline in productivity, in spite of the fact that overall the available technology has improved. We conjecture potential causes for this decline.", "e:keyword": ["European distribution centers", "Warehouses", "Operations", "Benchmarking", "Monitoring"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0014", "e:abstract": "We model strategic behavior of two types of suppliers in B2B spot markets: a supplier that has forward contracts and uses the spot market only for inventory liquidation, and a supplier that uses the spot market as its sole selling channel. We find that when the spot market demand is small, the supplier that has forward contracts has a higher incentive to invest in expanding the spot market. When the spot market demand exceeds a threshold size, this situation is reversed, and the supplier with no contracts benefits more from making the spot market more prevalent. We show that a supplier with forward contracts benefits from the existence of the spot market more than a supplier with no contracts and that this result holds with both negative and positive correlation between spot market demand and contracted demand. We find that suppliers producing only for the spot market gain from working in industries where contracted demand and spot market demand are positively correlated, whereas suppliers that have forward contracts benefit from working in industries with a negative correlation between demands, since it allows them to better manage risk. In addition, both total industry supply and spot market supply are higher in industries where demands are negatively correlated.", "e:keyword": ["B2B markets", "Supply chain", "Spot markets", "Competition", "Information"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0016", "e:abstract": "We consider the scheduling of ground station support times to low Earth orbit (LEO) satellites with overlapping visibilities. LEO satellites typically complete a revolution around the Earth in less than four hours at an altitude of a few hundred miles and are part of the critical infrastructure for natural resource management, crop yield estimation, meteorology, flood control, communication, and space research. Because these satellites are quite expensive to launch and operate, utilizing them in the best possible manner is of paramount importance for the agencies that own them. A ground station provides support time to a satellite to perform a variety of tasks when the satellite is visible to the station over a prespecified planning horizon; the payoff from providing such support is a function of the support time. When two or more satellites pass over the ground station, their visibility time windows may overlap. Thus, under overlapping visibilities, a relevant problem is that of scheduling ground station support time for each satellite with the objective of maximizing the total utility generated from supporting the satellites. We propose four basic scheduling models to address a variety of scenarios and investigate their computational complexities. For each model, we also identify special cases that are polynomially solvable.", "e:keyword": ["LEO satellites", "Complexity", "Algorithms", "Optimization", "Service scheduling"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0018", "e:abstract": "Buyers often find that obtaining complete information about suppliers is costly. In such scenarios, there is a trade-off between the costs of obtaining information and the benefits that accrue to the owners of such information. There are also various ways in which the missing information can be obtained or inferred. In this paper, we compare the efficiency of obtaining information via the classical mechanism design approach, which relies on the information available before the contracts are designed, with that of an “audit-based” approach, which relies on the information obtained after the fact.", "e:keyword": ["Procurement auction", "Auditing", "Information asymmetry", "Supply chain coordination"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0019", "e:abstract": "We develop a general model for software development process and propose a policy to manage system coordination using system fault reports (e.g., interface inconsistencies, parameter mismatches, etc.). These reports are used to determine the timing of coordination activities that remove faults. We show that under an optimal policy, coordination should be performed only if a “threshold” fault count has been exceeded. We apply the policy to software development processes and compare the management of those projects under different development conditions. A series of numerical experiments are conducted to demonstrate how the fault threshold policy needs to be adjusted to changes in system complexity, team skill, development environment, and project schedule. Moreover, we compare the optimal fault threshold policy to an optimal release-based policy. The release-based policy does not take into account fault data and is easier to administer. The comparisons help to define the range of project parameters for which observing fault data can provide significant benefits for managing a software project.", "e:keyword": ["Software development", "Threshold policy", "Fault growth model", "Dynamic programming"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0023", "e:abstract": "The purpose of the paper is to demonstrate the usefulness of (1) system dynamics as a structural theory for operations management and (2) system dynamics models as content theories in operations management. The key findings are that, although feedback loops, accumulation processes, and delays exist and are widespread in operations management, often these phenomena are ignored completely or not considered appropriately. Hence, it is reasoned why system dynamics is well suited as an approach for many operations management studies, and it is shown how system dynamics theory can be used to explain, analyze, and understand such phenomena in operations management. The discussion is based on a literature review and on conceptual considerations, with examples of operations management studies based on system dynamics. Implications of using this theory include the necessary re-framing of some operations management issues and the extension of empirical studies by dynamic modeling and simulation. The value of the paper lies in the conceptualization of the link between system dynamics and operations management, which is discussed on the level of theory.", "e:keyword": ["System dynamics", "Structural theory", "Modeling", "Simulation", "Operations strategy"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0024", "e:abstract": "Drawing from three theoretical bases—“information stickiness” from the knowledge management literature, “service coproduction” from the service operations management literature, and “incomplete contract theory” from the transaction cost economics literature—we discuss a theoretical framework and develop models to study the efficiency of the service coproduction process in a knowledge-intensive consulting environment. We apply, refine, and interpret these theories to determine how work should be allocated between the consultant and the client and the corresponding pricing under different contractual relationships that occur in this industry. We find that, with a pricing schedule that relates the fee adjustment to the self-service level and one party's ownership of the residual right to specify the workload allocation, the client underinvests her efforts in the service coproduction process, whereas the consultant overinvests his efforts, resulting in an inefficient process. In addition, to improve overall process efficiency, we show that the more productive party should own the residual right to respecify the self-service level when the final service need emerges. Our results, as well as interview data from experienced consultants, provide insights into the causes of inefficient service delivery processes and offer direction for achieving better efficiency through contract design and pricing schedules.", "e:keyword": ["Information stickiness", "Service coproduction", "Incomplete contract theory", "Consulting services", "Service process design"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0025", "e:abstract": "Research on mass customization has largely overlooked the issue of organizational change associated with the mass production-to-mass customization transition. To address this gap in the literature, we conduct a longitudinal case study of a manufacturing facility belonging to a division of a Fortune 1000 discrete manufacturing firm as it seeks to transition from mass production to mass customization. We empirically identify five factors hindering the mass production-to-mass customization transition within the research site and articulate five corresponding generalizations explaining how and why these hindrance factors relate to the mass production-to-mass customization transition hazard beyond the research site (i.e., how and why the five hindrance factors, in general, threaten the likelihood of a successful mass production-to-mass customization transition). We then theoretically validate the five hindrance factors and corresponding generalizations by mapping them onto the antecedents and tenets of structural inertia theory. We conclude with a brief discussion of the scientific and pragmatic significance of the findings and highlight opportunities for future research.", "e:keyword": ["Mass customization", "Organizational change", "Structural inertia", "Case study", "Theory development"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0026", "e:abstract": "Rigorous development of theory in operations management has been lacking. Although many theories have been proposed, they are often not developed in a format and depth that can be falsified, refined, or supported. This special issue includes three papers that illustrate rigorous development of theory for future testing using mathematical, simulation, or managerial approaches.", "e:keyword": ["Theory", "Empirical", "Operations"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0028", "e:abstract": "Deposits held at Federal Reserve Banks are an essential input to the business activity of most depository institutions in the United States. Managing these deposits is an important and complex inventory problem for two reasons. First, Federal Reserve regulations require that depository institutions hold certain amounts of such deposits at the Federal Reserve Banks to satisfy statutory reserve requirements against customers' transaction accounts (demand deposits and other checkable deposits). Second, some inventory of such deposits is essential for banks to operate one of their core lines of business: furnishing payment services to households and firms. Because the Federal Reserve does not pay interest on such deposits used to satisfy statutory reserve requirements, banks seek to minimize their inventory of such deposits. In 1994, the banking industry introduced a new inventory management tool for such deposits, the retail deposit sweep program, which avoids the statutory requirement by reclassifying transaction deposits as savings deposits. This is an interesting inventory problem for fungible items, where the conversion process is reversible. We examine two methods for operating such sweeps programs within the limits of Federal Reserve regulations, and we develop a stochastic dynamic programming model to implement one such method, the threshold method.", "e:keyword": ["Retail banking", "Sweeps", "Regulation D", "Required reserves", "Stochastic dynamic programming"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0029", "e:abstract": "Should service capacities (such as agent groups in call centers) be pooled or not? This paper will show that there is no single answer. For the simple but generic situation of two (strictly pooled or unpooled) server groups, it will provide (1) insights and approximate formulae, (2) numerical support, and (3) general conclusions for the waiting-time effect of pooling. For a single call type, this effect is clearly positive, as represented by a pooling factor. With multiple job types, however, the effect is determined by both a pooling and a mix factor. Due to the mix factor, this effect might even be negative. In this case, it is also numerically illustrated that an improvement of both the unpooled and the strictly pooled scenario can be achieved by simple overflow or threshold scenarios. The results are of both practical and theoretical interest: practical for awareness of this negative effect, the numerical orders, and practical scenarios in call centers, and theoretical for further research in more complex situations.", "e:keyword": ["Call centers", "Queueing", "Pooling", "Overflow", "Thresholds"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0030", "e:abstract": "This paper explores the customer experience paradigm as it pertains to service operations strategy and design. First, we operationally define and discuss the concept of customer experience. In this context, we propose a reframing of the strategic role of operations strategy as one of choreographing experience-centric services. We then introduce the concept of services as destinations as an emerging business model for classifying experiential service strategies. Our conceptual typology of experience-based strategies uses two dimensions: (1) the depth of use of experience as a source of value creation, ranging from brand experience to the services as a destinations business model, and (2) the degree of integration of experience internally within the firm. Using this conceptual typology, we develop five propositions and use multiple cases to illustrate firms' use of these experience strategies. Laying the groundwork for future research, we highlight insights from the qualitative, multiple-case data as they pertain to service operations strategy and the business model that employs services as destinations. A number of questions for further research are suggested.", "e:keyword": ["Service operations strategy", "Destinations", "Experience", "Emotional response", "Case research"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0031", "e:abstract": "This paper investigates two approaches to patient classification: using patient classification only for sequencing patient appointments at the time of booking and using patient classification for both sequencing and appointment interval adjustment. In the latter approach, appointment intervals are adjusted to match the consultation time characteristics of different patient classes. Our simulation results indicate that new appointment systems that utilize interval adjustment for patient class are successful in improving doctors' idle time, doctors' overtime and patients' waiting times without any trade-offs. Best performing appointment systems are identified for different clinic environments characterized by walk-ins, no-shows, the percentage of new patients, and the ratio of the mean consultation time of new patients to the mean consultation time of return patients. As a result, practical guidelines are developed for managers who are responsible for designing appointment systems.", "e:keyword": ["Appointment scheduling", "Outpatient clinics", "Service operations", "Health care", "Simulation"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0032", "e:abstract": "This special issue of Production and Operations Management offers a sample of ongoing research that focuses currently on the services industries. The articles selected cover a spectrum of application areas as well as methodologies.", "e:keyword": ["Service industries", "Call centers", "Health care", "Financial services"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0034", "e:abstract": "What can service firms do to improve their ability to offer new services? In this paper we argue that new service development success results from building a competence in the management of service development resources and routines. We conceptualize new service development competence as a multidimensional, second-order latent construct that is represented by a system of four interrelated and complementary dimensions: (1) formalized new service development processes, (2) market acuity, (3) new service development strategy, and (4) information technology use and experience. We hypothesize that the growth of new service development competence is related to improved new service development performance. Using structural equations modeling, we analyze survey data from 166 retail banks and report three key empirical findings. First, we show that the four hypothesized dimensions are statistically significant in defining new service development competence. Second, contrary to conventional wisdom in new product development, we find that formalized processes play a lesser role in the success of new service development compared with the other three dimensions. Instead, market acuity—which captures the firm's ability to see the competitive environment clearly and to anticipate and respond to customers' evolving needs and wants—was the most important new service development competence indicator. Finally, we demonstrate the positive effect of new service development competence on new service development performance and show that new service development competence is also significantly related to business-level performance. Together, our empirical results suggest that complementary benefits arise from the adoption of a more holistic approach to the management of new service development at the program level.", "e:keyword": ["New service development", "Service operations management", "Competencies", "Structural equations modeling"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0035", "e:abstract": "We investigate trade-offs among markups, service quality, and product attributes across customer, Internet retailer, and wholesaler echelons. Research has documented the reality of retail price dispersion, but little is known about how retail markups, in particular, are related to service quality and product attributes. For example, do Internet retailers deliver superior service in return for high markups? Do product characteristics affect the relationship between service and markups for retailers? To examine these issues, we first developed a model of Internet retail profitability that separates revenues and costs related to sales from other profit sources. This framework allowed us to position our work alongside the extant literature about Internet retailing. Moreover, it led us to synthesize service quality dimensions found in Internet retailing studies. We subsequently developed a critical-event study based on the profit model and the synthesis of service quality dimensions to delineate service aspects that retailers should emphasize to address buyers' utility. Finally, we collected data from Internet purchases across retailers to isolate markup-service quality trade-offs along our delineated service aspects. We find that high markups are associated with superior performance across service quality dimensions. Furthermore, this trade-off becomes more acutely defined when products with variable popularity are transacted.", "e:keyword": ["Internet commerce", "e‐services", "Supply chain management", "Technology management", "Empirical research"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0039", "e:abstract": "We study the effect of strategic customer behavior on pricing and rationing decisions of a firm selling a single product over two periods. The seller may limit the availability of the product (that is, ration) in the second (clearance) period. Some customers are strategic and respond to the firm's decisions by timing their purchases. When capacity is nonconstraining and the seller has pricing flexibility, we show that rationing in the clearance period cannot improve revenue. However, when prices are fixed in advance, rationing can improve revenue. In the latter case, we conduct a detailed analysis for linear and exponential demand curves and derive explicit expressions for optimal rationing levels. We find that the policy of doing the better of not restricting availability at the clearance price or not offering the product at the clearance price is typically near optimal. Our analysis also suggests that rationing—although sometimes offering considerable benefit over allowing unrestricted availability in the clearance period—may allow the seller to obtain only a small fraction of the optimal revenue when the prices are chosen optimally without rationing. We extend the analysis to cases where the capacity is constraining and obtain similar results.", "e:keyword": ["Revenue management", "Clearance pricing", "Customer behavior"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0040", "e:abstract": "Research in revenue management is rapidly changing as the environment in which firms operate changes. The Internet, the adoption of new information technologies, and other market forces are driving a new wave of research in revenue management. At the same time, more and more industries are adapting the tools of revenue management to their needs. Promising research directions are more sophisticated models of consumer behavior, more general models and understanding of rivalry, and more general pricing mechanisms. These are important issues for today's revenue managers and promising areas for both theoretical and empirical research.", "e:keyword": ["Revenue management", "Pricing"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0041", "e:abstract": "The celebrated model of Gallego and van Ryzin is specialized to the case of constant elasticity of demand. A closed form is developed, which has an even simpler form than that arising with exponential demand and which possesses an excellent approximation. In this environment, monopoly is efficient, which means that all the behavior usually attributed to monopoly pricing is actually a consequence of efficient pricing and would arise even in a perfectly competitive environment. If the initial supply is not too large, consumers have no incentive to delay their purchases to get a lower price at the average inventory prevailing at any time.", "e:keyword": ["Revenue management", "Yield management", "Dynamic pricing", "Efficient pricing"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0042", "e:abstract": "We study the problem of combined pricing, resource allocation, and overbooking by service providers involved in dynamic noncooperative oligopolistic competition on a network that represents the relationships of the providers to one another and to their customers when service demand is uncertain. We propose, analyze, and compute solutions for a model that is more general than other models reported in the revenue management literature to date. In particular, previous models typically consider only three or four of five key revenue management features that we have purposely built into our model: (1) pricing, (2) resource allocation, (3) dynamic competition, (4) an explicit network, and (5) uncertain demand. Illustrative realizations of the abstract problem we study are those of airline revenue management and service provision by companies facing resource constraints. Under fairly general regularity conditions, we prove existence and uniqueness of a pure strategy Nash equilibrium for dynamic oligopolistic service network competition described by our model. We also show, for an appropriate notion of regularity, that competition leads to the underpricing of network services, a finding numerically illustrated by an example of intermediate size. Our proposed algorithm can be implemented using well-known off-the-shelf commercial software.", "e:keyword": ["Revenue management", "Pricing and allocation", "Overbooking", "Dynamic games", "Variational inequalities"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0043", "e:abstract": "It is well known that maximizing revenue from a fixed stock of perishable goods may require discounting prices rather than allowing unsold inventory to perish. This behavior is seen in industries ranging from fashion retail to tour packages and baked goods. A number of authors have addressed the markdown management problem in which a seller seeks to determine the optimal sequence of discounts to maximize the revenue from a fixed stock of perishable goods. However, merchants who consistently use markdown policies risk training customers to “wait for the sale.” We investigate models in which the decision to sell inventory at a discount will change the future expectations of customers and hence their buying behavior. We show that, in equilibrium, a single-price policy is optimal if all consumers are strategic and demand is known to the seller. Relaxing any of these conditions can lead to a situation in which a two-price markdown policy is optimal. We show using numerical simulation that if customers update their expectations of availability over time, then optimal sales limit policies can evolve in a complex fashion.", "e:keyword": ["Revenue management", "Consumer behavior", "Pricing"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0044", "e:abstract": "A significant portion of the services industry is focused on providing services (medical, legal, financial, personal, and travel) to individuals. However, studies have shown that a less visible but rapidly growing segment of the service sector comprises firms that provide business functions to other businesses. The sector covers tasks such as payroll processing, procurement, and information systems management, as well as business consulting, technical support, call center operations, and software development. Firms may choose to purchase, rather than perform, these business functions to reduce costs, to mitigate risk, or simply to focus on their processes that provide marketplace differentiation. Transferring a business function from within a firm to an outside supplier is often called “outsourcing”; when the supplier provides the service from a lower-cost country, it is called “offshoring.” The risks and benefits of outsourcing to the firm purchasing a business service have been studied in some detail by both academics and consultants. In this paper, we outline revenue management issues faced by business service providers and describe some new opportunities for the use of analytic methods in the service science sector.", "e:keyword": ["Revenue management", "Services", "Services science", "Service engineering"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0046", "e:abstract": "This paper considers a supply chain setting where several capacitated suppliers compete for orders from a single retailer in a multiperiod environment. At each period, the retailer places orders to the suppliers in response to the prices they announce. Each supplier has a fixed capacity. We consider a make-to-stock setting where the retailer can carry inventory. The retailer faces exogenous, price-dependent demand. We study the problem using ideas from fluid models. In particular, we (i) analyze when there are pure equilibrium policies in this setting and characterize the structure of these policies; (ii) consider coordination mechanisms; and (iii) present some preliminary computational results. We also consider a modified model that uses option contracts to coordinate the supply chain.", "e:keyword": ["Supply chain competition", "Fluid models", "Capacity", "Dynamic optimization", "Revenue management"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0054", "e:abstract": "We investigate a supply chain system with a common supplier selling to downstream retailers who are engaged in both price and inventory competition. We establish the existence and uniqueness of the pure-strategy Nash equilibrium for the retailer game and study how a supplier can coordinate the system to achieve the best performance. Our main conclusions are as follows: First, a buyback contract can be used to coordinate retailers competing on both price and inventory in a sense that optimal retail prices and inventory levels arise as the Pareto-dominant equilibrium. With symmetric retailers, the system optimum arises as the unique symmetric equilibrium. Second, the particular type of competition experienced by retailers (price versus inventory competition) affects the characteristics of the contract. Specifically, strong price competition leads to a coordination mechanism with a positive buyback rate, where the supplier subsidizes retailers for leftover inventories; however, strong inventory competition leads to a negative buyback rate, where retailers are punished for overstocking. Using a linear expected demand function, we further explore the impact of system parameters on the coordination contract and the competitive equilibrium. We also find that the performance of the supplier's optimal contract is asymptotic to the system optimal coordination contract as competition becomes fierce.", "e:keyword": ["Pricing", "Inventory", "Competition", "Coordination"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0055", "e:abstract": "We study a model with a single supplier and a single buyer who interact multiple times before the buyer sells her product in the end-consumer market. We show that when the supplier uses a wholesale price contract, even under perfect foresight, the supplier, the buyer, and the end consumers benefit from multiple trading opportunities versus a one-shot procurement agreement.", "e:keyword": ["Strategic interactions", "Advance capacity procurement", "Incremental quantity discounts", "Supply chain coordination"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0057", "e:abstract": "The process of introducing new and phasing out old products is called product rollover. This paper considers a periodic-review inventory system consisting of a manufacturer and a retailer, where the manufacturer introduces new and improved products over an infinite planning horizon using the solo-roll strategy. We consider two scenarios: (1) the manufacturer does not share the upstream information about new-product introduction with the retailer and (2) the manufacturer shares the information. For each scenario, we first derive the decentralized ordering policy and the system-optimal ordering policy with given cost parameters. We then devise an optimal supply chain contract that coordinates the inventory system. We demonstrate that when the inventory system is coordinated, information sharing improves the performance of both supply chain entities. However, this may not be true if the inventory system is not coordinated. We also show that under the optimal contract, the manufacturer has no incentive to mislead the retailer about new-product information in the information-sharing model. When demand variability increases, information sharing adds more benefits to the coordinated supply chain. Our research provides insights about coordinating product, financial, and information flows in supply chains with product rollover.", "e:keyword": ["Information sharing", "Supply chain coordination", "Product rollover", "Contracting and incentives"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0064", "e:abstract": "Motivated by the proliferation of multifunction products, we investigate product portfolio decisions of a single firm by analyzing the impact of three major factors. First, because multifunction products provide complete or partial functionalities of single-function products, we incorporate substitution or cannibalization effects between the potential products. Second, we explicitly model the variable costs of manufacturing the single-function and multifunction products. Third, we examine the firm's pricing decisions because of their impact on the degree of cannibalization between the multifunction product and one or more single-function products. Using an economic model, we first characterize the firm's optimal product portfolio (through a quantity-based decision), which in turn determines the market equilibrium prices for each product in its portfolio. Some of the unique insights stemming from our analysis are: (a) the optimal product portfolio choice is driven primarily by maximum profit margins for the single-function products weighted by the demand substitution effects; and (b) from a product design perspective, the complete functionality of the base single-function product is always included in the optimal product offering, but this is not necessarily the case with the complete functionality of the nonbase single-function product.", "e:keyword": ["Product functionalities", "Multifunction products", "Product portfolios", "Quantity and pricing decisions"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0066", "e:abstract": "Technologies such as radio-frequency identification and global positioning systems can provide improved real-time tracking information for products and replenishment orders along the supply chain. We call this type of visibility order progress information. In this paper, we investigate how order progress information can be used to improve inventory replenishment decisions. To this end, we examine a retailer facing a stochastic lead time for order fulfillment. We characterize a replenishment policy that is based on the classical (Q, R) policy and that allows for releasing emergency orders in response to the order progress information. We show that the optimal structure of this policy is given by a sequence of threshold values dependent on order progress information. In a numerical study we evaluate the cost savings due to this improved replenishment policy.", "e:keyword": ["Inventory control", "Supply chain visibility", "RFID", "Stochastic lead times", "Order progress information", "Emergency ordering", "Global supply chains"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0068", "e:abstract": "New developments in corporate information technology such as enterprise resource planning systems have significantly increased the flow of information among members of supply chains. However, the benefits of sharing information can vary depending on the supply chain structure and its operational characteristics. Most of the existing research has studied the impact of sharing downstream information (e.g., a manufacturer sharing information with its suppliers). We evaluate the benefits of sharing upstream yield information (e.g., a supplier sharing information with the manufacturer) in a two-stage serial supply chain in which the supplier has multiple internal processes and is faced with uncertain output due to yield losses. We are interested in determining when the sharing of the supplier's information is most beneficial to the manufacturer. After proposing an order-up-to type heuristic policy, we perform a detailed computational study and observe that this information is most beneficial when the supplier's yield variance is high and when end-customer demand variance is low. We also find that the manufacturer's backorder-to-holding cost ratio has little, if any, impact on the usefulness of information.", "e:keyword": ["Inventory control", "Information sharing", "Random yield", "Supply chain management"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.0069", "e:abstract": "The mixed-channel model is becoming increasingly popular in the marketplace. In this model, a firm selling through the traditional supply chain of wholesaler and retailer opens a direct channel to the customer through Internet sales. Because both channels have their respective advantages, the manufacturer is attracted to this business model. However, it also leads to channel conflict, with the retailer feeling threatened by direct competition. One way of eliminating the possibility of this channel conflict, where the retailer is allowed to add value to the product to differentiate its offering to the customers, is proposed in this paper. The retailer is also given full authority to make pricing decisions. This paper presents a model, under this scenario, of obtaining optimum pricing decisions by both parties, the amount of value added by the retailer, and the manufacturer's wholesale price to the retailer. Our model incorporates information asymmetry, where the manufacturer has incomplete information about the retailer's cost of adding value. We obtain closed-form contracts with incomplete information and compare them with those with complete channel coordination. We also develop a number of managerial guidelines and identify future research topics.", "e:keyword": ["Channel conflict", "Information asymmetry", "Mixed channel", "Value‐adding retailer"]}, {"@id": "http://dx.doi.org/10.3401/poms.1080.01137", "e:abstract": "", "e:keyword": []}, {"e:year": 2010, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01145.x", "e:abstract": "", "e:keyword": []}, {"e:year": 2010, "@id": "http://dx.doi.org/10.1111/j.1937-5956.2010.01146.x", "e:abstract": "", "e:keyword": []}]