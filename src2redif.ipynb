{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import collections\n",
    "import json\n",
    "import io\n",
    "import fix,parser\n",
    "def find_between( s, first, last ):\n",
    "    try:\n",
    "        start = s.index( first ) + len( first )\n",
    "        end = s.index( last, start )\n",
    "        return s[start:end]\n",
    "    except ValueError:\n",
    "        print 'between_error',s,first,last\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse(html,publisher,journal_name):\n",
    "    global s,s_body\n",
    "    if publisher=='ama':\n",
    "        s = bs(html, 'lxml').find('head')\n",
    "        s_body=bs(html, 'lxml').find('body')\n",
    "        year_vol_iss= s.find('meta',{'property':'og:description'})['content']\n",
    "        year=year_vol_iss.split(', Vol')[0][-4:]\n",
    "        vol= find_between(year_vol_iss,'Vol. ',', No.')\n",
    "        iss= find_between(year_vol_iss,'No. ',',')\n",
    "        title=s.find('meta',{'property':'og:title'})['content']\n",
    "        creators=s.findAll('meta',{'name':'dc.Creator'}); names=[c['content'].strip() for c in creators]\n",
    "        abstract=s_body.find('div',{'class':'abstractSection'}) or ''\n",
    "        keywords_html=s.findAll('meta',{'name':'dc.Subject'})\n",
    "        keywords=', '.join([k['content'] for k in keywords_html])\n",
    "        url=s.find('meta',{'property':'og:url'})['content']\n",
    "        if abstract is not '':\n",
    "            abstract=abstract.find('p').text\n",
    "\n",
    "    if publisher=='sag':\n",
    "        s = bs(html, 'lxml').find('head')\n",
    "        s_body=bs(html, 'lxml').find('body')\n",
    "        \n",
    "        try:\n",
    "            vol_iss_year=s_body.find('div',{\"class\":\"articleJournalNavTitle\"}).text.replace('\\n','').replace('\\t','')\n",
    "            year=vol_iss_year[-4:]\n",
    "            iss= vol_iss_year.split('Issue ')[1].split(', ')[0]         \n",
    "            vol= vol_iss_year.split('Vol ')[1].split(', ')[0]            \n",
    "        except Exception:\n",
    "            year=s_body.find('div',{\"class\":\"published-dates\"}).text.split('\\n')[1][-4:]\n",
    "            vol='';iss=''\n",
    "            pass\n",
    "        \n",
    "        title=s.find(\"meta\",{\"name\":\"dc.Title\"})['content']\n",
    "        creators=s.findAll(\"meta\",{\"name\":\"dc.Creator\"});names=[c['content'].strip() for c in creators]         \n",
    "        abstract=s.find(\"meta\",{\"name\":\"dc.Description\"}) or ''\n",
    "        keywords=s.find(\"meta\",{\"name\":\"keywords\"}) or ''\n",
    "        url=s.find(\"meta\",{\"name\":\"dc.Source\"})['content']        \n",
    "        if abstract is not '':\n",
    "            abstract= abstract['content']\n",
    "        if keywords is not '' : \n",
    "            keywords= keywords['content']\n",
    "    \n",
    "    if publisher=='taf':\n",
    "        s = bs(html, 'lxml').find('head')\n",
    "        year=int(s.find(\"meta\",{\"name\":\"og:description\"})['content'][1:5])\n",
    "        vol=s.find(\"meta\",{\"name\":\"pbContext\"})['content'].split('.i')[1].split(';')[0].lstrip('0')\n",
    "        iss=s.find(\"meta\",{\"name\":\"pbContext\"})['content'].split('.v')[1].split('.i')[0].lstrip('0')\n",
    "        title=s.find(\"meta\",{\"name\":\"dc.Title\"})['content']\n",
    "        creators=s.findAll(\"meta\",{\"name\":\"dc.Creator\"});names=[c['content'].strip() for c in creators]\n",
    "        abstract=s.find(\"meta\",{\"name\":\"dc.Description\"}) or ''\n",
    "        keywords=s.find(\"meta\",{\"name\":\"keywords\"}) or ''\n",
    "        doi=find_between(s.find(\"meta\",{\"name\":\"pbContext\"})['content']+';','article:article:',';').lower()\n",
    "        url='http://www.tandfonline.com/doi/'+doi\n",
    "        names=[' '.join(name.strip().split()) for name in names]\n",
    "        if keywords is not '':\n",
    "            keywords=keywords['content']\n",
    "        if abstract is not '':\n",
    "            abstract=abstract['content']\n",
    "\n",
    "\n",
    "    if publisher=='wly':\n",
    "        s = bs(html, 'lxml').find('head')\n",
    "        s_body=bs(html, 'lxml').find('body')\n",
    "        year=s.find('meta',{'name':'citation_publication_date'})['content'][:4]\n",
    "        vol= s.find('meta',{'name':'citation_volume'})['content']\n",
    "        iss= s.find('meta',{'name':'citation_issue'})['content']\n",
    "        title=s.find('meta',{'property':'og:title'})['content']\n",
    "        creators=s.findAll('meta',{'name':'citation_author'}); names=[c['content'].strip() for c in creators]\n",
    "        abstract=s_body.find('div',{'class':'article-section__content mainAbstract'}) or ''\n",
    "        keywords_html=s.findAll('meta',{'name':'citation_keywords'})\n",
    "        keywords=', '.join([k['content'] for k in keywords_html])\n",
    "        url=s.find('meta',{'name':'citation_abstract_html_url'})['content']\n",
    "        if abstract is not '':\n",
    "            abstract=abstract.find('p').text\n",
    "\n",
    "    article={\n",
    "        'source'   : journal_name,\n",
    "        'date'     : year,\n",
    "        'volume'   : vol,\n",
    "        'issue'    : iss,\n",
    "        'title'    : title,\n",
    "        'creator'  : names,\n",
    "        'abstract' : abstract,        \n",
    "        'keywords' : keywords,\n",
    "        'doi'      : doi,\n",
    "        'url'      : url        \n",
    "    }\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def src2redif(redif_folder,redif_file):\n",
    "    global article,f\n",
    "    folder=base_folder+\"/htmls\"\n",
    "    files=os.listdir(folder);print len(files)\n",
    "    l=[]\n",
    "    i=0\n",
    "    try:\n",
    "        os.remove(redif_file)\n",
    "    except OSError:\n",
    "        pass\n",
    "    for f in files:\n",
    "        i=i+1\n",
    "        if 'html' in f:\n",
    "            if i % 100 ==0:\n",
    "                print i,\n",
    "            html=open(folder+'/'+f).read()\n",
    "            article=parse(html,publisher,journal_name)\n",
    "            with io.open(redif_file, 'a', encoding=\"utf-8\") as f:\n",
    "                f.write(unicode('Template-Type: ReDIF-Article 1.0\\n'))\n",
    "                f.write(unicode('Title: '+article['title']+'\\n'))\n",
    "                for creator in article['creator']:\n",
    "                    f.write(unicode('Author-Name: '+creator+'\\n'))\n",
    "                f.write(unicode('Abstract: '+article['abstract']+'\\n'))\n",
    "                f.write(unicode('Year: '+str(article['date'])+'\\n'))\n",
    "                f.write(unicode('Volume: '+article['volume']+'\\n'))\n",
    "                f.write(unicode('Issue: '+article['issue']+'\\n'))\n",
    "                f.write(unicode('Keywords: '+article['keywords']+'\\n'))\n",
    "                f.write(unicode('File-url: '+article['url']+'\\n'))\n",
    "                f.write(unicode('Journal: '+article['source']+'\\n'))            \n",
    "                f.write(unicode('DOI: '+article['doi']+'\\n'))            \n",
    "                f.write(unicode('\\n'))            \n",
    "    print\n",
    "    return (redif_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taf jrnmis Journal of Management Information Systems 1346\n",
      "100 200 300 400 500 600 700 800 900 1000 1100 1200 1300\n"
     ]
    }
   ],
   "source": [
    "redif_base_folder='redif/src/'\n",
    "    \n",
    "with open('../OpenScience/subject_journals.json') as data_file:    \n",
    "    subject_journals = json.load(data_file)\n",
    "\n",
    "journals=[]\n",
    "for subject in subject_journals:\n",
    "    journals=journals+(subject['journals'])\n",
    "    \n",
    "for journal in journals:    \n",
    "    jname=journal['jname']\n",
    "    journal_name=journal['journal']\n",
    "    data=journal['data']\n",
    "    for type_pub in data:   \n",
    "        data_type=type_pub['type']\n",
    "        publisher=type_pub['publisher']\n",
    "        if data_type=='parse' and jname=='jrnmis':# and publisher in ['ama','taf','wly','sag']:\n",
    "            redif_folder=redif_base_folder+jname+'/'\n",
    "            if not os.path.exists(redif_folder): os.makedirs(redif_folder)\n",
    "            print publisher,jname,journal_name,\n",
    "            base_folder=data_type+'/'+publisher+'/'+jname\n",
    "            redif_file=redif_folder+(publisher+'.redif').replace('/','_')\n",
    "            #if not os.path.exists(redif_file):\n",
    "            src2redif(redif_folder,redif_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstract': 'More companies have realized that information technology (IT) outsourcing, once viewed as a cost reduction tool, could facilitate and even enable the transformation of their core business processes. The benefits from a potential outsourcing relationship expansion have strategic implications for relational incentive provision. Modeling \"information poaching\" in IT outsourcing as an incentive problem with contractibility constraints, our analysis shows that this problem could be mitigated in a repeated game where the outsourcing client and the service provider agree on a relational contract. When the two partners share the belief that they can potentially benefit from a future relationship expansion, they are more likely to behave cooperatively during the early stages of their relationship. However, when they disagree about the likelihood of the future relationship expansion, they will have different preferences on a set of otherwise equivalent relational bonus contracts. Specifically, they will adopt a rel...',\n",
       " 'creator': ['Xiaotong Li'],\n",
       " 'date': 2014,\n",
       " 'doi': '10.2753/mis0742-1222310211',\n",
       " 'issue': '31',\n",
       " 'keywords': 'contractibility, equilibrium selection, growth options, heterogeneous beliefs, IT outsourcing, outsourcing contracts, relational contracts, repeated games',\n",
       " 'source': u'Journal of Management Information Systems',\n",
       " 'title': 'Relational Contracts, Growth Options, and Heterogeneous Beliefs: A Game-Theoretic Perspective on Information Technology Outsourcing',\n",
       " 'url': 'http://www.tandfonline.com/doi/10.2753/mis0742-1222310211',\n",
       " 'volume': '2'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
