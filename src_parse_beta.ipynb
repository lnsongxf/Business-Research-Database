{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import collections\n",
    "import json\n",
    "import io\n",
    "import fix,parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse(html,publisher):\n",
    "    global s,s_body\n",
    "    if publisher=='sag':\n",
    "        1#article=parser.parse_sag(html)\n",
    "        s = bs(html, 'lxml').find('head')\n",
    "        s_body=bs(html, 'lxml').find('body')\n",
    "        \n",
    "        try:\n",
    "            vol_iss_year=s_body.find('div',{\"class\":\"articleJournalNavTitle\"}).text.replace('\\n','').replace('\\t','')\n",
    "            year=vol_iss_year[-4:]\n",
    "            iss= vol_iss_year.split('Issue ')[1].split(', ')[0]         \n",
    "            vol= vol_iss_year.split('Vol ')[1].split(', ')[0]            \n",
    "        except Exception:\n",
    "            year=s_body.find('div',{\"class\":\"published-dates\"}).text.split('\\n')[1][-4:]\n",
    "            vol='';iss=''\n",
    "            pass\n",
    "        \n",
    "        source= s.find(\"meta\",{\"name\":\"citation_journal_title\"})['content']\n",
    "        title=s.find(\"meta\",{\"name\":\"dc.Title\"})['content']\n",
    "        creators=s.findAll(\"meta\",{\"name\":\"dc.Creator\"});names=[c['content'] for c in creators]         \n",
    "        abstract=s.find(\"meta\",{\"name\":\"dc.Description\"}) or ''\n",
    "        keywords=s.find(\"meta\",{\"name\":\"keywords\"}) or ''\n",
    "        url=s.find(\"meta\",{\"name\":\"dc.Source\"})['content']\n",
    "\n",
    "        \n",
    "        if abstract is not '':\n",
    "            abstract= abstract['content']\n",
    "        if keywords is not '' : \n",
    "            keywords= keywords['content']\n",
    "    \n",
    "    if publisher=='taf':\n",
    "        1#article=parser.parse_sag(html)\n",
    "        s = bs(html, 'lxml').find('head')\n",
    "        source= s.find(\"meta\",{\"name\":\"citation_journal_title\"})['content']\n",
    "        year=s.find(\"meta\",{\"name\":\"og:description\"})['content'][1:5]\n",
    "        vol=s.find(\"meta\",{\"name\":\"pbContext\"})['content'].split('.i')[1].split(';')[0].lstrip('0')\n",
    "        iss=s.find(\"meta\",{\"name\":\"pbContext\"})['content'].split('.v')[1].split('.i')[0].lstrip('0')\n",
    "        title=s.find(\"meta\",{\"name\":\"dc.Title\"})['content']\n",
    "        creators=s.findAll(\"meta\",{\"name\":\"dc.Creator\"});names=[c['content'] for c in creators]\n",
    "        abstract=s.find(\"meta\",{\"name\":\"dc.Description\"}) or ''\n",
    "        keywords=s.find(\"meta\",{\"name\":\"keywords\"}) or ''\n",
    "        url=s.find(\"meta\",{\"name\":\"pbContext\"})['content'].split('article:article:')[1].split(';')[0] or ''\n",
    "        \n",
    "        \n",
    "        names=[' '.join(name.strip().split()) for name in names]\n",
    "        if url is not '':\n",
    "            url='http://www.tandfonline.com/doi/'+url\n",
    "        if keywords is not '':\n",
    "            keywords=keywords['content']\n",
    "        if abstract is not '':\n",
    "            abstract=abstract['content']\n",
    "\n",
    "\n",
    "    if publisher=='wly':\n",
    "        #article=parser.parse_wly(html)\n",
    "        s = bs(html, 'lxml').find('head')\n",
    "        s_body=bs(html, 'lxml').find('body')\n",
    "        source=s.find('meta',{'name':'citation_journal_title'})['content']\n",
    "        year=s.find('meta',{'name':'citation_publication_date'})['content'][:4]\n",
    "        vol= s.find('meta',{'name':'citation_volume'})['content']\n",
    "        iss= s.find('meta',{'name':'citation_issue'})['content']\n",
    "        title=s.find('meta',{'property':'og:title'})['content']\n",
    "        creators=s.findAll('meta',{'name':'citation_author'}); names=[c['content'] for c in creators]\n",
    "        abstract=s_body.find('div',{'class':'article-section__content mainAbstract'}) or ''\n",
    "        keywords_html=s.findAll('meta',{'name':'citation_keywords'}); keywords=', '.join([k['content'] for k in keywords_html])\n",
    "        url=s.find('meta',{'name':'citation_abstract_html_url'})['content']\n",
    "\n",
    "        if abstract is not '':\n",
    "            abstract=abstract.find('p').text\n",
    "\n",
    "    article={\n",
    "        'source'   : source,\n",
    "        'date'     : year,\n",
    "        'volume'   : vol,\n",
    "        'issue'    : iss,\n",
    "        'title'    : title,\n",
    "        'creator'  : names,\n",
    "        'abstract' : abstract,        \n",
    "        'keyword'  : keywords,\n",
    "        'url'      : url        \n",
    "    }\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def src2jsonld(publisher, journal_name,base_folder,redif_folder):\n",
    "    global article,e,f\n",
    "    folder=base_folder+\"/htmls\"\n",
    "    files=os.listdir(folder);print len(files)\n",
    "    l=[]\n",
    "    i=0\n",
    "    jsonld_file=redif_folder+(base_folder+'.redif').replace('/','_')\n",
    "\n",
    "    try:\n",
    "        os.remove(jsonld_file)\n",
    "    except OSError:\n",
    "        pass\n",
    "    for f in files:\n",
    "        i=i+1\n",
    "        if 'html' in f:\n",
    "            if i % 10 ==0:\n",
    "                print i,\n",
    "            html=open(folder+'/'+f).read()\n",
    "            article=parse(html,publisher)\n",
    "            with io.open(jsonld_file, 'a', encoding=\"utf-8\") as f:\n",
    "                f.write(unicode('Template-Type: ReDIF-Article 1.0\\n'))\n",
    "                f.write(unicode('Title: '+article['title']+'\\n'))\n",
    "                for creator in article['creator']:\n",
    "                    f.write(unicode('Author-Name: '+creator+'\\n'))\n",
    "                f.write(unicode('Abstract: '+article['abstract']+'\\n'))\n",
    "                f.write(unicode('Year: '+article['date']+'\\n'))\n",
    "                f.write(unicode('Volume: '+article['volume']+'\\n'))\n",
    "                f.write(unicode('Issue: '+article['issue']+'\\n'))\n",
    "                f.write(unicode('Keyword: '+article['keyword']+'\\n'))\n",
    "                f.write(unicode('File-url: '+article['url']+'\\n'))\n",
    "                f.write(unicode('Journal: '+article['source']+'\\n'))            \n",
    "                f.write(unicode('\\n'))            \n",
    "    return (jsonld_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wly popmgt Production and Operations Management 1538\n",
      "10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 510 520 530 540 550 560 570 580 590 600 610 620 630 640 650 660 670 680 690 700 710 720 730 740 750 760 770 780 790 800 810 820 830 840 850 860 870 880 890 900 910 920 930 940 950 960 970 980 990 1000 1010 1020 1030 1040 1050 1060"
     ]
    }
   ],
   "source": [
    "with open('journals.json') as data_file:    \n",
    "    journals = json.load(data_file)\n",
    "\n",
    "redif_folder='redif/src/parsed/'\n",
    "\n",
    "for journal in journals:\n",
    "    source=journal['jname']\n",
    "    journal_name=journal['journal']\n",
    "    data=journal['data']\n",
    "    for type_pub in data:   \n",
    "        file_type=type_pub['type']\n",
    "        publisher=type_pub['publisher']\n",
    "        if file_type=='src' and publisher in ['taf','wly','sag'][1:3]:\n",
    "            e=0\n",
    "            print publisher,source,journal_name,\n",
    "            base_folder=file_type+'/'+publisher+'/'+source\n",
    "            src2jsonld(publisher,journal_name,base_folder,redif_folder)\n",
    "            print 'fixed= ',e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
